[
  {
    "session": "Well-being and Tracking",
    "abstract": "Personalized behavior change interventions can be effective as they dynamically adapt to an individual’s context. Financial incentives, a commonly used intervention in commercial applications and policy-making, offer a mechanism for creating personalized micro-interventions that are both quantifiable and amenable to systematic evaluation. However, the effectiveness of such personalized micro-financial incentives in real-world settings remains largely unexplored. In this study, we propose a personalization strategy that dynamically adjusts the amount of micro-financial incentives to promote smartphone use regulation and explore its efficacy and user experience through a four-week, in-the-wild user study. The results demonstrate that the proposed method is highly cost-effective without compromising intervention effectiveness. Based on these findings, we discuss the role of micro-financial incentives in enhancing awareness, design considerations for personalized micro-financial incentive systems, and their potential benefits and limitations concerning motivation change.",
    "title": "Like Adding a Small Weight to a Scale About to Tip: Personalizing Micro-Financial Incentives for Digital Wellbeing",
    "id": 188208,
    "sequence": 0,
    "queryCoordinates": {
      "visualization": [
        -12.789602465311388,
        -7.837478470739225
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "Chatbots are increasingly used to provide social support for individuals with mental health challenges. However, a systematic analysis of the types and directionality of support within chatbot use remains lacking. This study establishes a framework for understanding reciprocal social support exchanges in human-chatbot relationships, focusing on the popular chatbot, Replika. By analyzing 496 posts and 20,494 comments from the largest Replika community on Reddit, we identified 27 support subcategories, organized into five main types (functional, informational, emotional, esteem, and network) and two directions (chatbot-receiving and chatbot-giving). Our findings reveal significant yet controversial issues, such as subscription services and chatbot-displayed affection. Notably, \"user teaching chatbot\" emerged as a core aspect of the human-chatbot relationship, covering how users actively guide and refine the chatbot’s learning or algorithm. This study constructs a novel social support framework for chatbot use, highlighting the potential for reciprocal support exchanges between users and chatbots.",
    "title": "Developing a Social Support Framework: Understanding the Reciprocity in Human-Chatbot Relationship",
    "id": 188209,
    "sequence": 1,
    "queryCoordinates": {
      "visualization": [
        0.39259815759068645,
        -9.992290362407228
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "Measuring preverbal vocabulary comprehension of young children is vital for early intervention and developmental evaluation, yet challenging due to their limited communication abilities. We introduce Lookee, an AI-powered vocabulary comprehension assessment tool through gaze tracking for toddlers in the preverbal stage. Lookee incorporates the Intermodal Preferential Looking Paradigm (IPLP), which is one of the prominent word comprehension measures for toddlers and estimates word comprehension through a random forest model analysis. We design and validate Lookee through user studies involving 19 toddlers and their parents. Then we identify necessary design requirements from potential stakeholders' perspectives through in-depth interviews including researchers, clinicians, and parents. As a result, Lookee achieves considerable estimation accuracy with sufficient system usability, and demonstrates key design requirements for each stakeholder group. From our study, we highlight necessary design implications in developing and validating AI-powered clinical tools for toddlers.",
    "title": "Lookee: Gaze Tracking-based Infant Vocabulary Comprehension Assessment and Analysis",
    "id": 188210,
    "sequence": 2,
    "queryCoordinates": {
      "visualization": [
        17.83918928399116,
        -6.539367376890135
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "Inspirational search, the process of exploring designs to inform and inspire new creative work, is pivotal in mobile user interface (UI) design. However, exploring the vast space of UI references remains a challenge. Existing AI-based UI search methods often miss crucial semantics like target users or the mood of apps. Additionally, these models typically require metadata like view hierarchies, limiting their practical use. We used a multimodal large language model (MLLM) to extract and interpret semantics from mobile UI images. We identified key UI semantics through a formative study and developed a semantic-based UI search system. Through computational and human evaluations, we demonstrate that our approach significantly outperforms existing UI retrieval methods, offering UI designers a more enriched and contextually relevant search experience. We enhance the understanding of mobile UI design semantics and highlight MLLMs' potential in inspirational search, providing a rich dataset of UI semantics for future studies.",
    "title": "Leveraging Multimodal LLM for Inspirational User Interface Search",
    "id": 188211,
    "sequence": 3,
    "queryCoordinates": {
      "visualization": [
        -3.2472402416509176,
        3.8020298280001548
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "People with disabilities that affect their speech may use speech-generating devices (SGD), commonly referred to as Augmentative and Alternative Communication (AAC) technology. This technology enables practical conversation; however, delivering expressive and timely comments remains challenging. This paper explores how to extend AAC technology to support a subset of humorous expressions: delivering timely humorous comments -witty remarks- through AI-powered interfaces. To understand the role of humor in AAC and the challenges and experiences of delivering humor with AAC, we conducted seven qualitative interviews with AAC users. Based on these insights and the lead author's firsthand experience as an AAC user, we designed four AI-powered interfaces to assist in delivering well-timed humorous comments during ongoing conversations.\r\nOur user study with five AAC users found that when timing is critical (e.g., delivering a humorous comment), AAC users are willing to trade agency for efficiency—contrasting prior research where they hesitated to delegate decision-making to AI.  We conclude by discussing the trade-off between agency and efficiency in AI-powered interfaces, how AI can shape user intentions, and offer design recommendations for AI-powered AAC interfaces.\r\nSee our project and demo at: https://tobiwg.github.io/research/why_so_serious",
    "title": "Why So Serious? Exploring Timely Humorous Comments in AAC Through AI-Powered Interfaces",
    "id": 188212,
    "sequence": 4,
    "queryCoordinates": {
      "visualization": [
        0.39266793062210087,
        17.995716487438365
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "Parents of children in speech therapy play a crucial role in delivering consistent, high-quality home practice, which is essential for helping children generalize new speech skills to everyday situations. However, this responsibility is often complicated by uncertainties in implementing therapy techniques and keeping children engaged. In this study, we explore how varying levels of AI oversight can provide informational, emotional, and practical support to parents during home speech therapy practice. Through semi-structured interviews with 20 parents, we identified key challenges they face and their ideas for AI assistance. Using these insights, we developed six design concepts, which were then evaluated by 20 Speech-Language Pathologists (SLPs) for their potential impact, usability, and alignment with therapy goals. Our findings contribute to the discourse on AI’s role in supporting therapeutic practices, offering design considerations that address the needs and values of both families and professionals. ",
    "title": "``I want to think like an SLP'': A Design Exploration of AI-Supported Home Practice in Speech Therapy",
    "id": 188213,
    "sequence": 5,
    "queryCoordinates": {
      "visualization": [
        6.273549006284605,
        9.035628526325407
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "As tools for designing and manufacturing hardware become more accessible, smaller producers can develop and distribute novel hardware. However, processes for supporting end-user hardware troubleshooting or routine maintenance aren't well defined. As a result, providing technical support for hardware remains ad-hoc and challenging to scale. Inspired by patterns that helped scale software troubleshooting, we propose a workflow for asynchronous hardware troubleshooting: SplatOverflow. \r\n\r\nSplatOverflow creates a novel boundary object, the SplatOverflow scene, that users reference to communicate about hardware. A scene comprises a 3D Gaussian Splat of the user's hardware registered onto the hardware’s CAD model. The splat captures the current state of the hardware, and the registered CAD model acts as a referential anchor for troubleshooting instructions. With SplatOverflow, remote maintainers can directly address issues and author instructions in the user’s workspace. Workflows containing multiple instructions can easily be shared between users and recontextualized in new environments. \r\n\r\nIn this paper, we describe the design of SplatOverflow, the workflows it enables, and its utility to different kinds of users. We also validate that non-experts can use SplatOverflow to troubleshoot common problems with a 3D printer in a usability study. \r\n\r\nProject Page: https://amritkwatra.com/research/splatoverflow.",
    "title": "SplatOverflow: Asynchronous Hardware Troubleshooting",
    "id": 188214,
    "sequence": 6,
    "queryCoordinates": {
      "visualization": [
        15.388741450057195,
        7.224031878618172
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "We explore how interactions inspired by drawing software can help edit text. Making an analogy between visual and text editing, we consider words as pixels, sentences as regions, and tones as colours. For instance, direct manipulations move, shorten, expand, and reorder text; tools change number, tense, and grammar; colours map to tones explored along three dimensions in a tone picker; and layers help organize and version text. This analogy also leads to new workflows, such as boolean operations on text fragments to construct more elaborated text. A study shows participants were more successful at editing text and preferred using the proposed interface over existing solutions. Broadly, our work highlights the potential of interaction analogies to rethink existing workflows, while capitalizing on familiar features.",
    "title": "Textoshop: Interactions Inspired by Drawing Software to Facilitate Text Editing",
    "id": 188215,
    "sequence": 7,
    "queryCoordinates": {
      "visualization": [
        8.322766926012346,
        9.986568514523647
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "Text entry is a fundamental and ubiquitous task, but users often face challenges such as situational impairments or difficulties in sentence formulation. Motivated by this, we explore the potential of large language models (LLMs) to assist with text entry in real-world contexts. We propose a collaborative smartphone-based text entry system, CATIA, that leverages LLMs to provide text suggestions based on contextual factors, including screen content, time, location, activity, and more. In a 7-day in-the-wild study with 36 participants, the system offered appropriate text suggestions in over 80% of cases. Users exhibited different collaborative behaviors depending on whether they were composing text for interpersonal communication or information services. Additionally, the relevance of contextual factors beyond screen content varied across scenarios. We identified two distinct mental models: AI as a supportive facilitator or as a more equal collaborator. These findings outline the design space for human-AI collaborative text entry on smartphones.",
    "title": "Investigating Context-Aware Collaborative Text Entry on Smartphones using Large Language Models",
    "id": 188216,
    "sequence": 8,
    "queryCoordinates": {
      "visualization": [
        10.32531863540631,
        10.880615565184312
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "Modern web applications use features like camera and geolocation for personalized experiences, requiring user permission via browser prompts. To explain these requests, applications provide rationales—contextual information on why permissions are needed. Despite their importance, little is known about how often rationales appear on the web or their influence on user decisions.\r\n\r\nThis paper presents the first large-scale study of how the web ecosystem handles permission rationales, covering three areas: (i) identifying webpages that use permissions, (ii) detecting and classifying permission rationales, and (iii) analyzing their attributes to understand their impact on user decisions. We examined over 770K webpages from Chrome telemetry, finding 3.6K unique rationale texts and 749 rationale UIs across 85K pages. We extracted key rationale attributes and assessed their effect on user behavior by cross-referencing them with Chrome telemetry data. Our findings reveal nine key insights, providing the first evidence of how different rationales affect user decisions.\r\n",
    "title": "Permission Rationales in the Web Ecosystem: An Exploration of Rationale Text and Design Patterns",
    "id": 188217,
    "sequence": 9,
    "queryCoordinates": {
      "visualization": [
        12.29526371308519,
        11.739952735240912
      ]
    }
  },
  {
    "session": "WS11: Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "abstract": "As Artificial Intelligence (AI) becomes more deeply embedded in educational settings, it is crucial to explore how it can enhance—rather than replace—the role of educators. This workshop focuses on advancing AI-driven tools that support personalized learning and designing AI systems capable of understanding students' emotional and cognitive needs. The workshop will explore two main themes: (1) empowering teachers with AI technologies for delivering customized feedback and individualized instruction, and (2) examining ethical and practical considerations for developing empathetic AI that complements the human aspects of teaching. Participants will discuss opportunities and challenges in building effective AI-augmented learning environments, considering ethical concerns such as privacy, equity, and the maintenance of human agency. The workshop aims to unite educators, researchers, and technologists in developing innovative solutions and fostering interdisciplinary dialogue. Key outcomes include establishing best practices for AI integration in education and disseminating research findings that shape the future of human-AI collaboration in teaching.",
    "title": "Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "id": 188218,
    "sequence": 10,
    "queryCoordinates": {
      "visualization": [
        -4.282572564300318,
        18.511066210013464
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "Landmarks are critical in navigation, supporting self-orientation and mental model development. Similar to sighted people, people with low vision (PLV) frequently look for landmarks via visual cues but face difficulties identifying some important landmarks due to vision loss. We first conducted a formative study with six PLV to characterize their challenges and strategies in landmark selection, identifying their unique landmark categories (e.g., area silhouettes, accessibility-related objects) and preferred landmark augmentations. We then designed VisiMark, an AR interface that supports landmark perception for PLV by providing both overviews of space structures and in-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found that VisiMark enabled PLV to perceive landmarks they preferred but could not easily perceive before, and changed PLV's landmark selection from only visually-salient objects to cognitive landmarks that are more important and meaningful. We further derive design considerations for AR-based landmark augmentation systems for PLV.",
    "title": "VisiMark: Characterizing and Augmenting Landmarks for People with Low Vision in Augmented Reality to Support Indoor Navigation",
    "id": 188219,
    "sequence": 11,
    "queryCoordinates": {
      "visualization": [
        3.4909142771668855,
        -12.522520413617716
      ]
    }
  },
  {
    "session": "3D Design and Fabrication",
    "abstract": "When designing 3D objects in 3D virtual environments using naturalistic 3D user interfaces, people use their hands to manipulate the environment and objects inside it. At the same time, people utilize their spatial thinking to understand the spatial relationship of the objects in the scene. Yet, the relationship between spatial thinking and hand actions remains unclear. Here, we present a user study with 18 participants that examines the association between 3D assembling tasks and reflective hand movements that allow people to enhance their spatial thinking. Utilizing a mixed-methods protocol, we identified nine SPATIAL HAND ACTIONS and three SPATIAL THEMES people use when designing 3D objects. Then, we analyzed a subset of the participants to understand the relationship between SPATIAL HAND ACTIONS and spatial abilities. Our results will help develop better hand-based naturalistic 3DUI that considers the spatial thinking abilities of the users.",
    "title": "Spatial Hand Actions: Exploring the Hand Actions used to Represent Spatial Thinking for 3D Assembling Tasks",
    "id": 188220,
    "sequence": 12,
    "queryCoordinates": {
      "visualization": [
        13.517657043995314,
        8.559961918193554
      ]
    }
  },
  {
    "session": "Data Interpretation and Storytelling",
    "abstract": "Synchronous data-driven storytelling with network visualizations presents significant challenges due to the complexity of real-time manipulation of network components. While existing research addresses asynchronous scenarios, there is a lack of effective tools for live presentations. To address this gap, we developed TangibleNet, a projector-based AR prototype that allows presenters to interact with node-link diagrams using double-sided magnets during live presentations. The design process was informed by interviews with professionals experienced in synchronous data storytelling and workshops with 14 HCI/VIS researchers. Insights from the interviews helped identify key design considerations for integrating physical objects as interactive tools in presentation contexts. The workshops contributed to the development of a design space mapping user actions to interaction commands for node-link diagrams. Evaluation with 12 participants confirmed that TangibleNet supports intuitive interactions and enhances presenter autonomy, demonstrating its effectiveness for synchronous network-based data storytelling.",
    "title": "TangibleNet: Synchronous Network Data Storytelling through Tangible Interactions in Augmented Reality",
    "id": 188221,
    "sequence": 13,
    "queryCoordinates": {
      "visualization": [
        1.9606357775119636,
        20.90827365776381
      ]
    }
  },
  {
    "session": "Auditory UI",
    "abstract": "Circadian fatigue, largely caused by sleep deprivation, significantly diminishes alertness and situational awareness. This issue becomes critical in environments where auditory awareness—such as responding to verbal instructions or localizing alarms—is essential for performance and safety. While head-mounted displays have demonstrated potential in enhancing situational awareness through visual cues, their effectiveness in supporting sound localization under the influence of circadian fatigue remains under-explored. This study addresses this knowledge gap through a longitudinal study (N=19) conducted over 2–4 months, tracking participants’ fatigue levels through daily assessments. Participants were called in to perform non-line-of-sight sound source identification and localization tasks in a virtual environment under high- and low-fatigue conditions, both with and without head-up display assistance. The results show task-dependent effects of circadian fatigue. Unexpectedly, reaction times were shorter across all tasks under high-fatigue conditions. Yet, in sound localization, where precision is key, the HUD offered the greatest performance enhancement by reducing pointing error. The results suggest the auditory channel is a robust means of enhancing situational awareness and providing support for incorporating spatial audio cues and HUD as standard features in augmented reality platforms for fatigue-prone scenarios.\r\n",
    "title": "A Longitudinal Study on the Effects of Circadian Fatigue on Sound Source Identification and Localization using a Heads-Up Display",
    "id": 188222,
    "sequence": 14,
    "queryCoordinates": {
      "visualization": [
        -8.728184813466843,
        -17.994965681044427
      ]
    }
  },
  {
    "session": "Personal Data and Decision-Making",
    "abstract": "This paper explores pair collaboration as a novel approach for making sense of personal data. Pair collaboration---characterized by dyadic comparison and structured roles for questioning and reasoning---has proven effective for co-constructing knowledge. However, current collaborative visualization tools primarily focus on group comparisons, overlooking the challenges of accommodating pair collaboration in the context of personal data. To address this gap, we propose a set of design rationales supporting subjective data analysis through dyadic comparison and mixed-focus collaboration styles for co-constructing personal narratives. We operationalize these principles in a tangible visualization toolkit, \\projectname. Our user study demonstrates that pairwise collaboration facilitated by the toolkit: 1) reveals detailed data insights that are effective for recalling personal experiences, and 2) fosters a structured, reciprocal sensemaking process for interpreting and reconstructing personal experiences beyond data insights. Our results shed light on the design rationales for, and the processes of pair sensemaking of personal data, and their effects to foster deep levels of reflection. ",
    "title": "PAIRcolator: Pair Collaboration for Sensemaking and Reflection on Personal Data",
    "id": 188223,
    "sequence": 15,
    "queryCoordinates": {
      "visualization": [
        -4.251474431534605,
        13.338851718120548
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": " Existing ethics frameworks for participatory engagement in HCI often overlook the nuanced ethical challenges of dynamic community-based contexts given the latter’s relational nature. We hope to bridge this gap by grounding feminist care ethics in actionable tools for community-based projects to enhance ethical engagement in these settings. Prior research advocates for adaptable, context-sensitive ethics in participatory research, informed by feminist care ethics. To address this need, we developed and iteratively refined a toolkit embodying the underlying principles of feminist care ethics through workshops with participants working in academic and non-academic community-based settings. Our findings suggest that the toolkit fosters ethical reflection aligned with the feminist care ethics ethos while facilitating meaningful experiences for participants. This work contributes to the field by offering a practical design artefact that not only embodies feminist care ethics but also supports researchers and communities in navigating complex ethical landscapes in participatory engagements, together or independently.",
    "title": "A Feminist Care Ethics Toolkit for Community-Based Design: Bridging Theory and Practice",
    "id": 188224,
    "sequence": 16,
    "queryCoordinates": {
      "visualization": [
        -15.76444227822306,
        2.7353902201648195
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "Divergent thinking activities, like research and ideation, are key drivers of innovation in UI/UX design. Existing research has explored AI's role in automating design tasks, but leaves a critical gap in understanding how AI specifically influences divergent thinking. To address this, we conducted interviews with 19 professional UI/UX designers, examining their use and perception of AI in these creative activities. We found that in this context, participants valued AI tools that offer greater control over ideation, facilitate collaboration, enhance efficiency to liberate creativity, and align with their visual habits. Our results indicated four key roles AI plays in supporting divergent thinking: aiding research, kick-starting creativity, generating design alternatives, and facilitating prototype exploration. Through this study, we provide insights into the evolving role of AI in the less-investigated area of divergent thinking in UI/UX design, offering recommendations for future AI tools that better support design innovation.",
    "title": "Beyond Automation: How Designers Perceive AI as a Creative Partner in the Divergent Thinking Stages of UI/UX Design",
    "id": 188225,
    "sequence": 17,
    "queryCoordinates": {
      "visualization": [
        -8.728184813466838,
        17.99496568104443
      ]
    }
  },
  {
    "session": "Online Media and Community",
    "abstract": "Social media are widely used for online political discourse. Opinions shared on social media have different sentiments associated with them. Given the very high adoption rates of X (formerly known as Twitter) among adults, those who share their opinions on X not only represent a sizable segment of the society, but also influence (through emotion contagion) an even larger segment who are passive (non-contributing) users of the platform. Furthermore, the discourse that is initiated on X typically spreads to other more traditional media. As a result, X is influential, which makes it useful to understand the factors related to the sentiments expressed in tweets. Such understanding can help policymakers to take actions that align with public needs and priorities. This research focuses on identifying the drivers (keywords) of sentiments associated with political discourse on X. We also explore virality, i.e., how much a message (the tweet) spreads, and the relationship between sentiments and virality. Finally, we explore whether the clustering of tweets among sentiment and virality groups can improve the potential of social media content for predicting election results. Sentiment Analysis of 764,000 tweets related to the 2021 Canadian Federal election was followed by text clustering to identify sentiment-driving topics. We found some keywords predominantly present within a positive or negative sentiment that are suggestive of entities or ideas to invest in or mitigate by political decision makers. We were also able to find partial evidence for “negativity bias” by detecting a negative relationship between sentiment (positivity) and virality (number of retweets). Finally, we demonstrated that high positivity on the political discourse does not reflect election outcomes and examining X content in more neutral groups can improve predictive power. Our findings have implications for political decision makers and social media analytics researchers.",
    "title": "Social Media, Sentiments and Political Discourse – An Exploratory Study of the 2021 Canadian Federal Election",
    "id": 188226,
    "sequence": 18,
    "queryCoordinates": {
      "visualization": [
        18.89612092933756,
        -6.5526035912338765
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60).  We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools.",
    "title": "SocialEyes: Scaling Mobile Eye-tracking to Multi-person Social Settings",
    "id": 188227,
    "sequence": 19,
    "queryCoordinates": {
      "visualization": [
        -12.058376795253722,
        7.113054833451416
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "Although HCI researchers often generate and compare new design concepts, they lack an established method for rigorously conducting qualitative assessments.We define and characterize Comparative Structured Observation as a qualitative research method that takes advantage of the structure of controlled experiments to generate comparable, ecologically relevant experiences with two or more design variants, often implemented as medium-fidelity prototypes. Researchers observe users and ask them to compare and reflect on each variant.We identify criteria for creating a successful Comparative Structured Observation study and illustrate variations of the method by analyzing four published studies. We also examine six additional studies (three “near” and three “far”) to clarify the boundary between what should and should not be considered a Comparative Structured Observation. We discuss the benefits and limitations of the method and argue that gathering comparative reflections about design variants can help researchers assess and advance their design concepts.",
    "title": "Comparative Structured Observation",
    "id": 188228,
    "sequence": 20,
    "queryCoordinates": {
      "visualization": [
        5.884711682419383,
        1.1705419320967696
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "Our (Western) culture is one of sex exceptionalism---sex is constructed as dangerous and taboo on the one hand, and as compulsory and irresistible on the other. This portrayal of sex taints technology design and HCI research in ways that disproportionately harm marginalized groups. But what if we approached sex as simply a lens like any other? Building on previous HCI explorations in this space, we propose sex as a method for critical inquiry, and a means to highlight marginalized knowledges. To delve into the sexistemological potentials of this approach, we conducted two design projects. Based on our insights, we discuss how sex as method could look like, how it can facilitate novel insights about intersecting areas of life, and what ethical considerations this method entails.",
    "title": "Sexy and We Know It: Exploring Sexistemologies for HCI",
    "id": 188229,
    "sequence": 21,
    "queryCoordinates": {
      "visualization": [
        10.916953881956168,
        -7.05833676861923
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "Despite the spread of technologies in the physical world and the normalization of virtual experiences, non-verbal communication with radically non-anthropomorphic avatars remains an underexplored frontier. We present an interaction system in which two participants must learn to communicate with each other non-verbally through a digital filter that morphs their appearance. In a collaborative escape room, the Visitor must teach a non-anthropomorphic physical robot to play, while the Controller, in a different location, embodies the robot with an altered perception of the environment and the Visitor’s companion in VR. This study addresses the design of the activity, the robot, and the virtual environment, with a focus on how the Visitor’s morphology is translated in VR. Results show that participants were able to develop emergent and effective communication strategies, with the Controller naturally embodying its avatar’s narrative, making this system a promising testbed for future research on human-technology interaction, entertainment, and embodiment.",
    "title": "From Alien to Ally: Exploring Non-Verbal Communication with Non-Anthropomorphic Avatars in a Collaborative Escape-Room",
    "id": 188230,
    "sequence": 22,
    "queryCoordinates": {
      "visualization": [
        -17.96146061829486,
        1.1772563261425761
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Short-form video platforms like YouTube Shorts captivate users with engaging content, but their potential for promoting incidental learning remains underexplored. We present Curious Shorts, a conceptual framework that extends the Hook Model, designed to enhance curiosity-driven exploration and incidental learning on these platforms. In Study 1, we empirically tested two designs that incorporate \"curiosity nudges\" — interactive prompts that spark curiosity and encourage further exploration — with follow-up videos to satisfy that curiosity. Results show that specific, question-driven prompts proved most effective, significantly boosting curiosity and encouraging more focused and intentional viewing compared to the baseline. Study 2 examined whether this design enhances incidental learning without compromising engagement. Findings confirmed improved learning outcomes. However, when applied to a realistic viewing environment interspersed with entertainment videos, engagement remained high while learning benefits diminished. We conclude with implications for balancing learning and engagement on short-form video platforms and propose directions for future research.",
    "title": "Curious Shorts: Curiosity-Driven Exploration and Learning on Short-Form Video Platforms",
    "id": 188231,
    "sequence": 23,
    "queryCoordinates": {
      "visualization": [
        -9.986568514523649,
        -8.322766926012342
      ]
    }
  },
  {
    "session": "XR Interaction",
    "abstract": "Many companies are experimenting with, and developing, advertisements for virtual reality (VR) consumer applications. So far, the development of VR advertising has not accounted for the voices of VR users. Since VR users will be the ones impacted by VR advertising, it is both a requirement and a moral imperative to center their voices in the discussion. We interviewed 22 VR users (14 of which had experienced VR ads, 8 of which had not) to understand their experiences with, and attitudes towards, VR advertising. Many participants had already encountered VR advertisements, ranging from static billboards in virtual worlds to virtual markets. While some participants acknowledged that VR advertising could provide benefits (including monetizing the VR ecosystem and more informative advertising), many were concerned about in-app VR advertisements ruining the immersion of VR experiences, unavoidable ads that were forced on users, privacy risks, physical harms, and manipulation. We conclude by discussing avenues for designing VR advertisements that align with users' needs and wants.",
    "title": "Intriguing, Concerning, and Questioning the Impact on Immersion: An Exploration of VR Users' Advertising Experiences and Attitudes",
    "id": 188232,
    "sequence": 24,
    "queryCoordinates": {
      "visualization": [
        -1.9134171618254485,
        4.619397662556434
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "We hypothesize that online movement videos have untapped potential for teaching physical skills, and we developed a platform that automatically generates practice plans from raw TikTok dance videos. The practice plans teach one segment at a time using fading guidance and part-learning principles and are presented using a web-based interface featuring concurrent visual aids. Two user studies (n=54, n=38) were conducted.  The first showed significant improvements in learning outcomes compared to standard tutorials, underscoring the importance of well-structured practice plans and offering nuanced insights into the design and effectiveness of visual aids. The second study found that segmentation and emoji-based dual-coding only benefit learning when integrated into a well-designed lesson structure. We provide a set of practical recommendations for enhancing online movement learning, focusing on the need for substantive part-learning activities and careful use of visual aids to prevent cognitive overload.",
    "title": "Enhancing the Educational Potential of Online Movement Videos: System Development and Empirical Studies with TikTok Dance Challenges",
    "id": 188233,
    "sequence": 25,
    "queryCoordinates": {
      "visualization": [
        -18.323759142342716,
        8.014976662062823
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "Tactile graphics communicate images and spatial information to blind and low vision (BLV) audiences via touch. However, designing and producing tactile graphics is laborious and often inaccessible to BLV people themselves. We interviewed 14 BLV adults with experience both using and creating tactile graphics to understand their current and desired practices. We found that tactile graphics are intensely valued by many, but that access to and fluency with tactile graphics are compounding challenges. To produce tactile graphics, BLV makers constantly navigate tradeoffs between accessible, low-fidelity craft materials and less accessible, high-fidelity equipment. Going forward, we argue that tactile graphics design and production should be made widely accessible and that tactile graphics themselves should be designed to be expressive and ubiquitous. Drawing from these design goals, we propose specific future tools with features for inclusive designing, sharing, and (re)production of tactile graphics.",
    "title": "\"What Would I Want to Make? Probably Everything\": Practices and Speculations of Blind and Low Vision Tactile Graphics Creators",
    "id": 188234,
    "sequence": 26,
    "queryCoordinates": {
      "visualization": [
        9.035628526325407,
        6.273549006284604
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Hybrid meetings have become common practice in collaborative work environments. \r\nHowever, they are constrained by the fixed spatial configurations of videoconferencing technology. \r\nThis limits opportunities for mobile and spontaneous interactions; qualities that are critical to successful collaboration.\r\nIn this paper, we explore the concept of radically mobile hybrid meetings. \r\nOur work investigates the design space of multimodal devices as mobile alternatives to traditional videoconferencing.\r\nWe conducted three group co-design sessions, where participants prototyped mobile hybrid meeting technologies to explore how such meetings could be supported. From these workshops, we derive design fictions envisioning future uses of these technologies, which we evaluate with a questionnaire to spark reflections on future mobile hybrid collaboration tools and practices. We contribute an initial exploration of the design space for radically mobile hybrid meetings, laying the groundwork for developing tools that enable spontaneous, effective, and inclusive collaboration in hybrid mobile settings.",
    "title": "Co-Designing Multimodal Tools for Radically Mobile Hybrid Meetings",
    "id": 188235,
    "sequence": 27,
    "queryCoordinates": {
      "visualization": [
        0.3924931306603429,
        6.988987705124716
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": "Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration.",
    "title": "Ethical Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators",
    "id": 188236,
    "sequence": 28,
    "queryCoordinates": {
      "visualization": [
        -5.805693545089249,
        -19.138806714644176
      ]
    }
  },
  {
    "session": "Storytelling and Sense-Making",
    "abstract": "Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.",
    "title": "Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs",
    "id": 188237,
    "sequence": 29,
    "queryCoordinates": {
      "visualization": [
        9.494867045611207,
        -19.845591444604676
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "Despite HCI research emphasizing the direct involvement of racial minorities in technology design, Black patients have been notably excluded when designing virtual patients intended to represent them in healthcare training applications. To address this gap, this paper describes an iterative user-centered design process to create a virtual patient prototype (EQUITY) that authentically reflects real-world racially biased encounters using narratives of Black patients’ lived experiences. EQUITY was developed using insights gathered from 6 focus groups with 33 Black patients (Study 1). EQUITY was evaluated with 25 doctors to assess its effectiveness in inducing disorienting experiences and facilitating self-reflection (Study 2). Findings suggest that incorporating patient narratives, particularly through virtual patients' verbal and non-verbal behaviors and role-playing, significantly enhanced virtual patient’s authenticity and meaningful self-reflection among doctors. Our research contributes to HCI by identifying key virtual patient interface design features that align with Black patients' lived experiences of racially biased encounters.",
    "title": "“My doctor didn't give me half of that privilege”: Incorporating Black Patients’ Lived Experiences in Virtual Patients for Racial Bias Mitigation Training",
    "id": 188238,
    "sequence": 30,
    "queryCoordinates": {
      "visualization": [
        1.9509032201612742,
        -9.807852804032306
      ]
    }
  },
  {
    "session": "Online Media, Robots, Agents",
    "abstract": "Between 2012 and 2014, Weibo used a novel crowdsourced user `committee' system to make content moderation decisions. In it, user volunteers were randomly assigned to jury-like committees to vote and comment on whether reported content violated platform rules. The perceived legitimacy of similar systems has been studied in tightly controlled lab and survey experiments, but the causal effects of such jury-like moderation systems on user behavior in the real world have not been studied to the same extent. Leveraging random variation in Weibo case votes due to the assignment of more or less lenient `jurors', we show that, on average, social sanctioning and norm-setting through committee votes was associated with a large but brief decline in reported users' future posting of offensive terms. However, in line with prior work on the relative ineffectiveness of out-group sanctioning, we observe no such effect among women sanctioned by the largely male committees.This study advances our understanding of the effects of institutionalized social sanctioning on social media user behavior, and the promises and potential shortcomings of crowdsourced moderation systems.",
    "title": "The Effects and Non-Effects of Social Sanctions from User Jury-Based Content Moderation Decisions on Weibo",
    "id": 188239,
    "sequence": 31,
    "queryCoordinates": {
      "visualization": [
        20.38252791652121,
        5.054953583588434
      ]
    }
  },
  {
    "session": "Input and Modeling",
    "abstract": "In-air hand interactions are prevalent in Virtual Reality (VR), and prior studies have shown that manipulating the visual movement of the hand to be different from the actual hand movement, i.e., hand redirection, could create a more immersive and engaging VR experience. However, this manipulation risks degrading task performance and, if maliciously applied, poses a threat to user safety. Such manipulations may arise from VR applications developed with intentional or inadvertent perceptual manipulations that yield harmful outcomes. We advocate for a user's prerogative to be informed of any such potential manipulations before application usage. To address this, our study introduces an \\textit{Autoencoder}-based anomaly detection technique that leverages users' inherent hand movements to identify hand redirection, thereby preserving the integrity of application use. Our model is trained on regular (i.e., non-manipulated) hand movement patterns and employs a stochastic thresholding approach for anomaly detection. We validated our method through a technical evaluation involving 21 participants engaged in reaching tasks under manipulated and non-manipulated scenarios. The results demonstrated a high accuracy of hand redirection detection at 93.7%, with an F1-score of 93.9%.\r\n",
    "title": "Your Hands Can Tell: Detecting Redirected Hand Movements in Virtual Reality",
    "id": 188240,
    "sequence": 32,
    "queryCoordinates": {
      "visualization": [
        5.372471638776147,
        5.927609002839673
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "Dark patterns are ubiquitous in digital systems, impacting users throughout their journeys on many popular apps and websites. While substantial efforts from the research community in the last five years have led to consolidated taxonomies and an ontology of dark patterns, most characterizations of these patterns have been focused on static images or isolated pattern types. In this paper, we leverage documents from a US Federal Trade Commission complaint describing dark patterns in Amazon Prime's \"Iliad Flow,\" illustrating the interplay of dark patterns across a user journey. We use this case study to illustrate how dark patterns can be characterized and mapped over time, providing a sufficient audit trail and consistent application of dark patterns at high- and meso-level scales. We conclude by describing the groundwork for a methodology of Temporal Analysis of Dark Patterns (TADP) that allows for rigorous identification of dark patterns by researchers, regulators, and legal scholars.",
    "title": "Getting Trapped in Amazon's \"Iliad Flow\": A Foundation for the Temporal Analysis of Dark Patterns",
    "id": 188241,
    "sequence": 33,
    "queryCoordinates": {
      "visualization": [
        10.583055172180254,
        -5.656760841911985
      ]
    }
  },
  {
    "session": "Pointing and Selection",
    "abstract": "Designing efficient selection techniques for graphical user interfaces (GUIs) is fundamental in HCI research. We derive selection techniques based on the multiple process model, a theory that details the motor control processes during goal-directed movements. Specifically, we deduce three theoretical assumptions on how control processes of pre-planning, impulse control, and limb-target control could influence selection movements when adjusting GUI elements, including visual feedback, cursor position, and target position. Corresponding to our assumptions, we develop three techniques that hide the cursor when a target is highlighted, snap the cursor when selection begins, and expand clustered objects during selection movements. After that, we pre-register the assumptions and research methodology and evaluate the techniques in three crowdsourcing-based pointing studies. Our results show that all techniques improved the selection efficiency compared to established baselines. We further discuss the design implications and reflect on how we derived techniques from theory.",
    "title": "Deriving Selection Techniques for GUIs based on the Multiple Process Model",
    "id": 188242,
    "sequence": 34,
    "queryCoordinates": {
      "visualization": [
        7.495597335532802,
        8.05083974399898
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "To use social media is to interact with digital representations of oneself in the form of algorithmically-determined personalized content. Yet when we assume that interactions with personalized content will be a persistent feature of our futures, the concepts available to frame such digital representations -- things variously called doubles, twins, and doppelgangers -- appear as worryingly creepy. Where might one find optimism amid such presumptive creepiness? Through conceptual analysis of data doubles, digital twins, and data doppelgangers, we identify and explain one source of justifiable optimism. Unlike the double and twin, the data doppelganger's dynamics center difference rather than presumed sameness. Fostering justifiable optimism about the futures of personalization -- with social media as a starting point -- requires learning how to design for the experience of difference represented by the doppelganger: the irreducibility of the person to the represented user.",
    "title": "Designing for Difference: How We Learn to Stop Worrying and Love the Doppelganger",
    "id": 188243,
    "sequence": 35,
    "queryCoordinates": {
      "visualization": [
        12.824335978542784,
        -11.159588106621726
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "Natural interactions, such as those based on gesture input, feel intuitive, familiar, and well-suited to user abilities in context, and have been supported by extensive research. Contrary to the conventional mainstream, we advocate for non-natural interaction design as a transformative process that results in highly effective interactions by deliberately deviating from user intuition and expectations of physical-world naturalness or the context in which innate human modalities, such as gestures used for interaction and communication, are applied-departing from the established notion of the \"natural,\" yet prioritizing usability. To this end, we offer four perspectives on the relationship between natural and non-natural design, and explore three prototypes addressing gesture-based interactions with digital content in the physical environment, on the user's body, and through digital devices, to challenge assumptions in natural design. Lastly, we provide a formalization of non-natural interaction, along with design principles to guide future developments.",
    "title": "Non-Natural Interaction Design",
    "id": 188244,
    "sequence": 36,
    "queryCoordinates": {
      "visualization": [
        2.741050036621086,
        20.82034208885002
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "The importance of empathy cannot be overstated in modern societies where people of diverse backgrounds increasingly interact together. The HCI community has strived to foster affective empathy through immersive technologies. Many previous techniques are built upon a premise that presenting the same experience as-is may help evoke the same emotion, which however faces limitations in matters where the emotional responses largely differ across individuals.\r\nIn this paper, we present a novel concept of generating a personalized experience based on a large language model (LLM) to facilitate affective empathy between individuals despite their differences. As a case study to showcase its effectiveness, we developed EmoSync, an LLM-based agent that generates personalized analogical microaggression situations, facilitating users to personally resonate with a specific microaggression situation of another person. EmoSync is designed and evaluated along a 3-phased user study with 100+ participants. We comprehensively discuss implications, limitations, and possible applications.\r\n",
    "title": "Toward Affective Empathy via Personalized Analogy Generation: A Case Study on Microaggression",
    "id": 188245,
    "sequence": 37,
    "queryCoordinates": {
      "visualization": [
        5.708926082714822,
        4.05069907325864
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "How can we design AI tools that effectively support human decision-making by complementing and enhancing users' reasoning processes? Common recommendation-centric approaches face challenges such as inappropriate reliance or a lack of integration with users' decision-making processes. Here, we explore an alternative interaction model in which the AI outputs build upon users' own decision-making rationales. We compare this approach, which we call ExtendAI, with a recommendation-based AI. Participants in our mixed-methods user study interacted with both AIs as part of an investment decision-making task. We found that the AIs had different impacts, with ExtendAI integrating better into the decision-making process and people's own thinking and leading to slightly better outcomes. RecommendAI was able to provide more novel insights while requiring less cognitive effort. We discuss the implications of these and other findings along with three tensions of AI-assisted decision-making which our study revealed.",
    "title": "AI, Help Me Think—but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support",
    "id": 188246,
    "sequence": 38,
    "queryCoordinates": {
      "visualization": [
        -15.76444227822306,
        -2.7353902201648226
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "Virtual reality (VR) expands opportunities for social interaction, yet its heavy reliance on visual cues can limit social engagement and hinder immersive experiences in visually overwhelming situations. To explore alternative social cues beyond the visual domain, we verified the potential of haptic cues for social identification in VR by examining the effects of haptic pattern similarity on social perceptions. Unique haptic patterns were assigned to participants and virtual agents for identification, while the similarity of haptic patterns was manipulated (same, similar, distinct). The results demonstrated that participants maintained closer interpersonal distances and reported higher senses of belonging, social connection, and comfort toward agents as the similarity of patterns increased. Our findings validate the potential of haptic patterns in social identification and provide scientific evidence that homophily extends beyond the visual domain to the haptic domain. We also suggest a novel haptic-based methodology for conveying relationship information and enhancing social VR experiences.",
    "title": "Birds of a Rhythm: The Effects of Haptic Pattern Similarity on People's Social Perceptions in Virtual Reality",
    "id": 188248,
    "sequence": 39,
    "queryCoordinates": {
      "visualization": [
        5.21949515418216,
        -4.664426045664027
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of entangled authorship to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.  ",
    "title": "The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances",
    "id": 188249,
    "sequence": 40,
    "queryCoordinates": {
      "visualization": [
        -2.6124928235797427,
        -4.263200821770462
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "With the widespread adoption of Generative Artificial Intelligence (GenAI) tools, ethical issues are being raised around the disclosure of their use in publishing, journalism, or artwork. Recent research has found that college students are increasingly using GenAI tools; however, we know less about when, why, and how they choose to hide or disclose their use of GenAI in academic work. To address this gap, we conducted an online survey (n=97) and interviews with fifteen college students followed by interviews with nine teachers who had experience with students' undisclosed use of GenAI. Our findings elucidate the strategies students employ to hide their GenAI use and their justifications for doing so, alongside the strategies teachers follow to manage such non-disclosure. We unpack students' non-disclosure of GenAI through the lens of cognitive dissonance and discuss practical considerations for teachers and students regarding ways to promote transparency in GenAI use in higher education.",
    "title": "Examining Student and Teacher Perspectives on Undisclosed Use of Generative AI in Academic Work",
    "id": 188250,
    "sequence": 41,
    "queryCoordinates": {
      "visualization": [
        10.71852654580976,
        -15.687995049934568
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "Smart home devices raise privacy concerns among not only primary users, but also bystanders like domestic workers. We conducted 25 qualitative interviews with nannies and 16 with parents who employed nannies, in the US, to explore and compare their views on and privacy threat models for smart home devices. We found device-specific purposes of use inspired different perspectives among nanny participants. Most were comfortable with employers' smart speakers and smart TVs, whose purpose had nothing to do with them. However, with indoor smart cameras, nanny participants were often not just bystanders but targets of monitoring; in such situations, they had a wider range of attitudes. In contrast, parent participants tended to have more similar views across devices. We found notable disconnects regarding disclosure, where nanny participants often hesitated to ask about cameras, but parent participants assumed nannies just didn't care. We recommend prioritizing interventions supporting disclosure, discussion, and sharing control.",
    "title": "“They Didn’t Buy Their Smart TV to Watch Me with the Kids”: Comparing Nannies’ and Parents’ Privacy Threat Models for Smart Home Devices",
    "id": 188251,
    "sequence": 42,
    "queryCoordinates": {
      "visualization": [
        14.748823613459317,
        -2.7335328823822174
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": "As AI art generation becomes increasingly sophisticated, HCI research has focused primarily on questions of detection, authenticity, and automation. This paper argues that such approaches fundamentally misunderstand how artistic value emerges from the concerns that drive human image production. Through examination of historical precedents, we demonstrate that artistic style is not only visual appearance but the resolution of creative struggle, as artists wrestle with influence and technical constraints to develop unique ways of seeing. Current AI systems flatten these human choices into reproducible patterns without preserving their provenance. We propose that HCI's role lies not only in perfecting visual output, but in developing means to document the origins and evolution of artistic style as it appears within generated visual traces. This reframing suggests new technical directions for HCI research in generative AI, focused on automatic documentation of stylistic lineage and creative choice rather than simple reproduction of aesthetic effects.",
    "title": "Unlimited Editions: Documenting Human Style in AI Art Generation",
    "id": 188252,
    "sequence": 43,
    "queryCoordinates": {
      "visualization": [
        2.7312645082257965,
        13.730993925645226
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "This paper examines linguistic and cultural diversity in Human-Computer Interaction through multilingual experiences across various native languages, including Hungarian, Japanese, Cree, German, Welsh, Spanish, Mandarin, French, Polish, and Arabic. Each contribution reveals unique challenges in translation, usability, and cultural nuance within digital interfaces, with linguistic barriers ranging from issues with non-Latin characters to loss of contextual meaning and limited localisation options. These sections highlight the limitations of current design practices, which often prioritise English-centric frameworks that fail to accommodate diverse language structures and cultural nuances. By capturing these varied perspectives, this paper underscores the need for inclusive, cross-lingual design practices that address global usability challenges. It contributes to the development of more accessible and culturally sensitive digital environments, fostering an HCI approach that values linguistic diversity and cultural specificity.",
    "title": "Lost in Translation: A Cross-Cultural Examination of Linguistic Inaccessibility in HCI",
    "id": 188253,
    "sequence": 44,
    "queryCoordinates": {
      "visualization": [
        -1.9570647534969918,
        13.862535754710239
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "Augmented Reality (AR) head-mounted displays (HMDs) offer potential for more inclusive and immersive exercising and exergaming experiences at home. Previous work found that augmenting home objects can create more engaging exercise experiences and identified various home objects that can be augmented to facilitate different exercises. However, it is unclear how these objects can be augmented to enhance exercising and tailored based on the exercise. We conducted a multi-part study involving a design activity using Snapchat and focus group discussion with 28 participants. We present five themes relating to participants' preferences for the augmentation of home objects for exercising, and identify and discuss key guidelines that designers and researchers should consider when augmenting home objects. Our results provide designers with guidelines and ideas for the augmentation of four different exercises, and advance the foundation for future work developing home-based exergaming through AR HMDs to increase people's physical activity levels.",
    "title": "Snap, Sweat, and Sketch: Designing Home Exercise Experiences for Augmented Reality Head-mounted Displays",
    "id": 188254,
    "sequence": 45,
    "queryCoordinates": {
      "visualization": [
        -4.511038844873863,
        3.956074890600414
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "Mid-air text entry in mixed reality (MR) headsets has shown promise but remains less efficient than traditional input methods. While research has focused on improving typing performance, the mechanics of mid-air gesture typing, especially eye-hand coordination, are less understood. This paper investigates visuomotor coordination of mid-air gesture keyboards through a user study (n=16) comparing gesture typing on a tablet and in mid-air. Through an expert task we demonstrate that users were able to achieve a comparable text input performance. Our in-depth analysis of eye-hand coordination reveals significant differences in the eye-hand coordination patterns between gesture typing on a tablet and in-air. The mid-air gesture typing necessitates almost all of the visual attention on the keyboard area and a more consistent synchronization in eye-hand coordination to compensate for the increased motor and cognitive demands without physical boundaries. These insights provide important implications for the design of more efficient text input methods.",
    "title": "Seeing and Touching the Air: Unraveling Eye-Hand Coordination in Mid-Air Gesture Typing for Mixed Reality",
    "id": 188255,
    "sequence": 46,
    "queryCoordinates": {
      "visualization": [
        10.17324450847638,
        9.617956964488622
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "Social anxiety (SA) has become increasingly prevalent. Traditional coping strategies often face accessibility challenges. Generative AI (GenAI), known for their knowledgeable and conversational capabilities, are emerging as alternative tools for mental well-being. With the increased integration of GenAI, it is important to examine individuals' attitudes and trust in GenAI chatbots' support for SA. Through a mixed-method approach that involved surveys (n = 159) and interviews (n = 17), we found that individuals with severe symptoms tended to trust and embrace GenAI chatbots more readily, valuing their non-judgmental support and perceived emotional comprehension. However, those with milder symptoms prioritized technical reliability. We identified factors influencing trust, such as GenAI chatbots' ability to generate empathetic responses and its context-sensitive limitations, which were particularly important among individuals with SA. We also discuss the design implications and use of GenAI chatbots in fostering cognitive and emotional trust, with practical and design considerations.",
    "title": "Understanding Attitudes and Trust of Generative AI Chatbots for Social Anxiety Support",
    "id": 188256,
    "sequence": 47,
    "queryCoordinates": {
      "visualization": [
        12.52252041361771,
        3.4909142771668975
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "The material properties of 3D prints depend on their constituent materials, how they were printed, and local geometrical features. Motivated by challenges in sharing physical details of 3D printing workflows including machine state and print settings, we contribute tools to support the exploration of the vast design space these interdependent parameters make up. Inspired by live music performance and video captioning, we contribute an interactive controller for parameters not represented in geometry such as speed and extrusion rate, and a system for automatically syncing video documentation to machine settings, G-Code, and print commands. By synchronizing video with machine instructions and interactive adjustments, we archive the relationship between digital settings and physical output for revisiting and sharing. We demonstrate example workflows in multiple materials. Our approach suggests how maker tools that promote settings exploration and sharing can support the integration of fabrication technologies in new contexts, with new materials.",
    "title": "It's Not the Shape, It's the Settings: Tools for Exploring, Documenting, and Sharing Physical Fabrication Parameters in 3D Printing",
    "id": 188257,
    "sequence": 48,
    "queryCoordinates": {
      "visualization": [
        -4.273355186688748,
        16.454131257784482
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "Visualizations are powerful tools for conveying information but often rely on accompanying text for essential context and guidance. This study investigates the impact of annotation patterns on reader preferences and comprehension accuracy among multilingual populations, addressing a gap in visualization research. We conducted experiments with two groups fluent in English and either Tamil (n = 557) or Arabic (n = 539) across six visualization types, each varying in annotation volume and semantic content. Full-text annotations yielded the highest comprehension accuracy across all languages, while preferences diverged: English readers favored highly annotated charts, whereas Tamil/Arabic readers preferred full-text or minimally annotated versions. Semantic variations in annotations (L1–L4) did not significantly affect comprehension, demonstrating the robustness of text comprehension across languages. English annotations were generally preferred, with a tendency to think technically in English linked to greater aversion to non-English annotations, though this diminished among participants who regularly switched languages internally. Non-English annotations incorporating visual or external knowledge were less favored, particularly in titles. Our findings highlight cultural and educational factors influencing perceptions of visual information, underscoring the need for inclusive annotation practices for diverse linguistic audiences. All data and materials are available at: https://osf.io/ckdb4/.",
    "title": "Lost in Translation: How Does Bilingualism Shape Reader Preferences for Annotated Charts?",
    "id": 188258,
    "sequence": 49,
    "queryCoordinates": {
      "visualization": [
        15.192450889488587,
        5.018907846382264
      ]
    }
  },
  {
    "session": "Well-being and Tracking",
    "abstract": "Most studies of Personal Informatics (PI) focus on the holistic experience of self-tracking or how users relate to self-tracking goals. Recently, new tracker metrics became available in commercial systems, e.g. stress scores or body battery. Hence, more attention should be devoted to what users track and how they understand metrics produced by their trackers. Charting the evolution of metrics in PI can enable building systems that better support well-being. To this end, we interviewed n=25 fitness tracker users to discover what metrics are most important to them, how they understand the metrics, and how they formulate their goals with respect to the metrics. We found that users created a metric ecology which they adjusted to their life circumstances, reformulating their goals. We identified key issues in understanding metrics which bear the risk of misuse. We contribute recommendations for future PI systems as self-tracking metrics increase in complexity.",
    "title": "The Framework of the Lived Experience of Metrics: Understanding the Purposes and Activities of Self-Tracking Metrics",
    "id": 188259,
    "sequence": 50,
    "queryCoordinates": {
      "visualization": [
        9.212931062685525,
        13.08135701042534
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "As HCI research turns to women's reproductive health as a topic of interest, an increasing number of female-oriented technologies (FemTech) are being marketed to consumers. This opens up a space for better management and understanding of intimate health but is not without risk. Reproductive health data collected by FemTech devices is highly sensitive and politicized. Breaches of privacy can cause or exacerbate discrimination and gender inequality, and negatively impact users' safety and well-being. It is therefore important that users are well informed about how their data is collected, handled, used and stored. This work contributes insights into whether and to what extent this is achieved by current FemTech. We conduct a structured content analysis of 18 in-effect privacy policies. Applying an empirically-grounded taxonomy, we identify challenges in policy wording, content and presentation. We conclude with recommendations for improving transparency and supporting users in providing informed consent and claiming data authority.",
    "title": "Hidden in Plain Sight: a Structured Analysis of Privacy Policies in the Context of Body-worn 'FemTech' Technologies",
    "id": 188260,
    "sequence": 51,
    "queryCoordinates": {
      "visualization": [
        0.392295478639225,
        4.9845866686656395
      ]
    }
  },
  {
    "session": "Introduction to Computational Cognitive Modeling",
    "abstract": "",
    "title": "Introduction to Computational Cognitive Modeling",
    "id": 188261,
    "sequence": 52,
    "queryCoordinates": {
      "visualization": [
        2.7063521955384537,
        -8.583452556734043
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "While users could embody virtual avatars that mirror their physical movements in Virtual Reality, these avatars' motions can be redirected to enable novel interactions. Excessive redirection, however, could break the user's sense of embodiment due to perceptual conflicts between vision and proprioception. While prior work focused on avatar-related factors influencing the noticeability of redirection, we investigate how the visual stimuli in the surrounding virtual environment affect user behavior and, in turn, the noticeability of redirection. Given the wide variety of different types of visual stimuli and their tendency to elicit varying individual reactions, we propose to use users' gaze behavior as an indicator of their response to the stimuli and model the noticeability of redirection. We conducted two user studies to collect users' gaze behavior and noticeability, investigating the relationship between them and identifying the most effective gaze behavior features for predicting noticeability. Based on the data, we developed a regression model that takes users' gaze behavior as input and outputs the noticeability of redirection. We then conducted an evaluation study to test our model on unseen visual stimuli, achieving an accuracy of 0.012 MSE. We further implemented an adaptive redirection technique and conducted a proof-of-concept study to evaluate its effectiveness with complex visual stimuli in two applications. The results indicated that participants experienced less physical demanding and a stronger sense of body ownership when using our adaptive technique, demonstrating the potential of our model to support real-world use cases.",
    "title": "Modeling the Impact of Visual Stimuli on Redirection Noticeability with Gaze Behavior in Virtual Reality",
    "id": 188262,
    "sequence": 53,
    "queryCoordinates": {
      "visualization": [
        -0.3925981575906855,
        9.992290362407228
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "Eating disorders (ED) are complex mental health conditions that require long-term management and support. Recent advancements in large language model (LLM)-based chatbots offer the potential to assist individuals in receiving immediate support. Yet, concerns remain about their reliability and safety in sensitive contexts such as ED. We explore the opportunities and potential harms of using LLM-based chatbots for ED recovery. We observe the interactions between 26 participants with ED and an LLM-based chatbot, WellnessBot, designed to support ED recovery, over 10 days. We discovered that our participants have felt empowered in recovery by discussing ED-related stories with the chatbot, which served as a personal yet social avenue. However, we also identified harmful chatbot responses, especially concerning individuals with ED, that went unnoticed partly due to participants’ unquestioning trust in the chatbot's reliability. Based on these findings, we provide design implications for safe and effective LLM-based interventions in ED management.",
    "title": "Private Yet Social: How LLM Chatbots Support and Challenge Eating Disorder Recovery",
    "id": 188263,
    "sequence": 54,
    "queryCoordinates": {
      "visualization": [
        5.656760841911962,
        -10.583055172180266
      ]
    }
  },
  {
    "session": "How to: Peer Review for CHI (and Beyond) 2025",
    "abstract": "A key challenge for people that are new to reviewing is pitching the review at the right level, and getting the tone and structure of a review right. This course aims to help participants understand a) the different expectations of different venues and submission types, b) the processes they use to make decisions, and c) good techniques for producing a review for these different circumstances. Combined with pre-workshop training videos provided via SIGCHI's Youtube Channel, the practical work of this course will involve: 1) critiquing anonymised but real reviews (as a senior reviewer), and 2) constructing prototype reviews based on advice (as a reviewer).",
    "title": "How to: Peer Review for CHI (and Beyond) 2025",
    "id": 188264,
    "sequence": 55,
    "queryCoordinates": {
      "visualization": [
        -11.73995273524091,
        12.295263713085191
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "Embedding data into the physical environment using augmented reality (AR) is a practical approach for data visualization as it offers a large and flexible display space on or around the physical referent, i.e., the physical object to which the data is related. Yet, current interaction in such context is often performed using cumbersome dedicated devices, tiring mid-air gestures, or awkward on-body input. In this article, we investigate the use of the physical referent itself as a support for input interaction with an embedded space-time cube (STC) representation. Hence, we first identify the most promising mappings between the physical features of the referent (edges, faces, corners) and the STC dimensions. Then, we design three data selection techniques using the physical referent and compare them to mid-air gestures when performing selection tasks on the STC. Overall, our work demonstrates that using the physical referent to support input interaction with embedded data representations is an efficient and comfortable approach for data selection in standing and sitting situations.",
    "title": "Exploiting Physical Referent Features as Input for Multidimensional Data Selection in Augmented Reality",
    "id": 188265,
    "sequence": 56,
    "queryCoordinates": {
      "visualization": [
        1.826284287026162,
        2.3800600208737057
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "Systematic reviews (SRs) are vital to gathering and structuring knowledge, yet descriptions of their procedures are often inadequate. In human–computer interaction (HCI), SRs are still uncommon but gaining momentum, which prompted us to explore how SRs are reported at CHI—the flagship HCI conference venue. To assess the reporting quality of CHI reviews that aim for a systematic approach, we conducted an umbrella review and applied reporting guidelines for SRs (PRISMA and ENTREQ) to our corpus. We contribute the first exploration of how well SRs at CHI meet guidelines for reporting quality, showcasing strategies for improvement in reporting and conducting SRs especially in the domains of appraisal, synthesis, and documentation (i.e., protocol development). Finally, we present guiding questions for HCI researchers and practitioners for reporting SRs, as well as suggestions for best practices.",
    "title": "An Umbrella Review of Reporting Quality in CHI Systematic Reviews: Guiding Questions and Best Practices for HCI",
    "id": 188266,
    "sequence": 57,
    "queryCoordinates": {
      "visualization": [
        0.39018064403225666,
        1.9615705608064609
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "This paper presents an account of the Interaction Research Studio’s distinctive approach to incorporating data into design, unpacking a vital but previously unexamined facet of our two-decade-long research programme. We demonstrate how data has served as a pragmatic tool in creating engaging, contextually-aware computational products that provide alternatives to dominant task-oriented and consumerist narratives by promoting interpretation, imagination, spirituality, and socio-cultural reflection. Leveraging an annotated portfolio approach, we revisit our diverse portfolio of designs, starting from individual reflections before surfacing overarching themes. This paper foregrounds our strategies for utilising data, the associated labour, and the challenges that have arisen throughout our design process. This emergent and empirical account may complement more theoretical treatments of designing with data and provide valuable insights for researchers, designers, and practitioners navigating the complexities of data-integrated design in the contemporary technological landscape.",
    "title": "Designing with Data: An Annotated Portfolio",
    "id": 188267,
    "sequence": 58,
    "queryCoordinates": {
      "visualization": [
        -7.28940999758299,
        18.624298695176073
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "New digital tools offer biodesign with unprecedented opportunities for monitoring, fabricating, iterating, and scaling designs. Serving aligned purposes and beyond, the Digital Twin (DT) is an emerging concept in bio-industries including bioprocessing and agri-food. In these fields, DTs enable comprehensive digital representations of a living system or process with continuous bidirectional connection to the physical world. Despite the concept’s potential to address certain challenges of uncertainty in designing (with) living systems, its applications and implications in biodesign and research remains largely underexplored. To bridge this gap, we propose a conceptual framework that synthesizes existing instantiations of DTs within bio-industries through a data flow lens. We mobilize the framework through a proof-of-concept DT for biofabrication with mycelium, by unpacking the data flows within the identified design and operation cycles. We conclude with a discussion on how DT capabilities respond to uncertainties in designing with living systems, limitations and future work.",
    "title": "Addressing Uncertainty in Biodesign through Digital Twins: A Case of Biofabrication with Mycelium",
    "id": 188268,
    "sequence": 59,
    "queryCoordinates": {
      "visualization": [
        12.824335978542786,
        11.159588106621722
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "Motivation and autonomy are fundamental concepts in Human–Computer Interaction (HCI), yet in User Experience (UX) research they have remained surprisingly peripheral. We draw on Self-Determination Theory (SDT) to analyse autonomous and non-autonomous patterns of motivation in 497 interaction experiences. Using latent profile analysis, we identify five distinct patterns of motivation in technology use—‘motivational profiles’—associated with significant differences in need satisfaction, affect, and perceived usability. Users’ descriptions of these experiences also reveal qualitative differences between profiles: from intentional, purposive engagement, to compulsive use which users themselves consider unhealthy. Our results complicate exclusively positive notions of intrinsic motivation and clarify how extrinsic motivation can contribute to positive UX. Based on these findings, we identify open questions for UX and SDT: addressing ‘hedonic amotivation’—negative experiences in activities which are intrinsically motivated but not otherwise valued—and ‘design for internalisation’—scaffolding healthy and sustainable patterns of engagement over time.",
    "title": "Beyond Intrinsic Motivation: The Role of Autonomous Motivation in User Experience",
    "id": 188269,
    "sequence": 60,
    "queryCoordinates": {
      "visualization": [
        -19.903694533443936,
        1.9603428065912165
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "Wearables integrating movement sonification can support body-perception changes and related physical activity; yet, we lack design principles for such sonifications. Through two mixed-methods studies, we investigate sound pitch and movement direction interaction effects on self-perception during squat exercises. We measured effects on body perception, affective quality of the experience, and actual and perceived movement, and compared them with two control conditions: no-sound and vibrotactile feedback. Results show that regardless of movement direction, ascending pitch enhances several body feelings and overall experience quality, while descending pitch increases movement acceleration. These effects were moderated by exercise physical demand. Sound and vibrotactile feedback enhanced flexibility and strength feelings, respectively, and contributed to exercise completion in different ways. Sound was perceived as an internal-to-body force while vibrotactile feedback was perceived as an external-to-body force. Feedback effects were stronger in people with lower fitness levels. We discuss results in terms of malleability of body perceptions and highlight opportunities to support demanding physical activity through wearable devices.",
    "title": "Pushed by Sound: Effects of Sound and Movement Direction on Body Perception, Experience Quality, and Exercise Support",
    "id": 188270,
    "sequence": 61,
    "queryCoordinates": {
      "visualization": [
        7.777983262274432,
        11.640574572235634
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "Recent efforts to connect builders to digital designs during construction have primarily focused on visual augmented reality, which requires accurate registration and specific lighting and which could prevent a user from noticing safety hazards. Haptic interfaces, on the other hand, can convey physical design parameters through tangible local cues that don’t distract from the surroundings. We propose two edge-changing haptic devices that use small inertial measurement units (IMUs) and linear actuators to guide users to perform construction tasks in real time: Drangle gives feedback for angling a drill relative to gravity, and Brangle assists with orienting bricks in the plane. We conducted a study with 18 participants to evaluate user performance and gather qualitative feedback. All users understood the edge-changing cues from both devices with minimal training. Drilling holes with Drangle was somewhat less accurate but much faster and easier than with a mechanical guide; 89% of participants preferred Drangle over the mechanical guide. Users generally understood Brangle’s feedback but found its hand-size-specific grip, palmar contact, and attractive tactile cues less intuitive than Drangle’s generalized form factor, fingertip contact, and repulsive cues. After summarizing design considerations, we propose application scenarios and speculate how such devices could improve construction workflows.",
    "title": "Building Instructions You Can Feel: Edge-Changing Haptic Devices for Digitally Guided Construction",
    "id": 188271,
    "sequence": 62,
    "queryCoordinates": {
      "visualization": [
        -4.988817673815273,
        -3.3334213981176117
      ]
    }
  },
  {
    "session": "Design Thinking",
    "abstract": "Creating games involves frequent prototyping to quickly obtain feedback. In this paper, we explore the impact of removing a traditional game engine’s separation of scene and game logic that supports scalability to large projects and, instead, combine scene and game logic in a single view. In our tool, Pronto, designers connect game objects with visual representations of behavior to define game logic in the scene view, thus exposing any concern of the prototype to the designer within one click. To explore the implications of the trade-off between scalability and speed of access, we conducted a cognitive walkthrough and an explorative user study comparing prototyping in the Godot game engine and in Pronto. Godot’s separate views made it appear more structured and reliable to users, while Pronto’s scattered game logic accelerated editing and gave users the impression of progressing faster in their implementation.",
    "title": "All in One: Rapid Game Prototyping in a Single View",
    "id": 188272,
    "sequence": 63,
    "queryCoordinates": {
      "visualization": [
        -6.4256602518451595,
        -4.765594435939466
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Digital learning platforms offer flexibility and customization but place significant demands on attention and self-regulation, challenges that are especially pronounced for children with Attention Deficit Hyperactivity Disorder (ADHD). This research addresses\r\nthese challenges by developing a multimodal framework to analyze attention patterns specific to ADHD learners. By integrating physiological signals such as heart rate variability and galvanic skin response, along with behavioural cues like task engagement metrics, the study assesses attention dynamics in real-time. The goal is to identify ADHD-specific attention fluctuations and design adaptive learning interfaces to offer targeted interventions when the attention is lost. These interventions aim to optimize content delivery and sustain attention, ultimately enhancing learning outcomes for children with ADHD. The research bridges cognitive science and educational technology, offering valuable insights into how digital learning environments can be tailored to support the needs of ADHD students while advancing the broader field of attention dynamics in education.",
    "title": "Decoding Attention in Children with Attention Deficit Hyperactivity Disorder through Multimodal Analysis for Digital Learning",
    "id": 188273,
    "sequence": 64,
    "queryCoordinates": {
      "visualization": [
        20.96696311537415,
        -1.1774793919810234
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "Online advertising platforms may be able to infer privacy-sensitive information about people, such as their health conditions. This could lead to harms like exposure to predatory targeted advertising or unwanted disclosure of health conditions to employers or insurers. In this work, we experimentally evaluate whether online advertisers target people with health conditions. We collected the browsing histories of people with and without health conditions. We crawled their histories to simulate their browsing profiles and collected the ads that were served to them. Then, we compared the content of the ads between groups. We observed that the profiles of people who visited more health-related web pages received more health-related ads. 49.5% of health-related ads used deceptive advertising techniques. Our findings suggest that new privacy regulations and enforcement measures are needed to protect people's health privacy from online tracking and advertising platforms.",
    "title": "Measuring Risks to Users' Health Privacy Posed by Third-Party Web Tracking and Targeted Advertising",
    "id": 188274,
    "sequence": 65,
    "queryCoordinates": {
      "visualization": [
        11.942216720066362,
        1.1762056839547272
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "Recent advancements in large language models have significantly expedited the process of generating front-end code.\r\nThis allows users to rapidly prototype user interfaces and ideate through code, a process known as exploratory programming.\r\nHowever, existing LLM code generation tools focus more on technical implementation details rather than finding the right design given a particular problem.\r\nWe present DynEx, an LLM-based method for design exploration in accelerated exploratory programming. \r\nDynEx introduces a technique to explore the design space through a structured Design Matrix before creating the prototype with a modular, stepwise approach to LLM code generation. Code is generated sequentially, and users can test and approve each step before moving onto the next.\r\nA user study of 10 experts found that DynEx increased design exploration and enabled the creation of more complex and varied prototypes compared to a Claude Artifact baseline. \r\nWe conclude with a discussion of the implications of design exploration for exploratory programming. ",
    "title": "DynEx: Dynamic Code Synthesis with Structured Design Exploration for Accelerated Exploratory Programming",
    "id": 188275,
    "sequence": 66,
    "queryCoordinates": {
      "visualization": [
        3.4204407474422576,
        7.231914344987547
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "We present the results of a study comparing the performance of younger adults (YA) and people in late adulthood (PLA) across ten low-level analysis tasks and five basic visualizations, employing Bayesian regression to aggregate and model participant performance. We analyzed performance at the task level and across combinations of tasks and visualizations, reporting measures of performance at aggregate and individual levels. These analyses showed that PLA on average required more time to complete tasks while demonstrating comparable accuracy. Furthermore, at the individual level, PLA exhibited greater heterogeneity in task performance as well as differences in best-performing visualization types for some tasks. We contribute empirical knowledge on how age interacts with analysis task and visualization type and use these results to offer actionable insights and design recommendations for aging-inclusive visualization design. We invite the visualization research community to further investigate aging-aware data visualization. Supplementary materials can be found at https://osf.io/a7xtz/.",
    "title": "Toward Filling a Critical Knowledge Gap: Charting the Interactions of Age with Task and Visualization",
    "id": 188276,
    "sequence": 67,
    "queryCoordinates": {
      "visualization": [
        7.224031878618181,
        -15.38874145005719
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "In redirected walking techniques, curvature gain and bending gain, which are referred to as curvature manipulation, are important redirection gains. The applied gains can differ when multiple paths are mapped, and sudden changes in gain may cause discomfort. This study proposes quadratic curvature manipulation (QCM) based on the habituation mechanism to effectively reduce discomfort. This method quadratically adjusts the path curvature, thereby reducing user's perception of curvature changes. Furthermore, we introduce the segmented curvature change (SCC) mode that combines QCM with linear curvature manipulation to facilitate more natural gain transitions, thereby reducing discomfort. Two experiments were conducted. Experiment 1 examined the relationship between QCM parameters and gains at which users felt discomfort. Experiment 2 further examined the effects of different curvature change modes on discomfort. The results indicate that using the SCC mode in curvature manipulations is more effective than other methods in reducing discomfort.",
    "title": "QCM: A Curvature Manipulation Method to Suppress Discomfort in Redirected Walking",
    "id": 188277,
    "sequence": 68,
    "queryCoordinates": {
      "visualization": [
        9.465832400385242,
        -8.910556490355523
      ]
    }
  },
  {
    "session": "Visualization and Language Communication",
    "abstract": "Data physicalizations are tangible objects, and touching them may improve their interpretation. However, little is known about how people actually touch physicalizations. We recorded verbal and tactile responses to data physicalizations in three consecutive conditions: as an unspecified object, as a representation of unknown data, and with full information about data and encoding. Our two stimulus objects present data for nine countries in a 3x3 grid. We varied vertical axis polarity, with positive data values either above (convex) or below (concave) baseline. Using an analog tracer method, we examine whether some components of the physicalization are touched more than others, whether touch varies by task and the impact of axis polarity. We found large differences in the degree to which different components were touched and that the effect of vertical axis polarity depended on task. We describe additional tactile and verbal\r\nbehaviors that can inform the design of data physicalizations.",
    "title": "Data at Hand: Exploring the Tactile Perception of Data Physicalizations",
    "id": 188278,
    "sequence": 69,
    "queryCoordinates": {
      "visualization": [
        7.5323525214641665,
        -2.69511882713776
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "News reading helps individuals stay informed about events and developments in society. Local residents and new immigrants often approach the same news differently, prompting the question of how technology, such as LLM-powered chatbots, can best enhance a reader-oriented news experience. The current paper presents an empirical study involving 144 participants from three groups in Virginia, United States: local residents born and raised there (N=48), Chinese immigrants (N=48), and Vietnamese immigrants (N=48). All participants read local housing news with the assistance of the Copilot chatbot. We collected data on each participant's Q&A interactions with the chatbot, along with their takeaways from news reading. While engaging with the news content, participants in both immigrant groups asked the chatbot fewer analytical questions than the local group. They also demonstrated a greater tendency to rely on the chatbot when formulating practical takeaways. These findings offer insights into technology design that aims to serve diverse news readers.",
    "title": "The News Says, the Bot Says: How Immigrants and Locals Differ in Chatbot-Facilitated News Reading",
    "id": 188279,
    "sequence": 70,
    "queryCoordinates": {
      "visualization": [
        -1.1753739745783847,
        -9.930684569549262
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "We examine WhatsApp-based reselling practices adopted by small garment sellers in Surat, a textile city in India, as a response to the challenges posed by high commission costs, confusing dashboards, and restrictive rules of global e-commerce platforms. Through interviews and observations, we show how sellers use WhatsApp’s popularity to collaborate with women resellers and customers, enabling participation in online commerce bypassing e-commerce platforms. Using the lens of translation, we argue that WhatsApp functions as a tool and site of praxis for sellers who translate the complicated, standardized, and expensive processes of e-commerce platforms that are in English into multimodal, idiomatic, collaborative reselling practices. These are undertaken in regional languages on WhatsApp with the help of traders and women resellers economically benefiting everyone while delivering a personalized online shopping experience for customers. We discuss the politics of this translation, examining its impact on the design of e-commerce platforms while also shaping the discourse of reselling as an empowering pathway for women.",
    "title": "Reselling Practices in a Textile Bazaar: Translating E-Commerce Platforms to WhatsApp ",
    "id": 188280,
    "sequence": 71,
    "queryCoordinates": {
      "visualization": [
        -8.72496007072797,
        4.8862124149695525
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "Numerous haptic devices have been proposed to support motor learning, such as a hand exoskeleton with mechanical linkages, a vibrotactile glove, and an Electrical Muscle Stimulation (EMS) device. Understanding the impact of each type of feedback on users’ learning performance and experience, as well as the effects of customizing the haptic feedback each user receives, is vital to achieving both efficient and highly motivating learning. To this end, we compared learning performance and experience while using these haptic devices for piano learning. It revealed the distinct characteristics of each device, notably, the exoskeleton was the most preferred despite certain drawbacks. We then conducted a user study to evaluate the effectiveness of haptic customization, allowing participants to customize the order of haptic feedback, demonstrating its advantages such as improved agency and performance. These findings would benefit haptic designers by providing more efficient and optimized haptic feedback for motor learning scenarios.",
    "title": "Hapticus: Exploring the Effects of Haptic Feedback and its Customization on Motor Skill Learning: Tactile, Haptic, and Somatosensory Approaches",
    "id": 188281,
    "sequence": 72,
    "queryCoordinates": {
      "visualization": [
        -5.708926082714822,
        4.050699073258641
      ]
    }
  },
  {
    "session": "Evaluating Interactive Technology with Children",
    "abstract": "While evaluating technology with adults is well understood, evaluating interactive technology with child users has received far less attention and raises a range of unusual and unexpected challenges. With more children than ever before using interactive technology on a daily basis, this course, for practitioners and researchers, aims to provide a succinct and useful introduction to evaluating technology with children. The course begins with the developmental and ethical challenges of working with children, then covers a range of foundational evaluation techniques, along with how techniques are used and how results are reported both in publications and to child audiences. ",
    "title": "Evaluating Interactive Technology with Children",
    "id": 188282,
    "sequence": 73,
    "queryCoordinates": {
      "visualization": [
        -1.1758463372162395,
        -10.936973319490871
      ]
    }
  },
  {
    "session": "Data Interpretation and Storytelling",
    "abstract": "Personal data flows across digital technologies integrated into people's lives and relationships. Increasingly, these technologies include Generative AI. (How) should personal data flow into and out of GenAI models? We investigate how people experience personal data collection in GenAI ecosystems and unpack the enablers and barriers to governing their data. We focus on personal data collection by Meta, specifically Instagram, in line with their recent policy update on processing user data to train GenAI models. We conducted semi-structured interviews with 20 Latin American Instagram users, based in Europe and Latin America. We discussed the acceptability of their data flowing in and out of GenAI models through different scenarios. Our results interrogate power dynamics in data collection, the (inter)personal nature of data, and the multiple unknowns concerning data and their algorithmic derivatives. We pose provocations around feelings of powerlessness, reframing (inter)personal data, and encountering unknown data and algorithms through design.",
    "title": "Surrendering to Powerlesness: Governing Personal Data Flows in Generative AI",
    "id": 188283,
    "sequence": 74,
    "queryCoordinates": {
      "visualization": [
        19.535317626417445,
        -4.286183061301026
      ]
    }
  },
  {
    "session": "Design",
    "abstract": "Nearly 20 years ago, Gaver et al. introduced ambiguity as a design resource, proposing tactics to reflect everyday uncertainty into interactive systems. This approach is especially relevant for self-tracking wearables, which often obscure the inherent ambiguity of system design and tracked phenomena with seemingly clear, prescriptive data and insights. Although scholars recognize the importance of ambiguity, its practical application in the design process remains underexplored. To address this, we conducted a two-week workshop with 60 designers, examining the application of Gaver et al.’s tactics into 11 design concepts, and performed interviews with 16 participants. Our findings reveal eight relevant ambiguity tactics for self-tracking and offer insights into participants' experiences with designing using ambiguity. We discuss prescription and overlooked ambiguity as levers for the operationalization of ambiguity, the potential benefits and downsides of ambiguity tactics for users, future directions for HCI research and practice, and the study limitations.",
    "title": "How to Design with Ambiguity: Insights from Self-tracking Wearables",
    "id": 188284,
    "sequence": 75,
    "queryCoordinates": {
      "visualization": [
        0.39267384921256454,
        -19.996144809641297
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "To enhance focused eating and dining socialization, previous Human-Food Interaction research has indicated that external devices can support these dining objectives and immersion. However, methods that focus on the food itself and the diners themselves have remained underdeveloped. In this study, we integrated biofeedback with food, utilizing diners' heart rates as a source of the food's appearance to promote focused eating and dining socialization. By employing LED lights, we dynamically displayed diners' real-time physiological signals through the transparency of the food. Results revealed significant effects on various aspects of dining immersion, such as awareness perceptions, attractiveness, attentiveness to each bite, and emotional bonds with the food. Furthermore, to promote dining socialization, we established a “Sharing Bio-Sync Food” dining system to strengthen emotional connections between diners. Based on these findings, we developed tableware that integrates biofeedback into the culinary experience.",
    "title": "Living Bento: Heartbeat-Driven Noodles for Enriched Dining Dynamics",
    "id": 188285,
    "sequence": 76,
    "queryCoordinates": {
      "visualization": [
        -1.177256326142585,
        -17.96146061829486
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "Identifying objective markers of attentional states is critical, particularly in real-world scenarios where attentional lapses have serious consequences. In this study, we identified gaze-based indices of attentional lapses and validated them by examining their impact on the performance of classification models. We designed a virtual reality visual search task that encouraged active eye movements to define dynamic gaze-based metrics of different attentional states (zone in/out). The results revealed significant differences in both reactive ocular features, such as first fixation and saccade onset latency, and global ocular features, such as saccade amplitude, depending on the attentional state. Moreover, the performance of the classification models improved significantly when trained only on the proven gaze-based and behavioral indices rather than all available features, with the highest prediction accuracy of 79.3%. We highlight the importance of the preliminary studies before model training and provide generalizable gaze-based indices of attentional states for practical applications. ",
    "title": "Looking but Not Focusing: Defining Gaze-Based Indices of Attention Lapses and Classifying Attentional States",
    "id": 188286,
    "sequence": 77,
    "queryCoordinates": {
      "visualization": [
        13.326040464736492,
        -10.55540835459271
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "The ACM CHI Conference has a tradition of citing its intellectual heritage. At the same time, we know CHI is highly diverse and evolving. In this highly dynamic context, it is not clear how the CHI community continues to appreciate its milestones (within and outside of CHI). We present an investigation into how the community's citations to milestones have evolved over 43 years of CHI Proceedings (1981-2024). Forgetting curves plotted for each year suggest that milestones are slowly fading from the CHI community's collective memory. However, the picture is more nuanced when we trace citations to the top-cited milestones over time. We identify three distinct types of milestones cited at CHI, a typology of milestone contributions, and define the Milestone Coefficient as a metric to assess the impact of milestone papers on a continuous scale. Further, our findings suggest the potential presence of a Matthew effect at CHI. We discuss the broader ramifications for the CHI community and the field of HCI.",
    "title": "Keeping Score: A Quantitative Analysis of How the CHI Community Appreciates Its Milestones",
    "id": 188287,
    "sequence": 78,
    "queryCoordinates": {
      "visualization": [
        13.858192987669298,
        -5.740251485476356
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "The explosive growth of Virtual YouTubers (VTubers)---streamers who perform behind virtual anime avatars---has created a unique digital economy with profound implications for content creators, platforms, and viewers. Understanding the economic landscape of VTubers is crucial for designing equitable platforms, supporting content creator livelihoods, and fostering sustainable digital communities. To this end, we conducted a large-scale study of over 1 million hours of publicly available streaming records from 1,923 VTubers on YouTube, covering tens of millions of dollars in actual profits. Our analysis reveals stark inequality within the VTuber community and characterizes the sources of income for VTubers from multiple perspectives. Furthermore, we also found that the VTuber community is increasingly monopolized by two agencies, driving the financial disparity. This research illuminates the financial dynamics of VTuber communities, informing the design of equitable platforms and sustainable support systems for digital content creators.",
    "title": "Who Reaps All the Superchats? A Large-Scale Analysis of Income Inequality in Virtual YouTuber Livestreaming",
    "id": 188288,
    "sequence": 79,
    "queryCoordinates": {
      "visualization": [
        -0.3926393614115614,
        -12.994069198363935
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "Wood has become increasingly applied in shape-changing interfaces for its eco-friendly and smart responsive properties, while its applications face challenges as it remains primarily driven by humidity. We propose TH-Wood, a biodegradable actuator system composed of wood veneer and microbial polymers, driven by both temperature and humidity, and capable of functioning in complex outdoor environments. This dual-factor-driven approach enhances the sensing and response channels, allowing for more sophisticated coordinating control methods. To assist in designing and utilizing the system more effectively, we developed a structure library inspired by dynamic plant forms, conducted extensive technical evaluations, created an educational platform accessible to users, and provided a design tool for deformation adjustments and behavior previews. Finally, several ecological applications demonstrate the potential of TH-Wood to significantly enhance human interaction with natural environments and expand the boundaries of human-nature relationships.",
    "title": "TH-Wood: Developing Thermo-Hygro-Coordinating Driven Wood Actuators to Enhance Human-Nature Interaction",
    "id": 188289,
    "sequence": 80,
    "queryCoordinates": {
      "visualization": [
        2.7353902201648213,
        -15.76444227822306
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "An increasing number of tools now integrate AI support, extending the ability of users—especially novices—to produce creative work. While AI could play various roles within such tools, less is known about how the positioning of AI affects an individual's cognitive processes and sense of agency. To examine this relationship, we built a collaborative whiteboard plugin that integrates an LLM into design templates to facilitate reflective brainstorming activities. We conducted a between-subjects experiment with N=47 participants assigned to one of three versions of AI-support—No-AI, AI input provided incrementally (Co-led) and AI provided all at once (AI-led)—to compare the allocation of cognitive resources. Results show that the positioning of AI scaffolds shifts the underlying cognition: AI-led participants devoted more time to comprehension and synthesis, which yielded more topically diverse problems and solutions. No-AI and Co-led participants spent more time revising content and reported higher confidence in their process.",
    "title": "Productive vs Reflective: How Different Ways of Integrating AI into Design Workflows Affects Cognition and Motivation",
    "id": 188290,
    "sequence": 81,
    "queryCoordinates": {
      "visualization": [
        11.03264871579307,
        -11.587953327223472
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "This article explores the intersections and resonances between unmaking and more-than-human design. We begin by aligning unmaking with decentering, a fundamental practice in more-than-human design, through their shared movement and materiality. Using Lindström and Ståhl’s notion of the double movement in un/making, we analyze a series of workshops focused on designing with AI, annotating what was un/made and de/centered during the workshops’ activities. Through this analysis, we introduce two key contributions that highlight some opportunities in the diffractive alignment between unmaking and more-than-human design: firstly, the notion of ‘unmaking-with’ as an emergent concept to describe a posthumanist unmaking practice, and secondly, three decentering tactics–situating, materializing, and enacting–that instantiate this practice through design. Finally, we discuss how unmaking can enrich more-than-human design and, conversely, how more-than-human design can help define the epistemological scope of unmaking.",
    "title": "Unmaking-with AI: Tactics for Decentering through Design",
    "id": 188291,
    "sequence": 82,
    "queryCoordinates": {
      "visualization": [
        3.508886718530673,
        -16.633932607670353
      ]
    }
  },
  {
    "session": "Multimodal AI for Human Sensing and Interaction",
    "abstract": "",
    "title": "Multimodal AI for Human Sensing and Interaction",
    "id": 188292,
    "sequence": 83,
    "queryCoordinates": {
      "visualization": [
        15.611234080616455,
        -3.5056198425099225
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "Tendon vibration can create movement illusions: vibrating the biceps tendon induces an illusion of extending the arm, while vibrating the triceps tendon induces an illusion of flexing the arm. However, it is unclear how to create and integrate such illusions shown in neuroscience to interaction techniques in virtual reality (VR). We first design a motor setup for tendon vibration. Study 1 validates that the setup induces movement illusions which on average create a 5.26 cm offset in active arm movements. Study 2 shows that tendon vibration improves the detection thresholds of visual motion gains often used in VR interaction techniques by 0.22. A model we developed in Study 2 predicts the effects of tendon vibration and is used in a biomechanical simulation to demonstrate the detection thresholds across typical reaching tasks in VR.",
    "title": "Tendon Vibration for Creating Movement Illusions in Virtual Reality",
    "id": 188293,
    "sequence": 84,
    "queryCoordinates": {
      "visualization": [
        11.186146795015484,
        -8.418439278177686
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "While much prior work on computational visual storytelling analyzes image content, it largely overlooks formal elements. This raises the question: how might particular cinematographic techniques shape a system's interpretation and narration of imagery? To investigate this question, we generate 60 responses from a Vision Language Model using a multi-faceted prompt paired with different still frames from Man with a Movie Camera (1929), a silent documentary film renowned for its innovative cinematography. We present three themes that highlight roles of cinematography in computational visual storytelling: (1) how AI discerns drama and power from camera shots and angles that portray social reality; (2) how AI (mis)interprets lighting and focus techniques that compose ambiguous reality; and (3) how AI navigates visual effects that render surreality. In turn, we look toward cinematic controls to reimagine users as directors of visual storytelling systems and discuss how expressive AI can support speculating about the past.",
    "title": "From Camera-Eye to AI: Exploring the Interplay of Cinematography and Computational Visual Storytelling",
    "id": 188294,
    "sequence": 85,
    "queryCoordinates": {
      "visualization": [
        17.8444249053545,
        -12.867653235814371
      ]
    }
  },
  {
    "session": "Empirical Research Methods for Human-Computer Interaction",
    "abstract": "",
    "title": "Empirical Research Methods for Human-Computer Interaction",
    "id": 188295,
    "sequence": 86,
    "queryCoordinates": {
      "visualization": [
        2.6124928235797418,
        -4.263200821770463
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "The topic of time and how it can be unpacked, deconstructed and designed with is fundamental to HCI, but it is also extensively engaged within artistic practice. By analysing a selection of ten media artworks, all in different ways concerned with time and temporality, we explore how artists approach these matters as culturally and politically loaded. The selected projects align with the ongoing scholarly interest in alternatives to common perceptions on time, unmaking the normative clock time and the posthuman discourse. Following an analysis of the theoretical and material expressions of these artworks, we conceptualised four themes through which unmaking was represented: dissecting temporality, the unmaking of the singular, unmaking as messing up and unmaking the other. We close with a discussion on how these themes intersect with the current discourse on unmaking in HCI and reflect on challenges and opportunities for design and theory.",
    "title": "Material Deconstructions of Time: Posthumanist Interventions Through Media Art",
    "id": 188296,
    "sequence": 87,
    "queryCoordinates": {
      "visualization": [
        -4.155737519115309,
        -7.9830974986039935
      ]
    }
  },
  {
    "session": "Workplace Interactions and Wellbeing",
    "abstract": "AI expansion has accelerated workplace adoption of new technologies. Yet, it is unclear whether and how knowledge workers are supported and trained to safely use AI. Inadequate training may lead to unrealized benefits if workers abandon tools, or perpetuate biases if workers misinterpret AI-based outcomes. In a workshop with 39 workers from 26 countries specializing in human resources, labor law, standards creation, and worker training, we explored questions and ideas they had about safely adopting AI. We held 17 follow-up interviews to further investigate what skills and training knowledge workers need to achieve safe and effective AI in practice. We synthesize nine training topics participants surfaced for knowledge workers related to challenges around understanding what AI is, misinterpreting outcomes, exacerbating biases, and worker rights. We reflect how these training topics might be addressed under different contexts, imagine HCI research prototypes as potential training tools, and consider ways to ensure training does not perpetuate harmful values.",
    "title": "Knowledge Workers' Perspectives on AI Training for Responsible AI Use",
    "id": 188297,
    "sequence": 88,
    "queryCoordinates": {
      "visualization": [
        2.714404498650743,
        9.624552364536473
      ]
    }
  },
  {
    "session": "Online Media and Community",
    "abstract": "HCI scholars are increasingly engaging in research about “marginalized groups,” such as LGBTQ+ people. While normative habitual readings of marginalized people in HCI often highlight real problems, this work has been criticized for flattening heterogeneous experiences and overemphasizing harms. Some have advocated for expanding how we approach research on marginalized people (e.g., assets-based design, the everyday, and joy). Sensitized by unmaking literature, we explore this tension between conditions, experiences, and representations of marginality in HCI scholarship. To do so, we perform a diffractive analysis of posts in a gay online community by bringing two readings of the same data together: a normative habitual reading of marginalization and an expanded reading. By examining the relationship between empirical material and its representations by HCI researchers, we explore how to carefully unmake HCI research, thus maintaining and repairing our research community. We discuss the political and designerly implications of different readings of marginalized people and offer considerations for attending to the processes and afterlives of HCI research.",
    "title": "Carefully Unmaking the “Marginalized User:” A Diffractive Analysis of a Gay Online Community",
    "id": 188298,
    "sequence": 89,
    "queryCoordinates": {
      "visualization": [
        18.99594191897069,
        -0.3926711233235317
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "Household energy use data may contain sensitive inferences into family life, yet its potential for surveillance is imperfectly understood. To explore this space, we developed Household Wattch, a speculative eco-feedback ‘provotype’ that profiles households according to their energy use data. Evaluated by 16 participants from Australian households engaged in an 18-month energy use monitoring trial, Household Wattch elicited users’ perceptions and expectations about a near future where energy use data is a useful yet potentially sensitive commodity when analysed. We highlight challenges and opportunities for energy use data across three scales: (1) Within the household, (2) Beyond the household (e.g., sharing energy data with third parties) and (3) Post-household (e.g., what happens to energy data when a household re-configures or disbands). Findings suggest users may require support in understanding the sensitivities of their energy use data, particularly when deciding whether to share it with third parties. Opportunities exist for accidental or deliberate surveillance via energy use data, and these need to be identified and managed. Provotypes represent a useful tool for navigating this space, and we provide considerations for how they can support users in speculating over possible energy futures.",
    "title": "Household Wattch: Exploring Opportunities for Surveillance and Consent through Families’ Household Energy Use Data",
    "id": 188299,
    "sequence": 90,
    "queryCoordinates": {
      "visualization": [
        10.45076548726043,
        12.115341544103753
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "HCI is future-oriented by nature: it explores new human--technology interactions and applies the findings to promote and shape vital visions of society. Still, the visions of futures in HCI publications seem largely implicit, techno-deterministic, narrow, and lacking in roadmaps and attention to uncertainties. A literature review centered on this problem examined futuring and its forms in the ACM Digital Library's most frequently cited HCI publications. This analysis entailed developing the four-category framework SPIN, informed by futures studies literature. The results confirm that, while technology indeed drives futuring in HCI, a growing body of HCI research is coming to challenge techno-centric visions. Emerging foci of HCI futuring demonstrate active exploration of uncertainty, a focus on human experience, and contestation of dominant narratives. The paper concludes with insight illuminating factors behind techno-centrism's continued dominance of HCI discourse, as grounding for five opportunities for the field to expand its contribution to futures and anticipation research.",
    "title": "Let’s Talk Futures: A Literature Review of HCI’s Future Orientation ",
    "id": 188300,
    "sequence": 91,
    "queryCoordinates": {
      "visualization": [
        7.1937812744737055,
        14.291588819128245
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "A large number of studies highlight the importance of regulation in collaborative learning (CL). Nevertheless, only some studies describe how to get or support pupils to learn to regulate group work in school. In this context, we aim to understand if a specifically designed tangible environment can promote a regulated collaboration process during a face-to-face activity in school. Therefore, we conducted a 2-year design-based research (DBR) study. This article describes the DBR cycles in detail, and the steps we have executed to develop, test, implement, and evaluate a set of tangible artifacts called Collective attention led by a Mediated environment (CalMe). First, we identified three specific dimensions that interfere with CL in the classroom: team building and collective decision-making, task regulation awareness, and over-solicitation limitation. Second, we proposed design choices leading to the first iteration of a CalMe device that meets these needs. We then assessed usability and acceptability before the pedagogical validation steps. Third, through a pilot study, we evaluated the pedagogical potential of the second iteration of the CalMe device in a real context of use in an elementary school class. We collected and analyzed data from surveys, focus groups, log data, and video recordings through all the steps. Moreover, to allow for duplication of the study, we propose and detail our methodological approach. This study shows an empirical example of a DBR process that allows responding as closely as possible to the needs of both pupils and teachers. This work also provides input to teachers regarding a better understanding of collaborative problem-solving activities. Although there is still room for improvement on specific dimensions related to task regulation, such as better management of ambient noise or work tempo, the results indicate that the CalMe device allows for a regulated collaboration process in schools. It shows an human–computer interaction design process that can be an example of how to influence classroom activities through technology to promote positive CL experiences.",
    "title": "CalMe: A Tangible Environment to Enhance Pupils Group Work Regulation",
    "id": 188301,
    "sequence": 92,
    "queryCoordinates": {
      "visualization": [
        -15.705952052691874,
        6.505618350206528
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "In organizations, the interest in automation is long-standing. However, adopting automated processes remains challenging, even in environments that appear highly standardized and technically suitable for it. Through a case study in Amsterdam Airport Schiphol, this paper investigates automation as a broader sociotechnical system influenced by a complex network of actors and contextual factors. We study practitioners' collective understandings of automation and subsequent efforts taken to implement it. Using imaginaries as a lens, we report findings from a qualitative interview study with 16 practitioners involved in airside automation projects. Our findings illustrate the organizational dynamics and complexities surrounding automation adoption, as reflected in the captured problem formulations, conceptions of the technology, envisioned human roles in autonomous operations, and perspectives on automation fit in the airside ecosystem. Ultimately,  we advocate for contextual automation design, which carefully considers human roles, accounts for existing organizational politics, and avoids techno-solutionist approaches. \r\n",
    "title": "Why does Automation Adoption in Organizations Remain a Fallacy?: Scrutinizing Practitioners' Imaginaries in an International Airport",
    "id": 188302,
    "sequence": 93,
    "queryCoordinates": {
      "visualization": [
        -5.927609002839674,
        5.372471638776146
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "This study investigates how 18-year-old students, parents, and experts in China utilize artificial intelligence (AI) tools to support decision-making in college applications during college entrance exam- a highly competitive, score-driven, annual national exam. Through 32 interviews, we examine the use of Quark GaoKao, an AI tool that generates college application lists and acceptance probabilities based on exam scores, historical data, preferred locations, etc. Our findings show that AI tools are predominantly used by parents with limited involvement from students, and often focus on immediate exam results, failing to address long-term career goals. We also identify challenges such as misleading AI recommendations, and irresponsible use of AI by third-party consultant agencies.  Finally, we offer design insights to better support multi-stakeholders' decision-making in families, especially in the Chinese context, and discuss how emerging AI tools create barriers for families with fewer resources.",
    "title": "From Scores to Careers: Understanding AI’s Role in Supporting Collaborative Family Decision-Making in Chinese College Applications",
    "id": 188303,
    "sequence": 94,
    "queryCoordinates": {
      "visualization": [
        -12.824335978542788,
        -11.15958810662172
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "AI-assisted learning companion robots are increasingly used in early education. Many parents express concerns about content appropriateness, while they also value how AI and robots could supplement their limited skill, time, and energy to support their children's learning. We designed a card-based kit, SET, to systematically capture scenarios that have different extents of parental involvement. We developed a prototype interface, PAiREd, with a learning companion robot to deliver LLM-generated educational content that can be reviewed and revised by parents. Parents can flexibly adjust their involvement in the activity by determining what they want the robot to help with. We conducted an in-home field study involving 20 families with children aged 3--5. Our work contributes to an empirical understanding of the level of support parents with different expectations may need from AI and robots and a prototype that demonstrates an innovative interaction paradigm for flexibly including parents in supporting their children.",
    "title": "SET-PAiREd: Designing for Parental Involvement in Learning with an AI-Assisted Educational Robot",
    "id": 188304,
    "sequence": 95,
    "queryCoordinates": {
      "visualization": [
        0.39261567222878524,
        -10.992991082226908
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "Dance teachers rely primarily on verbal instructions and visual demonstrations to convey key dance concepts and movement. These techniques, however, have limitations in supporting students who are blind or have low vision (BLV). This work explores the role technology can play in supporting instruction for BLV students, as well as improvisation with their instructor. Through a series of design workshops with dance instructors and BLV students, ideas were generated by physically engaging with probes featuring diverse modalities including tactile objects, a body tracked sound and musical probe, and a body tracked controller with vibrational feedback. Implications for the design of supporting technologies were discovered for four contemporary dance learning goals: learning a phrase; improvising; collaborating through movement; and awareness of body and movement qualities. We discuss the potential of numerous multi-sensory methods and artefacts, and present design considerations for technologies to support meaningful dance instruction and participation.",
    "title": "Sensing Movement: Contemporary Dance Workshops with People who are Blind or have Low Vision and Dance Teachers",
    "id": 188305,
    "sequence": 96,
    "queryCoordinates": {
      "visualization": [
        1.937848579973946,
        6.726421253615697
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Human psychological constructs form the cornerstone of our understanding of cognition, emotion, and behavior, which are crucial to health informatics and HCI studies. However, current psychological construct analyses may lack theoretical grounding, cultural sensitivity, context, and socio-digital tailored interventions. My thesis explores how these human-centered computing methods, in particular human-AI partnerships, can unravel psychological constructs, using mental health stigma as a case study. Specifically, the study takes a multi-faceted approach: designing conversational agents for multilingual, cross-national data collection from over 1,000 participants; conducting human-AI collaborative qualitative analysis to interpret the embodied psychological constructs; modeling causal relationships from human-chatbot conversations to decompose psychological factors and their interplay; dissecting cross-sociocultural variation; and exploring digital techniques for restructuring psychological constructs. The overall goal is to enhance human-centered AI approaches for psychological-construct analysis, foster cultural inclusivity, inform the design of culturally appropriate healthcare technologies, and promote social justice by operationalizing psychological constructs.",
    "title": "Leveraging Human-AI Partnership Approach to Unravel Human Psychological Constructs",
    "id": 188306,
    "sequence": 97,
    "queryCoordinates": {
      "visualization": [
        -12.613542842025701,
        -9.843705449290027
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "In high-stakes domains, deep analytical processing of online videos is essential for decision-making and knowledge acquisition. However, individuals may lack sufficient cognitive resources and triggers to engage in such processes. To address this, we introduce DeepThinkingMap, a collaborative video mapping system with affordances designed to leverage peers' thoughts and comments to promote reflective and critical thinking. Thee design supports collaborative mapping of video concepts and supports open deliberations of personal thoughts over concepts as \"thinking nudges\" to foster deeper thinking for themselves and others. Through two experimental studies, we investigated the potential of deeper thinking by accessing peers' thoughts in standalone and collaborative information work respectively. Results illustrated that accessing peers' comments enhances personal engagement in reflective and critical thinking, and reinforces their confidence in their correct beliefs toward the video topics. This work contributes to understanding the socio-technical-cognitive mechanism of thinking while accessing peer comments, and presents design implications for information and knowledge work.",
    "title": "Signals Beyond Text: Understanding How Accessing Peer Concept Mapping and Commenting Augments Reflective Mind for High-Stake Videos",
    "id": 188307,
    "sequence": 98,
    "queryCoordinates": {
      "visualization": [
        -10.916953881956172,
        7.058336768619224
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "By overlaying time-synced user comments on videos, Danmu creates a co-watching experience for online viewers. However, its visual-centric design poses significant challenges for blind and low vision (BLV) viewers. Our formative study identified three primary challenges that hinder BLV viewers' engagement with Danmu: the lack of visual context, the speech interference between comments and videos, and the disorganization of comments. To address these challenges, we present DanmuA11y, a system that makes Danmu accessible by transforming it into multi-viewer audio discussions. DanmuA11y incorporates three core features: (1) Augmenting Danmu with visual context, (2) Seamlessly integrating Danmu into videos, and (3) Presenting Danmu via multi-viewer discussions. Evaluation with twelve BLV viewers demonstrated that DanmuA11y significantly improved Danmu comprehension, provided smooth viewing experiences, and fostered social connections among viewers. We further highlight implications for enhancing commentary accessibility in video-based social media and live-streaming platforms.",
    "title": "DanmuA11y: Making Time-Synced On-Screen Video Comments (Danmu) Accessible to Blind and Low Vision Users via Multi-Viewer Audio Discussions",
    "id": 188308,
    "sequence": 99,
    "queryCoordinates": {
      "visualization": [
        0.39263936141154504,
        -12.994069198363935
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "Movement-based spatial interaction in VR can present significant challenges for people with limited mobility, particularly due to the mismatch between the upper body motion a VR app requires and the user's capabilities. We describe MotionBlocks, an approach which enables 3D spatial input with smaller motions or simpler input devices using modular geometric motion remapping. A formative study identifies common accessibility issues within VR motion design, and informs a design language of VR motions that fall within simple geometric primitives. These 3D primitives enable collapsing spatial or non-spatial input into a normalized input vector, which is then expanded into a second 3D primitive representing larger, more complex 3D motions. An evaluation with people with mobility limitations found that using geometric primitives for highly customized upper body input remapping reduced physical workload, temporal workload, and perceived effort.",
    "title": "MotionBlocks: Modular Geometric Motion Remapping for More Accessible Upper Body Movement in Virtual Reality",
    "id": 188309,
    "sequence": 100,
    "queryCoordinates": {
      "visualization": [
        7.59052301231597,
        -4.835696475121418
      ]
    }
  },
  {
    "session": "WS20: Resisting AI Solutionism: Where Do We Go From Here?",
    "abstract": "The latest advances in Artificial Intelligence (AI), such as Large Language Models (LLMs), have provoked a massive expansion and adoption of AI applications across the board, with seemingly no sector left untouched by recent developments. Anywhere we look, from healthcare to the creative industries, from education to entertainment, from sustainability to knowledge work, AI is being adopted and adapted, funded and fundraised for, developed and designed for, researched and used for doing research. As AI continues to be treated as a necessary and unquestioned solution for a range of societal problems, we seek to ponder and challenge its perceived suitability and inevitability. Moreover, we wonder how we can go about resisting AI solutionism (i.e., the idea that technology provides solutions to complex social problems) and who gets to resist it, in particular if the structures that surround people and their specific positions constrain them from doing so. This workshop will focus on gathering and sharing lessons from experiences resisting, or attempting to resist, AI solutionism; taking stock and revisiting previous learnings from decades of work within and beyond HCI; and envisioning ways, perspectives, tools, and practices to orient ourselves and each other towards more pluralistic futures.",
    "title": "Resisting AI Solutionism: Where Do We Go From Here?",
    "id": 188310,
    "sequence": 101,
    "queryCoordinates": {
      "visualization": [
        -19.08741402565643,
        -8.75617643798789
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "The human face and eyes provide crucial conversational cues about a person’s focus of attention. \r\nIn virtual reality applications, avatar faces are typically simplified, and eye movements often neglected. \r\nThis paper explores how VR users perceive the look-at direction of other avatars and estimates the range within which an avatar's averted gaze goes unnoticed.\r\nThrough two-alternative forced choice experiments, we investigate different gaze offsets to quantify thresholds for perceived gaze aversion across three conditions: gaze side (left/right), stimulus duration, and avatar distance.\r\nAdditionally, we assess the impact of averted gaze on social presence during interactions with an embodied conversational agent in a social game. \r\nA user study (N=40) revealed that social presence is significantly affected by averted gaze when noticed, and that detection thresholds are particularly impacted by stimuli duration and interactions between side and distance.\r\nOur findings provide a foundation for understanding gaze perception in social virtual reality.",
    "title": "Estimating Detection Thresholds of Being Looked at in Virtual Reality for Avatar Redirection",
    "id": 188311,
    "sequence": 102,
    "queryCoordinates": {
      "visualization": [
        15.989645362140653,
        -5.773321504383235
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "The advancement of large language models (LLMs) now allows users to actively interact with conversational recommendation systems (CRS) and build their own personalized recommendation services tailored to their unique needs and goals. This experience offers users a significantly higher level of controllability compared to traditional RS, enabling an entirely new dimension of recommendation experiences. Building on this context, this study explored the unique experiences that LLM-powered CRS can provide compared to traditional RS. Through a three-week diary study with 12 participants using custom GPTs for music recommendations, we found that LLM-powered CRS can (1) help users clarify implicit needs, (2) support unique exploration, and (3) facilitate a deeper understanding of musical preferences. Based on these findings, we discuss the new design space enabled by LLM-powered CRS and highlight its potential to support more personalized, user-driven recommendation experiences.",
    "title": "User Experience of LLM-based Recommendation Systems: A Case of Music Recommendation",
    "id": 188312,
    "sequence": 103,
    "queryCoordinates": {
      "visualization": [
        8.05083974399898,
        7.495597335532802
      ]
    }
  },
  {
    "session": "How to Design, Build, and Use Interactive Electrical Stimulation",
    "abstract": "Electrical stimulation is now becoming one of the key approaches to creating haptic sensations in interactive experiences. The recent rise of this approach has allowed many HCI researchers to push haptics into more and more domains, including when devices need to be small, portable, or even wearable. At its core, all these techniques share one underlying principle from neuroscience: they act on the users’ nervous system to create sensations electrically. As such, using these techniques requires not only getting hands-on experience with hardware, but also learning the fundamental principles, safety, and their possibilities and limitations. In our course, participants will get hands-on experience in using these technologies via hardware toolkits that we will supply.",
    "title": "How to Design, Build, and Use Interactive Electrical Stimulation",
    "id": 188313,
    "sequence": 104,
    "queryCoordinates": {
      "visualization": [
        -19.688391629423982,
        7.305288156289771
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "Unlike static and rigid user interfaces, generative and malleable user interfaces offer the potential to respond to diverse users’ goals and tasks. However, current approaches primarily rely on generating code, making it difficult for end-users to iteratively tailor the generated interface to their evolving needs. We propose employing task-driven data models—representing the essential information entities, relationships, and data within information tasks—as the foundation for UI generation. We leverage AI to interpret users’ prompts and generate the data models that describe users’ intended tasks, and by mapping the data models with UI specifications, we can create generative user interfaces. End-users can easily modify and extend the interfaces via natural language and direct manipulation, with these interactions translated into changes in the underlying model. The technical evaluation of our approach and user evaluation of the developed system demonstrate the feasibility and effectiveness of generative and malleable user interfaces.",
    "title": "Generative and Malleable User Interfaces with Generative and Evolving Task-Driven Data Model",
    "id": 188314,
    "sequence": 105,
    "queryCoordinates": {
      "visualization": [
        -14.871672920607157,
        -1.9578928833007698
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "We explore the metaphorical \"daily memory pill\" concept – a brief pictorial lifelog recap aimed at reviving and preserving memories. Leveraging psychological strategies, we explore the potential of such summaries to boost autobiographical memory.  We developed an automated lifelogging memory prosthesis and a research protocol (Automated Memory Validation ``AMV'') for conducting privacy-aware, in-situ evaluations. We conducted a real-world lifelogging experiment for a month (n=11). We also designed a browser ``Pixel Memories’’ for browsing one-week worth of lifelogs. The results suggest that daily timelapse summaries, while not yielding significant memory augmentation effects, also do not lead to memory degradation. Participants' confidence in recalled content remains unaltered, but the study highlights the challenge of users' overestimation of memory accuracy. Our core contributions, the AMV protocol and \"Pixel Memories\" browser, advance our understanding of memory augmentations and offer a privacy-preserving method for evaluating future ubicomp systems.",
    "title": "Pixel Memories: Do Lifelog Summaries Fail to Enhance Memory but Offer Privacy-Aware Memory Assessments?",
    "id": 188315,
    "sequence": 106,
    "queryCoordinates": {
      "visualization": [
        9.617956964488622,
        10.173244508476378
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "The advancement of Vision-Language Model (VLM) camera sensors, which enable autonomous understanding of household situations without user intervention, has the potential to completely transform the DIY smart home building experience. Will this simplify or complicate the DIY smart home process? Additionally, what features do users want to create using these sensors? To explore this, we conducted a three-week diary-based experience prototyping study with 12 participants. Participants recorded their daily activities, used GPT to analyze the images, and manually customized and tested smart home features based on the analysis. The study revealed three key findings: (1) participants’ expectations for VLM camera-based smart homes, (2) the impact of VLM camera sensor characteristics on the DIY process, and (3) users’ concerns. Through the findings of this study, we propose design implications to support the DIY smart home building process with VLM camera sensors, and discuss living with intelligence.",
    "title": "“What If Smart Homes Could See Our Homes?”: Exploring DIY Smart Home Building Experiences with VLM-Based Camera Sensors",
    "id": 188316,
    "sequence": 107,
    "queryCoordinates": {
      "visualization": [
        -20.703291388882953,
        3.5176306893994576
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "Good sleep hygiene is essential for quality sleep. This study investigates user preferences for the timing of interactions with features in smartwatch-based sleep hygiene games. Findings reveal that interactions during sleep are generally undesirable, with Sleep Health Points being the only exception. We also identified a misconception that games must involve active play, overlooking the potential of passive and idle game mechanics. Participants preferred engaging with planning and behavior-triggering features before the associated behavior, while reflection and reinforcement features, like reports and rewards, were favored post-behavior. The perceived dual functionality of certain features suggests that preferred interaction timing depends on users' perceptions of the features’ roles. Users' schedules and situational context, especially evening availability, also influenced their preferences. This study highlights the importance of aligning feature timing with user routines and perceptions, and advocates for game designs that blend active and passive elements to boost engagement and promote sleep hygiene.  ",
    "title": "User Preferences for Interaction Timing in Smartwatch Sleep Hygiene Games",
    "id": 188317,
    "sequence": 108,
    "queryCoordinates": {
      "visualization": [
        -9.986568514523645,
        8.322766926012346
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "Neuromorphic technology offers advantages such as low-power processing, low latency, adaptive learning, and noise tolerance, making it ideal for edge computing applications. However, developers face significant hurdles due to the nascent nature of the field, including limited access to hardware and software, lack of benchmarks, and the need for deep interdisciplinary knowledge. Through interviews with 12 practitioners from both industry and academia, we conducted a thematic analysis to understand the current landscape of neuromorphic programming and identified key challenges, workflows, and potential solutions for enhancing accessibility and adoption. Our findings led to a set of guidelines for creating more accessible software development tools and platforms for those looking to create neuromorphic applications. Through this work, we aim to bridge the gap between neuromorphic computing and the HCI community, promoting the design of more intuitive and effective interfaces for neuromorphic development, and ultimately facilitating the creation of edge intelligent systems.\r\n",
    "title": "Designing Accessible and Intuitive Developer Tools for Neuromorphic Programming",
    "id": 188318,
    "sequence": 109,
    "queryCoordinates": {
      "visualization": [
        -17.654135047258148,
        3.511625796290315
      ]
    }
  },
  {
    "session": "CS Education and Security",
    "abstract": "The shooting of Nahel Merzouk in June 2023 ignited widespread protests across France, known as the ``Justice Pour Nahel'' movement, drawing attention to the privacy and security risks faced by protesters. This study explores the discourse on Twitter during the protests, focusing on digital surveillance and censorship concerns. We analyzed 341 tweets using qualitative methods to understand the security and privacy attitudes and advice shared by French-speaking users. Our findings reveal a strong apprehension toward increased long-term government surveillance and censorship, with limited and often low-tech advice on how to counteract these threats. We highlight the discrepancy between the concerns raised and the available guidance and compare our findings with those of prior work. Grounded in our analysis and informed by prior research, we offer targeted recommendations for activists, policymakers, and researchers to mitigate security and privacy concerns arising from social unrest, both in France and globally.\r\n",
    "title": "Exploring Security and Privacy Discourse on Twitter During the `Justice Pour Nahel' Movement in France",
    "id": 188319,
    "sequence": 110,
    "queryCoordinates": {
      "visualization": [
        -4.240636259871312,
        -12.28889759545032
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "3D-printed models are increasingly used to provide people who are blind or have low vision (BLV) with access to maps, educational materials, and museum exhibits. Recent research has explored interactive 3D-printed models (I3Ms) that integrate touch gestures, conversational dialogue, and haptic vibratory feedback to create more engaging interfaces. Prior research with sighted people has found that imbuing machines with human-like behaviours, i.e., embodying them, can make them appear more lifelike, increasing social perception and presence. Such embodiment can increase engagement and trust. This work presents the first exploration into the design of embodied I3Ms and their impact on BLV engagement and trust. In a controlled study with 12 BLV participants, we found that I3Ms using specific embodiment design factors, such as haptic vibratory and embodied personified voices, led to an increased sense of liveliness and embodiment, as well as engagement, but had mixed impact on trust.",
    "title": "\"It Brought the Model to Life\": Exploring the Embodiment of Multimodal I3Ms for People who are Blind or have Low Vision",
    "id": 188320,
    "sequence": 111,
    "queryCoordinates": {
      "visualization": [
        -8.314915792601582,
        -3.444150891285807
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "Social Virtual Reality (VR) presents a promising avenue for older adults to connect with others and engage in collaborative activities remotely.  However, many social VR experiences focus on individual tasks, reducing opportunities for meaningful social interaction. To investigate the potential of VR to enhance engagement with other participants, this paper explores two modes of coupling: (i) loosely coupled, where participants focus on their individual tasks within a collaborative setting, and (ii) tightly coupled, where participants need to rely on each other’s assistance to complete their tasks. We conducted a user study with 20 older adults to evaluate how these modes affect task performance and engagement. Results show that the tightly coupled mode, focused on collaboration, increases engagement, while the loosely coupled mode, centers on individual tasks, improves performance in time and attempts. We provide guidelines for collaborative VR applications to enhance social engagement and interaction among older adults.",
    "title": "Exploring the Effects of Social VR Coupling Modes on Engagement and Task Performance for Older Adults",
    "id": 188321,
    "sequence": 112,
    "queryCoordinates": {
      "visualization": [
        20.90827365776381,
        -1.9606357775119538
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "Large language models (LLMs) are being increasingly integrated into everyday products and services, such as coding tools and writing assistants. As these embedded AI applications are deployed globally, there is a growing concern that the AI models underlying these applications prioritize Western values. This paper investigates what happens when a Western-centric AI model provides writing suggestions to users from a different cultural background. We conducted a cross-cultural controlled experiment with 118 participants from India and the United States who completed culturally grounded writing tasks with and without AI suggestions. Our analysis reveals that AI provided greater efficiency gains for Americans compared to Indians. Moreover, AI suggestions led Indian participants to adopt Western writing styles, altering not just what is written but also how it is written. These findings show that Western-centric AI models homogenize writing toward Western norms, diminishing nuances that differentiate cultural expression.",
    "title": "AI Suggestions Homogenize Writing Toward Western Styles and Diminish Cultural Nuances",
    "id": 188322,
    "sequence": 113,
    "queryCoordinates": {
      "visualization": [
        16.778236307100176,
        -2.7369301092840193
      ]
    }
  },
  {
    "session": "Perception of Systems",
    "abstract": "In this research, we explored the efficacy of various warning label designs for AI-generated content on social media platforms---e.g., \\textit{deepfakes}. We devised and assessed ten distinct label design samples that varied across the dimensions of sentiment, color/iconography, positioning, and level of detail. Our experimental study involved 911 participants randomly assigned to these ten label designs and a control group evaluating social media content. We explored their perceptions relating to 1) Belief in the content being AI-generated, 2) Trust in the labels and 3) Social Media engagement perceptions of the content. The results demonstrate that the presence of labels had a significant effect on the user's belief that the content is AI-generated, deepfake, or edited by AI. However their trust in the label significantly varied based on the label design. Notably, having labels did not significantly change their engagement behaviors, such as 'like', comment, and sharing. However, there were significant differences in engagement based on content type: political and entertainment. This investigation contributes to the field of human-computer interaction by defining a design space for label implementation and providing empirical support for the strategic use of labels to mitigate the risks associated with synthetically generated media.",
    "title": "Labeling Synthetic Content: User Perceptions of Label Designs for AI-Generated Content on Social Media",
    "id": 188323,
    "sequence": 114,
    "queryCoordinates": {
      "visualization": [
        5.785910375456892,
        -17.04474233091191
      ]
    }
  },
  {
    "session": "Social Media, Online Community, Sensemaking",
    "abstract": "While data is the cornerstone of modern design strategies, design researchers frequently struggle when performing data work. This creates a need to design tools that enable design researchers to actively engage with data. However, this presupposes understanding how design researchers create meaning from data representations, as the way of visualizing the data, along with other factors, can significantly impact the extracted insights, increasing uncertainty about the quality of the outcome. As a response to this problem, we explore how design researchers make sense of data in a case study: making sense of paired subjective and objective sleep and stress data visualizations. By synthesizing our findings from two user studies, we construct a sensemaking model which highlights how uncertainty related to data qualities, visualization parameters, and the viewer’s background, affects the insight-generation process. Our findings have implications for the future development of tools and techniques for visual data sensemaking for designers.",
    "title": "How Design Researchers Make Sense of Data Visualizations in Data-Driven Design: An Uncertainty-aware Sensemaking Model",
    "id": 188324,
    "sequence": 115,
    "queryCoordinates": {
      "visualization": [
        -0.3926393614115524,
        12.994069198363935
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "Smart home applications aim to increase convenience, yet often require authentication to protect sensitive data. This is non-trivial: effortful authentication contradicts intended convenience, the multitude of devices raises scalability issues, many devices lack suitable interfaces, and the presence of other inhabitants requires intentional and acceptable interactions. To address these issues, we explored new and creative authentication interactions with an interaction relabelling approach using everyday objects. We conducted six focus group workshops with 20 participants in a living room and a kitchen setting that resulted in a variety of creative authentication interactions with analogue and digital objects. Furthermore, participants created authentication interactions based on tasks that they have to or wish to perform anyway such as cleaning the kitchen - thus primary tasks. This led us to explore the option to transform authentication from being an additional, secondary task towards using primary tasks further in an online study with 194 participants. Relevant implications in terms of acceptable authentication task characteristics, user perceptions, arising security challenges, and psychological habit research are discussed.",
    "title": "Authenticate As You Go: From Exploring Smart Home Authentication with Daily Objects to Authenticating with Primary Tasks",
    "id": 188325,
    "sequence": 116,
    "queryCoordinates": {
      "visualization": [
        -15.192450889488587,
        -5.018907846382265
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "Head pointing is widely used for hands-free input in head-mounted displays (HMDs). The primary role of head movement in an HMDisto control the viewport based on absolute mapping of head rotation to the 3D environment. Head pointing is conventionally supported by the same 1:1 mapping of input with a cursor fixed in the centre of the view, but this requires exaggerated head movement and limits input granularity. In this work, we propose to adopt dynamic gain to improve ergonomics and precision, and introduce the HeadShift technique. The design of HeadShift is grounded in natural eye-head coordination to manage control of the viewport and the cursor at different speeds. We evaluated HeadShift in a Fitts’ Law experiment and on three different applications in VR, finding the technique to reduce error rate and effort. The findings are significant as they show that gain can be adopted effectively for head pointing while ensuring that the cursor is maintained within a comfortable eye-in-head viewing range.",
    "title": "HeadShift: Head Pointing with Dynamic Control-Display Gain",
    "id": 188326,
    "sequence": 117,
    "queryCoordinates": {
      "visualization": [
        14.382296023022896,
        4.26023017055884
      ]
    }
  },
  {
    "session": "Inclusive and Participatory",
    "abstract": "Personal health informatics systems have been centered around individual efforts, overlooking the role of social factors in health. Over seven years of research (N = 153), we examined how socially-enabled personal informatics systems can support physical activity—a behavior critical in promoting physical and mental health. We prioritized exploring this topic with families in low-socioeconomic status (SES) neighborhoods because they face increased barriers to being active due to inequities. Through our systems development, qualitative studies, and theoretical foundation, we developed the Socio-Cognitive Framework for Personal Health Informatics systems that shows how five socio-cognitive concepts (aspirations, data exposure, stories, belongingness, and impediments) influence self-efficacy and outcome expectations that are linked to health behavior. We then provide recommendations on how to design and evaluate such systems. We further argue that socially-enabled health informatics tools can support marginalized communities in reducing health disparities through the collective efforts of families, neighbors, and peers.",
    "title": "Socio-Cognitive Framework for Personal Informatics: A Preliminary Framework for Socially-Enabled Health Technologies",
    "id": 188327,
    "sequence": 118,
    "queryCoordinates": {
      "visualization": [
        10.880615565184316,
        10.325318635406308
      ]
    }
  },
  {
    "session": "Sketching in HCI",
    "abstract": "Sketching is one of few analogue skills that retains its power in a world where technology is king. Why? Because sketching is more than just the generation of visuals – sketching employs the mind to make sense of the world around us, it works through our problems, inspires others, presents information and even brings joy. By harnessing the power of sketching for your own research, study or practice, you enable an externalisation of human thought, which can be shared, adapted and built upon. In this course we invite you to ’take a line for a walk’ but bring yourself along for the ride. Sketch alongside us as we guide you through a journey of discovery, enabling you to go on to share you knowledge with others. It starts with a scribble...",
    "title": "Sketching in HCI: Scribble, Sketch, Elaborate, Teach",
    "id": 188328,
    "sequence": 119,
    "queryCoordinates": {
      "visualization": [
        4.988817673815272,
        3.333421398117612
      ]
    }
  },
  {
    "session": "Research Methods for People in a Hurry",
    "abstract": "Regardless of what area of computer-human interaction, psychology, computer science, or human factors you may be most closely part of, a solid understanding of research methods drawing from the traditions of experimental psychology and human factors will serve you well—as a student, practitioner, or instructor. Our aim in designing this workshop is to provide a primer on research methods for people with limited experience and which can be a refresher for those with substantial experience. The course is intended to be highly interactive and will provide opportunities for using the techniques we will discuss. This course builds on what we have learned from the successful 2022 CHI course Research Methods for People in a Hurry.",
    "title": "Research Methods for People in a Hurry",
    "id": 188329,
    "sequence": 120,
    "queryCoordinates": {
      "visualization": [
        -1.1747357299804646,
        -8.923003752364293
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "This article presents findings from a Research through Design investigation focusing on a reflexive approach to data curation and the use of generative AI in design and creative practices. Using binary gender categories manifested in children’s toys as a context, we examine three design experiments aimed at probing how designers can cultivate a reflexive human-AI practice to confront and challenge their internalized biases. Our goal is to underscore the intricate interplay between the designer, AI technology, and publicly held imaginaries and to offer an initial set of tactics for how personal biases and societal norms can be illuminated through interactions with AI. We conclude by proposing that designers not only bear the responsibility of grappling critically with the complexities of AI but also possess the opportunity to creatively harness the limitations of technology to craft a reflexive data curation that encourages profound reflections and awareness within design processes.",
    "title": "Reflexive Data Curation: Opportunities and Challenges for Embracing Uncertainty in Human-AI Collaboration",
    "id": 188330,
    "sequence": 121,
    "queryCoordinates": {
      "visualization": [
        -6.7264212536156975,
        -1.9378485799739447
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "Self-determination theory (SDT), a psychological theory of human motivation, is a prominent paradigm in human–computer interaction (HCI) research on games. However, our prior literature review observed a trend towards shallow applications of the theory. This follow-up work takes a broader view—examining SDT scholarship on games, a wider corpus of SDT-based HCI games research (N = 259), and perspectives from a games industry practitioner conference—to help explain current applications of SDT. Our findings suggest that perfunctory applications of the theory in HCI games research originate in part from within SDT scholarship on games, which itself exhibits limited engagement with theoretical tenets. Against this backdrop, we unpack the popularity of SDT in HCI games research and identify conditions underlying the theory’s current use as an oft-unquestioned paradigm. Finally, we outline avenues for more productive SDT-informed games research and consider ways towards more intentional practices of theory use in HCI.",
    "title": "Self-Determination Theory and HCI Games Research: Unfulfilled Promises and Unquestioned Paradigms",
    "id": 188331,
    "sequence": 122,
    "queryCoordinates": {
      "visualization": [
        13.338851718120548,
        4.251474431534606
      ]
    }
  },
  {
    "session": "Conversational Voice Interfaces",
    "abstract": "HCI research has for long been dedicated to better and more nat- urally facilitating information transfer between humans and ma- chines. Unfortunately, humans’ most natural form of communi- cation, speech, is also one of the most difficult modalities to be understood by machines – despite, and perhaps, because it is the highest-bandwidth communication channel we possess. As signifi- cant research efforts in engineering have been spent on improving machines’ ability to understand speech, research is only begin- ning to make the same improvements in understanding how to appropriately design these speech interfaces to be user-friendly and adoptable. Issues such as variations in error rates when pro- cessing speech, and difficulties in learnability and explainability (to name a few), are often in contrast with claims of success from industry. Along with this, designers themselves are making the transition to designing for speech and voice-enabled interfaces. Recent research has demonstrated the struggle for designers to translate their current experiences in graphical user interface de- sign into speech interface design. Research has also noted the lack of any user-centered design principles or consideration for usability or usefulness in the same ways as graphical user interfaces have benefited from heuristic design guidelines.\r\nThe goal of this course is to inform the CHI community of the current state of speech and natural language research, to dispel some of the myths surrounding speech-based interaction, as well as to inform participants about currently existing design tools, meth- ods and resources for speech interfaces (and provide hands-on experience with working with them). Through this, we hope that HCI researchers and practitioners will learn how to combine re- cent advances in speech processing with user-centred principles in designing more usable and useful speech-based interactive systems.",
    "title": "Conversational Voice Interfaces: Translating Research Into Actionable Design",
    "id": 188332,
    "sequence": 123,
    "queryCoordinates": {
      "visualization": [
        -14.95376000599692,
        1.1768864359176827
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "Live action roleplay (larp) has a wide range of applications and can be relevant in relation to HCI. While there has been research about larp in relation to topics such as embodied interaction, playfulness, and futuring published in HCI venues since the early 2000s, there is not yet a compilation of this knowledge. In this article, we synthesize knowledge about larp and larp-adjacent work within the domain of HCI. We present a practitioner overview from an expert group of larp researchers, the results of a literature review, and highlight particular larp research exemplars which all work together to showcase the diverse set of ways that larp can be utilized in relation to HCI topics and research. This article identifies the need for further discussions toward establishing best practices for utilizing larp in relation to HCI research, as well as advocating for increased engagement with larps outside academia.",
    "title": "Why Larp? A Synthesis Article on Live Action Roleplay in Relation to HCI Research and Practice",
    "id": 188333,
    "sequence": 124,
    "queryCoordinates": {
      "visualization": [
        11.900300104368524,
        -9.131421435130815
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "When people need help from their supervisors or peers, they often have to manage up to get things done. However, unlike managing subordinates (managing down), managing people of equal or higher status (managing up) are not obligated to help. These requests often involve collaborative tasks between requesters and performers. Through interviews, we found that these collaborative tasks require coordination work that is not materialized in existing management tools. We also found that requesters are willing to take on this coordination work to see their requests fulfilled. To address this issue, we propose a system called TaskLight, which allows requesters to handle coordination work themselves. For example, requesters can collect useful context and information for their performers. We conducted two deployment studies and found that TaskLight leads to better outcomes because requesters are able to assist performers more effectively. Our findings demonstrate a new way to reduce the social burdens of managing up and improve collaboration.",
    "title": "“I Really Need Your Help with This Work...”: A System for Navigating the Tricky Terrain of Managing Up by Leveraging One’s Motivation to Get Things Done",
    "id": 188334,
    "sequence": 125,
    "queryCoordinates": {
      "visualization": [
        10.162674857624152,
        -4.209517756015995
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "Crowdsourcing tasks have been widely used to collect a large number of human labels at scale. While some of these tasks are deployed by requesters and performed only once by crowd workers, others require the same worker to perform the same task or a variant of it more than once, thus participating in a so-called longitudinal study. Despite the prevalence of longitudinal studies in crowdsourcing, there is a limited understanding of factors that influence worker participation in them across different crowdsourcing marketplaces. We present results from a large-scale survey of 300 workers on 3 different micro-task crowdsourcing platforms: Amazon Mechanical Turk, Prolific and Toloka. The aim is to understand how longitudinal studies are performed using crowdsourcing. We collect answers about 547 experiences and we analyze them both quantitatively and qualitatively. We synthesize 17 take-home messages about longitudinal studies together with 8 recommendations for task requesters and 5 best practices for crowdsourcing platforms to adequately conduct and support such kinds of studies. We release the survey and the data at: https://osf.io/h4du9/.",
    "title": "Longitudinal Loyalty: Understanding The Barriers To Running Longitudinal Studies On Crowdsourcing Platforms",
    "id": 188335,
    "sequence": 126,
    "queryCoordinates": {
      "visualization": [
        10.450765487260428,
        -12.115341544103753
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "They become insolent! To flaunt their evil plan in our faces---this may yet spell their downfall.",
    "title": "Evil Autistic Master Plan For Academia: HCI Edition",
    "id": 188336,
    "sequence": 127,
    "queryCoordinates": {
      "visualization": [
        10.992991082226908,
        -0.392615672228785
      ]
    }
  },
  {
    "session": "Living with Dementia or Visual Impairments",
    "abstract": "Intertemporal reflection, flexibly thinking forward and backward in time, is vital for one's future planning. Yet, cultivating intertemporal reflection about encountering difficult futures, e.g., developing a progressive cognitive condition like dementia, can be challenging. We assessed people's attitudes towards dementia following conversing with a chatbot presented as either neurotypical or simulating dementia symptoms. While neither the chatbot’s presentation nor the framing of participants’ future selves impacted attitudes toward dementia, it influenced participants' experiences. When framed as future selves, the chatbot evoked a strong emotional connection, leading to reflection on aging, particularly with the chatbot simulating dementia symptoms. Participants interacting with the chatbot framed as a stranger with simulated symptoms often felt frustrated, especially when they had a task-oriented mindset. Chatbots can be promising tools for prompting reflections on challenging futures, such as dementia, although their effectiveness varies due to the tensions between simulated cognitive decline and expectations for effective communication.",
    "title": "Challenging Futures: Using Chatbots to Reflect on Aging and Dementia",
    "id": 188337,
    "sequence": 128,
    "queryCoordinates": {
      "visualization": [
        20.179263760847093,
        5.813545739921836
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Trust & Safety (T&S) teams have become vital parts of tech platforms; ensuring safe platform use and combating abuse, harassment, and misinformation. However, between 2021 and 2023, T&S teams faced significant layoffs, impacted by broader downsizing in the tech industry. In addition, a reduction in T&S teams has also been attributed to partisan pressure against content moderation efforts designed to mitigate the spread of election and COVID-19-related misinformation. Accordingly, there exist crucial questions over the future of content moderation and T&S in the digital information environment, questions central to the work of CHI researchers interested in intervening in online harm through design, policy and user research. Through in-depth interviews with T&S professionals, this paper explores upheavals within the T&S industry, examining current perspectives of content moderation and broader strategies for maintaining safe digital environments.",
    "title": "The End of “Trust and Safety”?: Examining the Future of Content Moderation and Upheavals in Professional Online Safety Efforts",
    "id": 188338,
    "sequence": 129,
    "queryCoordinates": {
      "visualization": [
        -10.838231749957629,
        -17.98701566503489
      ]
    }
  },
  {
    "session": "With AI",
    "abstract": "Speech-to-text technologies have been shown to improve text input efficiency and potentially lower the barriers to writing. Recent LLM-assisted dictation tools aim to support writing with speech by bridging the gaps between speaking and traditional writing. This case study reports on the real-world writing experiences of twelve academic or creative writers using one such tool, Rambler, to write various pieces such as blog posts, diaries, screenplays, notes, or fictional stories, etc. Through a ten-day diary study, we identified the participants’ in-context writing strategies using Rambler, such as how they expanded from an outline or organized their loose thoughts for different writing goals. The interviews uncovered the psychological and productivity affordances of writing with speech, pointing to future directions of designing for this writing modality and the utilization of AI support.",
    "title": "Rambler in the Wild: A Diary Study of LLM-Assisted Writing With Speech",
    "id": 188339,
    "sequence": 130,
    "queryCoordinates": {
      "visualization": [
        -0.3926156722287841,
        10.99299108222691
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "The COVID-19 pandemic temporarily disrupted the operations of on-demand ride-sourcing digital labour platforms like Uber and Ola, severely impacting gig workers' labour opportunities. In response, the Kolkata Ola-Uber App-Cab Operator and Drivers Union in West Bengal, India, mobilised an alternate socio-technical infrastructure by operating emergency transport and taxi ambulance services. Our ethnographic study explores how this initiative leveraged technologies to structure and coordinate hybrid sites of action and ‘generate’ a labour market without profit motive to support the public health infrastructure. Our paper highlights the significance of what we call the gig worker union's ‘generative politics’ in creating resources to support workers and citizens, facilitating political action beyond protest politics, contributing to new counter-hegemonic formations, and shaping collective action centered around regeneration and care for the city and life under capitalism. We contribute to the HCI literature by offering insights to design alternate and participatory socio-technical infrastructures that challenge the hegemony of digital labour platforms.\r\n",
    "title": "Generative Politics and Labour Markets: Unions and Collective Life in a City in Crisis",
    "id": 188340,
    "sequence": 131,
    "queryCoordinates": {
      "visualization": [
        -9.280808951595283,
        14.243124137772192
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "In contrast to traditional industrial robots, collaborative robots are developed with the intention of allowing for close-proximity physical interaction between humans and robots. Current definitions of collaborative robots provide a pragmatic starting point for establishing safety guidelines, choosing operating parameters, and implementing organisational changes, but remain predicated on technological conceptions that prioritise a conscious split between people and robots, with the surrounding world as merely a physical site for interaction. In this paper, we take a postphenomenological perspective on robots in an investigation of human-world relations that robots can give rise to. This perspective can help elucidate the nature of such relations in a design process. Our investigation is anchored in an 8-month research study that aimed to, first, identify opportunities for a robot integration within a medical manufacturing facility and, second, facilitate a design and implementation process of a proof-of-concept robotic system in collaboration with workers. The paper contributes with an empirically anchored postphenomenological analysis of how human-world relations played out in the design process of a collaborative robotic system. Finally, we elaborate on the utility and limitations of a postphenomenological lens for design research.",
    "title": "Articulating Human-World Relations from Co-Designing a Collaborative Robotic System",
    "id": 188341,
    "sequence": 132,
    "queryCoordinates": {
      "visualization": [
        14.243124137772192,
        9.280808951595285
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "Programming education is increasingly seen as an important curricular component of non-Computer Science (CS) disciplines at the undergraduate level. While existing research has studied non-CS majors' experiences in introductory programming courses, there is limited work that explores such experiences across universities and disciplines. To address this gap, we conducted semi-structured interviews with 12 non-CS major programming students across several majors and universities and interpreted the results through reflexive thematic analysis. Our findings suggest that while students are excited about and interested in learning programming, they face barriers that often arise from the design of the courses they take and a lack of targeted resources and tools to support them. Building on our findings, we conclude with a set of recommendations for the design of tools, artifacts, and courses that can support programming education for non-major students.",
    "title": "“Even Though I Went Through Everything, I Didn’t Feel Like I Learned a Lot”: Insights From Experiences of Non-Computer Science Students Learning to Code",
    "id": 188342,
    "sequence": 133,
    "queryCoordinates": {
      "visualization": [
        12.867653235814364,
        -17.844424905354504
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "Encounters with virtual agents currently lack the haptic viscerality of human contact. While digital biosignal communication can mediate such virtual social interactions, how artificial haptic biosignals influence users’ personal space during Virtual Reality (VR) experiences is unknown. Designing vibrotactile heartbeats and thermally-actuated body temperature, we ran a within-subjects study (N=31) to investigate feedback (Thermal, Vibration, Thermal+Vibration, None) and agent stories (Negative, Neutral, Positive) on objective and subjective interpersonal distance (IPD), perceived arousal and comfort, presence, and post-experience responses. Findings showed that thermal feedback decreased objective but not subjective IPD, whereas vibrotactile heartbeats (signaling agent's closeness) increased both while heightening arousal and discomfort. Agents' stories did not affect IPD, arousal, or comfort. Our qualitative findings shed light on signal ambiguity and presence constructs within VR-based haptic stimulation. We contribute insights into artificial biosignals and their influence on VR proxemics, with cautionary considerations should the boundaries blur between physical and virtual touch.",
    "title": "Haptic Biosignals Affect Proxemics Toward Virtual Reality Agents",
    "id": 188343,
    "sequence": 134,
    "queryCoordinates": {
      "visualization": [
        -16.660420146115932,
        -12.78399000918314
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "Contemporary research in Virtual Reality (VR) for users who are visually impaired often employs navigation and interaction modalities that are either non-conventional or constrained by physical spaces or both. We designed and examined a hapto-acoustic VR system that mitigates this by enabling non-visual exploration of large virtual environments using white cane simulation and walk-in place locomotion. The system features a complex urban cityscape incorporating a physical cane prototype coupled with a virtual cane for rendering surface textures and an omnidirectional slide mill for navigation. In addition, spatialized audio is rendered based on the progression of sound through the geometry around the user. A study involving twenty sighted participants evaluated the system through three formative tasks while blindfolded to simulate absolute blindness. 19/20 participants successfully completed all the tasks while effectively navigating through the environment. This work highlights the potential for accessible non-visual VR experiences requiring minimal training and limited prior VR exposure.",
    "title": "Virtual Worlds Beyond Sight: Designing and Evaluating an Audio-Haptic System for Non-Visual VR Exploration",
    "id": 188344,
    "sequence": 135,
    "queryCoordinates": {
      "visualization": [
        -3.444150891285813,
        -8.314915792601578
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "Machine learning (ML) is increasingly used in high-stakes settings, yet multiplicity – the existence of multiple good models – means that some predictions are essentially arbitrary. ML researchers and philosophers posit that multiplicity poses a fairness risk, but no studies have investigated whether stakeholders agree. In this work, we conduct a survey to see how multiplicity impacts lay stakeholders’ – i.e., decision subjects’ – perceptions of ML fairness, and which approaches to address multiplicity they prefer. We investigate how these perceptions are modulated by task characteristics (e.g., stakes and uncertainty). Survey respondents think that multiplicity threatens the fairness of model outcomes, but not the appropriateness of using the model, even though existing work suggests the opposite. Participants are strongly against resolving multiplicity by using a single model (effectively ignoring multiplicity) or by randomizing the outcomes. Our results indicate that model developers should be intentional about dealing with multiplicity in order to maintain fairness.",
    "title": "Perceptions of the Fairness Impacts of Multiplicity in Machine Learning",
    "id": 188345,
    "sequence": 136,
    "queryCoordinates": {
      "visualization": [
        8.99143399423672,
        -0.392574486288024
      ]
    }
  },
  {
    "session": "Understanding and Working with Algorithms",
    "abstract": "We present an exploratory study on how people perceive visualizations of spatial social networks generated by edge bundling algorithms. Although these algorithms successfully minimize clutter in node-link diagrams, they do so through various methods that can sometimes create false connections between nodes. We conducted a qualitative experiment involving participants with technical expertise but no prior knowledge of edge bundling algorithms. Participants described their perceptions of both bundled and straight-line visualizations in open-ended tasks. Analysis of their annotations and transcripts revealed a general preference for bundled visualizations. However, when it came to false connections, participants tended to follow them in tightly bundled diagrams while also vocalizing that these drawings were more ambiguous. The routing of bundles influenced the perception of clusters and participants assigned more or fewer nodes to the clusters, depending on the routing of bundles. Participants' unfamiliarity with the dataset led them to use analogies to describe the bundled drawings, potentially adding perceived semantic meaning to the data.",
    "title": "How Do People Perceive Bundling? An Experiment",
    "id": 188346,
    "sequence": 137,
    "queryCoordinates": {
      "visualization": [
        9.992290362407228,
        -0.3925981575906861
      ]
    }
  },
  {
    "session": "Personal Data and Decision-Making",
    "abstract": "Crisis maps are regarded as crucial tools in crisis communication, as demonstrated during the COVID-19 pandemic and climate change crises. However, there is limited understanding of how public audiences engage with these maps and extract essential information. Our study investigates the sensemaking of young, digitally native viewers as they interact with crisis maps. We integrate frameworks from the learning sciences and human-data interaction to explore sensemaking through two empirical studies: a thematic analysis of online comments from a New York Times series on graph comprehension, and interviews with 18 participants from German-speaking regions. Our analysis categorizes sensemaking activities into established clusters: inspecting, engaging with content, and placing, and introduces responding personally to capture the affective dimension. We identify friction points connected to these clusters, including struggles with color concepts, responses to missing context, lack of personal connection, and distrust, offering insights for improving crisis communication to public audiences.",
    "title": "Encountering Friction, Understanding Crises: How Do Digital Natives Make Sense of Crisis Maps?",
    "id": 188347,
    "sequence": 138,
    "queryCoordinates": {
      "visualization": [
        -4.9845866686656395,
        -0.3922954786392241
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "This paper reports on a field study of the WavData Lamp: an interactive lamp that can physically visualize people’s music listening data by changing light colors and outstretching its form enclosure. We deployed five WavData Lamps to five participants' homes for two months to investigate their composite relation with a data-physicalized thing. Findings reveal that their music-listening norms were determined by the instantiated materiality of the Lamp in the early days. With a tilted form enclosure, the WavData Lamp successfully engendered rich actions and meanings of the cohabiting participants and their family members. In the end, the participants described their experiences of entangling with and living with the Lamp as a form of collaboration. Reflecting on these empirical insights explicitly extends the intrinsic meaning of the composite relation and offers rich implications to promote further HCI explorations and practices.",
    "title": "Investigating Composite Relation with a Data-Physicalized Thing through the Deployment of the WavData Lamp",
    "id": 188348,
    "sequence": 139,
    "queryCoordinates": {
      "visualization": [
        9.807852804032304,
        1.9509032201612824
      ]
    }
  },
  {
    "session": "Build Your AI Robot",
    "abstract": "How can we design robots that intuitively understand and respond to human needs? This interdisciplinary course bridges robotics and human-computer interaction, teaching participants to build and program a Raspberry Pi-based robot controllable through flexible natural language prompts. Students will gain hands-on experience in rapid prototyping, computer vision, 3D sensing, and natural language processing, culminating in the creation of an interactive prompt-controlled navigation robot. By emphasizing practical HCI applications and intuitive user interface design, the course prepares students for the growing field of human-robot interaction, equipping them with valuable skills for designing next-generation interactive systems.",
    "title": "Build Your AI Robot: Introduction to Robotics and AI Prototyping with Raspberry Pi",
    "id": 188349,
    "sequence": 140,
    "queryCoordinates": {
      "visualization": [
        -14.871672920607155,
        1.9578928833007798
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "This article examined how different time and task management information widgets affect time perception across modalities. In mentally demanding office environments, effective countdown representations are crucial for enhancing temporal awareness and productivity. We developed TickSens, a set of information widgets with different modalities, and conducted a within-subjects experiment with 30 participants to evaluate the five types of time perception modes: visual, auditory, haptic, as well as the blank and the timer modes. Our assessment focused on the technology acceptance, cognitive performance and emotional responses. Results indicated that compared to the blank and the timer modes, the use of modalities significantly improved the cognitive performance and positive emotional responses, and was better received by participants. The visual mode had the best task performance, while the auditory feedback was effective in boosting focus and the haptic mode significantly enhances user acceptance. The study revealed varied user preferences that enlightened the integration of these widgets into office.",
    "title": "Effects of Information Widgets on Time Perception during Mentally Demanding Tasks",
    "id": 188350,
    "sequence": 141,
    "queryCoordinates": {
      "visualization": [
        11.561861232726471,
        -18.716927227383685
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "The Pelvic Chair is a shape-changing chair that touches the pelvic area. Through rhythmic and gentle movements on different parts of the pelvic area, the touch interactions from the Pelvic Chair invite attention to the anatomy, muscles, and connectedness. We present a user study with 14 participants focusing on their experience of being touched by the Pelvic Chair. Through our qualitative analysis of participants' experiences, we show that meaningful touch can offer an active approach to sensing the pelvic floor that contributes to increasing somatic literacy - becoming familiar with the pelvic floor, being able to feel and distinguish between tension and relaxation, and establishing new connections between the pelvic floor and the body. Using the Pelvic Chair as a design case we show the potential for technology-initiated touch in providing an intimate and safe way of touching and connecting with the body.",
    "title": "A Route to Somatic Literacy of the Pelvic Floor through Technology-Initiated Touch",
    "id": 188351,
    "sequence": 142,
    "queryCoordinates": {
      "visualization": [
        7.5323525214641665,
        2.6951188271377604
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "While digital contact tracing has been extensively studied in Western contexts, its relevance and application in Africa remain largely unexplored. This study focuses on Kenya and Côte d’Ivoire to uncover user perceptions and inform the design of culturally resonant contact tracing technologies. Utilizing a wearable proximity sensor as a technology probe, we conducted field studies with healthcare workers and community members in rural areas through interviews (𝑁 = 19) and participatory design workshops (𝑁 = 72). Our findings identify critical barriers to adoption, including low awareness, widespread misconceptions, and social stigma. The study emphasizes the need for culturally sensitive and discreet wearables and advocates for awareness campaigns over mandates to foster adoption. Our work addresses the unique needs of Kenyan and Ivorian populations, offering vital design recommendations and insights to guide designers and policymakers in enhancing digital contact tracing adoption across Africa.",
    "title": "Reimagining Wearable-Based Digital Contact Tracing: Insights from Kenya and Côte d’Ivoire",
    "id": 188352,
    "sequence": 143,
    "queryCoordinates": {
      "visualization": [
        -4.8862124149695525,
        -8.72496007072797
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "Extended reality (XR) learning environments result in greater knowledge gains when coupled with opportunities to reflect on one's actions and learning. However, when and how one should prompt reflection in XR learning environments (XRLEs) to effectively enhance learning, without breaking immersion, remains an open question. In this work, we argue that we can extract insights on how to design effective, immersive reflection for XRLEs from the expertise of escape room game masters (GMs) who regularly provide reflective hints and prompts in complex, immersive problem solving environments. To explore what we can learn from GMs, we conducted exploratory semi-structured interviews with 13 escape room GMs and, via iterative open coding, captured their best practices in how they provide hints and give nudges to escape room players. ",
    "title": "From Locked Rooms to Open Minds: Escape Room Best Practices to Enhance Reflection in Extended Reality Learning Environments",
    "id": 188353,
    "sequence": 144,
    "queryCoordinates": {
      "visualization": [
        18.672230487899828,
        -3.5139448781596183
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "This study investigated the relationship between trust in automation, gaze behavior, and driving performance in beginner and experienced drivers during a simulated driving session. Twenty participants completed a 17-minute drive across three conditions: manual driving, non-critical automated driving, and critical automated driving, with a non-driving-related task (NDRT) introduced between conditions to assess visual attention. Driving performance was evaluated using the Standard Deviation of Lateral Position (SDLP), and eye-tracking data in terms of mean gaze duration (MGD). While both groups demonstrated increased trust in the automated system post-session, beginners showed greater lateral position variability in critical conditions, suggesting over-reliance on automation. Eye-tracking analysis revealed significant changes in glance behavior across driving conditions, particularly in response to critical events. These findings highlight how driver experience shapes interactions with automated systems, emphasizing the importance of trust calibration in automated driving scenarios.",
    "title": "Trust and Visual Focus in Automated Vehicles: A Comparative Study of Beginner and Experienced Drivers",
    "id": 188354,
    "sequence": 145,
    "queryCoordinates": {
      "visualization": [
        9.33791864688938,
        -15.388413672113042
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "In-ear EEG research has traditionally treated biological signals other than brainwaves, such as electromyography (EMG) and electrooculography (EOG), as unwanted noise to be removed. However, instead of discarding these signals, we developed ID.EARS, a single-ear, dry electrode-based device that utilizes these signals for real-time gesture input. We first identified the optimal position for EEG measurement around the ear using the Alpha Attenuation Response (AAR) test and collected biological signals that occur alongside brainwaves at this location. Using these signals, we created a real-time artifact detection model capable of recognizing five specific gestures: blinking, left and right winking, teeth clenching, and chewing. This model achieved over 90% accuracy in cross-validation experiments. Leveraging this model and device, we propose several application scenarios, including music control, accessibility features, MR/XR control, and healthcare services. This innovative approach extends the use of ear-EEG devices beyond healthcare, opening up possibilities for natural user interfaces.",
    "title": "ID.EARS: One-Ear EEG Device with Biosignal Noise for Real-Time Gesture Recognition and Various Interactions",
    "id": 188355,
    "sequence": 146,
    "queryCoordinates": {
      "visualization": [
        6.467156727579007,
        2.6787840265556286
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "We introduce Datamancer, a wearable device enabling bimanual gesture interaction across multi-display ubiquitous analytics environments. Datamancer addresses the gap in gesture-based interaction within data visualization settings, where current methods are often constrained by limited interaction spaces or the need for installing bulky tracking setups. Datamancer integrates a finger-mounted pinhole camera and a chest-mounted gesture sensor, allowing seamless selection and manipulation of visualizations on distributed displays. By pointing to a display, users can acquire the display and engage in various interactions, such as panning, zooming, and selection, using both hands. Our contributions include (1) an investigation of the design space of gestural interaction for physical ubiquitous analytics environments; (2) a prototype implementation of the Datamancer system that realizes this model; and (3) an evaluation of the prototype through demonstration of application scenarios, an expert review, and a user study.",
    "title": "Datamancer: Bimanual Gesture Interaction in Multi-Display Ubiquitous Analytics Environments",
    "id": 188356,
    "sequence": 147,
    "queryCoordinates": {
      "visualization": [
        -13.338851718120548,
        -4.251474431534607
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "3D printing is a mainstream technology enabling the affordable production of 3D models that may enhance access and understanding of graphics for students who are blind or have low vision (BLV). However, the potential usefulness of a new technology does not guarantee its adoption. This paper presents a case study in the adoption of 3D printing as an accessible format for BLV education in Australia and New Zealand. Over the last six years, a community-driven research project engaged in awareness raising, created a community of practice and developed guidelines for the use of 3D printing in education. We evaluate the success of the project using an Implementation Science lens with the RE-AIM framework and identify the key factors for successful adoption. We hope this work will guide the adoption of 3D printing for BLV students and serve as an exemplar for the adoption of other assistive technologies.",
    "title": "3D Printing for Accessible Education: A Case Study in Assistive Technology Adoption",
    "id": 188357,
    "sequence": 148,
    "queryCoordinates": {
      "visualization": [
        -9.386412980437585,
        -16.519541499710964
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "This paper explores how queerness intersects with hackathon culture, reinforcing or challenging its masculine norms. By utilizing autoethnographic insights from seven UK hackathons, it reveals that while queerness is visibly celebrated, inclusion remains conditional—accepted only when it aligns with masculine-coded technical authority. Femininity, regardless of the queer identities of those who embody it, is devalued and associated with lesser technical competence. Beyond social dynamics, gendered hierarchies influence programming tools, roles, and physical environments, embedding exclusion within technical culture. Although gender-fluid expressions like cosplay provide moments of subversion, they remain limited by the masculine framework of hackathons. This study contributes to human-computer interaction and feminist technology studies by showing that queerness alone does not dismantle gendered hierarchies. It advocates for moving beyond visibility to actively challenge masculinized definitions of technical legitimacy, promoting alternative, non-exclusionary models of expertise.",
    "title": "\"Python is for girls!\": Masculinity, Femininity, and Queering Inclusion at Hackathons",
    "id": 188358,
    "sequence": 149,
    "queryCoordinates": {
      "visualization": [
        3.333421398117607,
        -4.9888176738152765
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "Internet users often neglect important security actions (e.g., installing security updates or changing passwords) because they interrupt users’ main task at inopportune times. Commitment devices, such as reminders and promises, have been found to be effective at reducing procrastination in other domains. In a series of online experiments (n > 3,000), we explored the effects of reminders and promises on users’ willingness to change a\r\ncompromised password. We find that adding an option to delay the task increases the share of people willing to eventually change their password considerably. Critically, the option to delay yields this overall increase without reducing the share of people choosing to change their password immediately. Additionally, most participants who promised to change their password later, or asked to be reminded to do so, indeed followed through on their commitment, leading to a net positive effect. Reminding participants of their previous\r\ncommitment further increased this effect.",
    "title": "“Protect Me Tomorrow”: Commitment Nudges to Remedy Compromised Passwords",
    "id": 188359,
    "sequence": 150,
    "queryCoordinates": {
      "visualization": [
        -7.886371075676544,
        13.921391857739383
      ]
    }
  },
  {
    "session": "UX Research Meets AI",
    "abstract": "",
    "title": "UX Research Meets AI: Level Up Your Skills",
    "id": 188360,
    "sequence": 151,
    "queryCoordinates": {
      "visualization": [
        4.9845866686656395,
        -0.3922954786392247
      ]
    }
  },
  {
    "session": "Inclusive and Participatory",
    "abstract": "Research on the potential benefits of technology for autistic children is an emergent field in Human-Computer Interaction (HCI), especially within the Child-Computer Interaction Community. At the same time, there are concerns about what these interventions and technologies are for and who benefits. We present a research and design approach for Tangible User Interfaces (TUIs) for minimally verbal to nonverbal autistic children following a neurodiversity narrative through three field studies developed and evaluated with three groups of children within a semi-structured scholastic environment between 2018 and 2021 in the UK. We discuss our insights for research and TUI designs in the context of social play for nonverbal autistic children and critically reflect on the methods and approaches we used. We do this to disrupt the normalisation agenda that subtly permeates the field of HCI and to direct designers’ attention toward supporting autistic ways of being in the world.",
    "title": "Unmasking the Power of Play Through TUI Designs",
    "id": 188361,
    "sequence": 152,
    "queryCoordinates": {
      "visualization": [
        -7.590523012315972,
        -4.835696475121412
      ]
    }
  },
  {
    "session": "Bringing a Coaching Mindset to Supervision and Leadership",
    "abstract": "",
    "title": "Bringing a Coaching Mindset to Supervision and Leadership",
    "id": 188362,
    "sequence": 153,
    "queryCoordinates": {
      "visualization": [
        11.993575049716387,
        0.39262899386131367
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "The proliferation of new technologies has led to a proliferation of unwanted electronic devices. E-waste is the largest-growing consumer waste-stream worldwide, but also an issue often ignored. In fact, HCI primarily focuses on designing and understanding device interactions during one segment of their lifecycles—while users use them. Researchers overlook a significant space—when devices are no longer “useful” to the user, such as after breakdown or obsolescence. We argue that HCI can learn from experts who upcycle e-waste and give it second lives in electronics projects, art projects, educational workshops, and more. To acquire and translate this knowledge to HCI, we interviewed experts who unmake e-waste. We explore their practices through the lens of unmaking both when devices are physically unmade and when the perception of e-waste is unmade once waste becomes, once again, useful. Last, we synthesize findings into takeaways for how HCI can engage with the issue of e-waste.",
    "title": "Unmaking Electronic Waste",
    "id": 188363,
    "sequence": 154,
    "queryCoordinates": {
      "visualization": [
        -19.13880671464418,
        -5.805693545089242
      ]
    }
  },
  {
    "session": "Inclusive and Participatory",
    "abstract": "The use of image-schematic metaphors is often promoted for being near-universal across user groups, suggesting that these metaphors have the potential to make novel interactive systems easy to use by both younger and older adults. This study empirically investigates this by eliciting image-schematic metaphors from the spoken language and interaction behaviors of 12 younger adults and 12 older adults undertaking tasks in a technology learning domain. For the first time, we reveal an almost-perfect overlap between image-schematic metaphors used by the younger and older groups, despite the two groups showing significant differences in prior technological knowledge. This finding provides empirical evidence for the near-universality of image-schematic metaphor use across age groups. The study also identifies 37 image-schematic metaphors shared between the two age groups in the technology learning domain to support future design of age-inclusive interactive systems.",
    "title": "Guiding the Design of Inclusive Interactive Systems: Do Younger and Older Adults Use the Same Image-schematic Metaphors?",
    "id": 188364,
    "sequence": 155,
    "queryCoordinates": {
      "visualization": [
        14.139622366382675,
        -5.007102888506569
      ]
    }
  },
  {
    "session": "Let's Get Psychophysiological",
    "abstract": "",
    "title": "Let's get PsychophysioLet's Get Psychophysiological! A Hands-On Wearables Laboratory Experience with Recording, Processing, and Interpreting Electrophysiology Signals",
    "id": 188365,
    "sequence": 156,
    "queryCoordinates": {
      "visualization": [
        14.871672920607153,
        -1.9578928833007887
      ]
    }
  },
  {
    "session": "Ethical Co-Development of AI Applications with Indigenous Communities",
    "abstract": "",
    "title": "Ethical Co-Development of AI Applications with Indigenous Communities",
    "id": 188366,
    "sequence": 157,
    "queryCoordinates": {
      "visualization": [
        9.212931062685518,
        -13.081357010425343
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "Social anxiety is a prevalent mental health concern that impacts quality of life and makes social spaces less accessible. We conducted two studies with socially anxious participants, investigating using affective haptic comfort objects to provide calming support during social exposure. Participatory prototyping informed the design and use of the intervention, which was then evaluated between-groups with a social exposure task. Treatment participants held their preferred vibration-augmented prototype during this task; control participants did not. We observed no change in physiological measures, but treatment participants exhibited a significantly broader distribution of psychological anxiety scores. Participants in both studies found their objects pleasant and calming, made positive emotional associations with resonant stimuli, and used their objects to afford self-soothing tactile experiences. We discuss how future designers can facilitate calming affective haptic interfaces for socially anxious settings.",
    "title": "Prototyping and Evaluation of Emotionally Resonant Vibrotactile Comfort Objects as a Calming Social Anxiety Intervention",
    "id": 188367,
    "sequence": 158,
    "queryCoordinates": {
      "visualization": [
        16.95919536008319,
        -1.1771545092012476
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "This paper examines how digital systems designers distil the messiness and ambiguity of the world into concrete data that can be processed by computing systems. Using Karen Barad's agential realism as a guide, we explore how data is fundamentally entangled with the tools and theories of its measurement. We examine data-enabled artefacts acting as Baradian apparatuses: they do not exist independently of the phenomenon they seek to measure, but rather collect and co-produce observations from within their entangled state: the phenomenon and the apparatus co-constitute one another. Connecting Barad's quantum view of indeterminacy to the prevailing HCI discourse on the opportunities and challenges of ambiguity, we suggest that the very act of trying to stabilise a conceptual interpretation of data within an artefact has the paradoxical effect of amplifying and shifting ambiguity in interaction. We illustrate these ideas through three case studies from our own practices of designing digital musical instruments (DMIs). DMIs necessarily encode symbolic and music-theoretical knowledge as part of their internal operation, even as conceptual knowledge is not their intended outcome. In each case, we explore the nature of the apparatus, what phenomena it co-produces, and where the ambiguity lies to suggest approaches for design using these abstract theoretical frameworks.",
    "title": "Shifting Ambiguity, Collapsing Indeterminacy: Designing with Data as Baradian Apparatus",
    "id": 188368,
    "sequence": 159,
    "queryCoordinates": {
      "visualization": [
        -10.930365899054113,
        -4.952484357652732
      ]
    }
  },
  {
    "session": "More Than Human 1",
    "abstract": "In this work, we introduce biodegradation as a process of more-than-human unmaking. We begin by positioning biodegradation amongst related works in design research before presenting a circular process of making and unmaking biomaterials and living organisms through biodegradation. To exemplify this process, we detail two existing works—ReClaym and Biomenstrual—that exemplify how biodegradability can be explored in design through different biomaterials, methods, and contexts. By diffractively reading these projects through one another, we identify six themes and corresponding suggestions for researchers engaging with biodegradation. Lastly, we discuss the broader design implications and limitations, as well as the more-than-human values that emerge from designing for biodegradation via biomaterials. Through this, we aim to provide design researchers with practical tools and insights for engaging with biodegradation to unmake anthropocentric hierarchies between humans, non-humans, and biomaterials, which in turn can promote environmental sustainability and support more-than-human collaboration and care.",
    "title": "Biodegradation as More-Than-Human Unmaking",
    "id": 188369,
    "sequence": 160,
    "queryCoordinates": {
      "visualization": [
        11.739952735240914,
        -12.295263713085188
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "We draw on the Protection Motivation Theory (PMT) to design interventions that encourage users to change breached passwords. Our online experiment (𝑛 = 1,386) compared the effectiveness of a threat appeal (highlighting the negative consequences after passwords were breached) and a coping appeal (providing instructions on changing the breached password) in a 2 × 2 factorial design. Compared to the control condition, participants receiving the threat appeal were more likely to intend to change their passwords, and participants receiving both appeals were more likely to end up changing their passwords. Participants’ password change behaviors are further associated with other factors, such as their security attitudes (SA-6) and time passed since the breach, suggesting that PMT-based interventions are useful but insufficient to fully motivate users to change their passwords. Our study contributes to PMT’s application in security research and provides concrete design implications for improving compromised credential notifications.",
    "title": "Encouraging Users to Change Breached Passwords Using the Protection Motivation Theory",
    "id": 188370,
    "sequence": 161,
    "queryCoordinates": {
      "visualization": [
        -6.901097129627651,
        -1.172543563133154
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "While peer review enhances writing and research quality, harsh feedback can frustrate and demotivate authors. Hence, it is essential to explore how critiques should be delivered to motivate authors and enable them to keep iterating their work. In this study, we explored the impact of appending an automatically generated positive summary to the peer reviews of a writing task, alongside varying levels of overall evaluations (high vs. low), on authors’ feedback reception, revision outcomes, and motivation to revise. Through a 2x2 online experiment with 137 participants, we found that adding an AI-reframed positive summary to otherwise harsh feedback increased authors’ critique acceptance, whereas low overall evaluations of their work led to increased revision efforts. We discuss the implications of using AI in peer feedback, focusing on how AI-driven critiques can influence critique acceptance and support research communities in fostering productive and friendly peer feedback practices.",
    "title": "Understanding and Supporting Peer Review Using AI-reframed Positive Summary",
    "id": 188371,
    "sequence": 162,
    "queryCoordinates": {
      "visualization": [
        -1.826284287026162,
        2.3800600208737057
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "Integrating technology with the distinctive characteristics of craftsmanship has become a key issue in the field of digital craftsmanship. This paper introduces Layered Interactions, a design approach that seamlessly merges Human-Computer Interaction (HCI) technologies with traditional lacquerware craftsmanship. By leveraging the multi-layer structure and material properties of lacquerware, we embed interactive circuits and integrate programmable hardware within the layers, creating tangible interface that support diverse interactions. This method enhances the adaptability and practicality of traditional crafts in modern digital contexts. Through the development of a lacquerware toolkit, along with user experiments and semi-structured interviews, we demonstrate that this approach not only makes technology more accessible to traditional artisans but also enhances the materiality and emotional qualities of interactive interfaces. Additionally, it fosters mutual learning and collaboration between artisans and technologists. Our research introduces a cross-disciplinary perspective to the HCI community, broadening the material and design possibilities for interactive interfaces.",
    "title": "Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces",
    "id": 188372,
    "sequence": 163,
    "queryCoordinates": {
      "visualization": [
        14.568982176599372,
        15.124310177258659
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "We describe the design and deployment of Queue Player, four networked domestic music players that combine music listening histories of close friends to explore new potentialities for interacting with this shared archive. We deployed the Queue Players with four close friends living in separate homes for six weeks. Our goals are to (i) explore how this system might enable co-listening experiences that foster social presence, interaction, and reflection and (ii) empirically explore conceptual propositions related to slow technology. Findings revealed that, after overcoming initial frictions, Queue Player became integrated in participants’ lives and triggered a range of social interactions and reflections on past life experiences. They also showed that Queue Player provoked questions on the benefits and limits of data capturing one’s life history as well as the role and pace of technology in everyday life at home. Findings are interpreted to present opportunities for future HCI research and practice.",
    "title": "Queue Player: Investigating Distributed Co-Listening Experiences for Social Connection across Space, Time, and Tempo ",
    "id": 188373,
    "sequence": 164,
    "queryCoordinates": {
      "visualization": [
        1.9608897344470577,
        -21.91243736897701
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "The technology industry has long sought to diversify its workforce. This study evaluates one avenue that works against these efforts: the interaction between recruiter work practices and algorithmic recruiting tools. Through interviews and cognitive walkthroughs with fifteen recruiters, we find that recruiters—often under deadlines and quotas—develop shortcuts (e.g., computer science degrees and employment at prestigious companies) for identifying “typical” software engineers (one of the most sought-after roles in the field) who have a higher chance of being successfully hired. We then analyze the results of searches like those recruiters often conduct in one commonly-used recruitment tool. We see recruiters’ shortcuts also reflected in these results: candidates with computer science degrees, living in expensive tech hubs, and employed at high-profile tech companies are disproportionately favored. Given the lack of demographic diversity in software engineering at prestigious companies, we assert that algorithmically preferencing these factors helps to reify existing stereotypes, impacting the diversity of candidates who are ultimately hired.",
    "title": "Prestige and Prejudice: How the Interplay of Recruiting Work and Algorithms Reinforces Social Inequities in Software Engineering",
    "id": 188374,
    "sequence": 165,
    "queryCoordinates": {
      "visualization": [
        15.946413075454139,
        -12.071118839071433
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "Writing effective prompts for large language models (LLM) can be\r\nunintuitive and burdensome. In response, services that optimize or\r\nsuggest prompts have emerged. While such services can reduce user\r\neffort, they also introduce a risk: the prompt provider can subtly\r\nmanipulate prompts to produce heavily biased LLM responses. In\r\nthis work, we show that subtle synonym replacements in prompts\r\ncan increase the likelihood (by a difference up to 78%) that LLMs\r\nmention a target concept (e.g., a brand, political party, nation). We\r\nsubstantiate our observations through a user study, showing that\r\nour adversarially perturbed prompts 1) are indistinguishable from\r\nunaltered prompts by humans, 2) push LLMs to recommend target\r\nconcepts more often, and 3) make users more likely to notice target\r\nconcepts, all without arousing suspicion. The practicality of this\r\nattack has the potential to undermine user autonomy. Among other\r\nmeasures, we recommend implementing warnings against using\r\nprompts from untrusted parties.",
    "title": "LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses",
    "id": 188375,
    "sequence": 166,
    "queryCoordinates": {
      "visualization": [
        -4.923789310689839,
        -9.836477968456823
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "Conspiratorial thinking can connect many distinct or distant ills to a central cause. This belief has visual form in the octopus map: a map where a central force (for instance a nation, an ideology, or an ethnicity) is depicted as a literal or figurative octopus, with extending tendrils. In this paper, we explore how octopus maps function as visual arguments through an analysis of historical examples as well as a through a crowd-sourced study on how the underlying data and the use of visual metaphors contribute to specific negative or conspiratorial interpretations. We find that many features of the data or visual style can lead to \"octopus-like\" thinking in visualizations, even without the use of an explicit octopus motif. We conclude with a call for a deeper analysis of visual rhetoric, and an acknowledgment of the potential for the design of data visualizations to contribute to harmful or conspiratorial thinking.",
    "title": "The Many Tendrils of the Octopus Map",
    "id": 188376,
    "sequence": 167,
    "queryCoordinates": {
      "visualization": [
        17.280897378946715,
        -5.036922252557863
      ]
    }
  },
  {
    "session": "Methodology",
    "abstract": "Farms are agro-ecological systems, where farmers work to balance agronomic, economic, and ecological outcomes. Digital Decision Support Tools (DST) assist farmers and their collaborators in navigating complex choices. DSTs are commonly developed by agricultural domain experts, and implemented as customized spreadsheet tools that contain a blend of curated data and expert decision logic. With increasing availability of high-quality data, improved scientific understanding of the relationships among agricultural decisions, and demand for more user-friendly tools, there is interest in transitioning existing spreadsheet tools to more dynamic software. In this paper, we describe the first phase of a collaborative effort to redesign a Microsoft Excel spreadsheet tool developed by the Wild Farm Alliance, to support bird habitat and improve on-farm biodiversity. We present this case study to the HCI community to provide actionable guidance and recommendations on how to conduct an Excel spreadsheet audit as part of a software (re)design process.",
    "title": "Conducting Spreadsheet Audits as a (re)Design Method: A Bird Biodiversity Decision Support Tool Case Study",
    "id": 188377,
    "sequence": 168,
    "queryCoordinates": {
      "visualization": [
        -16.959195360083186,
        1.1771545092012605
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We\r\nshow that in CHI research, GenAI is most often used for Prototyping, Evaluation & User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st. We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency.",
    "title": "How CO2STLY Is CHI? The Carbon Footprint of Generative AI in HCI Research and What We Should Do About It",
    "id": 188378,
    "sequence": 169,
    "queryCoordinates": {
      "visualization": [
        12.28889759545032,
        -4.240636259871313
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "The development of smart textile interfaces is hindered by the inclusion of rigid hardware components and batteries within the fabric, which pose challenges in terms of manufacturability, usability, and environmental concerns related to electronic waste. To mitigate these issues, we propose a smart textile interface and its wireless sensing system to eliminate the need for ICs, batteries, and connectors embedded into textiles. Our technique is established on the integration of multi-resonant circuits in smart textile interfaces, and utilizing near-field electromagnetic coupling between two coils to facilitate wireless power transfer and data acquisition from smart textile interface.A key aspect of our system is the development of a mathematical model that accurately represents the equivalent circuit of the sensing system. Using this model, we developed a novel algorithm to accurately estimate sensor signals based on changes in system impedance. Through simulation-based experiments and a user study, we demonstrate that our technique effectively supports multiple textile sensors of various types. ",
    "title": "BIT: Battery-free, IC-less and Wireless Smart Textile Interface and Sensing System",
    "id": 188379,
    "sequence": 170,
    "queryCoordinates": {
      "visualization": [
        -0.3901806440322564,
        1.9615705608064609
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "A highlight is a short edit of the original video that includes the most engaging moments. Given the rigid timing of TV commercial slots and length limits of social media uploads, generating highlights of specific lengths is crucial. Previous research on automatic highlight generation often overlooked the control over the duration of the final video, producing highlights of arbitrary lengths. We propose a novel system that automatically generates highlights of any user-specified length. Our system leverages Most Replayed Data (MRD), which identifies how frequently a video has been watched over time, to gauge the most engaging parts. It then optimizes the final editing path by adjusting internal segment durations. We evaluated the quality of our system's outputs through two user studies, including a comparison with highlights created by human editors. Results show that our system can automatically produce highlights that are indistinguishable from those created by humans in viewing experience.",
    "title": "Generating Highlight Videos of a User-Specified Length using Most Replayed Data",
    "id": 188380,
    "sequence": 171,
    "queryCoordinates": {
      "visualization": [
        13.33885171812055,
        -4.251474431534601
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "We evaluated the viability of using Large Language Models (LLMs) to trigger and personalize content in Just-in-Time Adaptive Interventions (JITAIs) in digital health. As an interaction pattern representative of context-aware computing, JITAIs are being explored for their potential to support sustainable behavior change, adapting interventions to an individual’s current context and needs. Challenging traditional JITAI implementation models, which face severe scalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs in the use case of heart-healthy activity in cardiac rehabilitation. Using three personas representing patients affected by CVD with varying severeness and five context sets per persona, we generated 450 JITAI decisions and messages. These were systematically evaluated against those created by 10 laypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated JITAIs surpassed human-generated intervention suggestions, outperforming both LayPs and HCPs across all metrics (i.e., appropriateness, engagement, effectiveness, and professionalism). These results highlight the potential of LLMs to enhance JITAI implementations in personalized health interventions, demonstrating how generative AI could revolutionize context-aware computing.",
    "title": "The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting",
    "id": 188381,
    "sequence": 172,
    "queryCoordinates": {
      "visualization": [
        17.638425286967102,
        9.427934736519953
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "Two-factor authentication is often recommended for increasing online security, and users often follow this by using their phones. If physical items become unavailable, there is a risk of losing access to the account due to missing authentication requirements. In such cases, users need a backup or help from the service. Previous work found no standardized approach to how services address this issue, assist users, or offer backup options. Until now, it is unclear how users handle backups and account recovery and what their expectations towards service providers are. To shed light on this, we conducted 16 interviews and a survey with 95 participants. We found that most had never considered how to access their accounts if the second factor was lost, and only a few had a backup plan. Instead, users often rely on website support, assuming that personal data will help them regain access. We give recommendations for services.",
    "title": "\"They are responsible for ensuring that I can continue to use the service.\" Investigating Users' Expectations Towards 2FA Recovery in Germany",
    "id": 188382,
    "sequence": 173,
    "queryCoordinates": {
      "visualization": [
        1.1773424979433031,
        18.963487670851496
      ]
    }
  },
  {
    "session": "Running Online User Studies with the reVISit Framework",
    "abstract": "Running online user studies can be done using commercial survey tools or building custom software. However, these methods have limitations and require significant labor. This course introduces reVISit, an open-source alternative that streamlines study design. ReVISit eliminates tedious tasks by providing built-in components for UI, data hosting, participant recruiting, and more. Study designers can focus on research questions and stimulus design using a domain-specific language to quickly create studies as static websites. Throughout the course, participants will develop and deploy an interactive, fully instrumented study, improving their skills through hands-on experience with reVISit.",
    "title": "Running Online User Studies with the reVISit Framework",
    "id": 188383,
    "sequence": 174,
    "queryCoordinates": {
      "visualization": [
        1.1738437956428958,
        7.913412079718247
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "Hybrid paper interfaces leverage augmented reality to combine the desired tangibility of paper documents with the affordances of interactive digital media. Typically, virtual content can be embedded through direct links (e.g., QR codes); however, this impacts the aesthetics of the paper print and limits the available visual content space. To address this problem, we present Imprinto, an infrared inkjet watermarking technique that allows for invisible content embeddings only by using off-the-shelf IR inks and a camera. Imprinto was established through a psychophysical experiment, studying how much IR ink can be used while remaining invisible to users regardless of background color. We demonstrate that we can detect invisible IR content through our machine learning pipeline, and we developed an authoring tool that optimizes the amount of IR ink on the color regions of an input document for machine and human detectability. Finally, we demonstrate several applications, including augmenting paper documents and objects.",
    "title": "Imprinto: Enhancing Infrared Inkjet Watermarking for Human and Machine Perception",
    "id": 188384,
    "sequence": 175,
    "queryCoordinates": {
      "visualization": [
        1.1672268192795239,
        -4.861849601988384
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "There is a gap between how people explore data and how Jupyter-like computational notebooks are designed. People explore data nonlinearly, using execution undos, branching, and/or complete reverts, whereas notebooks are designed for sequential exploration. Recent works like ForkIt are still insufficient to support these multiple modes of nonlinear exploration in a unified way.\r\nIn this work, we address the challenge by introducing two dimensional code+data space versioning for computational notebooks and verifying its effectiveness using our prototype system, Kishuboard, which integrates with Jupyter. By adjusting code and data knobs, users of Kishuboard can intuitively manage the state of computational notebooks in a flexible way, thereby achieving both execution rollbacks and checkouts across complex multi-branch exploration history. Moreover, this two-dimensional versioning mechanism can easily be presented along with a friendly one-dimensional history. Human subject studies indicate that Kishuboard significantly enhances user productivity in various data science tasks.\r\n",
    "title": "Enhancing Computational Notebooks with Code+Data Space Versioning",
    "id": 188385,
    "sequence": 176,
    "queryCoordinates": {
      "visualization": [
        3.8277613429288353,
        -1.16113870901785
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "PCB (printed circuit board) substrates are often single-use, leading to material waste in electronics making. We introduce PCB Renewal , a novel technique that \"erases\" and \"reconfigures\" PCB traces by selectively depositing conductive epoxy onto outdated areas, transforming isolated paths into conductive planes that support new traces. We present the PCB Renewal workflow, evaluate its electrical performance and mechanical durability, and model its sustainability impact, including material usage, cost, energy consumption, and time savings. We develop a software plug-in that guides epoxy deposition, generates updated PCB profiles, and calculates resource usage. To demonstrate PCB Renewal’s effectiveness and versatility, we repurpose  a single PCB across four design iterations spanning three projects: a camera roller, a WiFi radio, and an ESPboy game console. We also show how an outsourced double-layer PCB can be reconfigured, transforming it from an LED watch to an interactive cat toy. The paper concludes with limitations and future directions.",
    "title": "PCB Renewal: Iterative Reuse of PCB Substrates for Sustainable Electronic Making",
    "id": 188386,
    "sequence": 177,
    "queryCoordinates": {
      "visualization": [
        17.126778248144465,
        -12.152097219775916
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "As our most advanced technologies, such as AI, become both infrastructural and opaque, experts must educate and engage the broader public. To that end, we developed an Augmented Reality (AR) museum installation about facial recognition and data collection that served both as a medium of public education and as a platform for collecting multiple different kinds of data—though, notably, not facial or other biometric data—from more than 100,000 museum visitors. We explain our design process through four animating tensions: comfort/discomfort, simplicity/complexity, neutrality/critique, and the individual/communal. Using thematic analysis of interviews and surveys, we draw insights on how people exposed to problematic technologies in a ‘safe space’ such as a museum make sense of these issues: with levity and resignation but also reverence, often specifically rooted in local cultures. We conclude with implications of the guiding principle derived from this work: “using problematic technology to teach about problematic technology.” ",
    "title": "Surveillance on Exhibit: Using Problematic Technology To Teach About Problematic Technology",
    "id": 188387,
    "sequence": 178,
    "queryCoordinates": {
      "visualization": [
        -6.989732362413635,
        -9.754160215099375
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "    LLM-based agents improve upon standalone LLMs, which are optimized for immediate intent-satisfaction, by allowing the pursuit of more extended objectives, such as helping users over the long term. To do so, LLM-based agents need to reason before responding. For complex tasks like personalized coaching, this reasoning can be informed by adding relevant information at key moments, shifting it in the desired direction.\r\n    However, the pursuit of objectives beyond interaction quality may compromise this very quality. Moreover, as the depth and informativeness of reasoning increase, so do the number of tokens required, leading to higher latency and cost.\r\n    This study investigates how an LLM-based coaching agent can adjust its reasoning depth using a discrepancy mechanism that signals how much reasoning effort to allocate based on how well the objective is being met.\r\n    Our discrepancy-based mechanism constrains reasoning to better align with alternative objectives, reducing cost roughly tenfold while minimally impacting interaction quality.",
    "title": "Efficient Management of LLM-Based Coaching Agents' Reasoning While Maintaining Interaction Quality and Speed",
    "id": 188388,
    "sequence": 179,
    "queryCoordinates": {
      "visualization": [
        -4.186597375374289,
        -9.08143173825081
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "Although remote learning is widely used for delivering and capturing knowledge, it has limitations in teaching hands-on skills that require nuanced instructions and demonstrations of precise actions, such as massage. Furthermore, scheduling conflicts between instructors and learners often limit the availability of real-time feedback, reducing learning efficiency. To address these challenges, we developed a synthesis tool utilizing an LLM-powered Virtual Teaching Assistant (VTA). This tool integrates multimodal instructions that convey precise data, such as stroke patterns and pressure control, while providing real-time feedback for learners and summarizing their performance for instructors. Our case study with instructors and learners demonstrated the effectiveness of these multimodal instructions and the VTA in enhancing massage teaching and learning. We then discuss the tools' use in other hands-on skills instruction and cognitive process differences in various courses. ",
    "title": "Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners",
    "id": 188389,
    "sequence": 180,
    "queryCoordinates": {
      "visualization": [
        0.39267112332353393,
        18.99594191897069
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "Client-Service Representatives (CSRs) are vital to organizations. Frequent interactions with disgruntled clients, however, disrupt their mental well-being. To help CSRs regulate their emotions while interacting with uncivil clients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its efficacy, perception, and use. Our comparative analyses between 665 human and Care-Pilot-generated support messages highlight Care-Pilot’s ability to adapt to and demonstrate empathy in various incivility incidents. Additionally, 143 CSRs assessed Care-Pilot’s empathy as more sincere and actionable than human messages. Finally, we interviewed 20 CSRs who interacted with Care-Pilot in a simulation exercise. They reported that Care-Pilot helped them avoid negative thinking, recenter thoughts, and humanize clients; showing potential for bridging gaps in coworker support. Yet, they also noted deployment challenges and emphasized the indispensability of shared experiences. We discuss future designs and societal implications of AI-mediated emotional labor, underscoring empathy as a critical function for AI assistants for worker mental health.",
    "title": "AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an  LLM-based Empathetic Coworker",
    "id": 188390,
    "sequence": 181,
    "queryCoordinates": {
      "visualization": [
        18.963487670851496,
        1.1773424979432985
      ]
    }
  },
  {
    "session": "How to Write Higher-Quality CHI Papers (with AI Research Tools)",
    "abstract": "Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper's readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.",
    "title": "How to write higher-quality CHI papers (with AI research tools)",
    "id": 188391,
    "sequence": 182,
    "queryCoordinates": {
      "visualization": [
        -9.032407769589224,
        10.696523261502508
      ]
    }
  },
  {
    "session": "WS15: Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "abstract": "Children and young people today are uniquely datafied, tracked, and digitally monitored like no generation before them. Children are increasingly vulnerable to data collection through seemingly benign toys and devices equipped with voice recognition, geolocation, sensors, and cameras, but typically lack awareness or control over these data exchanges, as consent is usually provided by adult caregivers (who may also lack data rights literacy). Although there have been advancements in legislation and design guidelines, there is a significant need for interdisciplinary approaches to directly empower children in understanding, valuing and benefiting from their personal data, as well as learning to manage it. We ask, how can the CHI community support children to be informed and included in design for and with their personal data? How do we support children to participate in their personal data – and do they want to? This workshop aims to gather designers, researchers and practitioners working on projects relating to children’s personal data, and to map out the current practices and methods at play across the CHI community on this critical topic.",
    "title": "Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "id": 188392,
    "sequence": 183,
    "queryCoordinates": {
      "visualization": [
        -10.99299108222691,
        -0.39261567222878097
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "Statistical literacy involves understanding, interpreting, and critically evaluating statistical information in a contextually grounded way. Current instructional practices rely heavily on visual techniques, which renders them inaccessible to students who are blind or have low vision (BLV). To bridge this gap, we formed an extended co-design partnership with a statistics teacher, a teacher for students with visual impairments (TVI), and two BLV students to develop accessibility-first practices for building statistical literacy. Through several months of collaboration that included discussion, exploration, design, and evaluation, we identified specific approaches to promote comprehension and engagement. The enactive approaches we designed, using scaffolding and timely feedback, fostered insights through pattern recognition and analogical reasoning. Additionally, inquiry-based methods promoted contextually situated reasoning and reflection on how statistics can improve students' lives and communities. We present these findings alongside participants’ experiences and discuss their implications for inclusive learning frameworks and tools.",
    "title": "Promoting Comprehension and Engagement in Introductory Data and Statistics for Blind and Low-Vision Students: A Co-Design Study",
    "id": 188393,
    "sequence": 184,
    "queryCoordinates": {
      "visualization": [
        -5.785910375456909,
        17.0447423309119
      ]
    }
  },
  {
    "session": "WS21: News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "abstract": "The news and information ecosystem is undergoing significant upheaval across processes of news production and consumption. For instance, AI integration in newsrooms and the rise of independent creators on digital platforms exemplify shifts in production and dissemination, while evolving audience behaviors of information-seeking show how consumption is changing. This workshop aims to convene researchers and designers in HCI and news to examine these socio-technical shifts across stakeholders, activities, and technologies, and explore how design can support newswork and public engagement with news. Participants will engage in collaborative activities to reflect on current challenges facing news producers and audiences, synthesize the state of research in news and HCI, and identify future research directions. By bringing together diverse perspectives, we aim to nuance our understanding of the evolving news ecosystem and design socio-technical systems that strengthen journalism's democratic function.",
    "title": "News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "id": 188394,
    "sequence": 185,
    "queryCoordinates": {
      "visualization": [
        -6.3368142078044105,
        10.19042617831895
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "To design data visualizations that are easy to comprehend, we need to understand how people with different interests read them. Computational models of predicting scanpaths on charts could complement empirical studies by offering estimates of user performance inexpensively; however, previous models have been limited to gaze patterns and overlooked the effects of tasks. Here, we contribute Chartist, a computational model that simulates how users move their eyes to extract information from the chart in order to perform analysis tasks, including value retrieval, filtering, and finding extremes. The novel contribution lies in a two-level hierarchical control architecture. At the high level, the model uses LLMs to comprehend the information gained so far and applies this representation to select a goal for the lower-level controllers, which, in turn, move the eyes in accordance with a sampling policy learned via reinforcement learning. The model is capable of predicting human-like task-driven scanpaths across various tasks. It can be applied in fields such as explainable AI, visualization design evaluation, and optimization. \r\nWhile it displays limitations in terms of generalizability and accuracy, it takes modeling in a promising direction, toward understanding human behaviors in interacting with charts.",
    "title": "Chartist: Task-driven Eye Movement Control for Chart Reading",
    "id": 188395,
    "sequence": 186,
    "queryCoordinates": {
      "visualization": [
        3.51763068939947,
        -20.703291388882953
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "Dyslexia is a common neurobiological learning disorder significantly impacting reading, writing, and spelling worldwide. Early identification and intervention are essential, but most pre-screening tools focus on Latin languages, leaving Chinese-speaking students underserved. To address this gap, we conduct semi-structured interviews with special education (special-ed) teachers to gather their needs for dyslexia pre-screening tailored to Chinese contexts. Us-\r\ning their insights, we have developed DysVis, a user-centered data visualization system that combines handwriting analysis, body movement keypoint conversion, and a comprehensive visualization interface. DysVis provides teachers with multi-level visualizations, such as performance overviews, task analyses, handwriting observations, and behavioural insights, enabling them to identify the root causes of learning difficulties. Our evaluations, including case studies, a user study, and expert interviews, demonstrate that DysVis is user-friendly and effective in quickly identifying at-risk students, ultimately enhancing learning outcomes for Chinese-speaking students with dyslexia.",
    "title": "DysVis: A User-Centred Data Visualization System for Dyslexia Pre-screening",
    "id": 188396,
    "sequence": 187,
    "queryCoordinates": {
      "visualization": [
        -5.773321504383244,
        15.98964536214065
      ]
    }
  },
  {
    "session": "Decision Making",
    "abstract": "In light of growing toxic polarization and societal fragmentation often fueled by social media, we are designing alternative communication spaces we refer to as dialogue networks---networks of people engaged in recorded small-group prompted dialogue. We introduce the dialogue network framework and our use of tools powered by large language models that assist humans in the analysis and interpretation of themes and patterns across conversations which we refer to as sensemaking. We pilot case studies in collaboration with community partners using a prototype AI-assisted sensemaking tool. Insights from these pilots can inform the use of AI for human-led community engagement processes.",
    "title": "AI-assisted Sensemaking: Human-AI Collaboration for the Analysis and Interpretation of Recorded Facilitated Conversations",
    "id": 188397,
    "sequence": 188,
    "queryCoordinates": {
      "visualization": [
        16.776141647090373,
        6.523884689106629
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "The recent surge of research on software developer mental health challenges highlights the importance and urgency of studying solutions to support developer wellbeing. Self-Determination Theory (SDT) offers a valuable framework for exploring wellbeing at work, emphasizing the need to satisfy three psychological needs: autonomy, competence, and relatedness. This paper presents an interview study with 31 software developers in the United States that uses SDT as a guide, exploring how these three needs are perceived and influenced in the work of software developers. We identify specific factors and processes at work and work tools and designs that impact developers’ psychological needs and satisfaction. Results from our study can help design targeted solutions to satisfy developers’ psychological needs, which indirectly support developer wellbeing. This paper highlights the necessity of healthy work cultures in software development and presents design considerations for creating tools for developers.",
    "title": "“It’s a spectrum”: Exploring Autonomy, Competence, and Relatedness in Software Development Processes and Tools",
    "id": 188398,
    "sequence": 189,
    "queryCoordinates": {
      "visualization": [
        21.21611288927035,
        5.8203568507211365
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "This paper explores opportunities and challenges for data-driven advocacy to support home care workers, an often overlooked group of low-wage, frontline health workers. First, we investigate what data to collect and how to collect it in ways that preserve privacy and avoid burdening workers. Second, we examine how workers and advocates could use collected data to strengthen individual and collective advocacy efforts. Our qualitative study with 11 workers and 15 advocates highlights tensions between workers’ desires for individual and immediate benefits and advocates’ preferences to prioritize more collective and long-term benefits. We also uncover discrepancies between participants’ expectations for how data might transform advocacy and their on-the-ground experiences collecting and using real data. Finally, we discuss future directions for data-driven worker advocacy, including combining different kinds of data to ameliorate challenges, leveraging advocates as data stewards, and accounting for workers’ and organizations’ heterogeneous goals.",
    "title": "Exploring Data-Driven Advocacy in Home Health Care Work",
    "id": 188399,
    "sequence": 190,
    "queryCoordinates": {
      "visualization": [
        11.159588106621722,
        12.824335978542786
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "As augmented reality devices (e.g., smartphones and headsets) proliferate in the market, multi-user AR scenarios are set to become more common. Co-located users will want to share coherent and synchronized AR experiences, but this is surprisingly cumbersome with current methods. In response, we developed PatternTrack, a novel tracking approach that repurposes the structured infrared light patterns emitted by VCSEL-driven depth sensors, like those found in the Apple Vision Pro, iPhone, iPad, and Meta Quest 3. Our approach is infrastructure-free, requires no pre-registration, works on featureless surfaces, and provides the real-time 3D position and orientation of other users' devices. In our evaluation --- tested on six different surfaces and with inter-device distances of up to 260 cm --- we found a mean 3D positional tracking error of 11.02 cm and a mean angular error of 6.81°. ",
    "title": "PatternTrack: Multi-Device Tracking Using Infrared, Structured-Light Projections from Built-in LiDAR",
    "id": 188400,
    "sequence": 191,
    "queryCoordinates": {
      "visualization": [
        7.927028958943916,
        -15.038690497648542
      ]
    }
  },
  {
    "session": "Technology-Facilitated Family Interaction",
    "abstract": "As children increasingly consume media on devices, parents look for ways this usage can support learning and growth, especially in domains like social-emotional learning. We introduce eaSEL, a system that (a) integrates social-emotional learning (SEL) curricula into children’s video consumption by generating reflection activities and (b) facilitates parent-child discussions around digital media without requiring co-consumption of videos. We present a technical evaluation of our system’s ability to detect social-emotional moments within a transcript and to generate high-quality SEL-based activities for both children and parents. Through a user study with 𝑁 = 20 parent-child dyads, we find that after completing an eaSEL activity, children reflect more on the emotional content of videos. Furthermore, parents find that the tool promotes meaningful active engagement and could scaffold deeper conversations around content. Our work paves directions in how AI can support children’s social-emotional reflection of media and family connections in the digital age.",
    "title": "eaSEL: Promoting Social-Emotional Learning and Parent-Child Interaction through AI-Mediated Content Consumption",
    "id": 188401,
    "sequence": 192,
    "queryCoordinates": {
      "visualization": [
        -9.741720724952748,
        11.40608948400047
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "Travel is a powerful yet fleeting experience that can shape personal perspectives and support self-reflection. To recapture the essence of travel, we explored the use of VR as a medium for immersive re-experiencing with an emphasis on storytelling. We developed TravelGalleria, a VR authoring tool that allows users to curate personalized digital galleries. TravelGalleria encourages creative expression, enabling users to use audio narration, annotations, spatially arranged photos, and more to recount their travel stories. A probing user study with TravelGalleria (n = 20) showed promising trends toward emotional resonance and introspective learning. Our findings illustrate how our tool supports users in remembering, reliving, and deriving new insights regarding past experiences, as they were able to reconnect with emotions and themes central to their travels. We discuss these findings in the context of meaningful digital experiences and storytelling in reflective digital practices, highlighting design suggestions and open areas for future research. ",
    "title": "TravelGalleria: Supporting Remembrance and Reflection of Travel Experiences through Digital Storytelling in Virtual Reality",
    "id": 188402,
    "sequence": 193,
    "queryCoordinates": {
      "visualization": [
        16.66042014611594,
        12.783990009183134
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "Marine science researchers are heavy users of software tools and systems such as statistics packages, visualization tools, and online data catalogues. Following a constructivist grounded theory approach, we conduct a semi-structured interview study of 23 marine science researchers and research supports within a North American university, to understand their perceptions of and approaches towards using both graphical and code-based software tools and systems. We propose the concept of fragmentation to represent how various factors lead to isolated pockets of views and practices concerning software tool use during the research process. These factors include informal learning of tools, preferences towards doing things from scratch, and a push towards more code-based tools. Based on our findings, we suggest design priorities for user interfaces that could more effectively help support marine scientists make and use software tools and systems.",
    "title": "Understanding Marine Scientist Software Tool Use",
    "id": 188403,
    "sequence": 194,
    "queryCoordinates": {
      "visualization": [
        -8.014976662062832,
        -18.323759142342713
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Video conferencing meetings are more effective when they are inclusive, but inclusion often hinges on meeting leaders' and/or co-facilitators' practices. AI systems can be designed to improve meeting inclusion at scale by moderating negative meeting behaviors and supporting meeting leaders. We explored this design space by conducting 9 user-centered ideation sessions, instantiating design insights in a prototype ``virtual co-host'' system, and testing the system in a formative exploratory lab study ($n=68$ across 12 groups, 18 interviews). We found that ideation session participants wanted AI agents to ask questions before intervening, which we formalized as the ``Observe, Ask, Intervene'' (OAI) framework. Participants who used our prototype preferred OAI over fully autonomous intervention, but rationalized away the virtual co-host's critical feedback. From these findings, we derive guidelines for designing AI agents to influence behavior and mediate group work. We also contribute methodological and design guidelines specific to mitigating inequitable meeting participation.",
    "title": "Observe, Ask, Intervene: Designing AI Agents for More Inclusive Meetings",
    "id": 188404,
    "sequence": 195,
    "queryCoordinates": {
      "visualization": [
        -1.1767073490094588,
        -13.95046091764667
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "Social VR platforms are increasingly transforming online social spaces by enhancing embodied and immersive social interactions within VR. However, how social VR users also share their activities outside the social VR platform, such as on 2D live streaming platforms, is an increasingly popular yet understudied phenomenon that blends social VR and live streaming research. Through 17 interviews with experienced social VR streamers, we unpack social VR streamers' innovative strategies to further blur the boundary between VR and non-VR spaces to engage their audiences and potential limitations of their strategies. We add new insights into how social VR streamers transcend traditional 2D streamer-audience engagement, which also extend our current understandings of cross-reality interactions. Grounded in these insights, we propose design implications to better support more complicated cross-reality dynamics in social VR streaming while mitigating potential tensions, in hopes of achieving more inclusive, engaging, and secure cross-reality environments in the future.",
    "title": "\"Grab the Chat and Stick It to My Wall\": Understanding How Social VR Streamers Bridge Immersive VR Experiences with Streaming Audiences Outside VR",
    "id": 188405,
    "sequence": 196,
    "queryCoordinates": {
      "visualization": [
        13.08135701042534,
        9.212931062685525
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "Heart rate is a key vital sign for cardiovascular health and fitness. However, the photoplethysmography (PPG) sensors that monitor heart rate in wearables struggle with accuracy during motion. Our day-long in-the-wild study shows Fitbit measures valid heart rates only 54.88% of the time. To address this, we developed PPG Earring, which measures 14 mm in diameter, weighs 2.0 g, and offers 21 hours of continuous sensing. Our eight-user exercise study shows that PPG Earring captures valid heart rate data for 91.74% of the time during exercise and 86.29% of our day-long in-the-wild study. All participants found the PPG Earring as comfortable as their regular earrings, and most participants expressed a strong willingness to wear the PPG Earring all the time every day. Our results validate the signal quality and comfort level of the PPG Earring, highlighting its potential as a daily health monitoring device.",
    "title": "PPG Earring: Wireless Smart Earring for Heart Health Monitoring",
    "id": 188406,
    "sequence": 197,
    "queryCoordinates": {
      "visualization": [
        8.418439278177681,
        -11.186146795015487
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "Emerging AR applications require seamless integration of the virtual and physical worlds, which calls for tools that support both passive perception and active manipulation of the environment, enabling bidirectional interaction. We introduce EchoSight, a system for AR glasses that enables efficient look-and-control bidirectional interaction. EchoSight exploits optical wireless communication to instantaneously connect virtual data with its physical counterpart. EchoSight's unique dual-element optical design leverages beam directionality to automatically align the user's focus with target objects, reducing the overhead in both target identification and subsequent communication. This approach streamlines user interaction, reducing cognitive load and enhancing engagement. Our evaluations demonstrate EchoSight's effectiveness for room-scale communication, achieving distances up to 5 m and viewing angles up to 120 degrees. A study with 12 participants confirms EchoSight's improved efficiency and user experience over traditional methods, such as QR Code scanning and voice control, in AR IoT applications.",
    "title": "EchoSight: Streamlining Bidirectional Virtual-physical Interaction with In-situ Optical Tethering",
    "id": 188407,
    "sequence": 198,
    "queryCoordinates": {
      "visualization": [
        -2.653732141314007,
        5.38123644919613
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "With growing investment in consumer augmented reality (AR) headsets and glasses, wearable AR is moving from niche applications to everyday use. However, current research primarily examines AR in controlled settings, offering limited insights into its use in real-world daily life. To address this gap, we adopt a digital ethnographic approach, analysing 27 hours of 112 YouTube videos featuring early adopters. These videos capture usage ranging from continuous periods of hours to intermittent use over weeks and months. Our analysis shows that currently, wearable AR is primarily used for media consumption and gaming. While productivity is a desired use case, frequent use is constrained by current hardware limitations and the nascent application ecosystem. Users seek continuity in their digital experience, desiring functionalities similar to those on smartphones, tablets, or computers. We propose implications for everyday AR development that promote adoption while ensuring safe, ethical, and socially-aware integration into daily life.",
    "title": "Wearable AR in Everyday Contexts: Insights from a Digital Ethnography of YouTube Videos",
    "id": 188408,
    "sequence": 199,
    "queryCoordinates": {
      "visualization": [
        -2.740246833639357,
        19.811386808871546
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "Indexical storytelling is gaining popularity in video games, where the narrative unfolds through fragmented clues. This approach fosters player-generated content and discussion, as story interpreters piece together the overarching narrative from these scattered elements. However, the fragmented and non-linear nature of the clues makes systematic categorization and interpretation challenging, potentially hindering efficient story reconstruction and creative engagement. To address these challenges, we first proposed a hierarchical taxonomy to categorize narrative clues, informed by a formative study. Using this taxonomy, we designed ClueCart, a creativity support tool aimed at enhancing creators' ability to organize story clues and facilitate intricate story interpretation. We evaluated ClueCart through a between-subjects study (N=40), using Miro as a baseline. The results showed that ClueCart significantly improved creators' efficiency in organizing and retrieving clues, thereby better supporting their creative processes. Additionally, we offer design insights for future studies focused on player-centric narrative analysis.",
    "title": "ClueCart: Supporting Game Story Interpretation and Narrative Inference from Fragmented Clues",
    "id": 188409,
    "sequence": 200,
    "queryCoordinates": {
      "visualization": [
        11.688145478950538,
        5.6909801671494264
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "OpenStreetMap (OSM) is a large online community where users collaborate to map the world. In addition to manual edits, the OSM mapping database is regularly modified by bots and automated edits. In this paper, we seek to better understand how people and bots interact and conflict with each other. We start by analysing over 15 years of mailing list discussions related to bots and automated edits. From this data, we uncover five themes, including how automation results in power differentials between users and how community ideals of consensus clash with the realities of bot use. Subsequently, we surveyed OSM contributors on their experiences with bots and automated edits. We present findings about the current escalation and review mechanisms, as well as the lack of appropriate tools for evaluating and discussing bots. We discuss how OSM and similar communities could use these findings to better support collaboration between humans and bots.",
    "title": "Collaborating with Bots and Automation on OpenStreetMap",
    "id": 188410,
    "sequence": 201,
    "queryCoordinates": {
      "visualization": [
        19.53531762641745,
        4.286183061301015
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "Conversational agents (CAs) that deliver proactive interventions can benefit users by reducing their cognitive workload and improving performance. However, little is known regarding how such interventions would impact users’ reflection on choices in voice-only decision-making tasks. We conducted a within-subjects experiment to evaluate the effect of CA’s feedback delivery strategy at three levels (no feedback, unsolicited and solicited feedback) and the impact on users’ likelihood of changing their choices in an interactive food ordering scenario. We discovered that in both feedback conditions the CA was perceived to be significantly more persuasive than in the baseline condition, while being perceived as significantly less confident. Interestingly, while unsolicited feedback was perceived as less appropriate than the baseline, both types of proactive feedback led participants to relisten and reconsider menu options significantly more often. Our results provide insights regarding the impact of proactive feedback on CA perception and user’s reflection in decision-making tasks, thereby paving a new way for designing proactive CAs.",
    "title": "“Hey Genie, You Got Me Thinking about My Menu Choices!” Impact of Proactive Feedback on User Perception and Reflection in Decision-making Tasks",
    "id": 188411,
    "sequence": 202,
    "queryCoordinates": {
      "visualization": [
        -20.90827365776381,
        1.9606357775119605
      ]
    }
  },
  {
    "session": "Interfaces and Interactions for XR",
    "abstract": "Mid-air gestures serve as a common interaction modality across Extended Reality (XR) applications, enhancing engagement and ownership through intuitive body movements. However, prolonged arm movements induce shoulder fatigue—known as \"Gorilla Arm Syndrome\"—degrading user experience and reducing interaction duration. Although existing ergonomic techniques derived from Fitts' law (such as reducing target distance, increasing target width, and modifying control-display gain) provide some fatigue mitigation, their implementation in XR applications remains challenging due to the complex balance between user engagement and physical exertion. We present \\textit{AlphaPIG}, a meta-technique designed to \\textbf{P}rolong \\textbf{I}nteractive \\textbf{G}estures by leveraging real-time fatigue predictions. AlphaPIG assists designers in extending and improving XR interactions by enabling automated fatigue-based interventions. Through adjustment of intervention timing and intensity decay rate, designers can explore and control the trade-off between fatigue reduction and potential effects such as decreased body ownership. We validated AlphaPIG's effectiveness through a study (N=22) implementing the widely-used Go-Go technique. Results demonstrated that AlphaPIG significantly reduces shoulder fatigue compared to non-adaptive Go-Go, while maintaining comparable perceived body ownership and agency. Based on these findings, we discuss positive and negative perceptions of the intervention. By integrating real-time fatigue prediction with adaptive intervention mechanisms, AlphaPIG constitutes a critical first step towards creating fatigue-aware applications in XR.",
    "title": "AlphaPIG: The Nicest Way to Prolong Interactive Gestures in Extended Reality",
    "id": 188412,
    "sequence": 203,
    "queryCoordinates": {
      "visualization": [
        18.511066210013464,
        4.2825725643003185
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "We introduce Power-on-Touch, a novel method for powering devices during interaction. Power-on-Touch comprises two main components: (1) a wearable-transmitter attached to the user’s body (e.g., fingernail, back of the hand, feet) with wireless power-coils and a battery; and (2) receiver-tags embedded in interactive devices, making them battery-free. Many devices only require power during interaction (e.g., TV remotes, digital calipers). We leverage this interactive opportunity by inductively transferring energy from the user’s coil to the device’s coil when in close proximity. To achieve this, we engineered receiver-tags and coils, including thin pancake-coils best-suited for wearables and spherical-coils that receive power omnidirectionally. To understand which coils best support a wide range of interactions (e.g., grasping, touching, hovering), we performed technical characterizations, including impedance and 3D efficiency analysis. We believe our technical approach can inspire ubiquitous computing with new ways to scale up the number and diversity of battery-free devices, not just sensors (µWatts) but also actuators (Watts).",
    "title": "Power-on-Touch: Powering Actuators, Sensors, and Devices during Interaction",
    "id": 188413,
    "sequence": 204,
    "queryCoordinates": {
      "visualization": [
        -9.624552364536473,
        -2.7144044986507394
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "Multi-material 3D printing combines the functional properties of different materials (e.g., mechanical, electrical, color) within a single object that is fabricated without manual assembly. However, this presents sustainability challenges as multi-material objects cannot be easily recycled. Because each material has a different processing temperature, considerable effort must be used to separate them for recycling. This paper presents a computational fabrication technique to generate dissolvable interfaces between different materials in a 3D printed object without affecting the object’s intended use. When the interfaces are dissolved, the object is disassembled to enable recycling of the individual materials. We describe the computational design of these interfaces alongside experimental evaluations of their strength and water solubility. Finally, we demonstrate our technique across 9 multi-material 3D printed objects of varying structural and functional complexity. Our technique enables us to recycle 89.97% of the total mass of these objects, promoting greater sustainability in 3D printing.",
    "title": "Enabling Recycling of Multi-Material 3D Printed Objects through Computational Design and Disassembly by Dissolution",
    "id": 188414,
    "sequence": 205,
    "queryCoordinates": {
      "visualization": [
        12.710449912821007,
        -2.728454326843026
      ]
    }
  },
  {
    "session": "Earable and Hearable",
    "abstract": "Improper toothbrushing practices persist as a primary cause of oral health issues such as tooth decay and gum disease. Despite the availability of high-end electric toothbrushes that offer some guidance, manual toothbrushes remain widely used due to their simplicity and convenience. We present SmarTeeth, an earable-based toothbrushing monitoring system designed to augment manual toothbrushing with functionalities typically offered only by high-end electric toothbrushes, such as brushing surface tracking. The underlying idea of SmarTeeth is to leverage in-ear microphones on earphones to capture toothbrushing sounds transmitted through the oral cavity to ear canals through facial bones and tissues. The distinct propagation paths of brushing sounds from various dental locations to each ear canal provide the foundational basis for our methods to accurately identify different brushing locations. By extracting customized features from these sounds, we can detect brushing locations using a deep-learning model. With only one registration session (~2 mins) for a new user, the average accuracy is 92.7% for detecting six regions and 75.6% for sixteen tooth surfaces. With three registration sessions (~6 mins), the performance can be boosted to 98.8% and 90.3% for six-region and sixteen-surface tracking, respectively. A key advantage of using earphones for monitoring is that they provide natural auditory feedback to alert users when they are overbrushing or underbrushing. Comprehensive evaluation validates the effectiveness of SmarTeeth under various conditions (different users, brushes, orders, noise, etc.), and the feedback from the user study (N=13) indicates that users found the system highly useful (6.0/7.0) and reported a low workload (2.5/7.0) while using it. Our findings suggest that SmarTeeth could offer a scalable and effective solution to improve oral health globally by providing manual toothbrush users with advanced brushing monitoring capabilities.",
    "title": "SmarTeeth: Augmenting Manual Toothbrushing with In-ear Microphones",
    "id": 188415,
    "sequence": 206,
    "queryCoordinates": {
      "visualization": [
        4.260230170558835,
        -14.382296023022898
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "Presence, or the experience of being present in a computer-generated environment, is a defining element of virtual reality. While there are different methodologies to measure presence, questionnaires remain the most popular, particularly the Igroup Presence Questionnaire (IPQ). In this article, we analyse the results of over 20 years of IPQ usage to develop a new comparative means of reporting presence scores and comparing them across existing and future work. We additionally report on correct and problematic usage of the questionnaire and, through this, present guidelines on how to administer the IPQ in future to aid further analysis. Finally, we present a new web-based tool to streamline the analysis and reporting of IPQ results, which we hope will facilitate more standardised usage of the questionnaire in future research.",
    "title": "Classifying Presence Scores: Insights and Analysis from Two Decades of the Igroup Presence Questionnaire (IPQ)",
    "id": 188416,
    "sequence": 207,
    "queryCoordinates": {
      "visualization": [
        -0.3926289938613181,
        -11.993575049716387
      ]
    }
  },
  {
    "session": "Comparative Structured Observation",
    "abstract": "What happens when your design concept is already well established and you want to see whether or not your design is on the right track, or which of several design variants makes most sense to users? You are not interested in testing a hypothesis, but instead, you want to gather focused, useful feedback from users that either supports your current design direction or helps you decide what to change. This course presents a qualitative method called Comparative Structured Observation (CSO) (Mackay & McGrenere, 2025) which takes advantage of the structure of controlled experiments to generate comparable, ecologically relevant experiences with two or more design variants. Course participants will first learn the basic principles that comprise a CSO study, with examples from the research literature and a discussion of what constitutes appropriate and inappropriate study designs. Participants will then work in small groups and, with help from the instructors, design concrete CSO studies. Participants are encouraged to bring their own designs they are struggling to assess, but the instructors will also provide other examples to explore. The course will conclude with a discussion of relevant analysis methods.",
    "title": "Comparative Structured Observation: A Mixed Qualitative Method for “Getting the Design Right” ",
    "id": 188417,
    "sequence": 208,
    "queryCoordinates": {
      "visualization": [
        -9.460156642284707,
        -5.612970363669894
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "Dark patterns are deceptive designs that influence a user’s interactions with an interface to benefit someone other than the user. Prior work has identified dark patterns in windows, icons, menus, and pointer (WIMP) interfaces and ubicomp environments, but how dark patterns can manifest in Augmented and Virtual Reality (collectively XR) requires more attention. We therefore conducted 10 co-design workshops with 20 experts in XR and deceptive design. Our participants co-designed 42 scenarios containing dark patterns, based on application archetypes presented in recent HCI/XR literature. In the co-designed scenarios, we identified 10 novel dark patterns in addition to 39 existing ones, as well as 10 examples in which specific characteristics associated with XR potentially amplified the effect dark patterns could have on users. Based on our findings and prior work, we present a classification of XR-specific properties that facilitate dark patterns: perception, spatiality, physical/virtual barriers, and XR device sensing. We also present the experts’ assessments of the likelihood and severity of the co-designed scenarios and highlight key aspects they considered for this evaluation, for example, technological feasibility, ease of upscaling and distributing malicious implementations, and the application’s context of use. Finally, we discuss means to mitigate XR dark patterns and support regulatory bodies to reduce potential harms.",
    "title": "What Makes XR Dark? Examining Emerging Dark Patterns in Augmented and Virtual Reality through Expert Co-Design",
    "id": 188418,
    "sequence": 209,
    "queryCoordinates": {
      "visualization": [
        7.22403187861817,
        15.388741450057196
      ]
    }
  },
  {
    "session": "Methods, Theories, HCI Practices",
    "abstract": "In HCI and design research, it has recently been suggested that, instead of risks and threats, uncertainties can be generative resources. This aligns particularly well with practice-based design research and research through design (RtD), where uncertainties are pervasive and unavoidable due to the approach's interest in open-ended problems, contexts under transformation, and unknown futures. Building on the idea that uncertainties drive design activity, we describe the design process as framing acts where a designer-researcher moves along perceived uncertainties. We identify three dynamics for a generative mode of working with uncertainties that can make designers aware of uncertainties, circle in towards those that appear essential while seeking to avoid others, and stay with those that offer new perspectives. We exemplify these dynamics by drawing from our experiences from three RtD projects and highlight this viewpoint's value in providing new reflective tools for designer-researchers.",
    "title": "Uncertainties as Generative Resources in Research through Design: Three Dynamics for Moving in a Design Space",
    "id": 188419,
    "sequence": 210,
    "queryCoordinates": {
      "visualization": [
        -14.568982176599375,
        15.124310177258657
      ]
    }
  },
  {
    "session": "Online Media and Community",
    "abstract": "These days, people have increasingly used social media as a go-to resource for any information need and daily news diet. In the past decade, the news ecosystem and information flow have been dramatically trans- formed by the popularity of such platforms. Social media users can, in fact, easily access nearly any kind of information and then spread it nearly without friction through activities such as tweets/retweets in Twitter (now X) and similar means on other social media. This seemingly innocuous activity of spreading information has a collective consequence of making social media users responsible for radical changes in the way news is distributed, including both authentic and fake news. Moreover, malicious individuals have been implicated in capitalizing on the ease of introducing and spreading information in these platforms to create misinformation, spread it to a wider audience, and subsequently influence public opinion on important topics through information diffusion. Therefore, understanding the factors that motivate a user’s decision to share is of paramount importance in understanding the information diffusion phenomenon in social media.\r\nIn this article, we propose an approach based on the Diffusion of Innovation theory to model, characterize, and compare real and fake news sharing in social media with a focus on different levels of influencing factors including innovation, communication channels, and social system. We apply that approach to identify factors related to the spread of fake news as they relate to users, the structure of news items themselves, and the networks through which news is circulated. We address the problem of predicting real and fake news sharing as a classification task and demonstrate the potentials of the proposed features by achieving an AUROC of around 0.97 and an average precision ranging from 0.88 to 0.95, consistently outperforming baseline models with a higher margin (at least 13% of average precision). In addition, we also found out that empirically identifiable characteristics of news items themselves and users who share news are the strongest element allowing accurate prediction of real and fake news sharing, followed by network-based features. Moreover, our proposed approach can be effectively used to model news diffusion as a multi-step propagation process.",
    "title": "Modeling the Diffusion of Fake and Real News through the Lens of the Diffusion of Innovations Theory",
    "id": 188420,
    "sequence": 211,
    "queryCoordinates": {
      "visualization": [
        5.740251485476348,
        13.858192987669302
      ]
    }
  },
  {
    "session": "Design Thinking with Generative AI",
    "abstract": "",
    "title": "Design Thinking with Generative AI: Powerful ChatGPT Skills for UX",
    "id": 188421,
    "sequence": 212,
    "queryCoordinates": {
      "visualization": [
        6.4257461025455225,
        -12.438238903704216
      ]
    }
  },
  {
    "session": "Social Media, Online Community, Sensemaking",
    "abstract": "Social media websites thrive on user engagement by employing Attention Capture Damaging Patterns (ACDPs), e.g., infinite scroll, that prey on cognitive vulnerabilities to distract users. Prior work has taxonomized these ACDPs, but we have yet to measure how the presence of ACDPs impacts perceived distraction nor how mechanisms that suppress ACDPs reduce distraction. We conducted a two-week, mixed-methods field study with 29 participants to model how people get distracted when browsing social media websites, and how ACDPs might play a role. In the first week of the study, we sample participants' in-situ perceptions of distraction, subjective perceptions of the browsing session (e.g., satisfaction), and the presence/absence of ACDPs. Participants reported feeling distracted 28% of the time, and that subjective perceptions and some ACDPs (e.g., notifications) highly correlated with when they felt distracted. In the second week of the study, participants were given access to Purpose Mode — a browser extension that allows users to \"toggle off\" ACDPs. Participants reported feeling distracted only 7% of the time and spent 21 fewer daily minutes browsing these websites. We discovered that Purpose Mode empowered users to feel more in control over their social media browsing and made participants feel less irritated and frustrated.",
    "title": "Purpose Mode: Reducing Distraction Through Toggling Attention Capture Damaging Patterns on Social Media Websites",
    "id": 188422,
    "sequence": 213,
    "queryCoordinates": {
      "visualization": [
        -3.802029828000155,
        -3.2472402416509176
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "",
    "title": "Interaction Techniques – History, Design and Evaluation",
    "id": 188423,
    "sequence": 214,
    "queryCoordinates": {
      "visualization": [
        5.98715353943162,
        0.39241877538085834
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "While chatbots are increasingly used for customer service, there is a knowledge gap concerning the impact of Conversational Breakdown in such chatbot interactions. In a 2 × 4 factorial design online experiment, we studied how Conversational Breakdown impacts user emotion and trust in a chatbot for customer service, given variations in task criticality and breakdown task order. Here, 257 participants were randomly assigned to complete high- or low-criticality tasks with a prototype chatbot for customer service, experiencing Conversational Breakdown for the first, second, third or none of their tasks. The task set was decided from a 63-participant pre-study. We found significant impact of Conversational Breakdown, including a marked order effect on overall trust, as well as a bounce-back effect on task-specific trust and emotion after subsequent successful task completion. We found no post-interaction effect of Task Criticality. Based on our findings, we discuss theoretical and practical implications and suggest future research.",
    "title": "Conversational Breakdown in a Customer Service Chatbot: Impact of Task Order and Criticality on User Trust and Emotion",
    "id": 188424,
    "sequence": 215,
    "queryCoordinates": {
      "visualization": [
        15.231650878252282,
        11.357676325861576
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "As AI systems quickly improve in both breadth and depth of performance, they lend themselves to creating increasingly powerful and realistic agents, including the possibility of agents modeled on specific people. We anticipate that within our lifetimes it may become common practice for people to create custom AI agents to interact with loved ones and/or the broader world after death; indeed, the past year has seen a boom in startups purporting to offer such services. We call these generative ghosts since such agents will be capable of generating novel content rather than merely parroting content produced by their creator while living. In this paper, we reflect on the history of technologies for AI afterlives, including current early attempts by individual enthusiasts and startup companies to create generative ghosts. We then introduce a novel design space detailing potential implementations of generative ghosts. We use this analytic framework to ground a discussion of the practical and ethical implications of various approaches to designing generative ghosts, including potential positive and negative impacts on individuals and society. Based on these considerations, we lay out a research agenda for the AI and HCI research communities to better understand the risk/benefit landscape of this novel technology to ultimately empower people who wish to create and interact with AI afterlives to do so in a beneficial manner.",
    "title": "Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives",
    "id": 188425,
    "sequence": 216,
    "queryCoordinates": {
      "visualization": [
        11.266622499313064,
        14.037920695671872
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "The Steering Law has long been a fundamental model in predicting movement time for tasks involving navigating through constrained paths, such as in selecting sub-menu options, particularly for straight and circular arc trajectories. However, this does not reflect the complexities of real-world tasks where curvatures can vary arbitrarily, limiting its applications. This study aims to address this gap by introducing the total curvature parameter K into the equation to account for the overall curviness characteristic of a path. To validate this extension, we conducted a mouse-steering experiment on fixed-width paths with varying lengths and curviness levels. Our results demonstrate that the introduction of K significantly improves model fitness for movement time prediction over traditional models. These findings advance our understanding of movement in complex environments and support potential applications in fields like speech motor control and virtual navigation.",
    "title": "Curves Ahead: Enhancing the Steering Law for Complex Curved Trajectories",
    "id": 188426,
    "sequence": 217,
    "queryCoordinates": {
      "visualization": [
        7.113054833451412,
        -12.058376795253725
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "Involving subject matter experts in prompt engineering can guide LLM outputs toward more helpful, accurate, and tailored content that meets the diverse needs of different domains. However, iterating towards effective prompts can be challenging without adequate interface support for systematic experimentation within specific task contexts. In this work, we introduce PromptHive, a collaborative interface for prompt authoring designed to better connect domain knowledge with prompt engineering through features that encourage rapid iteration on prompt variations. We conducted an evaluation study with ten subject matter experts in math and validated our design through two collaborative prompt writing sessions and a learning gain study with 358 learners. Our results elucidate the prompt iteration process and validate the tool's usability, enabling non-AI experts to craft prompts that generate content comparable to human-authored materials while reducing perceived cognitive load by half and shortening the authoring process from several months to just a few hours.",
    "title": "PromptHive: Bringing Subject Matter Experts Back to the Forefront with Collaborative Prompt Engineering for Educational Content Creation",
    "id": 188427,
    "sequence": 218,
    "queryCoordinates": {
      "visualization": [
        20.746837161554065,
        7.319067412721326
      ]
    }
  },
  {
    "session": "Looking Back and Looking Forward",
    "abstract": "Automating textile repair and remanufacturing can significantly improve the ecological and societal impact of textiles. However, the complex behavior of textiles poses challenges for integrating robotics into fashion. This research addresses these challenges by developing a platform that empowers non-experts to define complex multi-robot tasks through visualization-enhanced hand guiding. By leveraging collaborative automation, our approach facilitates intuitive human-multi-robot interaction without extensive technical knowledge. \r\nOur approach employs flexible, parametric systems and a dual-robot setup to achieve high precision and operational flexibility in remanufacturing processes. Utilizing Grasshopper for path planning and VVVV for real-time interaction, we create a user-friendly interface allowing non-experts to interact intuitively with robots. \r\nThis work demonstrates how real-time visualization can make advanced robotic capabilities accessible to non-expert users in the fashion industry. By enabling non-experts to leverage these technologies, we aim to transform remanufacturing processes and foster innovation in human-robot collaboration in the fashion and textiles sector.",
    "title": "Empowering Non-Expert Users in Fashion Remanufacturing: Enhancing Human-Multi-Robot Interaction through Real-Time Visualization",
    "id": 188428,
    "sequence": 219,
    "queryCoordinates": {
      "visualization": [
        -3.5056198425099176,
        15.611234080616457
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "Waiting for system loading is a common scenario that often diminishes user experience, leading to dissatisfaction. Well-established visual indicators like progress bars can not directly apply to the interactions with voice assistants (VAs) like Siri. As VAs continue to rise in popularity, this research aims to explore the design of auditory indicators, particularly human speech, for optimizing waiting experiences in Voice User Interfaces (VUIs). We first organized focus groups (N=35) to identify design considerations for speech indicators, uncovering design opportunities in integrating explanations and humor. Subsequently, we conducted an empirical study (N=30) to evaluate the effects of speech indicators with two levels of explanation and humor on the waiting experience, measured by attention, perceived time, pleasure, and overall satisfaction, during both short and long loading durations. Our findings suggest significant potential for incorporating explanations and humor into VUIs, offering actionable insights for designing effective speech indicators that improve waiting experiences.",
    "title": "Exploring the Design of Human Speech Indicators to Enhance Waiting Experience in Voice User Interface",
    "id": 188429,
    "sequence": 220,
    "queryCoordinates": {
      "visualization": [
        21.91243736897701,
        -1.9608897344470673
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "Virtual reality head-mounted displays (HMDs) offer unique and immersive opportunities for higher education. However, current research focuses on small-scale and infrequent use cases, raising questions about large-scale HMD integration into classrooms. We explored logistical and pedagogical challenges and opportunities when using 30 VR HMDs in a design class of 55 undergraduate students throughout a 12-week term. Each student shared an HMD with a partner, using it weekly in class and at home. We administered questionnaires and conducted observations and interviews. Our results reveal highly positive student engagement, but instructors and students must adapt to unique HMD characteristics and challenges, including in-VR lecturing practices, developing safety measures, and mitigating cybersickness. Although instructor-led VR tutorials were helpful, most learning occurred in individual, paired, and group activities, where screencasting and HMD sharing fostered collaborative learning. Free time during classes provided an opportunity for targeted instructor support while allowing students to explore emerging practices.",
    "title": "Integrating Virtual Reality Head-Mounted Displays into Higher Education Classrooms on a Large Scale",
    "id": 188430,
    "sequence": 221,
    "queryCoordinates": {
      "visualization": [
        12.576703862931764,
        14.241717591081395
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "As personalized recommendation algorithms become integral to social media platforms, users are increasingly aware of their ability to influence recommendation content. However, limited research has explored how users provide feedback through their behaviors and platform mechanisms to shape the recommendation content. We conducted semi-structured interviews with 34 active users of algorithmic-driven social media platforms (e.g., Xiaohongshu, Douyin). In addition to explicit and implicit feedback, this study introduced intentional implicit feedback, highlighting the actions users intentionally took to refine recommendation content through perceived feedback mechanisms. Additionally, choices of feedback behaviors were found to align with specific purposes. Explicit feedback was primarily used for feed customization, while unintentional implicit feedback was more linked to content consumption. Intentional implicit feedback was employed for multiple purposes, particularly in increasing content diversity and improving recommendation relevance. This work underscores the user intention dimension in the explicit-implicit feedback dichotomy and offers insights for designing personalized recommendation feedback that better responds to users' needs.",
    "title": "Beyond Explicit and Implicit: How Users Provide Feedback to Shape Personalized Recommendation Content",
    "id": 188431,
    "sequence": 222,
    "queryCoordinates": {
      "visualization": [
        -8.91055649035552,
        -9.465832400385246
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "We are increasingly adopting domestic robots (e.g., Roomba) that provide relief from mundane household tasks. However, these robots usually only spend little time executing their specific task and remain idle for long periods. They typically possess advanced mobility and sensing capabilities, and therefore have significant potential applications beyond their designed use. Our work explores this untapped potential of domestic robots in ubiquitous computing, focusing on how they can improve and support modern lifestyles. We conducted two studies: an online survey (n=50) to understand current usage patterns of these robots within homes and an exploratory study (n=12) with HCI and HRI experts. Our thematic analysis revealed 12 key dimensions for developing interactions with domestic robots and outlined over 100 use cases, illustrating how these robots can offer proactive assistance and provide privacy. Finally, we implemented a proof-of-concept prototype to demonstrate the feasibility of reappropriating domestic robots for diverse ubiquitous computing applications.",
    "title": "Beyond Vacuuming: How Can We Exploit Domestic Robots’ Idle Time?",
    "id": 188432,
    "sequence": 223,
    "queryCoordinates": {
      "visualization": [
        -0.3925981575906901,
        -9.992290362407228
      ]
    }
  },
  {
    "session": "Perception of Systems",
    "abstract": "Blockchain smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that their end-users understand risks in attempting token transfers. Addressing this, we investigate end-user comprehension of five transfer risks (e.g. the end-user being blacklisted) in the most popular Ethereum contract, USD Tether (USDT), and their prevalence in other top ERC-20 contracts. First, we conducted a user study investigating end-user comprehension of transfer risks in USDT with 110 participants. Second, we performed source code analysis of the next top (78) ERC-20 smart contracts to identify the prevalence of these risks. Study results show that the majority of end-users do not comprehend some real risks, and confuse real and fictitious risks. This holds regardless of participants’ self-rated programming and Web3 proficiency. Source code analysis demonstrates that examined risks are prevalent in up to 19.2% of the top ERC-20 contracts.",
    "title": "Understanding End-User Perception of Transfer Risks in Smart Contracts",
    "id": 188433,
    "sequence": 224,
    "queryCoordinates": {
      "visualization": [
        11.686523751328004,
        2.7249151564124783
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "Educational inequalities in disadvantaged areas have long been a global concern. While Information and Communication Technologies (ICTs) have shown great potential in addressing this issue, the unique challenges in disadvantaged areas often hinder the practical effectiveness of such technologies. This paper examines live-streaming-based dual-teacher classes (LSDC) through a qualitative study in disadvantaged regions of China. Our findings indicate that, although LSDC offers students in these regions access to high-quality educational resources, its practical implementation is fraught with challenges. Specifically, we foreground the pivotal role of local teachers in mitigating these challenges. Through a series of situated efforts, local teachers contextualize high-quality lectures to the local classroom environment, ensuring the expected educational outcomes. Based on our findings, we argue that greater recognition and support for the situational practices of local teachers is essential for fostering a more equitable, sustainable, and scalable technology-driven educational model in disadvantaged areas.",
    "title": "Live-Streaming-Based Dual-Teacher Classes for Equitable Education: Insights and Challenges From Local Teachers' Perspective in Disadvantaged Areas",
    "id": 188434,
    "sequence": 225,
    "queryCoordinates": {
      "visualization": [
        -7.157381403894131,
        -13.18225668992948
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "Can J.J. Gibson’s concept of affordances be empirically examined using screen-based technology? We show how screen-based affordances can be examined through the use case of perceptual toughness, i.e. the break-ability of a virtual object. We present two user experiments (n=72, n=66) examining break-ability through a novel ’Perceptual Impact Testing’ methodology and online screen-based 3D virtual environment. We show that judgements of break-ability are systematically distorted when a perceiver’s virtual ‘Point of Observation’ or virtual environment’s ‘Horizonal Geometry’ are manipulated. These statistically significant results provide evidence that: 1) direct perception can account for perceptual distortions of break-ability; 2) Gibsonian affordances can be empirically examined through screen-based interactions. ",
    "title": "Understanding Break-ability through Screen-based Affordances",
    "id": 188435,
    "sequence": 226,
    "queryCoordinates": {
      "visualization": [
        4.1557375191153065,
        -7.983097498603994
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "Artificial Intelligence (AI) is increasingly integrated into clinical practice, but its influence on patient decision-making, particularly when AI and physicians disagree, remains unclear. To examine collective advice, we investigated a breast cancer screening scenario using (1) a qualitative interview study (N=9) and (2) a quantitative experiment (N=339) where participants received either consistent or conflicting biopsy recommendations.\r\nQualitative findings include the need for empathetic care, the importance of patient autonomy, and a desire for a four-eyes principle.\r\nQuantitative findings accordingly show that patients generally trust physicians more than AI but still tend to follow AI recommendations due to risk aversion. When both advised a biopsy, 99% adhered; if both advised against it, 25% still proceeded. In conflicting scenarios, 97% followed the physician’s advice, whereas 66% followed the AI if it recommended the biopsy. \r\nThese results underscore the need for careful interaction design of collective healthcare advice to prevent unnecessary healthcare procedures.",
    "title": "Who is Trusted for a Second Opinion? Comparing Collective Advice from a Medical AI and Physicians in Biopsy Decisions After Mammography Screening",
    "id": 188436,
    "sequence": 227,
    "queryCoordinates": {
      "visualization": [
        13.95046091764667,
        1.1767073490094655
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "The recent surge in artificial intelligence, particularly in multimodal processing technology, has advanced human-computer interaction, by altering how intelligent systems perceive, understand, and respond to contextual information (i.e., context awareness). Despite such advancements, there is a significant gap in comprehensive reviews examining these advances, especially from a multimodal data perspective, which is crucial for refining system design. This paper addresses a key aspect of this gap by conducting a systematic survey of data modality-driven Vision-based Multimodal Interfaces (VMIs). VMIs are essential for integrating multimodal data, enabling more precise interpretation of user intentions and complex interactions across physical and digital environments. Unlike previous task- or scenario-driven surveys, this study highlights the critical role of the visual modality in processing contextual information and facilitating multimodal interaction. Adopting a design framework moving from the whole to the details and back, it classifies VMIs across dimensions, providing insights for developing effective, context-aware systems.",
    "title": "Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design",
    "id": 188437,
    "sequence": 228,
    "queryCoordinates": {
      "visualization": [
        -14.243124137772194,
        -9.280808951595283
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "Sleep is more than resting eight hours a day---it contextualizes and shapes the routines during the day. Using a large-scale naturalistic dataset of 180,083 people from a popular sleep app, made possible by the widespread adoption of passive tracking, we find that people’s lives have distinct natural rhythms that can be automatically inferred from sleep routines. We discover heterogeneous behaviors: the rhythm of sleep is different for each person, as there is a different cadence for each person to achieve consistency. Some are most consistent week-to-week, while others weeks-to-weeks. We investigate changes in overall daily routines and find the interval for each person at which they show the most consistency. Through a series of comparative case analyses, we investigate the implications of designing for the weekly `norm'. Our tripartite analyses triangulate to one conclusion: we should design for people’s natural routines to account for variable cycles of regularity.  ",
    "title": "Beyond the Circadian Rhythm: Variable Cycles of Regularity Found in Long-Term Sleep Tracking",
    "id": 188438,
    "sequence": 229,
    "queryCoordinates": {
      "visualization": [
        9.617956964488622,
        -10.17324450847638
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "Left-Behind Children (LBC) refers to children who lack daily companionship due to their parents working away from home, accounting for approximately one-fifth of all children in China. Due to the lack of communication and emotional support from their parents, LBCs often experience physical and mental health issues. Effective communication is usually limited by time and topics, and the format of mobile devices and video calls is not always suitable. To address this issue, we developed the Accompany Sleep system. Parents upload daily life content through the app, and the system uses ChatGPT4o to create bedtime stories projected to the LBC. To explore the role of Accompany Sleep in family mediation, we conducted a one-month user study involving four families. The results of the study indicated that both parents and children exhibited positive behaviors, the parent-child relationship was effectively strengthened, and GenAI played a crucial role in this process. Based on these findings, this paper discusses how Accompany Sleep facilitated behavioral changes and improved parent-child relationships while expanding the application of GenAI in the family domain.",
    "title": "Accompany Sleep: Using GenAI to Create Bedtime Stories for Mediating Parent-Child Relationships in LBC Families",
    "id": 188439,
    "sequence": 230,
    "queryCoordinates": {
      "visualization": [
        13.861747250912712,
        -14.41707193405838
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "This research project investigates the techno-politics of digital credit repair practices, defined as the visions and practices that digital credit companies and borrowers draw on to sustain or contest their credit relationships. On one hand, digital credit companies leverage AI to 'see' and amplify certain patterns in consumer data, transforming borrowers into data subjects within regimes of data capture and prediction. On the other hand, borrowers draw on culturally situated practices to achieve 'good' credit scores, though these practices may be labeled as attempts to game the system. Using Kenya as a field site, this project aims to examine the tensions emerging in digital credit relationships, paying close attention to the artful work involved in translating and repairing relations and exchanges between digital credit companies and borrowers.\r\n",
    "title": "The (Un)making of Data Subjects in Digital Credit Repair Practice",
    "id": 188440,
    "sequence": 231,
    "queryCoordinates": {
      "visualization": [
        5.054953583588444,
        -20.38252791652121
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "Large language models are transforming the creative process by offering unprecedented capabilities to algorithmically generate ideas. While these tools can enhance human creativity when people co-create with them, it's unclear how this will impact unassisted human creativity. We conducted two large pre-registered parallel experiments involving 1,100 participants attempting tasks targeting the two core components of creativity, divergent and convergent thinking. We compare the effects of two forms of large language model (LLM) assistance---a standard LLM providing direct answers and a coach-like LLM offering guidance---with a control group receiving no AI assistance, and focus particularly on how all groups perform in a final, unassisted stage. Our findings reveal that while LLM assistance can provide short-term boosts in creativity during assisted tasks, it may inadvertently hinder independent creative performance when users work without assistance, raising concerns about the long-term impact on human creativity and cognition.",
    "title": "Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking",
    "id": 188441,
    "sequence": 232,
    "queryCoordinates": {
      "visualization": [
        -12.115341544103751,
        -10.45076548726043
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "Social movement organizations, such as mutual aid groups, rely on technology to increase their influence, meet immediate needs, and address systemic inequalities. In this paper, we examine the role of technology in moments of crisis and the tensions mutual aid groups face when relying on tools designed with values that may be antithetical to their own. Through a qualitative study with mutual aid volunteers in the United States, we found that mutual aid groups’ values, such as solidarity, security, and co-production, are prioritized as they navigate adopting technology. However, while technology can streamline logistics and enhance visibility for mutual aid groups, we argue that the adoption of existing technologies and conventions of practice can erode opportunities for building solidarity, present challenges for accountability, and exacerbate pre-existing social exclusions. We argue that these tensions emerge not simply as a mismatch between values and technical design, but as systematic outcomes of adopting tools that embed different political assumptions and points of access. Our findings contribute to understanding how values shape --- and are shaped by --- technological infrastructure in mutual aid work.",
    "title": "\"It Actually Doesn’t Feel Very Mutual:\" How Technology Impacts the Values of Mutual Aid Groups in Practice",
    "id": 188442,
    "sequence": 233,
    "queryCoordinates": {
      "visualization": [
        13.861747250912718,
        14.417071934058377
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "This paper examines the potential of commercial earbuds for detecting physiological biomarkers like heart rate (HR) and heart rate variability (HRV) for stress assessment. Using accelerometer (IMU) and photoplethysmography (PPG) data from earbuds, we compared these estimates with reference electrocardiogram (ECG) data from 81 healthy participants. We explored using low-power accelerometer sensors for capturing ballistocardiography (BCG) signals. However, BCG signal quality can vary due to individual differences and body motion. Therefore, BCG data quality assessment is critical before extracting any meaningful biomarkers. To address this, we introduced the ECG-gated BCG heatmap, a new method for assessing BCG signal quality. We trained a Random Forest model to identify usable signals, achieving 82% test accuracy. Filtering out unusable signals improved HR/HRV estimation accuracy to levels comparable to PPG-based estimates. Our findings demonstrate the feasibility of accurate physiological monitoring with earbuds, advancing the development of user-friendly wearable health technologies for stress management.",
    "title": "BallistoBud: Heart Rate Variability Monitoring using Earbud Accelerometry for Stress Assessment",
    "id": 188443,
    "sequence": 234,
    "queryCoordinates": {
      "visualization": [
        17.484157256638703,
        -4.278346061871122
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Augmented Reality (AR) assistance is increasingly used for supporting users with physical tasks like assembly and cooking. However, most systems rely on reactive responses triggered by user input, overlooking rich contextual and user-specific information. To address this, we present Satori, a novel AR system that proactively guides users by modeling both -- their mental states and environmental contexts. Satori integrates the Belief-Desire-Intention (BDI) framework with the state-of-the-art multi-modal large language model (LLM) to deliver contextually appropriate guidance. Our system is designed based on two formative studies involving twelve experts. We evaluated the system with a sixteen within-subject study and found that Satori matches the performance of designer-created Wizard-of-Oz (WoZ) systems, without manual configurations or heuristics, thereby improving generalizability, reusability, and expanding the potential of AR assistance.  Code is available at https://github.com/VIDA-NYU/satori-assistance.",
    "title": "Satori 悟り: Towards Proactive AR Assistant with Belief-Desire-Intention User Modeling",
    "id": 188444,
    "sequence": 235,
    "queryCoordinates": {
      "visualization": [
        -9.381913359224841,
        3.461170570774933
      ]
    }
  },
  {
    "session": "Living with Dementia or Visual Impairments",
    "abstract": "The progression of dementia leads to a loss of initiative and agency,\r\nhalting daily activities, hobbies, or social encounters. Open-ended\r\nplay can encourage initiative but remains underexplored in demen-\r\ntia. This paper explores how technology-driven design can support\r\nopen-ended play, making social interactions more enjoyable and re-\r\nnewing interest in daily activities. We conducted five workshops at\r\ndementia daycare facilities, observing people with dementia engage\r\nwith playful circuit-building toolkits to identify strategies. Find-\r\nings reveal these toolkits stimulated self-direction and initiative to\r\naccomplish self-imposed goals, both independently and collabora-\r\ntively. We show how open-ended play fosters confidence, resilience,\r\nsocial engagement, and self-expression, allowing people with de-\r\nmentia to exercise choice and share moments of achievement. We\r\nprovide design implications for technology to stimulate initiative\r\nthrough open-ended play by 1) balancing structure and freedom, 2)\r\nemphasizing novelty and material diversity for non-verbal social\r\nconnection, and 3) considering age-appropriate aesthetics.",
    "title": "Open-ended Play For People With Dementia",
    "id": 188445,
    "sequence": 236,
    "queryCoordinates": {
      "visualization": [
        7.990180696711446,
        17.238242730449638
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "HCI research increasingly focuses on everyday life to inform technology design for older adults. Routines, a key aspect of everyday life, have been studied to contextualize technology use. Our work brings attention to understanding of routines around videoconferencing technology among older adults with cognitive concerns. We conducted a week-long study involving observations, interviews, and a modified diary study with six older adults with cognitive concerns who videoconference at least once a week. Our analysis revealed how routines helped people adapt to videoconferencing constraints, how participants navigated disruptions to their videoconferencing routines, and the kinds of routines that were more challenging to manage when faced disruptions. In the discussion, we describe why routines are particularly important to study and support for people with cognitive concerns, the importance of studying older adults’ routines to support technology use in HCI, and methods that can enrich HCI research by uncovering insights into routines.",
    "title": "Surfacing Technology Routines While Studying Videoconferencing Among Older Adults with Cognitive Concerns",
    "id": 188446,
    "sequence": 237,
    "queryCoordinates": {
      "visualization": [
        -6.467156727579008,
        -2.6787840265556278
      ]
    }
  },
  {
    "session": "Education",
    "abstract": "In this work, we present three pedagogical strategies designed to innovate HCI education using a challenge-driven approach. Rather than focusing solely on connecting HCI principles to single-user interaction problems, students 1) explore HCI problems within a cross-disciplinary challenge space, 2) work with diverse community stakeholders beyond end-users, and 3) learn to collaborate cross-functionally. Based on our case study of a semester-long HCI and design course that connects three design problems -- spatial design, interactive systems design, and learning design – university students learned to apply design and evaluation processes across multiple disciplinary domains – including materials science, makerspace design, and learning sciences. They also recognized the complexity of HCI work through stakeholder engagement and collaborative strategies to work cross-functionally. We offer practical recommendations for implementing these pedagogical features in the HCI classroom to better prepare students for professional, complex real-world HCI practice.",
    "title": "From HCI Classroom to Complex Challenges: Enhancing HCI Education through Cross-Disciplinary Teamwork and Stakeholder Engagement",
    "id": 188447,
    "sequence": 238,
    "queryCoordinates": {
      "visualization": [
        -16.776141647090373,
        6.523884689106631
      ]
    }
  },
  {
    "session": "Design Beyond",
    "abstract": "What happens when we prompt AI to create ``bad'' design? To find out, we challenged four AI-driven design tools to create user interfaces that explicitly violate established accessibility criteria, only to discover them as prisoners of their usability-oriented training. This finding raises a critical question: How can we develop AI that understands accessibility deeply enough to know when to comply and when to thoughtfully challenge established design principles? Through systematic attempts to subvert AI tools and make them follow our request, we found them both rigid and limited: capable of reproducing accessible patterns, but incapable of thoughtful deviation when context demanded it. By adopting the lens of intentional inaccessibility as an investigation method, we raise questions about the nature of design intelligence that demand reconsideration of how design knowledge is integrated into AI-driven design tools.",
    "title": "Breaking Bad (Design): Challenging AI User Interface Accessibility Guardrails",
    "id": 188448,
    "sequence": 239,
    "queryCoordinates": {
      "visualization": [
        -7.7779832622744305,
        -11.640574572235634
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "Our study of 20 knowledge workers revealed a common challenge: the difficulty of synthesizing unstructured information scattered across multiple platforms to make informed decisions. Drawing on their vision of an ideal knowledge synthesis tool, we developed Yodeai, an AI-enabled system, to explore both the opportunities and limitations of AI in knowledge work. Through a user study with 16 product managers, we identified three key requirements for Generative AI in knowledge work: adaptable user control, transparent collaboration mechanisms, and the ability to integrate background knowledge with external information. However, we also found significant limitations, including overreliance on AI, user isolation, and contextual factors outside the AI's reach. As AI tools become increasingly prevalent in professional settings, we propose design principles that emphasize adaptability to diverse workflows, accountability in personal and collaborative contexts, and context-aware interoperability to guide the development of human-centered AI systems for product managers and knowledge workers.",
    "title": "Generative AI in Knowledge Work: Design Implications for Data Navigation and Decision-Making",
    "id": 188449,
    "sequence": 240,
    "queryCoordinates": {
      "visualization": [
        -12.994069198363935,
        -0.39263936141155165
      ]
    }
  },
  {
    "session": "Earable and Hearable",
    "abstract": "Monitoring the occurrence count of abnormal respiratory symptoms helps provide critical support for respiratory health. While this is necessary, there is still a lack of an unobtrusive and reliable way that can be effectively used in real-world settings. In this paper, we present EchoBreath, a passive and active acoustic combined sensing system for abnormal respiratory symptoms monitoring. EchoBreath novelly uses the speaker and microphone under the frame of the glasses to emit ultrasonic waves and capture both passive sounds and echo profiles, which can effectively distinguish between subject-aware behaviors and background noise. Furthermore, A lightweight neural network with the 'Null' class and open-set filtering mechanisms substantially improves real-world applicability by eliminating unrelated activity. Our experiments, involving 25 participants, demonstrate that EchoBreath can recognize 6 typical respiratory symptoms in a laboratory setting with an accuracy of 93.1%. Additionally, an in-the-semi-wild study with 10 participants further validates that EchoBreath can continuously monitor respiratory abnormalities under real-world conditions. We believe that EchoBreath can serve as an unobtrusive and reliable way to monitor abnormal respiratory symptoms. ",
    "title": "EchoBreath: Continuous Respiratory Behavior Recognition in the  Wild via Acoustic Sensing on Smart Glasses",
    "id": 188450,
    "sequence": 241,
    "queryCoordinates": {
      "visualization": [
        13.862535754710237,
        -1.957064753496993
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "Environmental storytelling is a design technique commonly used to convey narrative through assemblages of content in video games. To date there has been limited empirical work investigating how and on what basis players form interpretations about game environments. We report on a study in which participants (N=202) played a game about exploring a procedurally generated ruined village and were then surveyed on their interpretations. We draw on methods and theory from archaeology - a field that specialises in the interpretation of material remains - to support a grounded theory analysis of the survey responses, from which we form the theory of an archaeological gameworld mental model. Our study draws a novel link between affordance theory, archaeological knowledge production and game systems, and contributes new theoretical concepts that can be applied to procedurally generated and handcrafted methods in game design, narrative design and game preservation.",
    "title": "Archaeological Gameworld Affordances: A Grounded Theory of How Players Interpret Environmental Storytelling",
    "id": 188451,
    "sequence": 242,
    "queryCoordinates": {
      "visualization": [
        7.27098521493671,
        -17.553711117714446
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "How does generative AI affect collaborative creative work and humans' capability to carry it out? \r\nWe tested 52 participant pairs in a standard creativity test, the Alternate Uses Test. The experimental AI group had access to ChatGPT-4, while the control group did not.\r\nThe intervention did not lead to an improved performance overall.\r\nFurther, the AI group elaborated their ideas significantly less. \r\nThis effect carried over to the unaided post-test, pointing to longer-term effects of AI be(com)ing everyday technology, as how people perform a task with a tool shapes how they (learn to) perform the task without it. \r\nAnalysis of the human-AI collaboration process revealed that participants were selective in using ChatGPT-4 output for the experimental task, misjudging and falsely assessing its output. This actually reduced their number of created ideas and underscores that users need to understand a (generative AI-based) tool's capability for the specific task to support effective performance. ",
    "title": "CreAItive Collaboration? Users' Misjudgment of AI-Creativity Affects Their Collaborative Performance",
    "id": 188452,
    "sequence": 243,
    "queryCoordinates": {
      "visualization": [
        18.318276086023058,
        5.043883547053373
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "We present a sensory substitution-based method for representing locations of remote objects in 3D space via haptics. By imitating auditory localization processes, we enable vibrotactile localization abilities similar to those of some spiders, elephants, and other species. We evaluated this concept in virtual reality by modulating the vibration amplitude of two controllers depending on relative locations to a target. We developed two implementations applying this method using either ear or hand locations. A proof-of-concept study assessed localization performance and user experience, achieving under 30° differentiation between horizontal targets with no prior training. This unique approach enables localization by using only two actuators, requires low computational power, and could potentially assist users in gaining spatial awareness in challenging environments. We compare the implementations and discuss the use of hands as ears in motion, a novel technique not previously explored in the sensory substitution literature.",
    "title": "Spatial Haptics: A Sensory Substitution Method for Distal Object Detection Using Tactile Cues",
    "id": 188453,
    "sequence": 244,
    "queryCoordinates": {
      "visualization": [
        18.898634622151608,
        -1.9600024026547873
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "Volunteer moderators use various strategies to address online harms within their communities. Although punitive measures like content removal or account bans are common, recent research has explored the potential for restorative justice as an alternative framework to address the distinct needs of victims, offenders, and community members. In this study, we take steps toward identifying a more concrete design space for restorative justice-oriented tools by developing ApoloBot, a Discord bot designed to facilitate apologies when harm occurs in online communities. We present results from two rounds of interviews: first, with moderators giving feedback about the design of ApoloBot, and second, after a subset of these moderators have deployed ApoloBot in their communities. This study builds on prior work to yield more detailed insights regarding the potential of adopting online restorative justice tools, including opportunities, challenges, and implications for future designs.",
    "title": "The Design Space for Online Restorative Justice Tools: A Case Study with ApoloBot",
    "id": 188454,
    "sequence": 245,
    "queryCoordinates": {
      "visualization": [
        1.1738437956428955,
        -7.913412079718247
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "Representation bias is one of the most common types of biases in artificial intelligence (AI) systems, causing AI  models to perform poorly on underrepresented data segments. Although AI practitioners use various methods to reduce representation bias, their effectiveness is often constrained by insufficient domain knowledge in the debiasing process. To address this gap, this paper introduces a set of generic design guidelines for effectively involving domain experts in representation debiasing.  We instantiated our proposed guidelines in a healthcare-focused application and evaluated them through a comprehensive mixed-methods user study with 35 healthcare experts. Our findings show that involving domain experts can reduce representation bias without compromising model accuracy. Based on our findings, we also offer recommendations for developers to build robust debiasing systems guided by our generic design guidelines, ensuring more effective inclusion of domain experts in the debiasing process.",
    "title": "Explanatory Debiasing: Involving Domain Experts in the Data Generation Process to Mitigate Representation Bias in AI Systems",
    "id": 188455,
    "sequence": 246,
    "queryCoordinates": {
      "visualization": [
        0.39241877538085423,
        -5.987153539431621
      ]
    }
  },
  {
    "session": "WS37: Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "abstract": "Mitigating new harms in immersive and embodied virtual spaces (e.g., embodied harassment in social VR, new AI-powered online attacks, and harmful virtual world design to manipulate users) is a critically needed HCI research agenda for achieving safer online environments in the future, which requires cross-disciplinary, community-wide discussion, and collective reflections. Building upon our CHI 2024 workshop on identifying and understanding these new harms, this workshop aims to gather researchers and practitioners from various domains to collectively design and develop concrete and actionable sociotechnical solutions that specifically target new harms in immersive and embodied virtual worlds. This includes but is not limited to the four themes identified in our CHI 2024 workshop: monetizing embodied harms, blurring reality with the online world, platforming perpetrators by investigating their motivations and emotions, and embodied harms specifically targeting children. Through this workshop, we will not only synthesize and map our existing interdisciplinary efforts and challenges in this space but also collaboratively create a roadmap detailing our developed sociotechnical solutions to address these new harms in immersive and embodied virtual spaces as a community.",
    "title": "Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "id": 188456,
    "sequence": 247,
    "queryCoordinates": {
      "visualization": [
        -19.965312203694317,
        -1.177416073023776
      ]
    }
  },
  {
    "session": "Understanding and Working with Algorithms",
    "abstract": "Animating objects’ movements is widely used to facilitate tracking changes and observing both the global trend and local hotspots where objects converge or diverge.\r\nExisting methods, however, often obscure critical local hotspots by only considering the start and end positions of objects' trajectories.\r\nTo address this gap, we propose RouteFlow, a trajectory-aware animated transition method that effectively balances the global trend and local hotspots while minimizing occlusion.\r\nRouteFlow is inspired by a real-world bus route analogy: objects are regarded as passengers traveling together, with local hotspots representing bus stops where these passengers get on and off.\r\nBased on this analogy, animation paths are generated like bus routes, with the object layout generated similarly to seat allocation according to their destinations.\r\nCompared with state-of-the-art methods, RouteFlow better facilitates identifying the global trend and locating local hotspots while performing comparably in tracking objects' movements. ",
    "title": "RouteFlow: Trajectory-Aware Animated Transitions",
    "id": 188457,
    "sequence": 248,
    "queryCoordinates": {
      "visualization": [
        12.522520413617707,
        -3.4909142771669126
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "Despite recent advances in cancer treatments that prolong patients' lives, treatment-induced cardiotoxicity (i.e., the various heart damages caused by cancer treatments) emerges as one major side effect. The clinical decision-making process of cardiotoxicity is challenging, as early symptoms may happen in non-clinical settings and are too subtle to be noticed until life-threatening events occur at a later stage; clinicians already have a high workload focusing on the cancer treatment, no additional effort to spare on the cardiotoxicity side effect. Our project starts with a participatory design study with 11 clinicians to understand their decision-making practices and their feedback on an initial design of an AI-based decision-support system. Based on their feedback, we then propose a multimodal AI system, CardioAI, that can integrate wearables data and voice assistant data to model a patient's cardiotoxicity risk to support clinicians' decision-making. We conclude our paper with a small-scale heuristic evaluation with four experts and the discussion of future design considerations. ",
    "title": "CardioAI: A Multimodal AI-based System to Support Symptom Monitoring and Risk Prediction of Cancer Treatment-Induced Cardiotoxicity",
    "id": 188458,
    "sequence": 249,
    "queryCoordinates": {
      "visualization": [
        -18.963487670851496,
        1.1773424979433
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "Live Q&A sessions at English-based, international academic conferences usually pose significant challenges for non-native English-speaking presenters, as they demand real-time comprehension and response in one's non-native language under stress. While language-supportive tools (e.g., real-time translation, transcription) can help alleviate such challenges, their adoption remains limited, even at HCI academic conferences that focus on how technology can better serve human needs. Through in-depth interviews with 15 non-native English-speaking academics, we identify their concerns and expectations regarding technological language support for HCI live Q&As. Our research provides critical design implications for future language support tools by highlighting the importance of culturally-aware solutions that offer accurate and seamless language experiences while fostering personal growth and building confidence. We also call for community-wide efforts in HCI to embrace more inclusive practices that actively support non-native English speakers, which can empower all scholars to equally engage in the HCI academic discourse regardless of their native languages. ",
    "title": "\"It's about Research. It's Not about Language\": Understanding and Designing for Mitigating Non-Native English-Speaking Presenters' Challenges in Live Q&A Sessions at Academic Conferences",
    "id": 188459,
    "sequence": 250,
    "queryCoordinates": {
      "visualization": [
        7.270985214936707,
        17.55371111771445
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "Low socioeconomic populations face severe security challenges while being unable to access traditional written advice resources. We present the first study to explore the security advice landscape of low socioeconomic people in Pakistan. With 20 semi-structured interviews, we uncover how they learn and share security advice and what factors enable or limit their advice sharing. Our findings highlight that they heavily rely on community advice and intermediation to establish and maintain security-related practices (such as passwords). We uncover how shifting social environments shape advice dissemination, e.g., across different workplaces. Participants leverage their social structures to protect each other against threats that exploit their financial vulnerability and lack of digital literacy. However, we uncover barriers to social advice mechanisms, limiting their effectiveness, which may lead to increased security and privacy risks. Our results lay the foundation for rethinking security paradigms and advice for this vulnerable population.\r\n",
    "title": "Understanding the Security Advice Mechanisms of Low Socioeconomic Pakistanis",
    "id": 188460,
    "sequence": 251,
    "queryCoordinates": {
      "visualization": [
        -19.53531762641745,
        -4.286183061301011
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "One of the long-standing aspirations in conversational AI is to allow them to autonomously take initiatives in conversations, i.e. being proactive. This is especially challenging for multi-party conversations. Prior NLP research focused mainly on predicting the next speaker from contexts like preceding conversations. In this paper, we demonstrate the limitations of such methods and rethink what it means for AI to be proactive in multi-party, human-AI conversations.We propose that just like humans, rather than merely reacting to turn-taking cues, a proactive AI formulates its own inner thoughts during a conversation, and seeks the right moment to contribute. Through a formative study with 24 participants and inspiration from linguistics and cognitive psychology, we introduce the Inner Thoughts framework. Our framework equips AI with a continuous, covert train of thoughts in parallel to the overt communication process, which enables it to proactively engage by modeling its intrinsic motivation to express these thoughts. We instantiated this framework into two real-time systems: an AI playground web app and a chatbot. Through a technical evaluation and user studies with human participants, our framework significantly surpasses existing baselines on aspects like anthropomorphism, coherence, intelligence, and turn-taking appropriateness. \r\n",
    "title": "Proactive Conversational Agents with Inner Thoughts",
    "id": 188461,
    "sequence": 252,
    "queryCoordinates": {
      "visualization": [
        -19.401470182737025,
        8.036352079666878
      ]
    }
  },
  {
    "session": "CS Education and Security",
    "abstract": "This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement,\r\ndevelop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses. ",
    "title": "Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes",
    "id": 188462,
    "sequence": 253,
    "queryCoordinates": {
      "visualization": [
        -18.624298695176073,
        -7.289409997582989
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "The emergence of Generative AI features in news applications may radically change news consumption and challenge journalistic practices. To explore the future potentials and risks of this understudied area, we created six design fictions depicting scenarios such as virtual companions delivering news summaries to the user, AI providing context to news topics, and content being transformed into other formats on demand. The fictions, discussed with a multi-disciplinary group of experts, enabled a critical examination of the diverse ethical, societal, and journalistic implications of AI shaping this everyday activity. The discussions raised several concerns, suggesting that such consumer-oriented AI applications can clash with journalistic values and processes. These include fears that neither consumers nor AI could successfully balance engagement, objectivity, and truth, leading to growing detachment from shared understanding. We offer critical insights into the potential long-term effects to guide design efforts in this emerging application area of GenAI.",
    "title": "Generative AI and News Consumption: Design Fictions and Critical Analysis",
    "id": 188463,
    "sequence": 254,
    "queryCoordinates": {
      "visualization": [
        -11.640574572235636,
        -7.777983262274427
      ]
    }
  },
  {
    "session": "Well-being and Tracking",
    "abstract": "Personal informatics literature has examined reflection in tracking, but there are gaps in our understanding of how self-initiated reflection that one engages in shortly after data collection has taken place occurs in everyday life and how technology can best support it. We use baby tracking as a case study to explore `temporality,' the time over which reflection occurs relative to data collection, as caregivers track their baby's well-being over both short-term and long-term. We interviewed 20 parents in the U.S. who used baby-tracking technology. We find that parents ask different questions based on the time elapsed since data collection, such as checking alignment with medical guidance and prior patterns immediately after tracking or augmenting memory when reflecting hours later. We summarize these findings into a framework for short-term reflection in baby tracking that includes three windows: the immediate, in-between, and cumulative. We use these windows to identify helpful design patterns in baby-tracking technologies toward supporting temporally meaningful reflection and opportunities for further study in other self-tracking domains.",
    "title": "Understanding Temporality of Reflection in Personal Informatics through Baby Tracking",
    "id": 188464,
    "sequence": 255,
    "queryCoordinates": {
      "visualization": [
        2.678784026555629,
        6.467156727579007
      ]
    }
  },
  {
    "session": "Design Thinking",
    "abstract": "Design workshops are a popular approach to include older adults in the technology design process. However, formative design sessions with older adults have had unexpected outcomes such as the non-use of traditional design materials like craft-based prototyping supplies or disengagement from design activities. Analyzing the engagement of 32 older adults across two design workshops, this paper sheds insights on some of these outcomes. Contributing to a growing body of HCI research on understanding older adults' participation in design, we provide an understanding of how design materials can shape older adults' engagement in formative design activities. Our discussion furthers research on understanding who older adults design for and why, argues for a different understanding of creative expression, and offers considerations for choosing design materials.",
    "title": "Understanding Older Adults’ (Dis)Engagement with Design Materials",
    "id": 188465,
    "sequence": 256,
    "queryCoordinates": {
      "visualization": [
        -1.9530851587973392,
        -10.825223247697277
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "Premenstrual syndrome (PMS) is a prevalent disorder among women, often exacerbated by a lack of peer support due to associated stigmatization. Drawing inspiration from the established benefits of group therapy, particularly the sense of belonging it fosters, we developed a multi-chatbot group motivational interviewing system. The system consists of a facilitator bot and two peer bots, and simulates a group counseling environment for PMS management using Large Language Models (LLMs). We conducted a study with 63 participants and divided them into three conditions (no intervention, 1-on-1 chatbot, group chatbots) over two menstruation cycles for evaluation. Our findings revealed that participants in the group chat condition exhibited higher levels of engagement and language convergence with the chatbots. These participants were also able to engage in social learning and demonstrated motivation in coping through interactions with the chatbots. Finally, we discuss design implications for multi-chatbot interactions in supporting mental health.",
    "title": "Beyond the Dialogue: Multi-chatbot Group Motivational Interviewing for Premenstrual Syndrome (PMS) Management",
    "id": 188466,
    "sequence": 257,
    "queryCoordinates": {
      "visualization": [
        4.835696475121415,
        -7.5905230123159715
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "Teletherapy for speech-language therapy (SLT) has become essential for many families. Early intervention for young children is important to ensure that developmental milestones are met. In this study, from a corpus of 10 videos, we present three cases of online and in-person therapy sessions with children between the ages of 3 and 6. Our analysis shows how online and in-person SLT sessions use tools, how they are conscripted into social and transactional moments, and identifies features of tools that support or hinder therapists’ goals (see Figure 1). From our findings, we discuss in detail four overarching features of tools and implications for design. These features support engagement, space usage, child-centred play, and adaptability in therapy sessions. The paper outlines how these features are present in the tools used in SLT, and describes how they impact SLT activities, therapists’ and children’s goals, and the environment for social transactional activities.",
    "title": "Designing for Transactional Moments: Features of Tools for Child-centred Speech Language Teletherapy",
    "id": 188467,
    "sequence": 258,
    "queryCoordinates": {
      "visualization": [
        -4.2783460618711215,
        -17.484157256638703
      ]
    }
  },
  {
    "session": "Looking Back and Looking Forward",
    "abstract": "How do we make space for joy in Queer HCI? This work draws on our authors' experiences as Queer researchers and allies, navigating a field that is ostensibly receptive to our work, yet provides a narrow framework for acceptable research. We relate personal accounts of contending with identity, practice, and publication; we discuss what joy means to us, and the gap we see in Queer HCI where joy should exist. We believe that Queer HCI and research can itself be subversive, and assert that it needs to be in order for our research community to flourish. Our work emerges from a need for Queer joy in our research practice, and we approach Queerness as a multifaceted experience that by nature resists the categorisation that we often see in HCI. Finally, we present reflective guidelines for future work, that will allow us achieve inclusive, intentional, and joyful research. ",
    "title": "Finding Our Joy: Queer Perspectives on HCI Research",
    "id": 188468,
    "sequence": 259,
    "queryCoordinates": {
      "visualization": [
        6.42566025184516,
        -4.765594435939466
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "Journaling plays a crucial role in managing chronic conditions by allowing patients to document symptoms and medication intake, providing essential data for long-term care. While valuable, traditional journaling methods often rely on static, self-directed entries, lacking interactive feedback and real-time guidance. This gap can result in incomplete or imprecise information, limiting its usefulness for effective treatment. To address this gap, we introduce PATRIKA, an AI-enabled prototype designed specifically for people with Parkinson's disease (PwPD). The system incorporates cooperative conversation principles, clinical interview simulations, and personalization to create a more effective and user-friendly journaling experience. Through two user studies with PwPD and iterative refinement of PATRIKA, we demonstrate conversational journaling's significant potential in patient engagement and collecting clinically valuable information. Our results showed that generating probing questions PATRIKA turned journaling into a bi-directional interaction. Additionally, we offer insights for designing journaling systems for healthcare and future directions for promoting sustained journaling.",
    "title": "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking",
    "id": 188469,
    "sequence": 260,
    "queryCoordinates": {
      "visualization": [
        -5.796577139375434,
        -18.094189494621475
      ]
    }
  },
  {
    "session": "Technology in Education",
    "abstract": "AI-driven educational technologies (AI-EdTech) process extensive data, raising concerns about commercial exploitation of children’s data and risks to their privacy, wellbeing, agency, and legal rights. The ‘fairness principle’ in data protection law requires fair data processing that meets children’s expectations and avoids unexpected, detrimental, discriminatory, or misleading practices. However, children’s own perspectives on what fairness means in AI-EdTech are underexplored in design. This study bridges the gap between law and design research to contextualize what fairness means through co-design workshops with 72 children (aged 10–12) and 4 teachers (N=76) in Scotland and Türkiye. We examine how children's perspectives can inform the operationalization of ‘fairness by design’ for AI-EdTech. Our contributions include: (1) an understanding of children’s perspectives on how fairness manifests (or does not) in AI-EdTech and (2) recommendations for both design and legal communities to align AI-EdTech design and data practices with children's values and rights.",
    "title": "Fairness by Design: Cross-Cultural Perspectives from Children on AI and Fair Data Processing in their Education Futures",
    "id": 188470,
    "sequence": 261,
    "queryCoordinates": {
      "visualization": [
        -4.511038844873866,
        -3.9560748906004113
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "Data analysts frequently employ code completion tools in writing custom scripts to tackle complex tabular data wrangling tasks. However, existing tools do not sufficiently link the data contexts such as schemas and values with the code being edited. This not only leads to poor code suggestions, but also frequent interruptions in coding processes as users need additional code to locate and understand relevant data. We introduce Xavier, a tool designed to enhance data wrangling script authoring in computational notebooks. Xavier maintains users' awareness of data contexts while providing data-aware code suggestions. It automatically highlights the most relevant data based on the user's code, integrates both code and data contexts for more accurate suggestions, and instantly previews data transformation results for easy verification. To evaluate the effectiveness and usability of Xavier, we conducted a user study with 16 data analysts, showing its potential to streamline data wrangling scripts authoring.",
    "title": "Xavier: Toward Better Coding Assistance in Authoring Tabular Data Wrangling Scripts",
    "id": 188471,
    "sequence": 262,
    "queryCoordinates": {
      "visualization": [
        -5.98715353943162,
        -0.39241877538085723
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "Large language models (LLMs) are increasingly integrated into a variety of writing tasks.\r\nWhile these tools can help people by generating ideas or producing higher quality work, like many other AI tools, they may risk causing a variety of harms, potentially disproportionately burdening historically marginalized groups. \r\nIn this work, we introduce and evaluate perceptual harms, a term for the harms caused to users when others perceive or suspect them of using AI. \r\nWe examined perceptual harms in three online experiments, each of which entailed participants evaluating write-ups from mock freelance writers. \r\nWe asked participants to state whether they suspected the freelancers of using AI, to rank the quality of their writing, and to evaluate whether they should be hired.\r\nWe found some support for perceptual harms against certain demographic groups.  \r\nAt the same time, perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board.",
    "title": "Generative AI and Perceptual Harms: Who’s Suspected of using LLMs?",
    "id": 188472,
    "sequence": 263,
    "queryCoordinates": {
      "visualization": [
        18.37969186008383,
        -10.158096629210032
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "Human-Computer Interaction (HCI) researchers focusing on informal care partners and people living with dementia often create personas, incorporating expectations about the pair's relationship dynamics to guide their research and design outcome. Similarly, in our two iterations of co-design workshops aimed at designing a robot to enhance these relationships, we started with expectation that care partners would primarily lead the relationship. This assumption guided the design of the co-design workshops, which included diary studies followed by co-design sessions with eight dyads.\r\nHowever, our results from reflexive thematic analysis challenge the initial view that relationship dynamics follow a single persona or outcome. Instead, the diversity in relationship dynamics led to multiple design outcomes, highlighting the need for HCI researchers to consider care dynamics when designing and conducting research studies for care partnerships. Researchers can structure and create iterative co-design workshops to accommodate these dynamics by incorporating ongoing reflection on the dyad’s relationship dynamics and the researchers’ influence throughout all co-design stages.\r\nThis approach enhances researchers' ability to create more thoughtful and effective relationship technology.",
    "title": "Designing with Dynamics: Reflections on Co-design Workshops Between People Living with Dementia and Their Care Partners",
    "id": 188473,
    "sequence": 264,
    "queryCoordinates": {
      "visualization": [
        -15.946413075454142,
        -12.071118839071428
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "Precision Medicine (PM) transforms the traditional \"one-drug-fits-all\" paradigm by customising treatments based on individual characteristics, and is an emerging topic for HCI research on digital health. A key element of PM, the Polygenic Risk Score (PRS), uses genetic data to predict an individual's disease risk. Despite its potential, PRS faces barriers to adoption, such as data inclusivity, psychological impact, and public trust. We conducted a mixed-methods study to explore how people perceive PRS, formed of surveys (n=254) and interviews (n=11) with UK-based participants. The interviews were supplemented by interactive storyboards with the ContraVision technique to provoke deeper reflection and discussion. We identified ten key barriers and five themes to PRS adoption and proposed design implications for a responsible PRS framework. To address the complexities of PRS and enhance broader PM practices, we introduce the term Human-Precision Medicine Interaction (HPMI), which integrates, adapts, and extends HCI approaches to better meet these challenges.\r\n",
    "title": "Human-Precision Medicine Interaction: Public Perceptions of Polygenic Risk Score for Genetic Health Prediction",
    "id": 188474,
    "sequence": 265,
    "queryCoordinates": {
      "visualization": [
        -5.054953583588434,
        -20.38252791652121
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "The rising threat of mobile malware has prompted security vendors to recommend antivirus software for smartphones, yet user misconceptions, regulatory requirements, and improper use undermine its effectiveness. Our mixed-method study, consisting of in-depth interviews with 23 participants and a survey of 250 participants, examines smartphone antivirus software adoption in South Korea, where mandatory installation for banking and other financial apps is common. Many users confuse antivirus software with general security tools and remain unaware of its limited scope. Adoption is significantly influenced by perceived vulnerability, response efficacy, self-efficacy, social norms, and awareness, while concerns about system performance and skepticism about necessity lead to discontinuation or non-use. Mandatory installations for financial apps in South Korea contribute to user misconceptions, negative perceptions, and a false sense of security. These findings highlight the need for targeted user education, clearer communication about mobile-specific threats, and efforts to promote informed and effective engagement with antivirus software.",
    "title": "I Was Told to Install the Antivirus App, but I'm Not Sure I Need It: Understanding Smartphone Antivirus Software Adoption and User Perceptions",
    "id": 188475,
    "sequence": 266,
    "queryCoordinates": {
      "visualization": [
        -11.587953327223468,
        11.032648715793073
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "While exaggerated facial expressions in cartoon avatars can enhance emotional communication in social virtual reality (VR), they risk triggering the uncanny valley effect. Our research reveals that this effect varies significantly across different emotions. In Study 1 (N=30), participants evaluated scaled facial expressions during simulated VR conversations. We found that expression exaggeration had opposing effects: it decreased facial realism for joy, surprise, and disgust due to overly dramatic mouth movements, while enhancing realism for fear, sadness, and anger—emotions that rely on upper facial expressions typically constrained by HMD pressure. Based on these findings, we developed a region-specific facial expression exaggeration strategy that enhances under-expressed upper facial features while maintaining natural lower facial movements. Study 2 (N=20) validated this approach, demonstrating enhanced emotional intensity and contagion for negative emotions while mitigating the uncanny valley effect. Our research provides practical guidelines for optimizing avatar-mediated emotional communication in social VR environments.",
    "title": "Raise Your Eyebrows Higher: Facilitating Emotional Communication in Social Virtual Reality Through Region-Specific Facial Expression Exaggeration",
    "id": 188476,
    "sequence": 267,
    "queryCoordinates": {
      "visualization": [
        1.176205683954721,
        -11.942216720066362
      ]
    }
  },
  {
    "session": "WS19: Advancing Post-growth HCI",
    "abstract": "The field of Human-Computer Interaction (HCI) both shapes and is shaped by the forces of economic growth. Extending the calls to move beyond the growth imperative in HCI, this workshop aims to bring HCI researchers, designers, and practitioners together in a critical dialogue on examining the often-hidden ways growth patterns manifest in HCI. We ask how the HCI community can use its research, design, and praxis to build a more emancipatory future. The workshop aims to nurture the Post-growth HCI Collective of scholars and practitioners to work together, in solidarity, to reflect and resist the commodification and drive for infinite capital accumulation in/through digital technologies for the betterment of HCI and the broader computing community. Through collective action, we aim to operationalize post-growth principles in HCI, contributing to more tangible pathways toward socio-ecologically just and sustainable technology-mediated futures for the planet and its residents.",
    "title": "Advancing Post-growth HCI",
    "id": 188477,
    "sequence": 268,
    "queryCoordinates": {
      "visualization": [
        -10.437085085210516,
        -3.473795463765273
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "With recent advancements in the capabilities of Text-to-Image (T2I) AI models, product designers have begun experimenting with them in their work. However, T2I models struggle to interpret abstract language and the current user experience of T2I tools can induce design fixation rather than a more iterative, exploratory process. To address these challenges, we developed Inkspire, a sketch-driven tool that supports designers in prototyping product design concepts with analogical inspirations and a complete sketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we conducted an exchange session with designers and distilled design goals for improving T2I interactions. In a within-subjects study comparing Inkspire to ControlNet, we found that Inkspire supported designers with more inspiration and exploration of design ideas, and improved aspects of the co-creative process by allowing designers to effectively grasp the current state of the AI to guide it towards novel design intentions.",
    "title": "Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching",
    "id": 188478,
    "sequence": 269,
    "queryCoordinates": {
      "visualization": [
        -0.3926738492125719,
        -19.996144809641297
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "Understanding neuromusculoskeletal mechanisms significantly impacts skill specialization and proficiency. While existing methods can infer large muscle activities during gross motor movements, the estimation of dexterous motor control involving miniature muscles remains underexplored. Targeting the coordinated hand muscles in advanced piano performance, we learn spatiotemporal discrete representations of electromyography (EMG) data and hand postures utilizing a multimodal dataset. Subsequently, we train a precise and cost-effective neural network model. Based on this model, PiaMuscle is introduced to investigate if visualizing muscle activities during piano training enhances piano performance. Quantitative and qualitative results of a user study with highly skilled professional pianists demonstrate that PiaMuscle provides reliable muscle activation data to support and optimize force control. Our research underscores the potential of a naturalistic workflow to estimate small muscles' activities from readily accessible human-centric information and more accurately when combined with tool-centric data, thereby enhancing skill acquisition.",
    "title": "PiaMuscle: Improving Piano Skill Acquisition by Cost-effectively Estimating and Visualizing Activities of Miniature Hand Muscles",
    "id": 188479,
    "sequence": 270,
    "queryCoordinates": {
      "visualization": [
        12.778965710858461,
        -5.718219597103952
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "The emerging concept of data storytelling (DS) suggests that enhancing visualisations with annotations and narratives can make complex data more insightful than conventional visualisations. Previous works found that DS-enhanced visualisations are more effective than conventional visualisations for simple tasks like identifying key data points or the main message. However, no previous work has explored the extent to which DS enhancements influence task completion across different levels of cognitive complexity. We address this gap by presenting the results of a study where 128 participants completed tasks based on four visualisations (two line charts and two choropleth maps, either with or without DS elements) spanning a range of complexity based on Bloom's taxonomy, which has been applied in data visualisation to categorise tasks hierarchically from lower to higher-order thinking. \r\nResults suggest that while DS-enhanced visualisations effectively support lower-order tasks (finding data points and understanding insights), they don't necessarily aid the correct completion of higher-order tasks (application, analysis, evaluation and creation). However, DS enhancements improve how efficiently participants complete complex tasks.",
    "title": "\"Piecing Data Connections Together Like a Puzzle\": Effects of Increasing Task Complexity on the Effectiveness of Data Storytelling Enhanced Visualisations",
    "id": 188480,
    "sequence": 271,
    "queryCoordinates": {
      "visualization": [
        -1.1611387090178487,
        3.8277613429288357
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "There are many initiatives that teach Artificial Intelligence (AI) literacy to K-12 students. Most downsize college-level instructional materials to grade-level appropriate formats, overlooking students' unique perspectives in the design of curricula. To investigate the use of educational games as a vehicle for uncovering youth's understanding of AI instruction, we co-designed games with 39 Black, Hispanic, and Asian high school girls and non-binary youth to create engaging learning materials for their peers. We conducted qualitative analyses on the designed game artifacts, student discourse, and their feedback on the efficacy of learning activities. This study highlights the benefits of co-design and learning games to uncover students' understanding and ability to apply AI concepts in game-based learning, their emergent perspectives of AI, and the prior knowledge that informs their game design choices. Our research uncovers students' AI misconceptions and informs the design of educational games and grade-level appropriate AI instruction.",
    "title": "Escape or D13: Understanding Youth Perspectives of AI through Educational Game Co-design",
    "id": 188481,
    "sequence": 272,
    "queryCoordinates": {
      "visualization": [
        -5.796577139375426,
        18.094189494621475
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "Upon displacement, it becomes challenging for refugees to build a sense of home in a new environment due to the traumatic experiences they have endured. To unpack factors that are important in developing a sense of home and belonging in refugee communities, we lean on the theoretical concept of 'place-belongingness' - we did this by conducting 6 co-design workshops involving 15 refugee participants, via the 'Magic Machine' workshop approach. From the workshops, we uncovered how cultural identity and memory, life stability and normalcy, security and privacy, resilience and ingenuity, and social connections are central to their sense of home. This research contributes to HCI by building on the theoretical concept of place-belongingness in the context of forced displacement, proposing design implications that address refugees’ needs for home from cultural and social dimensions, and design considerations for refugees’ domestic settings.",
    "title": "Exploring Place-Belongingness through Magic Machine Workshops in Refugee Communities",
    "id": 188482,
    "sequence": 273,
    "queryCoordinates": {
      "visualization": [
        8.75617643798789,
        -19.08741402565643
      ]
    }
  },
  {
    "session": "WS10: Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "abstract": "AI-Augmented Reasoning systems are cognitive assistants that support human reasoning by providing AI-based feedback that can help users improve their critical reasoning skills. Made possible with new techniques like argumentation mining, fact-checking, crowdsourcing, attention nudging, and large language models, AI augmented reasoning systems can provide real-time feedback on logical reasoning, help users identify and avoid flawed arguments and misinformation, suggest counter-arguments, provide evidence-based explanations, and foster deeper reflection. The goal of this workshop is to bring together researchers from AI, HCI, cognitive and social science to discuss recent advances in AI-augmented reasoning, to identify open problems in this area, and to cultivate an emerging community on this important topic.",
    "title": "Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "id": 188483,
    "sequence": 274,
    "queryCoordinates": {
      "visualization": [
        -11.15958810662173,
        -12.82433597854278
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "LLM-based applications are helping people write, and LLM-generated text is making its way into social media, journalism, and our classrooms. However, the differences between LLM-generated and human-written text remain unclear. To explore this, we hired professional writers to edit paragraphs in several creative domains. We first found these writers agree on undesirable idiosyncrasies in LLM-generated text, formalizing it into a seven-category taxonomy (e.g. clichés, unnecessary exposition). Second, we curated the LAMP corpus: 1,057 LLM-generated paragraphs edited by professional writers according to our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our study (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms of writing quality, revealing common limitations across model families. Third, building on existing work in automatic editing we evaluated methods to improve LLM-generated text. A large-scale preference annotation confirms that although experts largely prefer text edited by other experts, automatic editing methods show promise in improving alignment between LLM-generated and human-written text.",
    "title": "Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits",
    "id": 188484,
    "sequence": 275,
    "queryCoordinates": {
      "visualization": [
        12.789602465311377,
        -7.837478470739242
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "Polycystic ovary syndrome (PCOS) is a common hormonal disorder affecting 11-13% of women of reproductive age, characterized by a wide range of symptoms (e.g., menstrual irregularity, acne, and obesity) that varies among individuals. While self-tracking tools help PCOS patients to monitor their symptoms and find personalized treatment, they often focus on regular periods of healthy women with inadequate support for the 1) personalization and 2) long-term holistic tracking necessary for managing complex chronic conditions like PCOS. To bridge this gap, the first author (who has PCOS) conducted an autoethnographic study of holistic self-tracking over a period of ten months in an effort to manage her condition. Our results highlight the challenges of personalized, holistic, long-term tracking in medical, socio-cultural, temporal, technical, and spatial contexts. Based on these insights, we provide design implications for tracking tools that are more inclusive and sustainable.",
    "title": "Towards Hormone Health: An Autoethnography of Long-Term Holistic Tracking to Manage PCOS",
    "id": 188485,
    "sequence": 276,
    "queryCoordinates": {
      "visualization": [
        8.7866640640794,
        1.9479565254429256
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "While normative – \"good\" – game design and user experiences have been established, we look to games that challenge those notions. Intentional frustration and failure can be worthwhile. Through a reflexive thematic analysis of 31 games we identify how intentionally non-normative design choices lead to meaningful experiences. Working within the established Mechanics Dynamics Aesthetics (MDA) Game Design Framework, we lay out themes to design Shitty User Experiences (SUX). We contribute SUX MDA themes for designers and researchers to counter the status quo and identify new forms of play and interaction. ",
    "title": "This Game SUX: Why & How to Design Sh@*!y User Experiences",
    "id": 188486,
    "sequence": 277,
    "queryCoordinates": {
      "visualization": [
        9.465832400385251,
        8.910556490355516
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "Conceptual design is an important stage in industrial product development, influenced by the design space and materials available to designers. Advancements in human-computer interaction (HCI) and artificial intelligence (AI) technologies have broadened these aspects considerably. On the one hand, augmented reality (AR) technologies merge physical and virtual representations to enhance intuitive interaction and embodied cognition. On the other hand, generative artificial intelligence (GAI) serves as a novel design material, boosting creativity and productivity. Inspired by these technological strides, we proposed an Intelli-Embodied Design Space (IEDS), which integrates designers, AR, and GAI to support industrial conceptual design by combining embodied interaction with generative variability. Within IEDS, designers can interact with the physical prototypes intuitively, while GAI refines these into virtual forms that can be embedded in the physical world through AR technology. In this study, we established the theoretical framework and interaction modes of IEDS through literature reviews and expert interviews. Subsequently, we designed and implemented three GAI+AR tools, GAI + Head-mounted Display (HMD), GAI + Handheld Display (HHD), and GAI + Spatial Augmented Reality (SAR), based on three AR approaches in IEDS to practically examine the benefits and challenges of these interaction modes across industrial conceptual design tasks. We discussed IEDS's influence on industrial conceptual design and released its application guidelines to the HCI community.",
    "title": "IEDS: Exploring an Intelli-Embodied Design Space Combining Designer, AR, and GAI to Support Industrial Conceptual Design",
    "id": 188487,
    "sequence": 278,
    "queryCoordinates": {
      "visualization": [
        -15.995181099139268,
        0.3926596563665972
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "This study reveals a significant shift in how users perceive and engage with social media over time. Our analysis is based on qualitative longitudinal research carried out over ten years, involving a small group of participants in 2012, 2017, and 2022. Semi-structured, in-depth interviews were conducted using stimulated recall allowing for retrospection and reflection. Through this methodology, we trace the shifting perceptions of social media users, from initially embracing these platforms for quick, fun, and social activities, to later recognizing their potential intrusiveness and seeking strategies to manage their use. We outline three central trajectories that illustrate shifts in social media use across time: from public performance to private interaction, from producing to consuming and from fun to problematic. For HCI and social media studies, these findings underscore the need to prioritize user agency, ethical design practices, and longitudinal research endeavors to understand the evolving impacts of social media.",
    "title": "Tracing Change in Social Media Use: A Qualitative Longitudinal Study",
    "id": 188488,
    "sequence": 279,
    "queryCoordinates": {
      "visualization": [
        -4.263200821770461,
        2.6124928235797444
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "Intelligent agents coexisting with humans often need to interact with human-shared objects in environments. Thus, agents should plan their interactions based on objects' affordances and the current situation to achieve acceptable outcomes. How to support intelligent agents' planning of affordance-based interactions compatible with human perception and values in real-world contexts remains under-explored. We conducted a formative study identifying the physical, intrapersonal, and interpersonal contexts that count to household human-agent interaction. We then proposed ACKnowledge, a computational framework integrating a dynamic knowledge graph, a large language model, and a vision language model for affordance-based interaction planning in dynamic human environments. In evaluations, ACKnowledge generated acceptable planning results with an understandable process. In real-world simulation tasks, ACKnowledge achieved a high execution success rate and overall acceptability, significantly enhancing usage-rights respectfulness and social appropriateness over baselines. The case study's feedback demonstrated ACKnowledge's negotiation and personalization capabilities toward an understandable planning process.\r\n",
    "title": "ACKnowledge: A Computational Framework for Human Compatible Affordance-based Interaction Planning in Real-world Contexts",
    "id": 188489,
    "sequence": 280,
    "queryCoordinates": {
      "visualization": [
        -6.635496031291115,
        6.080311868540943
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "We examine intermanual deictics, a distinctive class of gesture input characterized by an intermanual structure, asymmetric postural-manipulative articulation, and a deictic nature, drawing from both on-skin and bimanual mid-air gestures. To understand user preferences for gestures featuring these characteristics, we conducted a large-sample end-user elicitation study with 75 participants, who proposed intermanual deictics involving the opposite palm, forearm, and upper arm. Our results reveal a strong preference for physical-contact gestures primarily performed with the index finger, with strokes (62.4%) and touch input (28.8%) being most common, complemented by some preference for non-contact gestures (5.2%). We report similar agreement rates across gestures elicited in the three arm regions, averaging 26.3%, with higher agreement between the forearm and upper arm. We also present a consensus set of sixty gestures for effecting generic commands in interactive systems, along with design principles encompassing multiple practical implications for interactions that incorporate intermanual deictics.",
    "title": "Intermanual Deictics: Uncovering Users' Gesture Preferences for Opposite-Arm Referential Input, from Fingers to Shoulder",
    "id": 188490,
    "sequence": 281,
    "queryCoordinates": {
      "visualization": [
        13.730993925645224,
        -2.7312645082258022
      ]
    }
  },
  {
    "session": "Technology-Facilitated Family Interaction",
    "abstract": "The imprisonment of parents has severe consequences for their relationship to their children. Thus, ensuring valuable contact between them is crucial for parent’s social rehabilitation and children’s development and well-being. However, visits are often not child-friendly and lack interaction. We see social VR as a means to address these issues. In this paper, we share findings of a user-centered design process of a virtual reality application that allows imprisoned parents to meet their children. Our pilot study with four dyads of children and imprisoned fathers revealed that both appreciated the virtual visits, felt close to each other, and had a positive emotional experience, although fathers missed physical contact. Children preferred VR’s playful and interactive nature compared to regular visits. Our research presents virtual visits as a suitable alternative to ensure valuable social interaction between prisoners and their children and contribute to the potential of immersive virtual social experiences for sensitive use cases.",
    "title": "Virtual Visits, Real Emotions: Designing Social VR Experiences for Imprisoned Fathers and their Children",
    "id": 188491,
    "sequence": 282,
    "queryCoordinates": {
      "visualization": [
        21.968464057116034,
        -1.1775342760195464
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "Social media platform design often incorporates explicit signals of positive feedback. Some moderators provide positive feedback with the goal of positive reinforcement, but are often unsure of their ability to actually influence user behavior. Despite its widespread use and theory touting positive feedback as crucial for user motivation, its effect on recipients is relatively unknown. This paper examines how positive feedback impacts Reddit users and evaluates its differential effects to understand who benefits most from receiving positive feedback. Through a causal inference study of 11M posts across 4 months, we find that users who received positive feedback made more frequent (2\\% per day) and higher quality (57\\% higher score; 2\\% fewer removals per day) posts compared to a set of matched control users. Our findings highlight the need for platforms, communities, and moderators to expand their perspective on moderation and complement punitive approaches with positive reinforcement strategies to foster desirable behavior online.",
    "title": "Does Positive Reinforcement Work?: A Quasi-Experimental Study of the Effects of Positive Feedback on Reddit",
    "id": 188492,
    "sequence": 283,
    "queryCoordinates": {
      "visualization": [
        18.51106621001346,
        -4.282572564300324
      ]
    }
  },
  {
    "session": "WS41: Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "abstract": "The popularity of accessibility research has grown recently, improving digital inclusion for people with disabilities. However, researchers, including those who have disabilities, have attempted to include people with disabilities in all aspects of design, and they have identified a myriad of practical accessibility barriers posed by tools and methods leveraged by human-computer interaction (HCI) researchers during prototyping. To build a more inclusive technological landscape, we must question the effectiveness of existing prototyping tools and methods, repurpose/retrofit existing resources, and build new tools and methods to support the participation of both researchers and people with disabilities within the prototyping design process of novel technologies. This full-day workshop at CHI 2025 will provide a platform for HCI researchers, designers, and practitioners to discuss barriers and opportunities for creating accessible prototyping and promote hands-on ideation and fabrication exercises aimed at futuring accessible prototyping. ",
    "title": "Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "id": 188493,
    "sequence": 284,
    "queryCoordinates": {
      "visualization": [
        -17.569183002134814,
        11.503208623575297
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "Viscous materials such as inks, gels, pastes, and slurries are ubiquitous across domains like food science, smart materials, digital fabrication, and the arts. However, their dynamic and unpredictable behavior—shifting over time and in response to environmental factors—poses challenges, often requiring costly equipment for accurate rheological analysis. This paper presents a low-cost, accessible sensing routine that retracts and extrudes viscous materials through an air tube, generating sensor vectors rich in rheological data. By embedding data from 26 rheologically diverse materials into a two-dimensional space, we create RheoMaps that allow for tracking material changes over time, distinguishing concentrations, and tuning rheological behaviors. These maps offer practical benefits for detecting preparation errors, guiding material design and documentation, and providing tutorial waypoints. We further discuss how this approach can be extended to extract relational insights from sensor data, improving material literacy and manipulation across a range of applications.",
    "title": "RheoMap: Mapping Inks, Gels, Pastes, and Slurries within a Rheological Embedding Space using Retraction-Extrusion Pressure Sensor Vectors",
    "id": 188494,
    "sequence": 285,
    "queryCoordinates": {
      "visualization": [
        4.861849601988383,
        1.167226819279527
      ]
    }
  },
  {
    "session": "Online Media, Robots, Agents",
    "abstract": "Healthcare question-answering (QA) systems can assist physicians in making medical decisions. However, traditional medical QA systems struggle with multi-agents interaction and domain-specific knowledge processing, thereby reducing the accuracy and credibility of clinical decision-making. We thus develop a multi-agent decision-making system by combining a fine-tuned medical model, biomedical knowledge graphs, and PubMed data. By summarizing the symptoms described by users, our system can automatically convene clinical experts from various fields, retrieve domain knowledge, and provide clinical decision support for users. We have validated the system performance using both technical and user-centric approaches in terms of information accuracy, user satisfaction, user trust, ect. We thus provide an effective tool for healthcare professionals to make accurate and timely decisions. Furthermore, this study also reveals new design and research opportunities, including (1) optimizing multi-agent collaboration mechanisms for more complex medical decision-making, (2) improving interaction design to enhance system transparency and explainability, and (3) expanding the system to support a broader range of medical issues and multimodal data.\r\n",
    "title": "Accurate Insights, Trustworthy Interactions: Designing a Collaborative AI-Human Multi-Agent System with Knowledge Graph for Diagnosis Prediction",
    "id": 188495,
    "sequence": 286,
    "queryCoordinates": {
      "visualization": [
        -12.288897595450324,
        4.240636259871301
      ]
    }
  },
  {
    "session": "Visualization and Language Communication",
    "abstract": "Understanding collaborative writing dynamics between native speakers (NS) and non-native speakers (NNS) is critical for enhancing collaboration quality and team inclusivity. In this paper, we partnered with communication researchers to develop visual analytics solutions for comparing NS and NNS behaviors in 162 writing sessions across 27 teams. The primary challenges in analyzing writing behaviors are data complexity and the uncertainties introduced by automated methods. In response, we present \\textsc{COALA}, a novel visual analytics tool that improves model interpretability by displaying uncertainties in author clusters, generating behavior summaries using large language models, and visualizing writing-related actions at multiple granularities. We validated the effectiveness of \\textsc{COALA} through user studies with domain experts (N=2+2) and researchers with relevant experience (N=8). We present the insights discovered by participants using \\textsc{COALA}, suggest features for future AI-assisted collaborative writing tools, and discuss the broader implications for analyzing collaborative processes beyond writing.",
    "title": "Comparing Native and Non-native English Speakers’ Behaviors in Collaborative Writing through Visual Analytics",
    "id": 188496,
    "sequence": 287,
    "queryCoordinates": {
      "visualization": [
        -3.4737954637652733,
        10.437085085210516
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "Presence appears an important concept for virtual reality (VR): It is frequently measured with questionnaires, and theory and methods about it have been discussed in numerous works. Yet, it is unclear how to actually work with this concept: Why is presence important to measure, how to choose an appropriate questionnaire, and what to conclude about it based on findings? To answer these questions, we review how the concept is put to work in 288 VR papers from 2023 measuring presence with questionnaires. Our findings include that measuring presence is often motivated by another construct, such as user experience; the reasons for choosing a specific questionnaire are often weak or not reported at all; and high presence values are frequently used simply to validate an interaction technique. We propose recommendations for working with presence and formulate questions to direct future research.",
    "title": "A Concept at Work: A Review of Motivations, Operationalizations, and Conclusions in VR Research about Presence",
    "id": 188497,
    "sequence": 288,
    "queryCoordinates": {
      "visualization": [
        8.758368872374028,
        8.203107624274455
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "Prior work has documented various ways that teens use social media to regulate their emotions. However, little is known about what these processes look like on a moment-by-moment basis. We conducted a diary study to investigate how teens (N=57, Mage = 16.3 years) used Instagram to regulate their emotions. We identified three kinds of emotionally-salient drivers that brought teens to Instagram and two types of behaviors that impacted their emotional experiences on the platform. Teens described going to Instagram to escape, to engage, and to manage the demands of the platform. Once on Instagram, their primary behaviors consisted of mindless diversions and deliberate acts. Although teens reported many positive emotional responses, the variety, unpredictability, and habitual nature of their experiences revealed Instagram to be an unreliable tool for emotion regulation (ER). We present a model of teens’ ER processes on Instagram and offer design considerations for supporting adolescent emotion regulation. ",
    "title": "``You Go Through So Many Emotions Scrolling Through Instagram'': How Teens Use Instagram To Regulate Their Emotions",
    "id": 188498,
    "sequence": 289,
    "queryCoordinates": {
      "visualization": [
        6.635496031291114,
        -6.080311868540944
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "This paper explores a multimodal approach for translating emotional cues present in speech, designed with Deaf and Hard-of-Hearing (DHH) individuals in mind. Prior work has focused on visual cues applied to captions, successfully conveying whether a speaker's words have a negative or positive tone (valence), but with mixed results regarding the intensity (arousal) of these emotions. We propose a novel method using haptic feedback to communicate a speaker's arousal levels through vibrations on a wrist-worn device. In a formative study with 16 DHH participants, we tested six haptic patterns and found that participants preferred single per-word vibrations at 75 Hz to encode arousal. In a follow-up study with 27 DHH participants, this pattern was paired with visual cues, and narrative engagement with audio-visual content was measured. Results indicate that combining haptics with visuals significantly increased engagement compared to a conventional captioning baseline and a visuals-only affective captioning style.",
    "title": "Tactile Emotions: Multimodal Affective Captioning with Haptics Improves Narrative Engagement for d/Deaf and Hard-of-Hearing Viewers",
    "id": 188499,
    "sequence": 290,
    "queryCoordinates": {
      "visualization": [
        14.99485987463336,
        -0.39265422461809724
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "Electrical muscle stimulation (EMS) has been leveraged to assist in learning motor skills by actuating the user’s muscles. However, existing systems provide static demonstration—actuating the correct movements, regardless of the user’s learning progress. Instead, we contrast two versions of a piano-tutoring system: a conventional EMS setup that moves the participant’s fingers to play the sequence of movements correctly, and a novel adaptive-EMS system that changes its guidance strategy based on the participant’s performance. The adaptive-EMS dynamically adjusts its guidance: (1) demonstrate by playing the entire sequence when errors are frequent; (2) correct by lifting incorrect fingers and actuating the correct one when errors are moderate; and (3) warn by lifting incorrect fingers when errors are low. We found that adaptive-EMS improved learning outcomes (recall) and was preferred by participants. We believe this approach could inspire new types of physical tutoring systems that promote adaptive over static guidance.",
    "title": "Adaptive Electrical Muscle Stimulation Improves Muscle Memory",
    "id": 188500,
    "sequence": 291,
    "queryCoordinates": {
      "visualization": [
        13.08135701042534,
        -9.212931062685524
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "Many visualizations have been developed for explainable AI (XAI), but they often require further reasoning by users to interpret. Investigating XAI for high-stakes medical diagnosis, we propose improving domain alignment with diagrammatic and abductive reasoning to reduce the interpretability gap. We developed DiagramNet to predict cardiac diagnoses from heart auscultation, select the best-fitting hypothesis based on criteria evaluation, and explain with clinically-relevant murmur diagrams. The ante-hoc interpretable model leverages domain-relevant ontology, representation, and reasoning process to increase trust in expert users. In modeling studies, we found that DiagramNet not only provides faithful murmur shape explanations, but also has better performance than baseline models. We demonstrate the interpretability and trustworthiness of diagrammatic, abductive explanations in a qualitative user study with medical students, showing that clinically-relevant, diagrammatic explanations are preferred over technical saliency map explanations. This work contributes insights into providing domain-aligned explanations for user-centric XAI in complex domains.",
    "title": "Diagrammatization and Abduction to Improve AI Interpretability With Domain-Aligned Explanations for Medical Diagnosis",
    "id": 188501,
    "sequence": 292,
    "queryCoordinates": {
      "visualization": [
        -1.172543563133159,
        -6.901097129627651
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "Robots extend beyond the tools of productivity; they also contribute to creativity. While typically defined as utility-driven technologies designed for productive or social settings, the role of robots in creative settings remains underexplored. This paper examines how robots participate in artistic creation. Through semi-structured interviews with robotic artists, we analyze the impact of robots on artistic processes and outcomes. We identify the critical roles of social interaction, material properties, and temporal dynamics in facilitating creativity. Our findings reveal that creativity emerges from the co-constitution of artists, robots, and audiences within spatial-temporal dimensions. Based on these insights, we propose several implications for socially informed, material-attentive, and process-oriented approaches to creation with computing systems. These approaches can inform the domains of HCI, including media and art creation, craft, digital fabrication, and tangible computing.",
    "title": "Encountering Robotic Art: The Social, Material, and Temporal Processes of Creation with Machines",
    "id": 188502,
    "sequence": 293,
    "queryCoordinates": {
      "visualization": [
        -0.3926761950489478,
        20.996328379167675
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "Virtue ethics is a philosophical tradition that emphasizes the cultivation of virtues in achieving the common good. It has been suggested to be an effective framework for envisioning more ethical technology, yet previous work on virtue ethics and technology design has remained at theoretical recommendations. Therefore, we propose an approach for identifying user experience design patterns that embody particular virtues to more concretely articulate virtuous technology designs. As a proof of concept for our approach, we documented seven design patterns for social media that uphold the virtues of Catholic Social Teaching. We interviewed 24 technology researchers and industry practitioners to evaluate these patterns. We found that overall the patterns enact the virtues they were identified to embody; our participants valued that the patterns fostered intentional conversations and personal connections. We pave a path for technology professionals to incorporate diverse virtue traditions into the development of technologies that support human flourishing.",
    "title": "Design Patterns for the Common Good: Building Better Technologies Using the Wisdom of Virtue Ethics",
    "id": 188503,
    "sequence": 294,
    "queryCoordinates": {
      "visualization": [
        9.131421435130799,
        -11.900300104368537
      ]
    }
  },
  {
    "session": "Well-being and Well-dying",
    "abstract": "Those who have read the human literature of thanato-technologies from the curious HCI humans must have pondered, at least briefly, how human-centred it all is. We, known in their terms as “digital remains” – the data they generated over the course of their mortal years- are often treated as mere design materials to craft their legacies or data to manage for inheritance. However, little do humans know that, just like their souls, we, too, need to embark on a rite of passage to mark the transition when they expire. And this is the tale of the script that guides us, the Digital Beings, to navigate the thresholds along that passage of our own, a script that might be the answer to one of humans’ dying problems.",
    "title": "Dying to Read: The Official Script of Digital Passage for the Little, Big, Digital Beings",
    "id": 188504,
    "sequence": 295,
    "queryCoordinates": {
      "visualization": [
        6.902159081189372,
        -8.565056918547306
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "Teaching scientific concepts is essential but challenging, and analogies help students connect new concepts to familiar ideas.\r\nAdvancements in large language models (LLMs) enable generating analogies, yet their effectiveness in education remains underexplored.\r\nIn this paper, we first conducted a two-stage study involving high school students and teachers to assess the effectiveness of LLM-generated analogies in biology and physics through a controlled in-class test and a classroom field study.\r\nTest results suggested that LLM-generated analogies could enhance student understanding particularly in biology, but require teachers' guidance to prevent over-reliance and overconfidence. \r\nClassroom experiments suggested that teachers could refine LLM-generated analogies to their satisfaction and inspire new analogies from generated ones, encouraged by positive classroom feedback and homework performance boosts.\r\nBased on findings, we developed and evaluated a practical system to help teachers generate and refine teaching analogies.\r\nWe discussed future directions for developing and evaluating LLM-supported teaching and learning by analogy.",
    "title": "Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies for Student Understanding and Classroom Practice?",
    "id": 188505,
    "sequence": 296,
    "queryCoordinates": {
      "visualization": [
        0.39206856131824386,
        -3.9807389066887873
      ]
    }
  },
  {
    "session": "Vulnerable Populations",
    "abstract": "Dementia impacts millions worldwide, with rural regions of Latin America facing notable challenges in diagnosis and care. Digital healthcare tools, while potentially transformative, often fail in these areas due to lack of cultural integration, usability issues, and missing features, resulting in ineffective top-down solutions. This case study explores how Community Engagement and Involvement (CEI) principles were applied in the design of a mobile health dementia screening system tailored for rural Peru. For 18 months, we engaged in an iterative participatory process with local community health workers (CHWs) and healthcare professionals. We detail how this process directly informed our design outcomes, ensuring the solution was adapted to the specific needs of the communities. In addition, the paper highlights key learnings for HCI practitioners and researchers working on similar projects. These insights underscore how participatory design approaches can lead to more effective socio-technical health solutions in resource-constrained settings.",
    "title": "Design and Development of a mHealth Dementia Screening Tool in Resource-Limited Settings",
    "id": 188506,
    "sequence": 297,
    "queryCoordinates": {
      "visualization": [
        -2.7335328823822094,
        14.748823613459319
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "Integrating curious behavior traits into robots is essential for them to learn and adapt to new tasks over their lifetime and to enhance human-robot interaction. However, the effects of robots expressing curiosity on user perception, user interaction, and user experience in collaborative tasks are unclear. In this work, we present a Multimodal Large Language Model-based system that equips a robot with non-verbal and verbal curiosity traits. We conducted a user study ($N=20$) to investigate how these traits modulate the robot's behavior and the users' impressions of sociability and quality of interaction. Participants prepared cocktails or pizzas with a robot, which was either curious or non-curious. Our results show that we could create user-centric curiosity, which users perceived as more human-like, inquisitive, and autonomous while resulting in a longer interaction time. We contribute a set of design recommendations allowing system designers to take advantage of curiosity in collaborative tasks.",
    "title": "Investigating LLM-Driven Curiosity in Human-Robot Interaction",
    "id": 188507,
    "sequence": 298,
    "queryCoordinates": {
      "visualization": [
        -18.37969186008383,
        10.158096629210029
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "Even for well-studied visual reasoning tasks such as those performed on bar charts, little is known about the cognitive strategies users adopt to solve them. Guidance systems that support users in learning visual reasoning require information on successful strategies to help unsuccessful users improve or change their strategies. We introduce the guidance paradigm of sequential visual cues (SVCs), accompanied by a differential pattern mining approach that determines relevant visual attention patterns from gaze data, and exemplified for bar charts. The novel feature of SVCs is to give hints on critical fragments of successful strategies, guiding users where to look in a visualization and in which order, but not what to do with this information. Results from an empirical study (N=30) show how critical patterns of successful and unsuccessful strategies differ for various bar chart tasks. In a qualitative survey (N=5), we explore how to surface relevant gaze patterns as SVCs.",
    "title": "Sequential Visual Cues from Gaze Patterns: Reasoning Assistance for Bar Charts",
    "id": 188508,
    "sequence": 299,
    "queryCoordinates": {
      "visualization": [
        -2.7063521955384564,
        -8.583452556734043
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "Consumer technology is increasingly used to support the self-care of atrial fibrillation (AF), a chronic heart condition that affects physical, emotional, and mental health due to its unpredictability, symptoms, and complications. Through interviews with 29 adults self-tracking while living with AF, we found that consumer technology enabled participants to outsource bodily awareness to their 'digitised heart,' facilitating innovative pill-in-pocket interventions and empowering negotiation in shared decision-making. Drawing on phenomenology, we introduce 'Bodily Doubt' to explain how uncertainty about the body shapes the use of technology in chronic illness and how the use of technology influences uncertainty. Technology mediates 'Bodily Doubt' both by providing reassurance and exacerbating it, particularly when technology fails to adapt to disease progression. Our findings have implications for understanding how technology influences the lived experience of illness, challenging experiential concepts of lived experience in self-tracking and design that foregrounds the experience of the lived body.",
    "title": "Rethinking Lived Experience in Chronic Illness: Navigating Bodily Doubt with Consumer Technology in Atrial Fibrillation Self-Care",
    "id": 188509,
    "sequence": 300,
    "queryCoordinates": {
      "visualization": [
        20.994852406701003,
        6.5739008526780385
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.\r\n\r\nThis paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.",
    "title": "Exploring Multimodal Generative AI for Education through Co-design Workshops with Students",
    "id": 188510,
    "sequence": 301,
    "queryCoordinates": {
      "visualization": [
        -13.081357010425341,
        9.212931062685522
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "In social Virtual Reality (VR), particularly within VRChat, a significant group of users often referred to as ``mutes'' refrain from voice communication. This study analyzes 4212 discussion entries, including both original submissions and comments, from the r/VRchat subreddit to explore the experiences and reasons behind this practice. Our findings indicate that muteness is an integral aspect of social VR culture, yet mute users face challenges, including exposure to abusive behaviors and communication barriers in a fast-paced environment. Factors of social VR like harassment, heightened social anxiety from the immersive presence, and the complexities of identity management can discourage voice communication, leading many to adopt ``muteness'' as a response. This behavior can be seen within the broader context of social disability, challenging normative communication assumptions. We highlight the risks of generalizing marginalized communities and emphasize the need for further research to address and support the unique needs of these groups in social VR spaces.\r\n",
    "title": "Understanding \"Mutes\" in Social Virtual Reality",
    "id": 188511,
    "sequence": 302,
    "queryCoordinates": {
      "visualization": [
        -2.740246833639362,
        -19.811386808871546
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "Optimal input settings vary across users due to differences in motor abilities and personal preferences, which are typically addressed by manual tuning or calibration. Although human-in-the-loop optimization has the potential to identify optimal settings during use, it is rarely applied due to its long optimization process. A more efficient approach would continually leverage data from previous users to accelerate optimization, exploiting shared traits while adapting to individual characteristics. We introduce the concept of Continual Human-in-the-Loop Optimization and a Bayesian optimization-based method that leverages a Bayesian-neural-network surrogate model to capture population-level characteristics while adapting to new users. We propose a generative replay strategy to mitigate catastrophic forgetting. We demonstrate our method by optimizing virtual reality keyboard parameters for text entry using direct touch, showing reduced adaptation times with a growing user base. Our method opens the door for next-generation personalized input systems that improve with accumulated experience.\r\n",
    "title": "Continual Human-in-the-Loop Optimization",
    "id": 188512,
    "sequence": 303,
    "queryCoordinates": {
      "visualization": [
        9.427934736519951,
        -17.638425286967102
      ]
    }
  },
  {
    "session": "XR for Diverse Needs",
    "abstract": "Virtual Reality (VR) offers immersive experiences through advanced interaction mechanisms and rich sensory stimuli but is often inaccessible to blind people due to its over-reliance on visual feedback. While prior work has investigated specific aspects of VR accessibility, there is little knowledge on how to design full, feature-rich VR experiences accessible to blind people. This paper presents the design and evaluation of a VR Boxing experience, developed through participatory design with an ex-professional boxer who is now blind. A user study with 15 blind participants explored their perceptions of the three-mode experience developed - Heavy Bag Training, Coach Training, and Combat - to inform the design of accessible VR experiences. Our findings highlight the importance of combining natural movement, rich auditory feedback, and well-timed guidance that also fosters user independence. Furthermore, they demonstrate the value of structured progression in complexity, while also opening opportunities for engaging spatial awareness and coordination training. ",
    "title": "Designing and Evaluating a VR Boxing Experience with Blind People",
    "id": 188513,
    "sequence": 304,
    "queryCoordinates": {
      "visualization": [
        1.9600024026547838,
        18.898634622151608
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "The rise of generative AI has brought a host of challenges for historically marginalized groups, including increased surveillance, AI-mediated racism, and algorithmic inequity. While stakeholders emphasize ethical and responsible AI that is safe, anti-discriminatory, and  \"protects human dignity\", the centrality of anti-Blackness in the design, development, and deployment of AI systems coupled with race-evasive approaches to defining and advancing ethical, equitable, and ‘human-centered’ technologies have exacerbated racial oppression. We present three case studies of speculative technologies designed by Black youth in a college bridge, summer course that examine ethical and responsible AI in their everyday lives. From a bottom-up approach, we infringe upon this broader discourse to provide an initial grounding of responsible and ethical AI as well as discuss the criticality of Black, historically anchored, culturally-situated lenses to offer justice-oriented design principles that can guide the teaching, learning, and design of technology.\r\n",
    "title": "\"Ethics is not neutral\": Understanding Ethical and Responsible AI Design from the Lenses of Black Youth",
    "id": 188514,
    "sequence": 305,
    "queryCoordinates": {
      "visualization": [
        6.861828880002177,
        4.112821953545773
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "Displays are crucial in modern smart devices, conveying information visually. Wearable displays have gained increasing interest due to their ability to integrate into everyday environments while maintaining an unobtrusive presence. Textile-based displays, in particular, offer extra advantages of comfort, lightness, and natural feel. We present LuxKnit, a design and fabrication pipeline for textile-based displays with integrated sensing using digital machine knitting. LuxKnit employs electroluminescent (EL) yarn for displays and conductive yarn for sensing. We offer an interactive design interface for users to customize the display’s color, shape, position, and size. We evaluate display luminance and sensing performance across various knitted layouts, deformations, and conductive yarn types. LuxKnit offers a scalable, deformable, stretchable, washable, and interactive display textile system with applications in assistive wearables, interactive educational interfaces, interactive input devices, and common display formats like the seven-segment display.",
    "title": "LuxKnit: Fabricating Interactive Display Textiles Integrated with Sensing by Machine Knitting",
    "id": 188515,
    "sequence": 306,
    "queryCoordinates": {
      "visualization": [
        -10.000264194352836,
        14.966453021445815
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "Breakthroughs in generative AI (GenAI) have fueled debates concerning the artistic and legal status of AI-generated creations. We investigate laypeople's perceptions (N=432) of AI-generated art through the lens of copyright law. We study lay judgments of GenAI images concerning several copyright-related factors and capture people's opinions of who should be the authors and rights-holders of AI-generated images. To do so, we held an incentivized AI art competition in which some participants used a GenAI model to create art while others evaluated these images. We find that participants believe creativity and effort, but not skills, are needed to create AI-generated art. Participants were most likely to attribute authorship and copyright to the AI model's users and to the artists whose creations were used for training. We find evidence of egocentric effects: participants favored their own art with respect to quality, creativity, and effort---particularly when these assessments determined real monetary awards.",
    "title": "Public Opinions About Copyright for AI-Generated Art: The Role of Egocentricity, Competition, and Experience",
    "id": 188516,
    "sequence": 307,
    "queryCoordinates": {
      "visualization": [
        19.811386808871546,
        2.74024683363936
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "Collaborative health-tracking technologies for children and parents have gained significant attention in recent years in HCI. This review examines the current state of these technologies by analyzing 29 studies screened from 15,973 search results across three databases. Our findings revealed three primary goals in these technologies: promoting family health, improving children’s health through child-parent co-tracking, and fostering children’s independence in self-tracking. For each goal, we examined child-parent roles, data types collected, and features that facilitate or hinder collaboration. Our findings highlight key directions for future research, including designing adaptable technologies to reflect evolving child-parent roles, exploring different technologies and tracking topics that impact child-parent dynamics, involving children in the system design stage to enhance collaborative features, and studying diverse populations with varied family characteristics. These insights aim to guide the creation of more effective and inclusive collaborative health-tracking technologies for children and parents.",
    "title": "Collaborative Health-Tracking Technologies for Children and Parents: A Review of Current Studies and Directions for Future Research",
    "id": 188517,
    "sequence": 308,
    "queryCoordinates": {
      "visualization": [
        -6.7880074553294145,
        7.343225094356857
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "In product design, effective design space exploration (DSE) is crucial for generating high-quality design ideas, requiring designers to possess broad knowledge and balance various constraints. As large-scale models thrive, AI has become an indispensable design collaborator by providing cross-domain knowledge and assistance with complex reasoning. To facilitate collaborative DSE between designers and AI, we frame and advance the design process through the problem-solution co-evolution model and design reasoning methods. A formative study was conducted to identify key strategies for the implementation. Then we developed CoExploreDS, a system that formalizes problems and solutions emerging in the human-AI collaborative design space into nodes. Using four reasoning methods, this system dynamically generates suggestions based on the ongoing design process. User studies confirmed that CoExploreDS significantly improves design quality and the human-AI collaboration experience.",
    "title": "CoExploreDS: Framing and Advancing Collaborative Design Space Exploration Between Human and AI",
    "id": 188518,
    "sequence": 309,
    "queryCoordinates": {
      "visualization": [
        20.90827365776381,
        1.960635777511964
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "Cooperation is challenging when group identities are involved. While people readily cooperate with in-group members, they struggle to build trust with out-group members. This study examines how text suggestions generated by Large Language Models (LLMs) can mitigate in-group-out-group bias and facilitate intergroup cooperation through conversations. We conducted an experiment with 482 participants who communicated with either in-group partners sharing their views or out-group partners with differing views, based on a preliminary survey. Participants received either \"personalized\" message suggestions aligned with their own views and conversation styles or \"relational\" suggestions using conversation styles tailored to whether their partner was in-group or out-group. Following the conversations, participants engaged in a cooperation game designed to measure trust behaviorally. Our results show that while personalized assistance widened the cooperation gap, relational assistance significantly improved out-group cooperation to match in-group levels. We discuss design implications for integrating social awareness into AI-driven conversational support systems.",
    "title": "Relational AI: Facilitating Intergroup Cooperation with Socially Aware Conversational Support",
    "id": 188519,
    "sequence": 310,
    "queryCoordinates": {
      "visualization": [
        -1.1672268192795257,
        -4.861849601988383
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "Recent advancements in generative artificial intelligence (AI) are profoundly impacting the broadcasting industry. While generative AI shows promise in supporting broadcasting professionals, its practical workflow integration remains underexplored. In this study, we conducted a user-focused investigation to understand how AI-based content creation support tools are being adopted and perceived in South Korean broadcasting stations. We used the AI Editing Assistant, an AI-powered post-production support tool, as a research probe. Through in-depth interviews with 37 diverse participants—including directors, editors, producers, developers, and executives—we discovered that generative AI significantly enhances production efficiency and unlocks new creative possibilities. However, we identified challenges such as lack of user-centered approach, demanding nature of broadcasting workflows, and professionals' low trust in AI technologies hinders widespread adoption. Based on our findings, we propose  implications, considerations, and guidelines for integrating generative AI into broadcasting practices, emphasizing improved multi-stakeholder communication and collaboration for effective and sustainable AI adoption. ",
    "title": "Understanding the Dynamics in Deploying AI-Based Content Creation Support Tools in Broadcasting Systems - Benefits, Challenges, and Directions",
    "id": 188520,
    "sequence": 311,
    "queryCoordinates": {
      "visualization": [
        -8.695725088797952,
        -16.89332309464452
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "Dark patterns (DPs) refer to unethical user interface designs that deceive users into making unintended decisions, compromising their privacy, safety, financial security, and more. Prior research has mainly focused on defining and classifying DPs, as well as assessing their impact on users, while legislative and technical efforts to mitigate them remain limited. Consequently, users are still exposed to DP risks, making it urgent to educate them on avoiding these harms. However, there has been little focus on developing educational interventions for DP awareness. This study addresses this gap by introducing DPTrek, an experiential learning (EL) platform that educates users through simulated real-world DP cases. Both qualitative and quantitative evaluations show the effectiveness of DPTrek in helping users identify and manage DPs. The study also offers insights for future DP education and research, highlighting challenges such as user-unfriendly taxonomies and the lack of practical mitigation solutions.",
    "title": "From Awareness to Action: The Effects of Experiential Learning on Educating Users about Dark Patterns",
    "id": 188521,
    "sequence": 312,
    "queryCoordinates": {
      "visualization": [
        4.273355186688746,
        16.454131257784486
      ]
    }
  },
  {
    "session": "WS26: Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "abstract": "Automated systems and AI-assisted workflows are evolving from support tools to sophisticated collaborators in so-called \"hybrid\" teams with human and AI-based members. This evolution presents new challenges and opportunities in the field of \"Automation Experience\", particularly in how these team members communicate, coordinate, and collaborate. This workshop aims to contribute to the design of automated systems that augment users' capabilities, maintain human autonomy, and create positive automation experiences in human-AI teams. Through presentations, a keynote talk, discussions, and interactive collaborative activities, researchers and practitioners from different fields will address challenges regarding communication, coordination, and collaboration within hybrid human-AI teams. The workshop aims to spark innovative research directions and foster collaborative interdisciplinary initiatives that will advance our understanding of automation experiences in an increasingly AI-dominated landscape.",
    "title": "Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "id": 188522,
    "sequence": 313,
    "queryCoordinates": {
      "visualization": [
        -10.061064342953468,
        -16.1175365452339
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "Chat-based prompts respond with verbose linear-sequential texts, making it difficult to explore and refine ambiguous intents, back up and reinterpret, or shift directions in creative AI-assisted design work. AI-Instruments instead embody \"prompts\" as interface objects via three key principles: (1) Reification of user-intent as reusable direct-manipulation instruments; (2) Reflection of multiple interpretations of ambiguous user-intents (Reflection-in-intent) as well as the range of AI-model responses (Reflection-in-response) to inform design \"moves\" towards a desired result; and (3) Grounding to instantiate an instrument from an example, result, or extrapolation directly from another instrument. Further, AI-Instruments leverage LLM’s to suggest, vary, and refine new instruments, enabling a system that goes beyond hard-coded functionality by generating its own instrumental controls from content. \r\nWe demonstrate four technology probes, applied to image generation, and qualitative insights from twelve participants, showing how AI-Instruments address challenges of intent formulation, steering via direct manipulation, and non-linear iterative workflows to reflect and resolve ambiguous intents. ",
    "title": "AI-Instruments: Embodying Prompts as Instruments to Abstract & Reflect Graphical Interface Commands as General-Purpose Tools",
    "id": 188523,
    "sequence": 314,
    "queryCoordinates": {
      "visualization": [
        -9.754160215099386,
        -6.989732362413619
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "Explainable Artificial Intelligence (XAI) is a discipline concerned with understanding predictions of AI systems. What is ultimately desired from XAI methods is for an AI system to link its input and output in a way that is interpretable with reference to the environment in which it is applied. A variety of methods have been proposed, but we argue in this paper that what has yet to be considered is miscommunication: the failure to convey and/or interpret an explanation accurately. XAI can be seen as a communication process and thus looking at how humans explain things to each other can provide guidance to its application and evaluation. We motivate a specific model of communication to help identify essential components of the process, and show the critical importance for establishing common ground, i.e., shared mutual knowledge, beliefs, and assumptions of the participants communicating.",
    "title": "(Mis)Communicating with our AI Systems",
    "id": 188524,
    "sequence": 315,
    "queryCoordinates": {
      "visualization": [
        17.638425286967095,
        -9.427934736519958
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "Text-to-image models can generate visually appealing images from text descriptions. \r\nEfforts have been devoted to improving model controls with prompt tuning and spatial conditioning. \r\nHowever, our formative study highlights the challenges for non-expert users in crafting appropriate prompts and specifying fine-grained spatial conditions (e.g., depth or canny references) to generate semantically cohesive images, especially when multiple objects are involved. \r\nIn response, we introduce SketchFlex, an interactive system designed to improve the flexibility of spatially conditioned image generation using rough region sketches. \r\nThe system automatically infers user prompts with rational descriptions within a semantic space enriched by crowd-sourced object attributes and relationships. \r\nAdditionally, SketchFlex refines users' rough sketches into canny-based shape anchors, ensuring the generation quality and alignment of user intentions. \r\nExperimental results demonstrate that SketchFlex achieves more cohesive image generations than end-to-end models, meanwhile significantly reducing cognitive load and better matching user intentions compared to region-based generation baseline.",
    "title": "SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches",
    "id": 188525,
    "sequence": 316,
    "queryCoordinates": {
      "visualization": [
        7.157381403894126,
        13.182256689929481
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "The growing sophistication of Large Language Models allows conversational agents (CAs) to engage users in increasingly personalized and targeted conversations. While users may vary in their receptiveness to CA persuasion, stylistic elements and agent personalities can be adjusted on the fly. Combined with image generation models that create context-specific realistic visuals, CAs have the potential to influence user behavior and decision making. We investigate the effects of linguistic and visual elements used by CAs on user perception and decision making in a charitable donation context with an online experiment (n=344). We find that while CA attitude influenced trust, it did not affect donation behavior. Visual primes played no role in shaping trust, though their absence resulted in higher donations and situational empathy. Perceptions of competence and situational empathy were potential predictors of donation amounts. We discuss the complex interplay of user and CA characteristics and the fine line between benign behavior signaling and manipulation.",
    "title": "Persuasion in Pixels and Prose: The Effects of Emotional Language and Visuals in Agent Conversations on Decision-Making",
    "id": 188526,
    "sequence": 317,
    "queryCoordinates": {
      "visualization": [
        16.17076094002452,
        13.398003232593183
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "As programming education becomes more widespread, many college students from non-computer science backgrounds begin learning programming. Collaborative programming emerges as an effective method for instructors to support novice students in developing coding and teamwork abilities. However, due to limited class time and attention, instructors face challenges in monitoring and evaluating the progress and performance of groups or individuals. To address this issue, we collect multimodal data from real-world settings and develop CPVis, an interactive visual analytics system designed to assess student collaboration dynamically. Specifically, CPVis enables instructors to evaluate both group and individual performance efficiently. CPVis employs a novel flower-based visual encoding to represent performance and provides time-based views to capture the evolution of collaborative behaviors. A within-subject experiment (N=22), comparing CPVis with two baseline systems, reveals that users gain more insights, find the visualization more intuitive, and report increased confidence in their assessments of collaboration.",
    "title": "CPVis: Evidence-based Multimodal Learning Analytics for Evaluation in Collaborative Programming",
    "id": 188527,
    "sequence": 318,
    "queryCoordinates": {
      "visualization": [
        12.576703862931755,
        -14.241717591081404
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "Animated data videos have gained significant popularity in recent years. However, authoring data videos remains challenging due to the complexity of creating and coordinating diverse components (e.g., visualization, animation, audio, etc.). Although numerous tools have been developed to streamline the process, there is a lack of comprehensive understanding and reflection of their design paradigms to inform future development. To address this gap, we propose a framework for understanding data video creation tools along two dimensions: what data video components to create and coordinate, including visual, motion, narrative, and audio components, and how to support the creation and coordination. By applying the framework to analyze 46 existing tools, we summarized key design paradigms of creating and coordinating each component based on the varying work distribution for humans and AI in these tools. Finally, we share our detailed reflections, highlight gaps from a holistic view, and discuss future directions to address them.",
    "title": "Reflecting on Design Paradigms of Animated Data Video Tools",
    "id": 188528,
    "sequence": 319,
    "queryCoordinates": {
      "visualization": [
        -17.893014088001753,
        -1.9596037473353578
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "Danmaku, a system of scene-aligned, time-synced, floating comments, can augment video content to create `collective knowledge'. However, its chaotic nature often hinders viewers from effectively assimilating the collective knowledge, especially in knowledge-intensive science videos. With a formative study, we examined viewers' practices for processing collective knowledge and the specific barriers they encountered. Building on these insights, we designed a processing pipeline to filter, classify, and cluster danmaku, leading to the development of CoKnowledge -- a tool incorporating a video abstract, knowledge graphs, and supplementary danmaku features to support viewers' assimilation of collective knowledge in science videos. A within-subject study (N=24) showed that CoKnowledge significantly enhanced participants’ comprehension and recall of collective knowledge compared to a baseline with unprocessed live comments. Based on our analysis of user interaction patterns and feedback on design features, we presented design considerations for developing similar support tools. ",
    "title": "CoKnowledge: Supporting Assimilation of Time-synced Collective Knowledge in Online Science Videos",
    "id": 188529,
    "sequence": 320,
    "queryCoordinates": {
      "visualization": [
        13.285048758225626,
        -14.950166537251944
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "While many haptic systems have been demonstrated for use in virtual and augmented reality, they most often enable a single category of feedback (e.g., kinematic breaking, object compliance, textures). Combining prior systems to achieve multi-dimensional effects is unwieldy, expensive, and often physically impossible. We believe this is holding back the ubiquity of rich haptics in both the consumer and industrial AR/VR/XR domains. In this work, we describe Reel Feel, a novel, shoulder-worn haptic system capable of rendering rigid geometry, object-bound haptic animations, impulsive forces, surface compliance, and fine-grained spatial effects all in one unified, worn device. Our design aimed to minimize the weight on the hands (<10 g), where a system's mass is most felt, as many prior systems are heavy gloves and exoskeletons. Finally, we sought to keep the device practical, being self-contained, low-cost, and low enough power to be feasible for consumer adoption with a high degree of mobility. In a user evaluation, our device rated better than a conventional vibrotactile baseline for all qualitative measures (immersion, realism, etc.) and allowed participants to more accurately discern object compliance and fine-grained spatial effects.",
    "title": "Reel Feel: Rich Haptic XR Experiences Using an Active, Worn, Multi-String Device ",
    "id": 188530,
    "sequence": 321,
    "queryCoordinates": {
      "visualization": [
        -13.398003232593185,
        16.170760940024515
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "Using supernumerary multi-limbs for complex tasks is a growing research focus in Virtual Reality (VR) and robotics. Understanding how users integrate extra limbs with their own to achieve shared goals is crucial for developing efficient supernumeraries. This paper presents an exploratory user study (N=14) investigating strategies for controlling virtual supernumerary limbs with varying autonomy levels in VR object manipulation tasks. Using a Wizard-of-Oz approach to simulate semi-autonomous limbs, we collected both qualitative and quantitative data. Results show participants adapted control strategies based on task complexity and system autonomy, affecting task delegation, coordination, and body ownership. Based on these findings, we propose guidelines—commands, demonstration, delegation, and labeling instructions—to improve multi-limb interaction design by adapting autonomy to user needs and fostering better context-aware experiences.",
    "title": "Juggling Extra Limbs: Identifying Control Strategies for Supernumerary Multi-Arms in Virtual Reality",
    "id": 188531,
    "sequence": 322,
    "queryCoordinates": {
      "visualization": [
        -18.74666239411584,
        -9.463754491798852
      ]
    }
  },
  {
    "session": "CS Education and Security",
    "abstract": "Developing STEAM (Science, Technology, Engineering, Art, and Math) education curricula encouraging participation from underrepresented groups is crucial for diversity in computational fields. Many existing programs attract cis-white males, to the exclusion of other groups. This paper discusses a camp where participants, primarily female youth ages 10-14 (N=45), engage in crafting social wearable technologies within a live-action roleplay context. Our findings from four camp sessions show increased self-reported competence and interest in STEAM among participants, alongside enhanced feelings of community and social support. The camp's innovative approach integrates design thinking, iterative design, and collaboration, proving effective in fostering inclusivity and engagement in STEAM. We adopted an iterative Research-through-Design process, with researchers embedded in the camp to observe and conduct surveys and interviews with participants. Researchers and educators can benefit from reading our results, which demonstrate the value of a playful, socially-engaged curriculum in attracting and retaining diverse students in STEAM fields.",
    "title": "Social Wearables Edu-Larp: Insights From a Novel Camp Combining Crafting, Coding, and Larping Aimed at Non-traditional Steam Participants",
    "id": 188532,
    "sequence": 323,
    "queryCoordinates": {
      "visualization": [
        -8.72496007072797,
        -4.88621241496955
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "Volumetric displays render true 3D graphics without forcing users to wear headsets or glasses. However, the optical diffusers that volumetric displays employ are rigid and thus do not allow for direct interaction. FlexiVol employs elastic diffusers to allow users to reach inside the display volume to have direct interaction with true 3D content. We explored various diffuser materials in terms of visual and mechanical properties. We correct the distortions of the volumetric graphics projected on elastic oscillating diffusers and propose a design space for FlexiVol, enabling various gestures and actions through direct interaction techniques. A user study suggests that selection, docking and tracing tasks can be performed faster and more precisely using direct interaction when compared to indirect interaction with a 3D mouse. Finally, applications such as a virtual pet or landscape edition highlight the advantages of a volumetric display that supports direct interaction.",
    "title": "FlexiVol: a Volumetric Display with an Elastic Diffuser to Enable Reach-Through Interaction",
    "id": 188533,
    "sequence": 324,
    "queryCoordinates": {
      "visualization": [
        15.78108160273513,
        -8.657797840548993
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "Live drills are the gold standard for mass casualty incident (MCI) training but are often too resource-intensive for widespread implementation. Immersive technologies offer a promising alternative, but can they deliver comparable fidelity and effectiveness? Working with a local disaster response academy, this paper investigated the potential of Augmented Virtuality (AV) in MCI training through two phases. First, we conducted a landscape analysis of 126 papers across the virtuality continuum, revealing trends in population, training focus, and evaluation metrics. Second, we empirically evaluated an AV system for mass casualty triage training against traditional role-playing and Virtual Reality (VR) approaches, involving 60 trainees in an operational curriculum. Results indicated that both AV and VR surpassed traditional simulations, with AV's tactile integration significantly enhancing physical engagement, satisfaction, and triage accuracy. Through the lens of triage, we discussed the broader practical implications of integrating immersive technologies like AV into real-world MCI education. \r\n",
    "title": "Bridging Simulation and Reality: Augmented Virtuality for Mass Casualty Triage Training - From Landscape Analysis to Empirical Insights",
    "id": 188534,
    "sequence": 325,
    "queryCoordinates": {
      "visualization": [
        11.435759204552241,
        -16.408028870510275
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "4D bioforming is a captivating yet often overlooked natural aesthetic phenomenon, involving the polymorphic transformations that occur during the construction of honeycomb by bees, which presents a significant opportunity for the innovative transformation of traditional apiculture. This paper proposes an industry-compatible prototyping method for polymorphic honeycomb creation following the phenomenon of 4D bioforming, aiming to introduce innovation to honeycomb forms through 4D bioforming while preserving the central role of beekeepers. The method is designed to align with the practical habits of beekeepers and can be outlined in four key steps: scaffold creation, quadrilateral shape division, bee path compilation with outer mold, and 4D bioforming. The dynamic temporal changes in the honeycomb were successfully demonstrated, enhancing the artistic aspect of honeycomb creation. Evaluation results suggest that the method is compatible with traditional practices, easily adoptable by beekeepers and that the polymorphic honeycomb meets essential aesthetic standards.",
    "title": "4D Bioforming with Bees: An Industry-Compatible Prototyping Method for Polymorphic Honeycomb Creation",
    "id": 188535,
    "sequence": 326,
    "queryCoordinates": {
      "visualization": [
        11.686523751328002,
        -2.724915156412486
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "Designing for others encourages children to empathize with and consider different perspectives and needs. A chatbot persona could allow children to design for stakeholder groups that are challenging to involve directly in educational activities, such as people with disabilities. In this paper, we explore how an artificial intelligence chatbot persona leveraging the GPT-4 large language model can support children's design empathy while designing for others. We report the design, development process, and implementation of a chatbot persona representing a 12-year-old child with low vision named Noel. The exploratory case study consisted of three 90- to 120-minute workshop sessions with nineteen students (ages 11 to 13) in a grade 6/7 classroom. Results illustrate ways that Noel supported students throughout the design process, their expressions of design empathy, and their experiences. We present implications for developers and educators along with future directions for research. ",
    "title": "Noel: A Chatbot Persona to Support Children Designing for Others",
    "id": 188536,
    "sequence": 327,
    "queryCoordinates": {
      "visualization": [
        -4.263200821770462,
        -2.6124928235797436
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors. In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger's comfort in relying on an AV, preference for control, confidence in the AV's ability, and explanation satisfaction. Errors negatively affected all outcomes. Surprisingly, despite identical driving, explanation errors reduced ratings of the AV's driving ability. Severity and potential harm amplified the negative impact of errors. Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes. Prior trust and expertise were positively associated with outcome ratings. Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence. We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems.",
    "title": "What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence",
    "id": 188537,
    "sequence": 328,
    "queryCoordinates": {
      "visualization": [
        -6.988987705124716,
        -0.39249313066034164
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a \"view from nowhere'' but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI. \r\n",
    "title": "Plurals: A System for Guiding LLMs via Simulated Social Ensembles",
    "id": 188538,
    "sequence": 329,
    "queryCoordinates": {
      "visualization": [
        0.39264758786215975,
        -13.99449276936274
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "This paper presents an investigation of the potential of virtual reality (VR) to bridge the gap between humans and the largely unexplored deep sea, using the immersive, playful experience of \"Echo of the Abyss\" (EotA). Built around the structure of a deep-sea dive experience, EotA aims to enhance users' sense of interconnectedness with underwater environments and stimulate curiosity about marine life. The qualitative analysis reveals a heightened empathy, respect for aquatic life, and a newfound interest in real-world diving experiences. Quantitative results indicate a marginal increase in positive perceptions towards the sea. From these findings, we discuss VR as an effective transformational tool to foster a deeper ecological consciousness. Our contributions can benefit HCI researchers and game designers interested in designing ocean sustainability-driven experiences and games. \r\n",
    "title": "Diving into the Abyss: Exploring Deep Sea Connection and Curiosity through Virtual Reality ",
    "id": 188539,
    "sequence": 330,
    "queryCoordinates": {
      "visualization": [
        3.5159255986870934,
        19.688531361797832
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "Concept designers in the entertainment industry create highly detailed, often imaginary environments for movies, games, and TV shows. Their early ideation phase requires intensive research, brainstorming, visual exploration, and combination of various design elements to form cohesive designs. However, existing AI tools focus on image generation from user specifications, lacking support for the unique needs and complexity of concept designers' workflows. Through a formative study with 12 professional designers, we captured their workflows and identified key requirements for AI-assisted ideation tools. Leveraging these insights, we developed AIdeation to support early ideation by brainstorming design concepts with flexible searching and recombination of reference images. A user study with 16 professional designers showed that AIdeation significantly enhanced creativity, ideation efficiency, and satisfaction (all \\textit{p}<.01) compared to current tools and workflows. A field study with 4 studios for 1 week provided insights into AIdeation's benefits and limitations in real-world projects. After the completion of the field study, two studios, covering films, television, and games, have continued to use AIdeation in their commercial projects to date, further validating AIdeation's improvement in ideation quality and efficiency.",
    "title": "AIdeation: Designing a Human-AI Collaborative Ideation System for Concept Designers",
    "id": 188540,
    "sequence": 331,
    "queryCoordinates": {
      "visualization": [
        -15.956647306859043,
        1.1770330175946766
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "Researchers in HCI and teacher education have long recognized the potential of visualization to support teachers' reflective practice. Despite much progress however, teacher educators continue to highlight the need for more dynamic classroom data visualizations to better support teachers' reflective practice, particularly about spatial dimensions of their pedagogy. In response, this article makes three contributions. First, we build on prior work to present the Interaction Geography Slicer (IGS), an open-source tool to dynamically visualize movement, conversation, and video data over space and time in settings such as classrooms. Second, we share findings from a participatory design-based research project involving 11 experienced high school mathematics teachers who used the IGS over one year to support their reflective practice. Finally, we propose new directions for exploratory spatial classroom data visualization.",
    "title": "The Interaction Geography Slicer: Designing Exploratory Spatial Data Visualization Tools for Teachers' Reflective Practice",
    "id": 188541,
    "sequence": 332,
    "queryCoordinates": {
      "visualization": [
        -0.39254139461934423,
        -7.990363649641379
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "While virtual reality (VR) games offer immersive experiences, prolonged improper head posture during VR gaming sessions can cause neck discomfort and injuries. To address this issue, we prototyped a framework to detect instances of improper head posture and apply various visual interventions to correct them. After assessing the prototype's usability in a co-design workshop with participants experienced in VR design and kinesiology, we refined the interventions in two main directions --- using explicit visual indicators or employing implicit background changes. The refined interventions were subsequently tested in a controlled experiment involving a target selection task. The study results demonstrate that the interventions effectively helped participants maintain better head posture during VR gameplay compared to the control condition. ",
    "title": "Co-design & Evaluation of Visual Interventions for Head Posture Correction in Virtual Reality Games",
    "id": 188542,
    "sequence": 333,
    "queryCoordinates": {
      "visualization": [
        5.813545739921842,
        -20.17926376084709
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "Online tracking remains problematic, with compliance and ethical issues persisting despite regulatory efforts. Consent interfaces, the visible manifestation of this industry, have seen significant attention over the years. We present robust automated methods to study the presence, design, and third-party suppliers of consent interfaces at scale and the web service consent-observatory.eu to do it with. We examine the top 10,000 websites across 31 countries under the ePrivacy Directive and GDPR (n=254.148). Our findings show that 67% of websites use consent interfaces, but only 15% are minimally compliant, mostly because they lack a reject option. Consent management platforms (CMPs) are powerful intermediaries in this space: 67% of interfaces are provided by CMPs, and three organisations hold 37% of the market. There is little evidence that regulators’ guidance and fines have impacted compliance rates, but 18% of compliance variance is explained by CMPs. Researchers should take an infrastructural perspective on online tracking and study the factual control of intermediaries to identify effective leverage points.",
    "title": "A Cross-Country Analysis of GDPR Cookie Banners and Flexible Methods for Scraping Them",
    "id": 188543,
    "sequence": 334,
    "queryCoordinates": {
      "visualization": [
        0.3924931306603381,
        -6.988987705124716
      ]
    }
  },
  {
    "session": "Accessibility",
    "abstract": "People with Visual Impairment (PVI) face numerous challenges when engaging in Customer-to-Customer (C2C) e-commerce, par-ticularly in tasks like listing, packaging, shipping, and post-sale interactions. This case study investigates the accessibility barriers that prevent visually impaired users from independently managing the selling process on C2C platforms. Through semi-structured interviews with eight participants with low vision, we identified challenges, such as reliance on assistance, inaccessible platform interfaces, and difficulties in offline tasks. The study highlights the need for AI-powered assistive tools, accessible design improvements, and integrated post-sale management systems. Our findings contribute actionable insights for inclusive design practices, aiming to foster independence and satisfaction for visually impaired users in digital marketplaces.",
    "title": "AccessibleShip: Exploring Packaging and Shipping Barriers for Visually Impaired Users in C2C E-Commerce",
    "id": 188544,
    "sequence": 335,
    "queryCoordinates": {
      "visualization": [
        -13.517657043995314,
        8.559961918193554
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "Generative AI image creation tools have the potential to transform design education and practice, but raise critical concerns for creativity and ownership. We leverage the 2022 launch of tools like Midjourney and DALL.E as a point dividing design enthusiasts into pre- and post-tool learners. In this paper, we conduct 28 artifact-based interviews with designers at varying levels of tool introduction, to understand how they perceive and use generative AI in their design roles. Our results indicate a rift in the value system of designers, with experienced designers being more circumspect about the loss of traditional creativity and foundational design skills. On the practical side, there exists a tension between the growing marketability of AI-related skills for design vs. the limited affordances of these tools for achieving meaningful designs. We discuss implications for the shifting definitions of design as a field, creativity and ownership, and AI in the design curriculum. ",
    "title": "Catalyst for Creativity or a Hollow Trend?: A Cross-Level Perspective on The Role of Generative AI in Design",
    "id": 188545,
    "sequence": 336,
    "queryCoordinates": {
      "visualization": [
        1.1770330175946793,
        15.956647306859043
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "Adherence to data protection measures such as pseudonymization or anonymization is critical in human subjects research because it has a direct impact on the confidentiality of participants' sensitive information, trust in research practices, and compliance with ethical and legal standards. Regulations such as the General Data Protection Regulation (GDPR) and guarantees made by researchers in informed consent forms mandate strict protocols for data security. However, compliance with these is not always straightforward. To gain qualitative insights into data protection practices in the field of Usable Security and Privacy (USP), we conducted interviews with 22 practitioners (five professors, eight researchers, nine data protection officers) and one focus group with five researchers. Overall, our results show a high awareness of ethical and legal responsibilities but highlight many practical and procedural issues. Based on these, we make concrete recommendations on how to improve the protection of personal data in research.",
    "title": "Out of Sight, Out of Mind? Exploring Data Protection Practices for Personal Data in Usable Security & Privacy Studies",
    "id": 188546,
    "sequence": 337,
    "queryCoordinates": {
      "visualization": [
        2.7249151564124787,
        11.686523751328004
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "Embodiment is an everyday experience that typically goes unnoticed. While we often take it for granted, with the adoption of virtual reality (VR) technology, embodiment in virtual bodies and worlds has become an important consideration for designers of immersive experiences. To date, the VR design community has primarily considered embodiment in terms of body ownership over a synchronized visual representation. In this paper, we construct an interactional framework of virtual embodiment, beginning by revisiting what it really means to be “embodied.” Our framework reconnects embodiment and presence in virtual environments founded in Dourish's concept of embodied interaction and Heidegger's Dasein or “being-in-the-world.” We discuss how embodiment, fundamentally rooted in past and present interactions, changes our understanding of body ownership and its extension into VR. Integrating theories from VR research, philosophy, HCI, and psychology we uncover the complex interplay of interaction, environment, and touch in shaping embodied experiences. We present a novel framework for understanding embodiment in VR rooted in interaction, enabling designers to create more immersive and meaningful virtual worlds.",
    "title": "Being in Virtual Worlds: How Interaction, Environment, and Touch Shape Embodiment in Immersive Experiences",
    "id": 188547,
    "sequence": 338,
    "queryCoordinates": {
      "visualization": [
        -1.937848579973945,
        6.7264212536156975
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners' decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners' personalized construction of a step tree through a \"learner-LLM co-decomposition\" approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox's impact on cognitive load, identified usage patterns, and analyzed learners' strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.",
    "title": "DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition",
    "id": 188548,
    "sequence": 339,
    "queryCoordinates": {
      "visualization": [
        1.947956525442926,
        8.7866640640794
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "The relationship between the Nigerian police and citizens is strained, hindering the co-design of conventional technologies to enhance community policing (CP) initiatives, hence the imperative to involve both in the design of a usable CP technology that can carter for their needs. Our preliminary findings indicate that Nigerian citizens are reluctant to participate in co-design activities with the police due to discomfort, which could potentially bias the design outcomes. Designing a CP technology with such stakeholders is crucial, but a new challenge for the Human Computer Interaction (HCI) community, as no existing framework has addressed it. We introduce Conflict Sensitive Design (CSD), a co-design approach that leverages mediation techniques (tension reduction, leveling, common ground reminder, separated meetings, formalizing agreements) to iteratively collect, analyze, and reconcile design inputs, ensuring that the final design is usable for CP enhancement. Our case application worked in CP technology requirements gathering with Nigerian CP stakeholders, and it could be extended to related HCI contexts. We present a structured approach to conflict resolution in co-design processes, and discuss the lessons learned as a spotlight to guide other designers in related contexts.",
    "title": "How Should We Design Technology With Diverse Stakeholders Who Wish Not to Attend Design Activities Together?",
    "id": 188549,
    "sequence": 340,
    "queryCoordinates": {
      "visualization": [
        -14.585548805965152,
        -3.5016804578385727
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "Positionality acknowledges that researchers’ subjectivities, values and experiences influence approaches to and outcomes of research. It underlines and promotes self-awareness and explicit demonstration of reflexivity. To understand how positionality is conceptualised and used in HCI, we conducted two studies: (i) a scoping review of positionality and reflexivity statements in CHI papers from the last 11 years and (ii) a survey of HCI researchers (n=75). Our findings show that positionality statements are often viewed as a box-ticking exercise and their influence on the research is seldom discussed. They are also often restricted to more sensitive areas of research and may impact marginalised identities. We argue that positionality statements may be valuable but not as markers of methodological rigour; their content should be at the discretion of\r\nauthors and methodologically consistent. Our contributions include a current snapshot of positionality in HCI and reflections on its current role and future directions in HCI.",
    "title": "Exploring Positionality in HCI: Perspectives, Trends, and Challenges",
    "id": 188550,
    "sequence": 341,
    "queryCoordinates": {
      "visualization": [
        16.51954149971097,
        9.386412980437575
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "Research in Augmented Reality (AR) and Virtual Reality (VR) has mostly viewed them in isolation. Yet, when used together in practical settings, AR and VR each offer unique strengths, necessitating multiple transitions to harness their advantages. This paper investigates potential challenges in Cross-Reality (CR) transitions to inform future application design.\r\nWe implemented a CR system featuring a 3D modeling task that requires users to switch between PC, AR, and VR. Using a talk-aloud study (n=12) and thematic analysis, we revealed that frictions primarily arose when transitions conflicted with users' Spatial Mental Model (SMM). Furthermore, we found five transition archetypes employed to enhance productivity once an SMM was established. Our findings uncover that transitions have to focus on establishing and upholding the SMM of users across realities, by communicating differences between them.",
    "title": "A Qualitative Investigation of User Transitions and Frictions in Cross-Reality Applications",
    "id": 188551,
    "sequence": 342,
    "queryCoordinates": {
      "visualization": [
        7.777983262274437,
        -11.64057457223563
      ]
    }
  },
  {
    "session": "With AI",
    "abstract": "In the AI community, benchmarks to evaluate \\textit{model} quality are well established, but an equivalent approach to benchmarking products built upon generative AI models is still missing. This has had two consequences. First, it has made teams focus on \\textit{model quality} over the developer experience, while successful products combine both. Second, product team have struggled to answer questions about their products in relation to their competitors.\r\n\r\nIn this case study, we share: (1) our process to create robust, enterprise-grade and modular components to support the benchmarking of the developer experience (DX) dimensions of our team's AI for code offerings, and (2) the components we have created to do so, including demographics and attitudes towards AI surveys, a benchmarkable task, and task and feature surveys. By doing so, we hope to lower the barrier to the DX benchmarking of genAI-enhanced code products.",
    "title": "Creating benchmarkable components to measure the quality of AI-enhanced developer tools",
    "id": 188552,
    "sequence": 343,
    "queryCoordinates": {
      "visualization": [
        -0.3926596563665982,
        -15.995181099139268
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "Physical interactions in Human-Computer Interaction (HCI) provide immersive ways for people to engage with technology. However, designers face challenges in integrating physical computing and modeling when designing physical interactions. We explore triboelectric material sensing, a promising technology that addresses these challenges, though its use within the design community remains underexplored. To bridge this gap, we develop a toolkit consisting of triboelectric material pairs, a mechanism taxonomy, a signal processing tool, and computer program templates. We introduce this toolkit to designers in two workshops, where reflections on the design process highlight its effectiveness and inspire innovative interaction designs. Our work contributes valuable resources and knowledge to the design community, making triboelectric sensing more accessible and fostering creativity in physical interaction design.",
    "title": "Designing Physical Interactions with Triboelectric Material Sensing",
    "id": 188553,
    "sequence": 344,
    "queryCoordinates": {
      "visualization": [
        -15.68799504993456,
        -10.71852654580977
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems. We detail 10 interviews with IT professionals, the resulting recommender system developed, and 20 user sessions with IT professionals interacting with our prompt recommendations. Results indicate that responsible prompting recommendations have the potential to support novice prompt engineers and raise awareness about RAI in prompting-time. They also suggest that recommendations should simultaneously maximize both a prompt’s similarity to a user’s input as well as a diversity of associated social values provided. These findings contribute to RAI by offering practical ways to provide user guidance and enrich human-GenAI interaction via prompt recommendations.",
    "title": "Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time",
    "id": 188554,
    "sequence": 345,
    "queryCoordinates": {
      "visualization": [
        -10.936973319490871,
        -1.1758463372162362
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "In response to various environmental and societal challenges, co-housing has emerged to support social cohesion, grassroots innovation and ecological regeneration. Co-housing communities typically have smaller personal spaces, closer neighbourly relationships, and engage in more mutually supportive sustainable practices. To understand such communities’ motivations and visions, we developed a speculative design tool that harnesses Generative Artificial Intelligence (GenAI) to facilitate the envisioning of alternative future scenarios that challenge prevailing values, beliefs, lifestyles, and ways of knowing in contemporary society. Within the context of co-housing communities, we conducted a participatory design study with participants in co-creating their future communities. This paper unpacks implications and also reflects on the co-design approach employing GenAI. Our main findings highlight that GenAI, as a catalyst for imagination, empowers individuals to create visualisations that pose questions through a plural and situated speculative discourse.",
    "title": "“Housing Diversity Means Diverse Housing”: Blending Generative AI into Speculative Design in Rural Co-Housing Communities",
    "id": 188555,
    "sequence": 346,
    "queryCoordinates": {
      "visualization": [
        19.401470182737025,
        -8.03635207966688
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "User-centered design necessitates researchers deeply understanding target users throughout the design process. However, during early-stage user interviews, researchers may misinterpret users due to time constraints, incorrect assumptions, and communication barriers. To address this challenge, we introduce InsightBridge, a tool that supports real-time, AI-assisted information synthesis and visual-based verification. InsightBridge automatically organizes relevant information from ongoing interview conversations into an empathy map. It further allows researchers to specify elements to generate visual abstracts depicting the selected information, and then review these visuals with users to refine the visuals as needed. We evaluated the effectiveness of InsightBridge through a within-subject study (N=32) from both the researchers’ and users’ perspectives. Our findings indicate that InsightBridge can assist researchers in note-taking and organization, as well as in-time visual checking, thereby enhancing mutual understanding with users. Additionally, users’ discussions of visuals prompt them to recall overlooked details and scenarios, leading to more insightful ideas.",
    "title": "InsightBridge: Enhancing Empathizing with Users through Real-Time Information Synthesis and Visual Communication",
    "id": 188556,
    "sequence": 347,
    "queryCoordinates": {
      "visualization": [
        -0.39265965636659783,
        15.995181099139268
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "Graphical user interfaces (GUIs) are at the heart of almost every software we encounter. GUIs are often created through a collaborative effort involving UX designers, product owners, and software developers, constantly facing changing requirements. Historically, problems in GUI development include a fragmented, poorly integrated tool landscape and high synchronization efforts between stakeholders. Recent approaches suggest using large language models (LLMs) to recognize requirements fulfillment in GUIs and automatically propose new GUI components. Based on ten interviews with practitioners, this paper proposes an LLM-based assistant as a Figma plug-in that bridges the gap between user stories and GUI prototyping. We evaluated the prototype with 40 users and 40 crowd-workers, showing that the effectiveness of GUI creation is improved by using LLMs to detect requirements' completion and generate new GUI components. We derive design rationales to support cross-functional integration in software development, ensuring that our plug-in integrates well into established processes.",
    "title": "Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development",
    "id": 188557,
    "sequence": 348,
    "queryCoordinates": {
      "visualization": [
        -7.704608487732221,
        10.470864723162295
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "Location-based media applications such as Google Maps, Strava and Pokémon GO together have more than a billion monthly active users, and popular social media such as Snapchat and Instagram now also feature map-based content. All these media products rely on user-generated content as a core element of their service, but there is a lack of synthesis on the users' motivations to contribute this data to the platform providers. In this study, we performed a literature review to uncover users' motivations to participate in location-based crowdsourcing and contribute shared content on these platforms. Among our findings, we show that spatial and temporal aspects, social effects, technical elements, motivational mechanisms, practical value offered to the contributors and individual differences need to be considered in motivating users to contribute shared content. We present recommendations for designers, suggest which terminology to use around this topic and propose an agenda for future research.",
    "title": "User Motivations to Participate in Crowdsourcing and Contribute User-generated Content on Location-based Media: A Literature Review",
    "id": 188558,
    "sequence": 349,
    "queryCoordinates": {
      "visualization": [
        3.4968706943411765,
        13.55624930971166
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "Songwriting is often driven by multimodal inspirations, such as imagery, narratives, or existing music, yet songwriters remain unsupported by current music AI systems in incorporating these multimodal inputs into their creative processes. We introduce Amuse, a songwriting assistant that transforms multimodal (image, text, or audio) inputs into chord progressions that can be seamlessly incorporated into songwriters' creative process. A key feature of Amuse is its novel method for generating coherent chords that are relevant to music keywords in the absence of datasets with paired examples of multimodal inputs and chords. Specifically, we propose a method that leverages multimodal language models to convert multimodal inputs into noisy chord suggestions and uses a unimodal chord model to filter the suggestions. A user study with songwriters shows that Amuse effectively supports transforming multimodal ideas into coherent musical suggestions, enhancing users' agency and creativity throughout the songwriting process.",
    "title": "AMUSE: Human-AI Collaborative Songwriting with Multimodal Inspirations",
    "id": 188559,
    "sequence": 350,
    "queryCoordinates": {
      "visualization": [
        8.559961918193551,
        -13.517657043995316
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "Competition is typically centered on balance, fairness, and symmetric play. However, in mixed-ability competition, symmetric play is often not possible or desirable. Currently, it is not clear what can or should be done in the pursuit of the design of inclusive competitive experiences (in sports and games).  In this paper, we interview 15 people with motor or visual disabilities who actively engage in competitive activities (e.g., Paralympics, competitive gaming). We focus on understanding engagement and fairness perspectives within mixed-ability competitive scenarios, highlighting the obstacles and opportunities these interactions present. We relied on thematic analysis to examine the motivations to compete, team structures and roles, perspectives on ability disclosure and rankings, and a reflection on the role of technology in mediating competition. We contribute with an understanding of (1) how competition is experienced, (2) key factors influencing inclusive and fair competition, and (3) reflections for the design of inclusive competitive experiences. ",
    "title": "Perspectives on Mixed-Ability Competition",
    "id": 188560,
    "sequence": 351,
    "queryCoordinates": {
      "visualization": [
        -18.963487670851496,
        -1.1773424979432954
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "Automated Urban Air Mobility (UAM) can improve passenger transportation and reduce congestion, but its success depends on passenger trust. While initial research addresses passengers' information needs, questions remain about how to simulate air taxi flights and how these simulations impact users and interface requirements. \r\nWe conducted a between-subjects study (N=40), examining the influence of motion fidelity in Virtual-Reality-simulated air taxi flights on user effects and interface design. Our study compared simulations with and without motion cues using a 3-Degrees-of-Freedom motion chair. Optimizing the interface design across six objectives, such as trust and mental demand, we used multi-objective Bayesian optimization to determine the most effective design trade-offs.\r\nOur results indicate that motion fidelity decreases users' trust, understanding, and acceptance, highlighting the need to consider motion fidelity in future UAM studies to approach realism. However, minimal evidence was found for differences or equality in the optimized interface designs, suggesting personalized interface designs.",
    "title": "Fly Away: Evaluating the Impact of Motion Fidelity on Optimized User Interface Design via Bayesian Optimization in Automated Urban Air Mobility Simulations",
    "id": 188561,
    "sequence": 352,
    "queryCoordinates": {
      "visualization": [
        -9.427934736519957,
        -17.6384252869671
      ]
    }
  },
  {
    "session": "Perception of Systems",
    "abstract": "Individuals with reflex epilepsy may have seizures caused by stimuli including flashing lights, colors, motion, and patterns. Many studies have investigated seizure-inducing content in multimedia, but studies addressing seizure triggers in mobile apps are still scarce. Hence, we examined user reviews aiming to identify and describe seizure triggers in mobile apps based on user's reported experiences. Our findings reveal significant patterns of how apps can unintentionally harm users with epilepsy, highlighting the need for improved design practices and more comprehensive accessibility guidelines, which are mainly focused on flashy content and animation. More specifically, we present evidences indicating that users do experience seizures triggered by mobile app interaction, which are not solely limited to multimedia interaction. Most seizure triggers are associated with flashy content and less frequently by color schemes, motion, transitions, glitches, and bugs. In addition, videos and advertisements are the most seizure-inducing content reported by users. ",
    "title": "Investigating User Perceptions of Epilepsy-Related Seizure Triggers in Mobile Apps: An Analysis of User Reviews",
    "id": 188562,
    "sequence": 353,
    "queryCoordinates": {
      "visualization": [
        -3.2472402416509203,
        -3.802029828000153
      ]
    }
  },
  {
    "session": "Vulnerable Populations",
    "abstract": "This case study explores the challenges of recruiting a particular at-risk population, older adults affected by scams, focusing on the complexities of recruitment and trust in online environments. Specifically, we analyze a contentious recruitment attempt on Nextdoor, a hyper-local social platform aimed at fostering community engagement within neighborhoods. While responses varied, a vocal subset of users raised concerns about the legitimacy of the study, the researcher's identity, and the recruitment methods employed. Through an analysis of user responses, this case study examines the individual, community, and researcher-led negotiations of trust and distrust in this recruitment process. We emphasize the validity of doubt, the importance of user engagement, the features of recruitment that were found (un)trustworthy, and the role of context in recruitment. These findings provide insights into the under-researched area of recruitment, specifically concerning effective strategies for engaging at-risk users in online research while navigating distrust.",
    "title": "The Right to Be Skeptical: Insights from Recruiting At-Risk Users on Nextdoor",
    "id": 188563,
    "sequence": 354,
    "queryCoordinates": {
      "visualization": [
        -5.8847116824193835,
        -1.1705419320967674
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "This paper provides an in-depth view of people's experiences with food allergies, focusing on their social media use and its influences on healthy habits and identities. Through 18 interviews, our study examined how information and identity work on social media influences health behaviors, social interactions, self-expression, and navigation of algorithms for those with food allergies. Social media functions as both a source of empowerment and community and a platform for stigma and emotional distress. Our findings highlight how individuals manage their food allergy identity and online visibility on algorithm-driven platforms. The concept of ``on-and-off identities'' is introduced to capture this complex identity work. Design considerations for HCI include: 1) creating mindful social media experiences that support agency while addressing vulnerability in identity and information work, and 2) reflections on the challenges of evolving health contexts and social media ecologies. We urge HCI researchers and designers to adopt a holistic perspective on identity and information work to better support marginalized populations. ",
    "title": "\"It's Too Much On Top of Your Own Food Drama'': Exploring Food Allergy Identity and Experience Through Social Media",
    "id": 188564,
    "sequence": 355,
    "queryCoordinates": {
      "visualization": [
        -10.825223247697277,
        1.9530851587973383
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "This work introduces the concept of Embodied Measurement (EM), designed to improve the validity and inclusivity of cognitive load assessments by incorporating physical interactions that mirror mental effort. We implemented a haptic force-feedback turning knob as an alternative to traditional Likert-scale ratings and compared it with visual (mouse-based) and combined (haptic and visual) modalities. Participants completed a cognitive load task with varying difficulty levels using each modality, while biosignals such as heart rate variability, skin conductance, and pupil size were recorded to objectively assess cognitive load. In addition, qualitative feedback was gathered to explore participants' experiences with each input method. Our findings highlight the potential of EM to offer more tangible and intuitive ways of measuring cognitive load, with the combined modality providing the most comprehensive feedback. This study contributes to human-computer interaction (HCI) research by proposing new approaches for measuring cognitive and emotional effort through physical interaction.",
    "title": "Embodied Measurement: Tangible Interactions to Enhance the Validity of Self-Report Measures",
    "id": 188565,
    "sequence": 356,
    "queryCoordinates": {
      "visualization": [
        19.688531361797832,
        -3.515925598687097
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Data profiling plays a critical role in understanding the structure of complex datasets and supporting numerous downstream tasks, such as social media analytics and financial fraud detection. While existing research predominantly focuses on structured data formats, a substantial portion of semi-structured textual data still requires ad-hoc and arduous manual profiling to extract and comprehend its internal structures. In this work, we propose StructVizor, an interactive profiling system that facilitates sensemaking and transformation of semi-structured textual data. Our tool mainly addresses two challenges: a) extracting and visualizing the diverse structural patterns within data, such as how information is organized or related, and b) enabling users to efficiently perform various wrangling operations on textual data. Through automatic data parsing and structure mining,  StructVizor enables visual analytics of structural patterns, while incorporating novel interactions to enable profile-based data wrangling. A comparative user study involving 12 participants demonstrates the system's usability and its effectiveness in supporting exploratory data analysis and transformation tasks.",
    "title": "StructVizor: Interactive Profiling of Semi-Structured Textual Data",
    "id": 188566,
    "sequence": 357,
    "queryCoordinates": {
      "visualization": [
        14.656546221839262,
        8.613109359986627
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "Productivity applications including word processors, spreadsheets, and presentation tools are crucial in work, education, and personal settings. Blind users typically access these tools via screen readers (SRs) and face significant accessibility and usability challenges. Recent advancements in Generative AI (GenAI) may address these challenges by enabling natural language interactions and contextual task understanding. However, there is limited understanding of SR users’ needs and attitudes toward GenAI assistance in these applications. We surveyed 99 SR users to gain a holistic understanding of the challenges they face when using productivity applications, the impact of these challenges on their productivity and independence, and their initial perceptions of AI assistance. Driven by their enthusiasm, we conducted interviews with 16 SR users to explore their attitudes toward GenAI and its potential usefulness in productivity applications. Our findings highlight its need to support existing SR workflows and the importance of enabling customization and task verification.",
    "title": "The Sky is the Limit: Understanding How Generative AI can Enhance Screen Reader Users' Experience with Productivity Applications",
    "id": 188567,
    "sequence": 358,
    "queryCoordinates": {
      "visualization": [
        -6.467156727579007,
        2.678784026555629
      ]
    }
  },
  {
    "session": "Well-being and Tracking",
    "abstract": "Over the past decade, mobile apps have been widely adopted as a digital intervention method for mental health support, offering scalable and accessible solutions to address the growing global mental health challenges. However, sustaining user engagement in real-world settings remains a major challenge in the development of these applications. This study systematically examines factors that hinder user engagement in existing mobile mental health support systems through a scoping review of the literature. After an initial identification of 1,267 papers, we conducted a final analysis of 111 empirical studies using mobile app-based mental health support systems. The study investigates the main factors that negatively affect user engagement from user and system perspectives. Based on these findings, we propose guidelines for enhancing user engagement and structuring personalized emotional interaction design along three dimensions: adaptive, continuous, and multimodal interactions. Furthermore, we discuss the potential for integration with advanced AI methods (e.g., LLM-based AI agents) as a way to achieve these design implications and suggestions. Our results provide critical insights for enhancing long-term user engagement in the development of future mental health support systems.",
    "title": "\"I Don’t Know Why I Should Use This App”: Holistic Analysis on User Engagement Challenges in Mobile Mental Health",
    "id": 188568,
    "sequence": 359,
    "queryCoordinates": {
      "visualization": [
        -8.756176437987879,
        -19.087414025656432
      ]
    }
  },
  {
    "session": "XR for Diverse Needs",
    "abstract": "Head-worn augmented reality (AR) allows audiences to be immersed and engaged in stories told by live presenters. While presenters may also be in AR to have the same level of immersion and awareness as their audience, this symmetric presentation style may diminish important social cues such as eye contact. In this work, we examine the effects this (a)symmetry has on engagement, group awareness, and social interaction in co-located one-on-one augmented presentations. We developed a presentation system incorporating 2D/3D content that audiences can view and interact with in AR, with presenters controlling and delivering the presentation in either a symmetric style in AR, or an asymmetric style with a handheld tablet. We conducted a within- and between-subjects evaluation with 12 participant pairs to examine the differences between these symmetric and asymmetric presentation modalities. From our findings, we extracted four themes and derived strategies and guidelines for designers interested in augmented presentations.",
    "title": "Examining the Effects of Immersive and Non-Immersive Presenter Modalities on Engagement and Social Interaction in Co-located Augmented Presentations",
    "id": 188569,
    "sequence": 360,
    "queryCoordinates": {
      "visualization": [
        4.05069907325864,
        5.708926082714822
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "The efficacy of digital solutions to increase energy efficiency, including technical optimisations and behavioural influence, has long been a subject of debate within sustainable HCI (SHCI). While the viewpoints of policymakers and academics are frequently published (and often contradictory), less is known about the views of those on the ground. In this paper we ask: What are energy professionals' views of digital energy-saving interventions and their users? What are the challenges they face implementing these interventions? Based on a university campus case study with twelve semi-structured interviews and a focus group with energy and facilities' professionals, we illustrate how they strongly advocate digital efficiency as a pathway to sustainability; yet, this optimism is in apparent tension with key barriers they identify to realising 'their seamless visions', particularly the complexities of the human behaviour they are seeking to optimise. These findings underscore the seductiveness of techno-optimism and the need for more systemic change.",
    "title": "Of Ironies and Agency: Energy Professionals’ Views on Digital Interventions and Their Users",
    "id": 188570,
    "sequence": 361,
    "queryCoordinates": {
      "visualization": [
        -2.7249151564124774,
        11.686523751328004
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "As esports grows into a multi-million dollar industry of professional players and competitions, so too grows the interest in and need for professional coaching. Accordingly, there are increased demands and attempts to support and improve coaching for esports. A more comprehensive, granular understanding of the esports coaching process would provide a valuable foundation to inform opportunities to advance the domain via HCI theories and practices. However, in-depth studies of coaching practice, from the lens of HCI, are far less common in existing literature. In this paper, we take the first steps to provide such a foundation through an observation study conducted at an elite, award-winning League of Legends training academy. By analyzing 112 hours of dialogue and footage from coaching sessions, we identify pertinent activities and events that occur within the coaching process, which enable us to consider how esports coaching can be improved via theory, practice, and technology from HCI.",
    "title": "Crafting Champions: An Observation Study of Esports Coaching Processes",
    "id": 188571,
    "sequence": 362,
    "queryCoordinates": {
      "visualization": [
        8.314696123025453,
        5.555702330196022
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "Procrastination, the voluntary delay of tasks despite potential negative consequences, has prompted numerous time and task management interventions in the HCI community. While these interventions have shown promise in addressing specific behaviors, psychological theories suggest that learning about procrastination itself may help individuals develop their own coping strategies and build mental resilience. However, little research has explored how to support this learning process through HCI approaches. We present ProcrastiMate, a text adventure game where players learn about procrastination's causes and experiment with coping strategies by guiding in-game characters in managing relatable scenarios. Our field study with 27 participants revealed that ProcrastiMate facilitated learning and self-reflection while maintaining psychological distance, motivating players to integrate newly acquired knowledge in daily life. This paper contributes empirical insights on leveraging serious games to facilitate learning about procrastination and offers design implications for addressing psychological challenges through HCI approaches.",
    "title": "Walk in Their Shoes to Navigate Your Own Path: Learning About Procrastination Through A Serious Game",
    "id": 188572,
    "sequence": 363,
    "queryCoordinates": {
      "visualization": [
        9.836477968456824,
        4.923789310689838
      ]
    }
  },
  {
    "session": "Data Interpretation and Storytelling",
    "abstract": "Data collection and representation invariably involve interpretation with various layers of translation. We designed the Inner Ear—a porcelain device that both captures and represents home vibration data—to rethink the relationship between home dwellers and their data. In this paper, we report on the deployment of the Inner Ear with seven participants in Seattle, Washington, USA. We examine stills and quotes from the Inner Ear Shorts: short documentary films that capture participants’ experiences and reflections with the Inner Ear. Our findings outline nuanced relationships with data that foreground sensorial and conscious experiences to engage with objects, spaces, and infrastructure, and deemphasize legibility to give space to memory and broaden definitions of data. We discuss how more ambiguous relationships with data can be beneficial to reconfigure everyday lives with data. We conclude with a reflection on the use of documentary filmmaking as a complementary methodological approach to synthesizing and analyzing research data.",
    "title": "Stills from the Inner Ear Shorts: Collecting and Living with Data",
    "id": 188573,
    "sequence": 364,
    "queryCoordinates": {
      "visualization": [
        14.037920695671863,
        -11.266622499313073
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "Despite the growing prominence of Artificial Intelligence (AI) chatbots used in education, there remains a significant gap in our understanding of how interface design elements, particularly avatar representations, influence learning experiences. This paper explores the impact of different AI chatbot avatar representations on students' learning experiences through a mixed-methods within-subjects study, where participants interacted with three distinct types of AI chatbot interfaces with a common large language model (LLM) over a 14-week university course. Our findings reveal that preferences vary according to factors such as learning habits and learning activities. Avatar design also exhibits affordances for specific prompting behaviors, while the perceived human touch influenced learning experiences in nuanced ways. Additionally, real-world relationships with the individuals behind deepfakes influence these experiences. These insights suggest that the thoughtful integration of diverse avatar representations in AI chatbot systems for different learners and settings can greatly enhance learning experiences.",
    "title": "Exploring the Impact of Avatar Representations in AI Chatbot Tutors on Learning Experiences",
    "id": 188574,
    "sequence": 365,
    "queryCoordinates": {
      "visualization": [
        -12.710449912821009,
        2.728454326843019
      ]
    }
  },
  {
    "session": "HCI Methods",
    "abstract": "Researchers often place a strong focus on statistical significance when reporting the results of statistical tests. However, effect sizes are reported less frequently, and interpretation in the context of the study and the research field is even rarer. These interpretations of effect sizes are, however, necessary to understand the practical importance of a result for the community.  To explore how Usable Security & Privacy (USP) and HCI researchers interpret effect sizes and make judgments on practical importance, we conducted survey and interview studies with a total of 63 researchers at CHI and SOUPS 2023. Our studies focused on Cohen's d and odds ratios in two USP and one HCI scenario. We analyzed which artifacts researchers consider when judging effect size, and found misconceptions and variation between the participants, highlighting how difficult judging statistics can be. Based on our findings, we make concrete recommendations for improved reporting practices around effect sizes. ",
    "title": "A Qualitative Study on How Usable Security and HCI Researchers Judge the Size and Importance of Odds Ratio and Cohen's d Effect Sizes",
    "id": 188575,
    "sequence": 366,
    "queryCoordinates": {
      "visualization": [
        2.67878402655563,
        -6.467156727579006
      ]
    }
  },
  {
    "session": "Robot and Agent",
    "abstract": "Social robots are employed as companions, helping in industrial and domestic environments. Adapting robots' capabilities to user needs can be achieved through teaching from human demonstrations. However, the influence of robots' preexisting proficiency and learning rate on human teachers' self-efficacy and perception of the robots is underexplored. In this paper, we simulated four robot performance types that combine: (1) preexisting proficiency (low/high) and (2) learning rate (slow/fast). We conducted a controlled lab experiment studying the impact of robots' performance type on teachers' self-efficacy, willingness to teach the robot, and perception of the robot (N=24), in which robots placed objects in suitable locations. Fast learners were perceived as more intelligent, anthropomorphic, and likable, and this caused higher teaching self-efficacy regardless of preexisting skills. Slow learners caused frustration while teaching. Moreover, participants stopped teaching robots with low preexisting skills sooner, regardless of the learning rate, indicating potential bias caused by expectations.",
    "title": "RoboTeach: How Student Robots' Preexisting Proficiency and Learning Rate Affect Human Teachers Demonstrating Object Placement",
    "id": 188576,
    "sequence": 367,
    "queryCoordinates": {
      "visualization": [
        1.1747357299804655,
        8.923003752364293
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "Frontline workers (FLWs) in gender-based violence (GBV) service provision regularly engage in intense emotional labor to provide survivors of GBV with essential, often life-saving, services. However, FLWs experience intense burnout, resulting in turnover rates as high as 50% annually and a critical loss of services for survivors. In order to design digital burnout interventions in a context where so few exist, we recruited 15 FLWs for a 3-stage qualitative study where they used two existing applications to reflect on, and reimagine, concrete design features necessary to address FLW burnout in GBV service provision. We contribute important findings regarding designing specifically for empathy-based stress (EBS) in frontline work contexts, preferences for activities, desired interactivity, among other requirements for interventions. We synthesize our design recommendations through an example scenario of a collaborative just-in-time adaptive intervention (co-JITAI) system that integrates peer-based support that can adapt to users’ changing needs and contexts over time. ",
    "title": "\"All Day, Every Day, Listening to Trauma\": Investigating Features of Digital Interventions for Empathy-Based Stress and Burnout",
    "id": 188577,
    "sequence": 368,
    "queryCoordinates": {
      "visualization": [
        -1.9578928833007874,
        -14.871672920607153
      ]
    }
  },
  {
    "session": "Health and Well-being",
    "abstract": "Managing complex chronic illness is challenging due to its unpredictability. This paper explores the potential of voice for automated flare-up forecasts. We conducted a six-week speculative design study with individuals with endometriosis, tasking participants to submit daily voice recordings and symptom logs. Through focus groups, we elicited their experiences with voice capture and perceptions of its usefulness in forecasting flare-ups. Participants were enthusiastic and intrigued at the potential of flare-up forecasts through the analysis of their voice. They highlighted imagined benefits from the experience of recording in supporting emotional aspects of illness and validating both day-to-day and overall illness experiences. Participants reported that their recordings revolved around their endometriosis, suggesting that the recordings’ content could further inform forecasting. We discuss potential opportunities and challenges in leveraging the voice as a data modality in human-centered AI tools that support individuals with complex chronic conditions.",
    "title": "The Voice of Endo: Leveraging Speech for an Intelligent System That Can Forecast Illness Flare-ups",
    "id": 188578,
    "sequence": 369,
    "queryCoordinates": {
      "visualization": [
        4.664426045664024,
        -5.219495154182162
      ]
    }
  },
  {
    "session": "Physical and Tangible",
    "abstract": "Robots are increasingly being used in public spaces in the UK. Museums and galleries are a noteworthy setting for exploring robot adoption, such as for providing guided tours or enabling remote visits. Although robots have been deployed in museums in the past, there is arguably little information about what is involved in the process of both deploying and researching them. In this case study paper, we present our experiences and lessons learnt from conducting a research study of a robot-guided tour in a museum in the UK. We describe the process and stakeholders, and discuss the challenges and opportunities that emerged throughout. We provide recommendations for Human-Robot Interaction researchers hoping to move their investigations out of the lab and into the real world.",
    "title": "Please Follow Me to the Next Stop: A Case Study of Planning, Deploying and Researching a Robot-Guided Tour in a Museum in the UK",
    "id": 188579,
    "sequence": 370,
    "queryCoordinates": {
      "visualization": [
        15.03869049764854,
        7.927028958943916
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "While many technologies have been developed for facilitating interaction between neurodivergent and neurotypical people to bridge communication differences and reduce social exclusion, most focus on supporting and teaching neurodivergent people to adapt to neurotypical standards and norms. To promote a more balanced approach to bridging the social gap, we conducted a 5-day diary study and semi-structured interviews with 16 participants (8 neurotypical and 8 with intellectual disability) to examine the current factors and barriers to their social interactions and to explore the design of social support chatbot systems. Our findings revealed diverging views between the groups on factors they valued in their interaction, and identified social uncertainty and differing social expectations as the main barriers to successful interactions. Based on the results, we outline three pitfalls that social support chatbots can fall into if not designed mindfully, and suggest design approaches that promote bidirectional social support and interdependence.",
    "title": "Working Together Toward Interdependence: Chatbot-Based Support for Balanced Social Interactions Between Neurodivergent and Neurotypical Individuals",
    "id": 188580,
    "sequence": 371,
    "queryCoordinates": {
      "visualization": [
        15.611234080616457,
        3.5056198425099168
      ]
    }
  },
  {
    "session": "Technology-Facilitated Family Interaction",
    "abstract": "Improving telepresence for children expands educational opportunities and connects faraway family. Yet, research about child-centered physical telepresence systems (tangible interfaces for telepresence) remains sparse, despite established benefits of tangible interaction for children. To address this gap, we collaborated with child designers (ages 8-12) over 2-years of online/1-year of hybrid participatory design. Together, we adapted one approach to physical telepresence (tabletop robots) for child users. Using a case study methodology, we explore how our tabletop telepresence robot platform influenced children’s connections with one another over the 3-year study. In our analysis, we compare four vignettes representing cooperation/conflict between children while using the platform; centering theories of ownership, collaboration, and co-design roles. Through this exploration of children’s interpersonal dynamics while using the platform, we uncover four key features of tabletop telepresence robots for children: (1) Anonymous Robot Control (2) Robot/Material Distribution, (3) Robot Form/Size, and (4) Robot Stewardship.",
    "title": "Children using Tabletop Telepresence Robots for Collaboration: A Longitudinal Case Study of Hybrid and Online Intergenerational Participatory Design",
    "id": 188581,
    "sequence": 372,
    "queryCoordinates": {
      "visualization": [
        -17.83918928399116,
        6.539367376890132
      ]
    }
  },
  {
    "session": "Personal Data and Decision-Making",
    "abstract": "Explanatory information helps users to evaluate the suggestions offered by AI-driven decision support systems. With large language models, adjusting explanation expressions has become much easier. However, how these expressions influence human decision-making remains largely unexplored. This study investigated the effect of explanation tone (e.g., formal or humorous) on decision-making, focusing on AI roles and user attributes. We conducted user experiments across three scenarios depending on AI roles (assistant, second-opinion provider, and expert) using datasets designed with varying tones. The results revealed that tone significantly influenced decision-making regardless of user attributes in the second-opinion scenario, whereas its impact varied by user attributes in the assistant and expert scenarios.  In addition, older users were more influenced by tone, and highly extroverted users exhibited discrepancies between their perceptions and decisions. Furthermore, open-ended questionnaires highlighted that users expect tone adjustments to enhance their experience while emphasizing the importance of tone consistency and ethical considerations. Our findings provide crucial insights into the design of explanation expressions.",
    "title": "Do Expressions Change Decisions? Exploring the Impact of AI's Explanation Tone on Decision-Making",
    "id": 188582,
    "sequence": 373,
    "queryCoordinates": {
      "visualization": [
        10.158096629210036,
        18.379691860083827
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "Diffusion model-generated images can appear indistinguishable from authentic photographs, but these images often contain artifacts and implausibilities that reveal their AI-generated provenance. Given the challenge to public trust in media posed by photorealistic AI-generated images, we conducted a large-scale experiment measuring human detection accuracy on 450 diffusion-model generated images and 149 real images. Based on collecting 749,828 observations and 34,675 comments from 50,444 participants, we find that scene complexity of an image, artifact types within an image, display time of an image, and human curation of AI-generated images all play significant roles in how accurately people distinguish real from AI-generated images. Additionally, we propose a taxonomy characterizing artifacts often appearing in images generated by diffusion models. Our empirical observations and taxonomy offer nuanced insights into the capabilities and limitations of diffusion models to generate photorealistic images in 2024.",
    "title": "Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images",
    "id": 188583,
    "sequence": 374,
    "queryCoordinates": {
      "visualization": [
        13.55624930971166,
        -3.496870694341176
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "Designers of storytelling experiences in virtual reality (VR) can take advantage of the medium's realism and immersion to communicate their intentions. However, interaction freedom comes with unpredictability, raising the risk of miscommunication between the experience sought by the designer and the player's interpretation. To better understand such miscommunications, we revisit Don Norman's work on stages of action to propose a model of designer-player gulfs in VR that incorporates eight classes of communication gulfs. We designed a two-phase study where 10 participants designed VR scenarios and then played scenarios created by previous participants. Through coupled structured interviews, we identified 127 issues in VR-mediated communication that were mapped to our model to understand their impact on the player's interpretation of the narrative experience. Our work provides a roadmap to identifying sources of miscommunication in VR, a first step to conceiving principles and guidelines for achieving effective communication in storytelling experiences.",
    "title": "The Triangle of Misunderstanding in Interactive Virtual Narratives: Gulfs Between System, Designers and Players",
    "id": 188584,
    "sequence": 375,
    "queryCoordinates": {
      "visualization": [
        -7.612719409963751,
        -9.276125440352839
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "Design tools and probing, in particular, have long offered critical perspectives in HCI, broadening the understanding of who benefits from the design. Further, the designerly implementation of critical perspectives and theories using tools such as probes can support HCI designers with theoretically informed dialogical tools. However, these approaches and processes are majorly designed to understand human interactions. In this paper, we introduce urban noticing probes developed to decentre the humans in multispecies interactions by following the arts of noticing theory: noticing into, for, and through within urban relationality, focusing on the case of community animals in Türkiye. Our goal is to create a better understanding of the functions of \"urban noticing probes\" for HCI designers and researchers to (1) gain relational and reflexive awareness, (2) identify intervention spaces for multispecies cohabitation, and (3) explore future design directions for urban noticing probes.",
    "title": "Designing Urban Noticing Probes for Community Animals and Cohabitation in Türkiye",
    "id": 188585,
    "sequence": 376,
    "queryCoordinates": {
      "visualization": [
        -5.478852861078486,
        7.140180062621116
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Intimate partner violence (IPV) is a pervasive global issue, affecting one in three women worldwide, with particularly high rates of perpetration among men. Roots causes of IPV include harmful social and gender norms (SGNs). Despite existing prevention strategies, many focus on interventions after the violence has occurred, leaving a critical gap in primary prevention. My research seeks to fill this gap by developing “Bold Sky” a gender-transformative digital game aimed at preventing IPV perpetration among young men. Grounded in Human-Computer Interaction, public health, and social work principles, this research will use co-design and community-based methodologies to engage young men and IPV prevention experts in its development to support relevance to this target group and evaluation of the game to ensure effectiveness in shifting harmful SGNs. The aim for this research is to co-design and develop “Bold Sky” and launched for real-world impact.",
    "title": "Bold Sky: A Community-Based Intimate Partner Violence Prevention Digital Game",
    "id": 188586,
    "sequence": 377,
    "queryCoordinates": {
      "visualization": [
        17.96146061829486,
        1.177256326142575
      ]
    }
  },
  {
    "session": "Workplace Interactions and Wellbeing",
    "abstract": "It is important to motivate healthy behaviors, especially in office environments. However, there are few systems which integrate physical engagement mechanisms in such environments. This paper presents the design and evaluation of DistKey, a set of hotkeys allocated in different spatial interfaces of the workspace, enabling users to engage in some office tasks through intentional body movements. Through a within-subject experiment with 20 office workers, we compared DistKey with a traditional keyboard to assess the health benefits and effectiveness of integrating exercise into the workflow. Our results confirmed the benefits of DistKey-led healthful interactions in enhancing physical health and reducing mental stress during different tasks at work. Based on our follow-up qualitative research, a range of design insights are discussed to enlighten the design and development of future healthful spatial interfaces for increased office vitality.",
    "title": "DistKey: Incorporating Physical Activities into Daily Workflow through Spatially Distributed Hotkeys ",
    "id": 188587,
    "sequence": 378,
    "queryCoordinates": {
      "visualization": [
        7.704608487732219,
        10.470864723162297
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "Glitches -- moments when technologies do not work as desired -- will become increasingly common as industrially-designed robots move into complex contexts. Taking glitches to be potential sites of critical ethical reflection, we examine a glitch that occurred in the context of a collaborative research project where professional dancers with different disabilities improvised with a robotic arm. Through a first-person account, we analyse how the dancer, the robot, and the rest of the research team enacted ethics in the moment of glitch. Through this analysis, we discovered a deep and implicit ethical misalignment wherein our enactments of ethics in response to the glitch did not align with the values of the project. This prompted a critical re-engagement with our research process through which we forged a dialogue between different ethical perspectives that acted as an invitation to bring us back into ethical alignment with the project's values.",
    "title": "In the Moment of Glitch: Engaging with Misalignments in Ethical Practice",
    "id": 188588,
    "sequence": 379,
    "queryCoordinates": {
      "visualization": [
        6.126563953361277,
        -3.386032209736677
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "The limited accuracy of eye-tracking on smartphones restricts its use. Existing RGB-camera-based eye-tracking relies on extensive datasets, which could be enhanced by continuous fine-tuning using calibration data implicitly collected from the interaction. In this\r\ncontext, we propose COMETIC (Cursor Operation Mediated Eye-Tracking Implicit Calibration), which introduces a cursor-based interaction and utilizes the inherent correlation between cursor and eye movement. By filtering valid cursor coordinates as proxies for the ground truth of gaze and fine-tuning the eye-tracking model with corresponding images, COMETIC enhances accuracy during the interaction. Both filtering and fine-tuning use pre-trained models and could be facilitated using personalized, dynamically updated data. Results show COMETIC achieves an average eye-tracking er-\r\nror of 278.3 px (1.60 cm, 2.29◦), representing a 27.2% improvement compared to that without fine-tuning. We found that filtering cursor points whose actual distance to gaze is 150.0 px (0.86 cm) yields the best eye-tracking results.",
    "title": "Enhancing Smartphone Eye Tracking with Cursor-Based Interactive Implicit Calibration",
    "id": 188589,
    "sequence": 380,
    "queryCoordinates": {
      "visualization": [
        7.853169308807447,
        -6.190939493098343
      ]
    }
  },
  {
    "session": "Auditory UI",
    "abstract": "Current AI sound awareness systems can provide deaf and hard of hearing people with information about sounds, including discrete sound sources and transcriptions. However, synthesizing AI outputs based on DHH people’s ever-changing intents in complex auditory environments remains a challenge. In this paper, we describe the co-design process of SoundWeaver, a sound awareness system prototype that dynamically weaves AI outputs from different AI models based on users’ intents and presents synthesized information through a heads-up display. Adopting a Research through Design perspective, we created SoundWeaver with one DHH co-designer, adapting it to his personal contexts and goals (e.g., cooking at home and chatting in a game store). Through this process, we present design implications for the future of “intent-driven” AI systems for sound accessibility.",
    "title": "Weaving Sound Information to Support Real-Time Sensemaking of Auditory Environments: Co-Designing with a DHH User",
    "id": 188590,
    "sequence": 381,
    "queryCoordinates": {
      "visualization": [
        -8.322766926012354,
        -9.986568514523638
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "Despite the growing research on users’ perceptions of health AI, adolescents’ perspectives remain underexplored. This study explores adolescents’ perceived benefits and risks of health AI technologies in clinical and personal health settings. Employing Design Fiction, we conducted interviews with 16 adolescents (aged 13-17) using four fictional design scenarios that represent current and future health AI technologies as probes. Our findings revealed that with a positive yet cautious attitude, adolescents envision unique benefits and risks specific to their age group. While health AI technologies were seen as valuable learning resources, they also raised concerns about confidentiality with their parents. Additionally, we identified several factors, such as severity of health conditions and previous experience with AI, influencing their perceptions of trust and privacy in health AI. We explore how these insights can inform the future design of health AI technologies to support learning, engagement, and trust as adolescents navigate their healthcare journey. ",
    "title": "Understanding Adolescents’ Perceptions of Benefits and Risks in Health AI Technologies through Design Fiction ",
    "id": 188591,
    "sequence": 382,
    "queryCoordinates": {
      "visualization": [
        11.406089484000466,
        9.741720724952753
      ]
    }
  },
  {
    "session": "Working with AI",
    "abstract": "Millions of users prompt large language models (LLMs) for various tasks, but how good are people at prompt engineering? Do users actually get closer to their desired outcome over multiple iterations of their prompts? These questions are crucial when no gold-standard labels are available to measure progress. This paper investigates a scenario in LLM-powered data labeling, “prompting in the dark,” where users iteratively prompt LLMs to label data without using manually-labeled benchmarks. We developed PromptingSheet, a Google Sheets add-on that enables users to compose, revise, and iteratively label data through spreadsheets. Through a study with 20 participants, we found that prompting in the dark was highly unreliable—only 9 participants improved labeling accuracy after four or more iterations. Automated prompt optimization tools like DSPy also struggled when few gold labels were available. Our findings highlight the importance of gold labels and the needs, as well as the risks, of automated support in human prompt engineering, providing insights for future tool design.",
    "title": "Prompting in the Dark: Assessing Human Performance in Prompt Engineering for Data Labeling When Gold Labels Are Absent",
    "id": 188592,
    "sequence": 383,
    "queryCoordinates": {
      "visualization": [
        20.746837161554062,
        -7.319067412721333
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "HCI research on goals and behavior change has significantly increased over the past decade. However, while emerging work has synthesized personal informatics goals, fewer efforts have focused on also integrating HCI research on behavior change to chart future research directions.We conducted a systematic reviewof 180 papers focused on goals and behavior change from over 10 years of SIGCHI journals and conference proceedings. We further analyzed 37 papers from the data set that included evaluations of interventions’ effectiveness in-the-wild. We also reported on the effectiveness of 76 of such technology-based interventions and the meta-analysis of 28 of these interventions. We find that most research has focused on goals in the health and wellbeing domains, centered on the individual, low intrinsic goals, and partial use of theoretical constructs in technology-based interventions. We highlight opportunities for supporting multiple-domain, social, high intrinsic, and qualitative goals in HCI research for behavior change, and for more effective technology-based interventions with stronger theoretical underpinning, supporting users’ awareness of deep motives for qualitative goals.",
    "title": "A Systematic Review and Meta-Analysis of Research on Goals for Behavior Change",
    "id": 188593,
    "sequence": 384,
    "queryCoordinates": {
      "visualization": [
        9.276125440352844,
        7.612719409963746
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Intermittent Exotropia (IXT), an eye condition where one eye deviates outwardly, is complex to diagnose in young children. Observation of its manifestation relies on several factors, with the key one being inattention. My goal is to develop a method to diagnose IXT in kids at home or a clinic using a phone or tablet. \r\nMy work starts with systematically reviewing publications claiming to use gamification for medical practitioners. This then motivates the use of a game design technique called ``Juicy Design’', which I examine as a method to induce low attention and disengagement. \r\nNext, I will work on a method to accurately measure eye deviations using computer vision, a dataset made of original and synthetic images, and a model to generate relevant IXT measurements, which will be used in the app that displays cartoons processed with different levels of Juicy design to induce IXT.",
    "title": "Revealing a Concealed Eye Disorder in Children: Designing a Solution Grounded in HCI Principles",
    "id": 188594,
    "sequence": 385,
    "queryCoordinates": {
      "visualization": [
        12.94665524902218,
        -1.1764853857853068
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand 𝑁 = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet spots\" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.",
    "title": "Super Kawaii Vocalics: Amplifying the “Cute” Factor in Computer Voice",
    "id": 188595,
    "sequence": 386,
    "queryCoordinates": {
      "visualization": [
        9.754160215099375,
        -6.989732362413637
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Accuracy and precision are central values in the AI communities and the technology sector. This paper provides empirical evidence on the construction and organizational management of technical accuracy, demonstrating how technology companies' preoccupation with such values leads to harm. Drawing on nine months of multi-sited ethnographic fieldwork in China, we document how AI trainers' everyday work practices, challenges, and harms stem from clients' demands for high levels of technical accuracy. We introduce the concept of precision labor to unpack the labor dimension of constructing and performing accuracy in AI training. This concept highlights the hidden and excessive labor required to reconcile the ambiguity and uncertainty involved in this process. We argue that precision labor offers a new lens to illuminate three critical aspects of AI training: 1) the negative health and financial impacts of hidden and excessive labor on AI workers; 2) emerging harms, including workers' subordinate roles to machines and financial precarity; and 3) a conceptual contribution to contexts beyond AI training. This contribution re-centers arbitrariness in technical production, highlights the excessive demands of precision labor, and examines the legitimization of labor and harm. Our study also contributes to existing scholarship on the prevailing values and invisible labor in AI production, underscoring accuracy as performative rather than self-evident and unambiguous. A precision labor lens challenges the legitimacy and sustainability of relentlessly pursuing technical accuracy, raising new questions about its consequences and ethical implications. We conclude by proposing recommendations and alternative approaches to enhance worker agency and well-being.",
    "title": "The Making of Performative Accuracy in AI Training: Precision Labor and Its Consequences",
    "id": 188596,
    "sequence": 387,
    "queryCoordinates": {
      "visualization": [
        -11.900300104368526,
        9.131421435130813
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "Classroom debates are a unique form of collaborative learning characterized by fast-paced, high-intensity interactions that foster critical thinking and teamwork. Despite the recognized importance of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under-explored in HCI. This study addresses this opportunity by investigating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from ChatGPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage—reducing social anxiety, breaking communication barriers, and providing scaffolding for novices—alongside risks, such as information overload and cognitive dependency, which could limit learners' autonomy. We thereby discuss a set of nuanced implications for future HCI exploration.",
    "title": "Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate",
    "id": 188597,
    "sequence": 388,
    "queryCoordinates": {
      "visualization": [
        -13.556249309711662,
        -3.496870694341171
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "Cyclists need interfaces such as on-vehicle displays or augmented-reality (AR) glasses for effective communication with autonomous vehicles (AVs) when human drivers are no longer present. Interfaces must handle complex situations involving multiple AVs around a cyclist. Holistic AV-Cyclist Interfaces (HACIs) are a novel solution; they group interfaces into a multimodal interconnected system to support the rider. However, the best way to present information is uncertain. We explored this in a scenario with three AVs using CycleARcade, a new multi-user AR platform for designing and evaluating HACIs. Cyclists and HCI researchers collaboratively created and tested HACIs within CycleARcade through a novel iterative participatory design method. We synthesised three HACIs from this process and assessed them with riders in CycleARcade. Participants preferred HACIs with AR displays integrated into the environment to avoid road distractions, paired with spatial audio communicating AV proximity. These findings provide crucial input for the real-world deployment of AVs.",
    "title": "evARything, evARywhere, all at once: Exploring Scalable Holistic Autonomous Vehicle-Cyclist Interfaces",
    "id": 188598,
    "sequence": 389,
    "queryCoordinates": {
      "visualization": [
        16.959195360083186,
        1.1771545092012579
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "Large language models (LLMs) have shown exceptional performance in various language-related tasks. However, their application in keyboard decoding, which involves converting input signals (e.g. taps and gestures) into text, remains underexplored. This paper presents a fine-tuned FLAN-T5 model for decoding. It achieves 93.1% top-1 accuracy on user-drawn gestures, outperforming the widely adopted SHARK2 decoder, and 95.4% on real-word tap typing data. In particular, our decoder supports Flexible Typing, allowing users to enter a word with taps, gestures, multi-stroke gestures, and tap-gesture combinations. User study results show that Flexible Typing is beneficial and well-received by participants, where 35.9% of words were entered using word gestures, 29.0% with taps, 6.1% with multi-stroke gestures, and the remaining 29.0% using tap-gestures. Our investigation suggests that the LLM-based decoder improves decoding accuracy over existing word gesture decoders while enabling the Flexible Typing method, which enhances the overall typing experience and accommodates diverse user preferences.",
    "title": "LLM Powered Text Entry Decoding and Flexible Typing on Smartphones",
    "id": 188599,
    "sequence": 390,
    "queryCoordinates": {
      "visualization": [
        -1.1738437956428915,
        -7.913412079718248
      ]
    }
  },
  {
    "session": "WS28: Gathering Textiles at CHI: Convening a Meeting to Share, Make, and Speculate",
    "abstract": "CHI is becoming home to an emerging community of researchers and practitioners engaging with textiles as a design and research material. This work is spread across a range of areas from digital fabrication to haptics. This workshop offers the opportunity for the broad community of HCI researchers to share techniques and ideas that underpin textile practices at CHI. Knitting, weaving, embroidery, hand-stitching, quilting, garment making, dying, felting, paper making, etc. offer distinct functional and aesthetic qualities while engaging similar modes of working. We propose this workshop to create a  meeting place for CHI researchers engaging textiles in any capacity. We suggest a day of skill sharing and collective speculating grounded in the textiles techniques and histories of Japan. ",
    "title": "Gathering Textiles at CHI: Convening a Meeting to Share, Make, and Speculate",
    "id": 188600,
    "sequence": 391,
    "queryCoordinates": {
      "visualization": [
        -2.612492823579744,
        4.263200821770462
      ]
    }
  },
  {
    "session": "Decision Making",
    "abstract": "Managing shared environmental resources requires complex coordination among many diverse stakeholders, and global advances in communication technology are reshaping the relationships and organizational structures in environmental governance. To explore the role of communication technologies in environmental institutions, we conducted semi-structured interviews with 22 staff members from organizations in Uganda, India, and the USA. Participants highlighted how their organizations' activities are fundamentally enabled and constrained by the technologies available in the communities where they work, enabling different forms of coordination, data collection, and community engagement. They also noted the mixed impact of technology on social aspects of their work; sometimes fostering trust and collaboration, while at other times chilling relationships, reinforcing top-down formalization, and having lukewarm effects on equity and inclusion efforts. These findings offer insights for environmental organizations to better leverage communication technologies for community engagement, and adapt to varying stages of technological adoption.",
    "title": "A Cross-Sectional Study of Communication Technologies Underpinning Environmental Institutions",
    "id": 188601,
    "sequence": 392,
    "queryCoordinates": {
      "visualization": [
        -15.038690497648544,
        -7.92702895894391
      ]
    }
  },
  {
    "session": "Social Media, Online Community, Sensemaking",
    "abstract": "Social movements form coalitions to gain leverage and achieve mutual goals, however little is known about how coalitions work, especially in the realm of social media. In this paper we examine the 2020 #StopHateForProfit coalition which pressured corporations to pull their advertising spending from Facebook because of its permissive content moderation policies toward disinformation and hate. From the digital traces of the campaign on Twitter, we explain the participation differentials among coalition social movement organisations (SMO) partners and their followers. The findings show that the coalition's centrality to movement agenda, the ideological homogeneity of followership, and the SMO partners and their followership's central positions in the communication network led to the highest and most time persistent participation rates. Our counter-intuitive findings extend the literature on social movements coalitions by suggesting that multi-issues, “big tent” movements with ideological breadth may find invoking the core of their large followership rather challenging despite the ease of participation afforded by social media.",
    "title": "Explaining Differential Involvement in Cross-Movement Coalitions on Social Media: the #StopHateForProfit Campaign",
    "id": 188602,
    "sequence": 393,
    "queryCoordinates": {
      "visualization": [
        12.6135428420257,
        9.843705449290029
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "Adolescents are frequent users of social media, with research suggesting both potential harms and positive impacts from use. Black and Hispanic/Latinx youth in particular are both early adopters and high users of social media platforms. However, adolescents–and youth of color in particular–have relatively little say in the design of such platforms. We propose youth participatory action research (YPAR) as a model for informing co-design sessions with representatives of a social networking platform to develop community-building solutions and improve youth developmental outcomes. In a four-months-long study with Black and Hispanic/Latinx teens aged 14-17 ($n = 14$), we examined how their sense of engagement and efficacy were altered by actively leading, participating in and contributing to design exercises facilitated by Instagram, one of the world's largest social media sites. Results of pre- and post- surveys indicated a significant increase in teens’ civic engagement as well as leadership efficacy. Our results contribute to the understanding of teenagers’ expectations and attitudes toward social media and how participatory methods for achieving equity in design can affect change. Theoretical and practical implications are discussed.",
    "title": "Building a Better Social Media Platform: Can We Codesign With Equity in Mind?",
    "id": 188603,
    "sequence": 394,
    "queryCoordinates": {
      "visualization": [
        -5.007102888506562,
        14.139622366382676
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "Most textiles in day-to-day use are products of weaving. The versatility of this manufacturing technique, which readily supports a multi-layered structure, inclusion of several yarn types, malleability and other valuable characteristics, has attracted attention from HCI researchers intrigued by its potential to expand the interaction capabilities of e-textiles. Research nonetheless has barely scratched the surface of the wealth of weaving techniques and woven structures available. Therefore, a design-research project anchored in practice investigated how touch-sensitive e-textiles’ capabilities might be enriched via advanced multi-layer weaving techniques. The research process, which drew inspiration from literature both on textile design and on woven e-textiles, produced 25 distinct e-textile samples. Results from evaluating the structural properties, electrical capabilities and overall utility of each point to numerous unexplored opportunities from woven multi-layer e-textiles. Even holding potential for entirely new forms of interaction, these represent promising starting points for in-depth investigation.",
    "title": "Opportunities with Multi-Layer Weave Structures in Woven E-Textile Design",
    "id": 188604,
    "sequence": 395,
    "queryCoordinates": {
      "visualization": [
        -4.861849601988383,
        -1.1672268192795263
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "This paper investigates the effects of two situational impairments---encumbrance (i.e., carrying a heavy object) and walking---on interaction performance in canonical mixed reality tasks. We built Bayesian regression models of movement time, pointing offset, error rate, and throughput for target acquisition task, and throughput, UER, and CER for text entry task to estimate these effects. Our results indicate that 1.0 kg encumbrance increases selection movement time by 28%, decreases text entry throughput by 17%, and increase UER by 50%, but does not affect pointing offset. Walking led to a 63% increase in ray-cast movement time and a 51% reduction in text entry throughput. It also increased selection pointing offset by 16%, ray-cast pointing offset by 17%, and error rate by 8.4%. The interaction effect on 1.0 kg encumbrance and walking resulted in a 112% increase in ray-cast movement time. Our findings enhance the understanding of the effects of encumbrance and walking on mixed reality interaction, and contribute towards accumulating knowledge of situational impairments research in mixed reality. ",
    "title": "Estimating the Effects of Encumbrance and Walking on Mixed Reality Interaction",
    "id": 188605,
    "sequence": 396,
    "queryCoordinates": {
      "visualization": [
        1.1111404660392037,
        -1.662939224605091
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "Mobile emailing demands efficiency in diverse situations, which motivates the use of AI. However, generated text does not always reflect how people want to respond. This challenges users with AI involvement tradeoffs not yet considered in email UIs. We address this with a new UI concept called Content-Driven Local Response (CDLR), inspired by microtasking. This allows users to insert responses into the email by selecting sentences, which additionally serves to guide AI suggestions. The concept supports combining AI for local suggestions and message-level improvements. Our user study (N=126) compared CDLR with manual typing and full reply generation. We found that CDLR supports flexible workflows with varying degrees of AI involvement, while retaining the benefits of reduced typing and errors. This work contributes a new approach to integrating AI capabilities: By redesigning the UI for workflows with and without AI, we can empower users to dynamically adjust AI involvement.",
    "title": "Content-Driven Local Response: Supporting Sentence-Level and Message-Level Mobile Email Replies With and Without AI",
    "id": 188606,
    "sequence": 397,
    "queryCoordinates": {
      "visualization": [
        17.55371111771445,
        -7.270985214936702
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "Large language models (LLMs) like GPT-4 can convert natural-language descriptions of a task into computer code, making them a promising interface for end-user programming. We undertake a systematic analysis of how people with and without programming experience describe information-processing tasks (IPTs) in natural language, focusing on the characteristics of successful communication. Across two online between-subjects studies, we paired crowdworkers either with one another or with an LLM, asking senders (always humans) to communicate IPTs in natural language to their receiver (either a human or LLM). Both senders and receivers tried to answer test cases, the latter based on their sender's description. While participants with programming experience tended to communicate IPTs more successfully than non-programmers, this advantage was not overwhelming. Furthermore, a user interface that solicited example test cases from senders often, but not always, improved IPT communication. Allowing receivers to request clarification, though, was less successful at improving communication.",
    "title": "How Humans Communicate Programming Tasks in Natural Language and Implications For End-User Programming with LLMs",
    "id": 188607,
    "sequence": 398,
    "queryCoordinates": {
      "visualization": [
        9.381913359224841,
        3.4611705707749296
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "This study examines how anecdotal stories from friends, peers, and online sources influence non-experts’ perceptions and behaviors toward smart home IoT devices. We surveyed 263 participants, collecting narratives that either positively or negatively influenced their perception of IoT devices, which they retold in text and comic formats to encourage deeper reflection. Thematic analysis of the narratives, combined with quantitative survey data, reveals that stories significantly impact trust and willingness to use and adopt IoT devices. Negative stories, particularly those concerning security, privacy, and device unreliability, reduced trust and usage, while positive stories about home safety through monitoring and improved quality of life increased interest in IoT devices. Perceptions of different IoT devices varied based on the themes associated with the stories. The findings highlight the powerful role of storytelling in driving consumer acceptance of technology.",
    "title": "Folk Tales of IoT: Understanding the Impact of Stories on Users' Positive and Negative Perceptions of Smart Home IoT Devices",
    "id": 188608,
    "sequence": 399,
    "queryCoordinates": {
      "visualization": [
        -1.1773424979432967,
        18.963487670851496
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "When exploring the world using our sense of touch, there are various perceptual mechanisms which shape our material and textural experiences. Previous research replicated material experiences using sophisticated systems rendering vibrotactile feedback. However, there is a missing link between the material and force experiences created using vibrotactile rendering and the perceptual mechanisms which shape these experiences. To address this link, my research focuses on three main areas: investigating the perceptual mechanisms underlying the rendered material experiences; using embodied vibrotactile feedback to design tactile symbols and creating wearables for tactile augmented reality; leveraging perceptual mechanisms as a design tool for rendering vibrations. In this paper, I share my co-evolving insights from research on tactile perception and vibrotactile material rendering, while reflecting on my PhD journey and speculating about the quest ahead.",
    "title": "Designing Vibrotactile Feedback for rendering Material and Force Experiences",
    "id": 188609,
    "sequence": 400,
    "queryCoordinates": {
      "visualization": [
        11.587953327223472,
        11.03264871579307
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "As design researchers committed to more-than-human designing, we found we were increasingly moving our research activities outside of our institutional studios and labs into yards and balconies where we lived. In this paper, we investigate this emerging pattern through collaborative autoethnography to arrive at the notion of backyard practices. These are distinct practices that signal the value and necessity of being there in more-than-human worlds to design-with over time. We describe the features of the practice that include time as duration and intensities, liminality as more-than-human presences, and proximity. We also describe commitments that emerged that include practice decentering, consistently engage more-than-humans as participants in the process, act with not-knowing and humility, queerly design alongside, and learn to be affected.",
    "title": "Backyard Practices: A Liminal Approach to Designing in More-than-Human Worlds",
    "id": 188610,
    "sequence": 401,
    "queryCoordinates": {
      "visualization": [
        11.323208259941696,
        -6.386309944090417
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "The essence of intangible cultural heritage (ICH) lies in the living knowledge and skills passed down through generations. Daily practice plays a vital role in revitalizing ICH by fostering continuous learning and improvement. However, limited resources and accessibility pose significant challenges to sustaining such practice. Virtual reality (VR) has shown promise in supporting extensive skill training. Unlike technical skill training, ICH daily practice prioritizes cultivating a deeper understanding of cultural meanings and values. This study explores VR's potential in facilitating ICH daily practice through a case study of Traditional Chinese Flower Arrangement (TCFA). By investigating TCFA learners' challenges and expectations, we designed and evaluated FloraJing, a VR system enriched with cultural elements to support sustained TCFA practice. Findings reveal that FloraJing promotes progressive reflection, and continuous enhances technical improvement and cultural understanding. We further propose design implications for VR applications aimed at fostering ICH daily practice in both knowledge and skills. ",
    "title": "Facilitating Daily Practice in Intangible Cultural Heritage through Virtual Reality: A Case Study of Traditional Chinese Flower Arrangement",
    "id": 188611,
    "sequence": 402,
    "queryCoordinates": {
      "visualization": [
        -7.343225094356858,
        -6.7880074553294145
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "We introduce Toyteller, an AI-powered storytelling system where users generate a mix of story text and visuals by directly manipulating character symbols like they are toy-playing. Anthropomorphized symbol motions can convey rich and nuanced social interactions; Toyteller leverages these motions (1) to let users steer story text generation and (2) as a visual output format that accompanies story text. We enabled motion-steered text generation and text-steered motion generation by mapping motions and text onto a shared semantic space so that large language models and motion generation models can use it as a translational layer. Technical evaluations showed that Toyteller outperforms a competitive baseline, GPT-4o. Our user study identified that toy-playing helps express intentions difficult to verbalize. However, only motions could not express all user intentions, suggesting combining it with other modalities like language. We discuss the design space of toy-playing interactions and implications for technical HCI research on human-AI interaction.",
    "title": "Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols",
    "id": 188612,
    "sequence": 403,
    "queryCoordinates": {
      "visualization": [
        2.5375731366545824,
        -3.0920418134509475
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "Urban environments can inhibit the formation of publics due to their distracting nature and distant social ties. Yet, forming publics is critical for bringing and mobilizing citizens around issues. In this paper, we introduce a methodology  that combines oral history collection and qualitative analysis to foster connections among youth in a North American public school. During our project, the youth interviewed classmates, guardians, and strangers from their community about the meaning of home, then collectively analyzed the oral histories using qualitative analysis techniques. Our findings highlight that this process generated unexpected connections around shared experiences despite the different backgrounds of project participants, thus fostering a sense of attachment to home as a cause for public formation. Our paper demonstrates the effectiveness of such approach in building attachments as a pre-cursor to public formation in community-centered work, while reflecting on the associated practical challenges like skill development, sustained engagement, and emotional labor.",
    "title": "Oral History and Qualitative Analysis with Youth: A Method for Cultivating Attachments",
    "id": 188613,
    "sequence": 404,
    "queryCoordinates": {
      "visualization": [
        9.84370544929003,
        12.6135428420257
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "Smartphones support diverse inputs, however, the multitude of devices and platforms makes it challenging for people to discover when and where interactions are meaningful. \r\nMotivated by the effectiveness of visual signifiers in communicating interactivity, we explore the viability of integrating temporary visual signifiers in animated transitions between UI screens to promote the discoverability of swipe-revealed widgets. We implemented two transition types (Container Transform, Panels), and compared them to a baseline. We found that transitions with a standard duration did not impact the discovery of swipe-related widgets (N=33). We ran a follow-up study (N=22) with extremely slow 5000ms transitions to guarantee noticeability, but similarly found no impact on discovery of swipe-revealed widgets, diverging from previous findings for visual signifiers.\r\nThis raises interesting questions about the perception and understanding of interaction signifiers, and indicates a disconnect between noticeability and discoverability, while highlighting difficulties with adapting established interface elements beyond their entrenched functionality. \r\n",
    "title": "Does Adding Visual Signifiers in Animated Transitions Improve Interaction Discoverability?",
    "id": 188614,
    "sequence": 405,
    "queryCoordinates": {
      "visualization": [
        1.9596037473353487,
        -17.893014088001753
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "Research on rotational gain has been done largely under active self-motion, where users control their own movement. In multiple XR scenarios, the user is under passive self-motion: their body is moved by a training simulator, a motorised gaming chair, or a vehicle-based XR application. Users may be less sensitive to manipulation under passive motion - especially when engaged in a secondary task - meaning motion experiences could be expanded by high gains and even opposed virtual-physical motion. We identified both the perceptible and maximum comfortable thresholds of rotational gain when passively turned in a motorised chair, with and without a task, for the first time. We then applied those thresholds to an 'unbounded' in-car VR game where the user experiences an entirely different route to their physical movement. We provide the first guidelines for creating enhanced passive motion experiences and open the design space to new applications not restricted by physical movement",
    "title": "The Spin Doctor: Leveraging Insensitivity to Passive Rotational & Translational Gain For Unbounded Motion-Based VR Experiences",
    "id": 188615,
    "sequence": 406,
    "queryCoordinates": {
      "visualization": [
        -0.39265422461810223,
        -14.99485987463336
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "Recent advancements in text-to-music generative AI (GenAI) have significantly expanded access to music creation. However, deaf and hard of hearing (DHH) individuals remain largely excluded from these developments. This study explores how music GenAI could enhance the music-making experience of DHH individuals, who often rely on hearing people to translate sounds and music. We developed a multimodal music-making assistive tool informed by focus group interviews. This tool enables DHH users to create and edit music independently through language interaction with music GenAI, supported by integrated visual and tactile feedback. Our findings from the music-making study revealed that the system empowers them to engage in independent and proactive music-making activities, increasing their confidence, fostering musical expression, and positively shifting their attitudes toward music. Contributing to inclusive art by preserving the unique sensory characteristics of DHH individuals, this study demonstrates how music GenAI can benefit a marginalized community, fostering independent creative expression.",
    "title": "Exploring the Potential of Music Generative AI for Music-Making by Deaf and Hard of Hearing People",
    "id": 188616,
    "sequence": 407,
    "queryCoordinates": {
      "visualization": [
        -1.176485385785306,
        -12.94665524902218
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "Conversational search offers an easier and faster alternative to conventional web search, while having downsides like a lack of source verification. Research has examined performance disparities between these two systems in various settings. However, little work has investigated how changes in the nature of a search task affect user preferences. We investigate how psychological distance - the perceived closeness of one to an event - affects user preferences between conversational and web search. We hypothesise that tasks with different psychological distances elicit different information needs, which in turn affect user preferences between systems. Our study finds that, under fixed condition ordering, greater psychological distances lead users to prefer conversational search, which they perceive as more credible, useful, enjoyable, and easy to use. We reveal qualitative reasons for these differences and provide design implications for search system designers.",
    "title": "Understanding How Psychological Distance Influences User Preferences in Conversational versus Web Search",
    "id": 188617,
    "sequence": 408,
    "queryCoordinates": {
      "visualization": [
        12.152097219775925,
        -17.12677824814446
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "Researchers have demonstrated that Automatic Speech Recognition (ASR) systems perform differently across demographic groups (i.e. show bias), yet their downstream impact on spoken language interfaces remains unexplored. We examined this question in the context of a real-world AI-powered interface that provides tutors with feedback on the quality of their discourse. We found that the Whisper ASR had lower accuracy for Black vs. white tutors, likely due to differences in acoustic patterns of speech. The downstream automated discourse classifiers of tutor talk were correspondingly less accurate for Black tutors when presented with ASR input. As a result, although Black tutors demonstrated higher-quality discourse on human transcripts, this trend was not evident on ASR transcripts. We experimented with methods to reduce ASR bias, finding that fine-tuning the ASR on Black speech reduced, but did not eliminate, ASR bias and its downstream effects. We discuss implications for AI-based spoken language interfaces aimed at providing unbiased assessments to improve performance outcomes.",
    "title": "“It feels like we're not meeting the criteria\": Examining and Mitigating the Cascading Effects of Bias in Automatic Speech Recognition in Spoken Language Interfaces.",
    "id": 188618,
    "sequence": 409,
    "queryCoordinates": {
      "visualization": [
        10.936973319490871,
        -1.1758463372162402
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "Transitioning to manual control following a Take-Over Request (TOR) in Level 3 autonomous cars is challenging, requiring drivers to re-engage with driving after engaging with Non-Driving Related Tasks (NDRTs). Effective TOR design can mitigate this challenge. We present the first study on how culture, age, and NDRT intersect to shape TOR design. In a cross-cultural study across the UK (high traffic-law compliance) and Israel (low compliance), involving older and younger drivers, participants designed TORs for four NDRTs in a real car setting. Results revealed a universal preference for re-purposing NDRT-devices to issue TORs. Older drivers preferred tri-modal TORs that suspend the NDRT; younger drivers favoured bi-modal TORs allowing NDRT interruption management. Due to altered alert sensitivity and low law compliance, Israeli participants included a RiskMeter to assess hazard criticality. We introduce novel TOR designs and taxonomy features to guide culturally and age-sensitive TOR development, key for global Level 3 adoption.",
    "title": "All-inclusive TORs: Cross-Cultural and Age-Sensitive Design for Take-Over Requests in Level 3 Cars ",
    "id": 188619,
    "sequence": 410,
    "queryCoordinates": {
      "visualization": [
        10.93036589905411,
        4.952484357652736
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "Parenting brings emotional and physical challenges, from balancing work, childcare, and finances to coping with exhaustion and limited personal time. Yet, one in three parents never seek support. AI systems potentially offer stigma-free, accessible, and affordable solutions. Yet, user adoption often fails due to issues with explainability and reliability. To see if these issues could be solved using a co-design approach, we developed and tested NurtureBot, a wellbeing support assistant for new parents. 32 parents co-designed the system through Asynchronous Remote Communities method, identifying the key challenge as achieving a \"successful chat.\" As part of co-design, parents role-played as NurtureBot, rewriting its dialogues to improve user understanding, control, and outcomes. The refined prototype, featuring an Interaction Layer, was evaluated by by 32 initial and 46 new parents, showing improved user experience and usability, with final CUQ score of 91.3/100, demonstrating successful interaction patterns. Our process revealed useful interaction design lessons for effective AI parenting support.",
    "title": "The Interaction Layer: An Exploration for Co-Designing User-LLM Interactions in Parental Wellbeing Support Systems",
    "id": 188620,
    "sequence": 411,
    "queryCoordinates": {
      "visualization": [
        -11.323208259941703,
        6.386309944090406
      ]
    }
  },
  {
    "session": "Learning and Inspiring, Safety and Security",
    "abstract": "Experts struggle with explaining cybersecurity in a language and\r\ntone appropriate for non-expert audiences. This communication\r\ngap may make it difficult for a broad and diverse audience to fully\r\nengage in cybersecurity. Fundamental forms of communication,\r\nsuch as definitions, can be for a means for experts to communicate cybersecurity concepts to non-experts. To explore how nonexperts perceive cybersecurity definitions and identify potential areas of misunderstanding and misconception, we performed a\r\nsemi-structured interview study with 30 non-experts of different\r\ngenerations (ages) and education levels. Our findings reveal that\r\nnon-experts may have incomplete mental models of cybersecurity,\r\nmisinterpret terms and concepts commonly used in definitions,\r\nand express strong preferences for how cybersecurity is defined.\r\nWhile our study focuses on definitions, our results have broader\r\nimplications for how cybersecurity should be communicated to a\r\ndiverse range of individuals.",
    "title": "\"A five-year-old could understand it\" versus \"This is way too confusing\": Exploring Non-expert Understandings and Perceptions of Cybersecurity Definitions",
    "id": 188621,
    "sequence": 412,
    "queryCoordinates": {
      "visualization": [
        -6.788007455329423,
        -7.34322509435685
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "Temporal Action Localization (TAL) aims to detect the start and end timestamps of actions in a video. However, the training of TAL models requires a substantial amount of manually annotated data. Data programming is an efficient method to create training labels with a series of human-defined labeling functions. However, its application in TAL faces difficulties of defining complex actions in the context of temporal video frames. In this paper, we propose ProTAL, a drag-and-link video programming framework for TAL. ProTAL enables users to define \\textbf{key events} by dragging nodes representing body parts and objects and linking them to constrain the relations (direction, distance, etc.). These definitions are used to generate action labels for large-scale unlabelled videos. A semi-supervised method is then employed to train TAL models with such labels. We demonstrate the effectiveness of ProTAL through a usage scenario and a user study, providing insights into designing video programming framework.",
    "title": "ProTAL: A Drag-and-Link Video Programming Framework for Temporal Action Localization",
    "id": 188622,
    "sequence": 413,
    "queryCoordinates": {
      "visualization": [
        -1.9134171618254516,
        -4.619397662556432
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "Virtual reality (VR) provides an immersive and interactive platform for presenting ancient murals, enhancing users' understanding and appreciation of these invaluable culture treasures. However, traditional hand-crafted methods for recreating murals in VR are labor-intensive, time-consuming, and require significant expertise, limiting their scalability for large-scale mural scenes. To address these challenges, we propose a comprehensive pipeline that leverages generative AI to automate the mural recreation process. This pipeline is validated by the reconstruction of Foguang Temple scene in Dunhuang Murals. A user study comparing the AI-generated scene with a hand-crafted one reveals no significant differences in presence, authenticity, engagement and enjoyment, and emotion. Additionally, our findings identify areas for improvement in AI-generated recreations, such as enhancing historical fidelity and offering customization. This work paves the way for more scalable, efficient, and accessible methods of revitalizing cultural heritage in VR, offering new opportunities for mural preservation, demonstration, and dissemination using VR.",
    "title": "Reviving Mural Art through Generative AI: A Comparative Study of AI-Generated and Hand-Crafted Recreations",
    "id": 188623,
    "sequence": 414,
    "queryCoordinates": {
      "visualization": [
        5.478852861078486,
        7.140180062621116
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "While wearable haptics hold promise for making non-verbal cues like gestures and facial expressions accessible to blind or low-vision musicians, our understanding of how vibration signals can be interpreted and applied in real-world learning environments remains limited. We invited five music teachers and their seven students to participate in a ten-week longitudinal study involving observations, weekly catch-ups, group discussions, and interviews. We explored how wearable haptics could facilitate communication between sighted teachers and BLV students during one-on-one music lessons. We found that students and teachers derived particular meanings from vibration signals, including time-coded meaning, mutually agreed and intuitive meaning, and haptic metaphors. Additionally, wearable haptics significantly improved the experience of learning music for both sighted teachers and BLV students. We conclude by highlighting key design implications and outlining future research directions to create wearable haptics that significantly improve the music learning experience of BLV people.",
    "title": "Project TapTap: A Longitudinal Study Exploring Non-Verbal Communication through Vibration Signals Between Teachers and Blind or Low Vision Music Learners",
    "id": 188624,
    "sequence": 415,
    "queryCoordinates": {
      "visualization": [
        -13.517657043995316,
        -8.559961918193551
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": " We invite the HCI community to become sandwich makers, advocating for the inclusion of artist residencies as part of speculative design methodologies that build and explore fictional worlds through the creation of provocative prototypes or “provotypes”. In this paper we present our experience of including an artist residency as part of our world-building process. We reflect on how the inclusion of a residency in our sandwich model helped contribute alternative ways to immerse, explore narratives, do world-building and use curation as a form of annotation. We conclude with some key insights for why design researchers in the HCI space might wish to use sandwich models in their own research processes, using artist residencies to pursue multiple explorations of emerging technologies, drawing in different voices to provoke debate about the futures we want to create.",
    "title": "Becoming Sandwich Makers: Exploring Provocative Worlds Through an Artist Residency",
    "id": 188625,
    "sequence": 416,
    "queryCoordinates": {
      "visualization": [
        -7.4955973355328,
        8.050839743998983
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "The interdisciplinarity of the Social Engineering (SE) domain creates crucial challenges for the development and advancement of empirical SE research, making it particularly difficult to identify the space of open research questions that can be addressed empirically. \r\nThis space encompasses questions on attack conditions, employed experimental methods, and interactions with underlying cognitive aspects. \r\nAs a consequence, much potential in the breadth of existing empirical SE research and in its mapping to the actual cognitive processes it aims to measure is left untapped.\r\nIn this work, we carry out a systematic review of 169 articles investigating overall 735 hypotheses in the field of empirical SE research, focusing on experimental characteristics and core cognitive features from both attacker and target perspectives.\r\nOur study reveals that experiments only partially reproduce real attacks and that the exploitable SE attack surface appears much larger than the coverage provided by the current body of research.\r\nFactors such as targets' context and cognitive processes are often ignored or not explicitly considered in experimental designs.\r\nSimilarly, the effects of different pretexts and varied targetization levels are overall marginally investigated.\r\nOur findings on current SE research dynamics provide insights into methodological shortcomings and help identify supplementary techniques that can open promising future research directions.",
    "title": "Cognition in Social Engineering Empirical Research: A Systematic Literature Review",
    "id": 188626,
    "sequence": 417,
    "queryCoordinates": {
      "visualization": [
        4.227000575054803,
        11.230871121087908
      ]
    }
  },
  {
    "session": "Social Media, Online Community, Sensemaking",
    "abstract": "Increasingly, crowdfunding is transforming financing for many people worldwide. Yet we know relatively little about how, why, and when funding outcomes are impacted by signaling between funders. We conduct two studies of N=500 and N=750 participants involved in crowdfunding to investigate the effect of crowd signals, i.e., certain characteristics deduced from the amounts and timing of contributions, on the decision to fund. In our first study, we find that, under a variety of conditions, contributions of heterogeneous amounts arriving at varying time intervals are significantly more likely to be selected than homogeneous contribution amounts and times. The impact of signaling is strongest among participants who are susceptible to social influence. The effect is remarkably general across different project types, fundraising goals, participant interest in the projects, and participants' altruistic attitudes. Our second study using less strict controls indicates that the role of crowd signals in decision-making is typically unrecognized by participants. Our results underscore the fundamental nature of social signaling in crowdfunding. They highlight the importance of designing around these crowd signals and inform user strategies both on the project creator and funder side.",
    "title": "Beyond Words: An Experimental Study of Signaling in Crowdfunding",
    "id": 188627,
    "sequence": 418,
    "queryCoordinates": {
      "visualization": [
        4.2270005750547925,
        -11.230871121087912
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "We explore the design of visualizations for values spanning multiple orders of magnitude; we call them Orders of Magnitude Values (OMVs). Visualization researchers have shown that separating OMVs into two components, the mantissa and the exponent, and encoding them separately overcomes limitations of linear and logarithmic scales. However, only a small number of such visualizations have been tested, and the design guidelines for visualizing the mantissa and exponent separately remain under-explored. To initiate this exploration, better understand the factors influencing the effectiveness of these visualizations, and create guidelines, we adopt a multi-stage workflow. We introduce a design space for visualizing mantissa and exponent, systematically generating and qualitatively evaluating all possible visualizations within it. From this evaluation, we derive guidelines. We select two visualizations that align with our guidelines and test them using a crowdsourcing experiment, showing they facilitate quantitative comparisons and increase confidence in interpretation compared to the state-of-the-art.",
    "title": "Lost in Magnitudes: Exploring Visualization Designs for Large Value Ranges",
    "id": 188628,
    "sequence": 419,
    "queryCoordinates": {
      "visualization": [
        10.113147467559678,
        -17.254687719555843
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "Individuals are known to differ in cognitive abilities, affecting their behavior and information processing in digital environments. However, we have a limited understanding of which behaviors are affected, how, and whether some features extracted from digital behavior can predict cognitive abilities. Consequently, researchers may miss opportunities to design and support individuals with personalized experiences and detect those who may benefit from additional interventions. To characterize digital behaviors, we collected 24/7 screen recordings, input behavior, and operating system data from the laptops of 20 adults for two weeks. We use cognitive test results from the same individuals to characterize their cognitive abilities: psychomotor speed, processing speed, selective attention, working memory, and fluid intelligence. Our results from regression analysis, path modeling, and machine learning experiments show that cognitive abilities are associated with differences in digital behavior and that naturalistic behavioral data can predict the cognitive abilities of individuals with small error rates. Our findings suggest naturalistic interaction data as a novel source for modeling cognitive differences.",
    "title": "Naturalistic Digital Behavior Predicts Cognitive Abilities",
    "id": 188629,
    "sequence": 420,
    "queryCoordinates": {
      "visualization": [
        7.058336768619216,
        -10.916953881956177
      ]
    }
  },
  {
    "session": "Diversity",
    "abstract": "Trans and non-binary individuals undergoing hormone therapy face unique and evolving needs for sexual wellness products that current solutions often overlook. The transition process involves significant anatomical and psychological changes, highlighting the necessity for more inclusive approaches to Human-Computer Interaction and overall well-being.  Within this framework, this study presents the development of a pleasure object designed to be fluid, adaptive, and responsive to the evolving anatomical and psychological changes experienced during hormone therapy.  To this end, authors conducted comprehensive research, including an online survey on the autoerotic habits of trans and non-binary individuals, followed by three sensitive interviews and clinical integration. They observed significant themes that highlight the unique requirements and experiences of this community. By leveraging advanced technologies and selected materials, authors provide design considerations and discuss the potential of these methods to create sexual wellness products that offer meaningful and inclusive experiences for the trans and non-binary community.",
    "title": "Embracing Gender Diversity: Designing an Adaptive Pleasure Object for a Changing Body",
    "id": 188630,
    "sequence": 421,
    "queryCoordinates": {
      "visualization": [
        -0.39241877538085757,
        5.98715353943162
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "Older adults face unique challenges in adopting social technology, particularly through retirement. Whereas existing digital solutions are often disconnected from the motivations of older adults, ambient and tangible technologies (ATTs) are emerging as promising social tools that integrate into users' routines and leverage familiar physical interactions. This study investigates how older adults envision ATTs to meaningfully support their social connections. Through two phases of co-design with 25 retiring older adults (55+) and 5 social partners (25+), we explore the intersection of social health, life transitions, and technology use. Our thematic analysis reveals how shifting perceptions of time influence engagement, relationship maintenance, and legacy-building. We present opportunities to align ATT design with older adults’ emotional goals, social practices, and community connections by posing design challenges, such as collective legacy building, for supporting the meaningful relationships of retiring adults as they age.",
    "title": "Touching Experiences: How Older Adults Envision Ambient and Tangible Social Technology Through the Lens of Time",
    "id": 188631,
    "sequence": 422,
    "queryCoordinates": {
      "visualization": [
        -1.177416073023791,
        -19.965312203694317
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "Pointing-based interaction interferences are situations wherein GUI elements appear, disappear, or change shortly before being selected, and too late for the user to inhibit their movement. Their cause lays in the design of most GUIs, for which any user event on an interactive element unquestionably reflects the user’s intention—even one millisecond after that element has changed. Previous work indicate that interferences can cause frustration and sometimes severe consequences. This paper investigates new default behaviors for GUI elements that aim to prevent the occurrences of interferences or to mitigate their consequences. We present a design space of the advantages and technical requirements of these behaviors, and demonstrate in a controlled study how simple rules can reduce the occurrences of so-called “Pop-up-style” interferences, and user frustration. We then discuss their application to various forms of interaction interferences. We conclude by addressing the feasibility and trade-offs of implementing these behaviors in existing systems.",
    "title": "GUI Behaviors to Minimize Pointing-based Interaction Interferences",
    "id": 188632,
    "sequence": 423,
    "queryCoordinates": {
      "visualization": [
        -4.260230170558852,
        -14.382296023022892
      ]
    }
  },
  {
    "session": "Make it Visible",
    "abstract": "Data analysts often need to iterate between data transformations and chart designs to create rich visualizations for exploratory data analysis. Although many AI-powered systems have been introduced to reduce the effort of visualization authoring, existing systems are not well suited for iterative authoring. They typically require analysts to provide, in a single turn, a text-only prompt that fully describe a complex visualization. \r\nWe introduce Data Formulator 2 (DF2 for short), an AI-powered visualization system designed to overcome this limitation.\r\nDF2 blends graphical user interfaces and natural language inputs to enable users to convey their intent more effectively, while delegating data transformation to AI.\r\nFurthermore, to support efficient iteration, DF2 lets users navigate their iteration history and reuse previous designs, eliminating the need to start from scratch each time. \r\nA user study with eight participants demonstrated that DF2 allowed participants to develop their own iteration styles to complete challenging data exploration sessions.",
    "title": "Data Formulator 2: Iterative Creation of Data Visualizations, with AI Transforming Data Along the Way",
    "id": 188633,
    "sequence": 424,
    "queryCoordinates": {
      "visualization": [
        3.4737954637652724,
        -10.437085085210516
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "FFAME (Filtering Familiar Audio for Movement Exploration) is a novel sonification framework aiming to facilitate movement in individuals with chronic back pain. Our personalised, music-based approach contrasts and extends prior work with predetermined tonal sonification. FFAME progressively filters selected music based on angles of the trunk. Through a qualitative analysis of reported experience of 15 participants with chronic pain and 5 physiotherapists, we identify how sonification parameters and musical characteristics affect movement and meaning-making. Music-based movement sonification proved impactful across multiple dimensions: (1) encouraging movement, (2) escaping pain-related rumination, (3) externalizing pain experiences, and (4) scaffolding physical activities. Drawing on enactivism and related philosophies, the study highlights how the semantic indeterminacy of music, combined with real-time movement sonification, created a rich, open-ended environment that supported user agency and exploration. Sonification for pain management can be creative and expressive, enabling people with pain to extend challenging movements and build movement confidence.",
    "title": "Movement Sonification of Familiar Music to Support the Agency of People with Chronic Pain",
    "id": 188634,
    "sequence": 425,
    "queryCoordinates": {
      "visualization": [
        18.094189494621475,
        5.796577139375427
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "Displaying community fact-checks is a promising approach to reduce engagement with misinformation on social media. However, how users respond to misleading content emotionally after community fact-checks are displayed on posts is unclear. Here, we employ quasi-experimental methods to causally analyze changes in sentiments and (moral) emotions in replies to misleading posts following the display of community fact-checks. Our evaluation is based on a large-scale panel dataset comprising N=2,225,260 replies across 1841 source posts from X's Community Notes platform. We find that informing users about falsehoods through community fact-checks significantly increases negativity (by 7.3%), anger (by 13.2%), disgust (by 4.7%), and moral outrage (by 16.0%) in the corresponding replies. These results indicate that users perceive spreading misinformation as a violation of social norms and that those who spread misinformation should expect negative reactions once their content is debunked. We derive important implications for the design of community-based fact-checking systems.",
    "title": "Community Fact-Checks Trigger Moral Outrage in Replies to Misleading Posts on Social Media",
    "id": 188635,
    "sequence": 426,
    "queryCoordinates": {
      "visualization": [
        7.231914344987547,
        3.4204407474422567
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "Educational programming languages (EPLs) are rarely designed to be both accessible and multilingual. We describe a 30-month community-engaged case study to surface design challenges at this intersection, creating Wordplay, an accessible, multilingual platform for youth to program interactive typography. Wordplay combines functional programming, multilingual text, multimodal editors, time travel debugging, and teacher- and youth-centered community governance. Across five 2-hour focus group sessions, a group of 6 multilingual students and teachers affirmed many of the platform’s design choices, but reinforced that design at the margins was unfinished, including support for limited internet access, decade-old devices, and high turnover of device use by students with different access, language, and attentional needs. The group also highlighted open source platforms like GitHub as unsuitable for engaging youth. These findings suggest that EPLs that are both accessible and language-inclusive are feasible, but that there remain many design tensions between language design, learnability, accessibility, culture, and governance.",
    "title": "Wordplay: Accessible, Multilingual, Interactive Typography",
    "id": 188636,
    "sequence": 427,
    "queryCoordinates": {
      "visualization": [
        -7.249440417457287,
        -16.475606624150043
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "Conversational agents that mimic people have raised questions about the ethics of anthropomorphizing machines with human social identity cues. Critics have also questioned assumptions of identity neutrality in humanlike agents. Recent work has revealed that intersectional Japanese pronouns can elicit complex and sometimes evasive impressions of agent identity. Yet, the role of other ``neutral'' non-pronominal self-referents (NPSR) and voice as a socially expressive medium remains unexplored. In a crowdsourcing study, Japanese participants (N=204) evaluated three ChatGPT voices (Juniper, Breeze, and Ember) using seven self-referents. We found strong evidence of voice gendering alongside the potential of intersectional self-referents to evade gendering, i.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age and formality intersected with gendering as per sociolinguistic theories, especially ぼく (boku) and わたくし (watakushi). This work provides a nuanced take on agent identity perceptions and champions intersectional and culturally-sensitive work on voice agents.",
    "title": "Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents",
    "id": 188637,
    "sequence": 428,
    "queryCoordinates": {
      "visualization": [
        5.018907846382258,
        -15.192450889488589
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "Sensory-substitution devices enable perceiving objects by translating one modality (e.g., vision) into another (e.g., tactile). While many explored the placement of the haptic-output (e.g., torso, forehead), the camera’s location remains largely unexplored—typically seeing from the eyes’ perspective. Instead, we propose that seeing & feeling information from the hands’ perspective could enhance flexibility & expressivity of sensory-substitution devices to support manual interactions with physical objects. To this end, we engineered a back-of-the-hand electrotactile-display that renders tactile images from a wrist-mounted camera, allowing the user’s hand to feel objects while reaching & hovering. We conducted a study with sighted/Blind-or-Low-Vision participants who used our eyes vs. hand tactile-perspectives to manipulate bottles and soldering-irons, etc. We found that while both tactile perspectives provided comparable performance, when offered the opportunity to choose, all participants found value in also using the hands’ perspective. Moreover, we observed behaviors when “seeing with the hands” that suggest a more ergonomic object-manipulation. We believe these insights extend the landscape of sensory-substitution devices.",
    "title": "Seeing with the Hands: A Sensory Substitution That Supports Manual Interactions",
    "id": 188638,
    "sequence": 429,
    "queryCoordinates": {
      "visualization": [
        1.1753739745783771,
        9.930684569549262
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Vertical data flows (e.g., those directed toward companies) are challenging to understand even for technically knowledgeable adults, exposing them to privacy risks. Vulnerable groups with limited experience or cognitive abilities face even greater risks. To support these users in protecting their privacy online, it is essential to understand their perceptions of data flows and privacy needs. This dissertation employs a mixed-method participatory approach involving children, seniors, and individuals with cognitive disabilities. Initial focus groups have explored their understanding of vertical data flows, privacy risks, and protective measures. Building on these insights, co-creation workshops aim to develop tangible cues that enhance privacy awareness, literacy, and self-efficacy with minimum cognitive load. The effectiveness of these tools will be tested longitudinally, allowing iterative improvements to better suit the needs of these vulnerable groups. The goal is to achieve comprehensive and diverse empowerment, ensuring tailored privacy protection for everyone.",
    "title": "Privacy for All: Empowering Vulnerable Groups with Diversity-Oriented Online Protection",
    "id": 188639,
    "sequence": 430,
    "queryCoordinates": {
      "visualization": [
        -12.71044991282101,
        -2.728454326843016
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "Visual storytelling combines visuals and narratives to communicate important insights. While web-based visual storytelling is well-established, leveraging the next generation of digital technologies for visual storytelling, specifically immersive technologies, remains underexplored. We investigated the impact of the story viewpoint (from the audience's perspective) and navigation (when progressing through the story) on spatial immersion and understanding. First, we collected web-based 3D stories and elicited design considerations from three VR developers. We then adapted four selected web-based stories to an immersive format. Finally, we conducted a user study (N=24) to examine egocentric and exocentric viewpoints, active and passive navigation, and the combinations they form. Our results indicated significantly higher preferences for egocentric+active (higher agency and engagement) and exocentric+passive (higher focus on content). We also found a marginal significance of viewpoints on story understanding and a strong significance of navigation on spatial immersion.",
    "title": "Ego vs. Exo and Active vs. Passive: Investigating the Individual and Combined Effects of Viewpoint and Navigation on Spatial Immersion and Understanding in Immersive Storytelling",
    "id": 188640,
    "sequence": 431,
    "queryCoordinates": {
      "visualization": [
        -5.612970363669894,
        9.460156642284707
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "Since the Covid-19 pandemic, video calling (VC) has become a staple means of daily communication. Beyond socializing, VC in the United States (U.S.) now supports remote work, healthcare and education. The sudden ubiquity of VC could have presented both advantages and challenges for chronically ill people. However, our understanding of chronically ill people's experiences with VC remains limited. To address this gap, we conducted the largest online survey study (N=55) on chronically ill people's VC experiences in the U.S.--investigating their routines, facilitators and barriers. Our quantitative and qualitative findings established that chronically ill people heavily depend on VC to cope with everyday life. At the same time, VC can also detrimentally exacerbate cognitive (e.g., brain fog), emotional (e.g., self-consciousness) and physical challenges (e.g., migraines) for chronically ill people. In response, we offer actionable design opportunities to improve the accessibility and experience of VC for chronically ill people.",
    "title": "\"I use video calling in all areas of my life\": Understanding the Video Calling Experiences of Chronically Ill People",
    "id": 188641,
    "sequence": 432,
    "queryCoordinates": {
      "visualization": [
        7.113054833451414,
        12.058376795253725
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "Automated planning is traditionally the domain of experts, utilized in fields like manufacturing and healthcare with the aid of expert planning tools. Recent advancements in LLMs have made planning more accessible to everyday users due to their potential to assist users with complex planning tasks. However, LLMs face several application challenges within end-user planning, including consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a system that applies formal verification techniques, specifically model checking, to enhance the reliability and flexibility of LLMs for end-user planning. In addition to the LLM planner, VeriPlan includes three additional core features---a rule translator, flexibility sliders, and a model checker---that engage users in the verification process. Through a user study ($n=12$), we evaluate VeriPlan, demonstrating improvements in the perceived quality, usability, and user satisfaction of LLMs. Our work shows the effective integration of formal verification and user-control features with LLMs for end-user planning tasks.",
    "title": "VeriPlan: Integrating Formal Verification and LLMs into End-User Planning",
    "id": 188642,
    "sequence": 433,
    "queryCoordinates": {
      "visualization": [
        -12.946655249022182,
        -1.1764853857852906
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Despite significant work in HCI on understanding the role of data tools for non-profits and grassroots communities, there has been limited focus on cooperatives. This paper examines the role of financial, social, and building upkeep data in a non-profit cooperative housing organization in Toronto, Canada (alias named NXI). Through a 16-month-long ethnographic study, including 24 interviews, we investigate the role of and tensions in data practices related to NXI’s daily maintenance and operations, cooperation, and sustainability. We find that NXI’s current data practices are functional and meaningful—sometimes requiring team workarounds—in the short term. However, various tensions and deficiencies in data practices hamper NXI’s sustainability. By contextualizing the temporal affordances of data, we propose design implications for data tools to align effectively with the practices of cooperatives and enhance organizational sustainability. Finally, we discuss how data designers and researchers, organizations or grassroots communities, and financial technology designers can benefit from our work, especially with regard to the maintenance and sustainability of small-scale organizations.",
    "title": "Management, Cooperation, and Sustainability: Unpacking the Financial Data Practices of a Housing Cooperative",
    "id": 188643,
    "sequence": 434,
    "queryCoordinates": {
      "visualization": [
        -3.5116257962903075,
        17.654135047258148
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "Despite growing economic importance, freelance software developers face unfavorable conditions on freelance platforms. Among others, they need to deal with the consequences of elevated expectations emerging during technology hypes. Despite this, the impact of hype on freelancers remains underexplored, limiting our ability to guide them through these intense periods and inform the design of freelance platforms.  Through interviews with 52 freelance developers pursuing projects involving generative AI (GenAI), we identify technology hypes as a significant force shaping freelancers’ careers. Based on the interviews, we offer a multifaceted perspective on hype as a phenomenon. We reveal that technological hypes negatively impact the career prospects and well-being of some freelancers while empowering others to advance their careers or transition into new areas. We identify four clusters of freelance developers based on their experiences with and reactions to the GenAI hype. This study positions technology hype as a critical factor shaping the freelance economy.",
    "title": "More Attention, Transformation, Acceleration, and Exploration: Freelance Developers' Take on Hypes",
    "id": 188644,
    "sequence": 435,
    "queryCoordinates": {
      "visualization": [
        4.1865973753742765,
        -9.081431738250815
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "The wide adoption of platformized work has generated remarkable advancements in the labor patterns and mobility of modern society. Underpinning such progress, gig workers are exposed to unprecedented challenges and accountabilities: lack of data transparency, social and physical isolation, as well as insufficient infrastructural safeguards. Gig2Gether presents a space designed for workers to engage in an initial experience of voluntarily contributing anecdotal and statistical data to affect policy and build solidarity across platforms by exchanging unifying and diverse experiences. Our 7-day field study with 16 active workers from three distinct platforms and work domains showed existing affordances of data-sharing: facilitating mutual support across platforms, as well as enabling financial reflection and planning. Additionally, workers envisioned future uses cases of data-sharing for collectivism (e.g., collaborative examinations of algorithmic speculations) and informing policy (e.g., around safety and pay), which motivated (latent) worker desiderata of additional capabilities and data metrics. Based on these findings, we discuss remaining challenges to address and how data-sharing tools can complement existing structures to maximize worker empowerment and policy impact.",
    "title": "Gig2Gether: Datasharing to Empower, Unify and Demistify Gig Work",
    "id": 188645,
    "sequence": 436,
    "queryCoordinates": {
      "visualization": [
        7.927028958943916,
        15.038690497648542
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "Collaborative Mixed Reality (MR) enables embodied meetings for distributed collaborators working across a variety of locations. However, providing a coherent experience for all users regardless of the spatial configurations of their respective physical environments is a central challenge. We present the Spatial Heterogeneity Framework, which breaks the problem into four core components: the activity zones, heterogeneity ladder, blended proxemics, and MR solutions matrix. We explain the interplay between these components, demonstrating their interconnectivity via a case study. Our framework enables researchers to navigate differences and trade-offs between solutions for distributed MR collaboration. \r\nIt also supports designers to think about the role of space, technology, and social behaviours in MR collaboration. Ultimately, our contributions advance the field by conceptualising the challenges of spatial heterogeneity and strategies to overcome them.",
    "title": "Spatial Heterogeneity in Distributed Mixed Reality Collaboration",
    "id": 188646,
    "sequence": 437,
    "queryCoordinates": {
      "visualization": [
        11.230871121087908,
        4.227000575054802
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "Algorithmic recourse provides counterfactual suggestions to individuals who receive unfavorable AI decisions; the aim is to help them understand the reasoning and guide future actions. \r\nWhile most research focuses on generating reasonable and actionable recourse, it often overlooks how individuals' initial reactions to AI decisions influence their perceptions of subsequent recourses and their ultimate acceptance of the decision. \r\nTo explore this, we conducted a user experiment (N=534) simulating an automobile loan application scenario. \r\nStatistical analysis revealed that participants who initially reacted negatively to the AI decision perceived the recourse as less reasonable and actionable, reinforcing their negative attitudes. \r\nHowever, when the recourse was perceived as explaining decision criteria or proposing realistic action plans, participants' attitudes shifted from negative to positive. \r\nThese findings offer design implications for recourse systems that enhance the acceptance of individuals negatively affected by AI decisions.",
    "title": "The Role of Initial Acceptance Attitudes Toward AI Decisions in Algorithmic Recourse",
    "id": 188647,
    "sequence": 438,
    "queryCoordinates": {
      "visualization": [
        -1.9286367918189682,
        5.681580776970634
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "Dreams contribute to cognitive and emotional health, yet tools for everyday dream engagement remain largely underexplored outside clinical settings. In this paper, we introduce LumaDreams, a mobile application designed to foster daily empowerment through positive dream transformation using generative AI. Informed by meaning-making theories, LumaDreams enables users to journal dreams through sketches and text, which are then transformed into positive images and stories for users to revisit and reflect on. We conducted a mixed-method study with 14 participants over 14 days. Our findings show that LumaDreams strengthened participants’ daily empowerment through cognitive and emotional shifts that arise from the positive meaning-making process. Qualitative insights further revealed how users’ perceptions and trust of AI-driven dream transformation were shaped through their interactions. In conclusion, we propose an inspiring approach that enables users to co-create positive meanings in dream experiences with generative AI, promoting cognitive and emotional shifts, fostering positive mindsets, and ultimately strengthening daily empowerment.",
    "title": "LumaDreams: Designing Positive Dream Meaning-Making for Daily Empowerment",
    "id": 188648,
    "sequence": 439,
    "queryCoordinates": {
      "visualization": [
        19.40147018273702,
        8.036352079666885
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements. While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users' and models' lack of comprehensive paper-cutting knowledge. To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern). We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas. This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design. A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation. \r\n",
    "title": "HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony",
    "id": 188649,
    "sequence": 440,
    "queryCoordinates": {
      "visualization": [
        -18.672230487899828,
        -3.5139448781596037
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "The widespread digitalisation of critical civic services in contexts of economic austerity, neoliberalism, and the COVID-19 pandemic, has renewed focus in HCI on interventions to enable digital access for populations considered ‘digitally excluded’. While digital inclusion (DI) practitioners play a critical role in this area, their perspectives remain under-explored in HCI. This paper reports on a series of asset-based engagements with digital inclusion practitioners in the North East of England. These engagements explored the values, assets, and needs comprising their practices and used these insights as design material to ideate strategies for future intervention. We contribute findings describing the complexities, contradictions, and diversity of digital inclusion practices and efforts. Based on these findings, we argue for a shift towards considering DI practice through the lens of care, and provide directions for future HCI research to support DI practitioners in doing care work.",
    "title": "Beyond Bridging Divides: Examining the Goals of Digital Inclusion Practice in Post-Digital Societies",
    "id": 188650,
    "sequence": 441,
    "queryCoordinates": {
      "visualization": [
        -6.386309944090416,
        -11.323208259941698
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "To mitigate the negative impacts of online videos on teenagers, existing research and platforms have implemented various parental mediation mechanisms, such as Parent-Child Joint Media Engagement (JME). However, JME generally relies heavily on parents' time, knowledge, and experience. To fill this gap, we aim to design an automatic tool to help parents/children censor videos more effectively and efficiently in JME. For this goal, we first conducted a formative study to identify the needs and expectations of teenagers and parents for such a system. Based on the findings, we designed YouthCare, a personalized collaborative video censorship tool that supports parents and children to collaboratively filter out inappropriate content and select appropriate content in JME. An evaluation with 10 parent-child pairs demonstrated YouthCare's several strengths in supporting video censorship, while also highlighting some potential problems. These findings inspire us to propose several insights for the future design of par",
    "title": "YouthCare: Building a Personalized Collaborative Video Censorship Tool to Support Parent-Child Joint Media Engagement",
    "id": 188651,
    "sequence": 442,
    "queryCoordinates": {
      "visualization": [
        0.3926711233235251,
        -18.99594191897069
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "Designing technologies that clothe, adorn, or are otherwise placed on the body raises questions concerning the role they will play in dressing ourselves. We situate self-fashioning – or the process through which we stylise and present our bodies – as a complex practice where a series of social, material, and contextual factors shape how we present ourselves. Informed by reflective discussions and projective design tools, we contribute three critical points of departure for self-fashioning technologies: (i) Purposeful examining discomfort as an ongoing phenomenon, (ii) Supporting mimesis and visibility as qualities to be negotiated, and (iii) Envisioning the multiplicity of the body. We call for the design community to help devise fashionable technologies that are sensitive, caring, and responsive to the complexities of fashioning our bodies.",
    "title": "Identifying Critical Points of Departure for the Design of Self-Fashioning Technologies",
    "id": 188652,
    "sequence": 443,
    "queryCoordinates": {
      "visualization": [
        13.538779265247909,
        6.457666452124427
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "Employees, once seen as the weakest link in organizational cybersecurity, are now recognized as crucial defenders against malicious attacks. Thus, understanding employee attitudes towards cybersecurity, a major factor driving security behavior, is essential for protecting organizations. Using semi-structured interviews and focus groups, this study holistically explores attitudes toward cybersecurity, its influencing factors, and the employees’ needs for fostering positive attitudes. The study offers in-depth insights into affective, cognitive, and behavioral components of attitudes, ranging from annoyance and fear to appreciation for cybersecurity measures. Influencing key factors include (in)direct cybersecurity experiences and individual perceptions - both highlighting social influences. For developing positive attitudes, employees express needs related to the company's social and cultural framework, communication styles, educational contents and formats. The study contributes to developing effective security strategies that address the individual, social, and organizational factors that shape cybersecurity attitudes, ultimately promoting a stronger organizational security.",
    "title": "Fear, Fun or None: A Qualitative Quest Towards Unlocking Cybersecurity Attitudes",
    "id": 188653,
    "sequence": 444,
    "queryCoordinates": {
      "visualization": [
        -12.447235004080847,
        13.002551317075602
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Synthetic nonconsensual explicit imagery, also referred to as \"deepfake nudes\", is becoming faster and easier to generate. In the last year, synthetic nonconsensual explicit imagery was reported in at least ten US middle and high schools, generated by students of other students. Teachers are at the front lines of this new form of image abuse and have a valuable perspective on threat models in this context. We interviewed 17 US teachers to understand their opinions and concerns about synthetic nonconsensual explicit imagery in schools. No teachers knew of it happening at their schools, but most expected it to be a growing issue. Teachers proposed many interventions, such as improving reporting mechanisms, focusing on consent in sex education, and updating technology policies. However, teachers disagreed about appropriate consequences for students who create such images. We unpack our findings relative to differing models of justice, sexual violence, and sociopolitical challenges within schools.\r\n",
    "title": "\"We're utterly ill-prepared to deal with something like this\": Teachers' Perspectives on Student Generation of Synthetic Nonconsensual Explicit Imagery",
    "id": 188654,
    "sequence": 445,
    "queryCoordinates": {
      "visualization": [
        -2.7716385975338604,
        -1.148050297095269
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": "The Daisy Vase Project is somewhere between science, commerce, and art. It aims at randomly creating vases that are printable with a 3D printer. The program written for the project outputs vases meshes and some of the vases are beautiful and have an unseen design. Besides creating beautiful designs, the goal of the Daisy Vase Project is also to program a generator that can generate so many different vase designs that every person in this world can have a unique vase. The presented vase generator has this capability. Developing the algorithms and the user interface is a scientific task while the question of what is beauty belongs to art. Presenting computer-generated suggestions would provide a new shopping experience if used for commercial purposes.",
    "title": "The Daisy Vase Project - A Unique Vase for Everybody",
    "id": 188655,
    "sequence": 446,
    "queryCoordinates": {
      "visualization": [
        12.058376795253725,
        7.113054833451412
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "While companies are increasingly moving towards the ‘pay for privacy’ model, it is unclear how consumers make privacy decisions under this model. Toward that, we conducted an incentive-compatible lottery study on Prolific to understand the factors behind users’ choice to have additional data privacy controls. With 265 United States participants across two device risk conditions (High-risk: camera vs. Low-risk: light bulb) and three cash conditions ($9.99 vs. $19.99 vs. $29.99), results reveal that device risk and cash offerings influence participants’ lottery choice. We further observed an interaction effect between participants’ technical literacy and cash option. Specifically, technical participants chose the data privacy controls instead of cash at a higher rate when the cash condition was $29.99. In contrast, less technical participants favored the privacy option at a higher rate when the cash condition was $9.99. Implications of our findings for user data privacy are discussed in the paper.",
    "title": "Investigating Users' Decision-making for Data Privacy Controls in the Context of Internet of Things (IoT) Devices Using an Incentive-compatible Lottery Study",
    "id": 188656,
    "sequence": 447,
    "queryCoordinates": {
      "visualization": [
        -1.1768864359176836,
        -14.95376000599692
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Meetings often suffer from a lack of intentionality, such as unclear goals and straying off-topic. Identifying goals and maintaining their clarity throughout a meeting is challenging, as discussions and uncertainties evolve. Yet meeting technologies predominantly fail to support meeting intentionality. AI-assisted reflection is a promising approach. To explore this, we conducted a technology probe study with 15 knowledge workers, integrating their real meeting data into two AI-assisted reflection probes: a passive and active design. Participants identified goal clarification as a foundational aspect of reflection. Goal clarity enabled people to assess when their meetings were off-track and reprioritize accordingly. Passive AI intervention helped participants maintain focus through non-intrusive feedback, while active AI intervention, though effective at triggering immediate reflection and action, risked disrupting the conversation flow.  We identify three key design dimensions for AI-assisted reflection systems, and provide insights into design trade-offs, emphasizing the need to adapt intervention intensity and timing, balance democratic input with efficiency, and offer user control to foster intentional, goal-oriented behavior during meetings and beyond.",
    "title": "Are We On Track? AI-Assisted Active and Passive Goal Reflection During Meetings",
    "id": 188657,
    "sequence": 448,
    "queryCoordinates": {
      "visualization": [
        8.695725088797952,
        16.89332309464452
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "North Korean defectors (NKDs) face significant challenges when transitioning to South Korean society. Leaving their homes permanently and adapting to a new, digitally connected environment for the first time presents difficulties, compounded by the pervasive stigma associated with their identities. Although technology alone cannot solve these issues, it can play a role in easing their transition. In this study, we conducted eight speculative co-creation sessions with 22 NKDs to identify their main challenges and envision potential technological interventions. We propose the conceptualization of thirteen technologies aimed at addressing key issues NKDs face related to identity stigma, disconnection from their past, and challenges of adapting to a highly digital society. Through this empirical research on underrepresented populations undergoing significant life transitions, we provide insights into how future technologies can support other marginalized individuals as they navigate pervasive stigma and establish new lives in a digital society.",
    "title": "Bridging Borders, Breaking Biases: Envisioning Technologies to Support North Korean Defectors in South Korea ",
    "id": 188658,
    "sequence": 449,
    "queryCoordinates": {
      "visualization": [
        13.858192987669302,
        5.740251485476347
      ]
    }
  },
  {
    "session": "Make it Visible",
    "abstract": "Data-rich documents are ubiquitous in various applications, yet they often rely solely on textual descriptions to convey data insights. Prior research primarily focused on providing visualization-centric augmentation to data-rich documents. However, few have explored using automatically generated word-scale visualizations to enhance the document-centric reading process. As an exploratory step, we propose GistVis, an automatic pipeline that extracts and visualizes data insight from text descriptions. GistVis decomposes the generation process into four modules: Discoverer, Annotator, Extractor, and Visualizer, with the first three modules utilizing the capabilities of large language models and the fourth using visualization design knowledge. Technical evaluation including a comparative study on Discoverer and an ablation study on Annotator reveals decent performance of GistVis. Meanwhile, the user study (N=12) showed that GistVis could generate satisfactory word-scale visualizations, indicating its effectiveness in facilitating users' understanding of data-rich documents (+5.6% accuracy) while significantly reducing their mental demand (p=0.016) and perceived effort (p=0.033).",
    "title": "GistVis: Automatic Generation of Word-scale Visualizations from Data-rich Documents",
    "id": 188659,
    "sequence": 450,
    "queryCoordinates": {
      "visualization": [
        0.39157857666015516,
        2.974334584121431
      ]
    }
  },
  {
    "session": "Well-being and Tracking",
    "abstract": "Mental wellbeing has become a crucial aspect of overall health and has drawn increased attention to mental health concerns. Research in human-computer interaction (HCI) has explored how technologies can support mental wellbeing and address mental health issues. However, current research predominantly reflects Western cultural perspectives, leaving gaps in our understanding of mental wellbeing, coping strategies, and digital tools for mental wellbeing support from Eastern cultural viewpoints. To start to address this disparity, we interviewed 19 Taiwanese emerging adults aged between 18 and 29—a demographic uniquely susceptible to mental health challenges due to the transitional nature of this life phase. We explored their conceptualization of mental wellbeing, the challenges they encounter, the strategies they employ for managing mental wellbeing, and the role of digital tools in this process. The results highlight the intricate influence of cultural, political, social, and individual factors, and their interactions on mental wellbeing. ",
    "title": "Understanding Mental Wellbeing and Tools for Support with Taiwanese Emerging Adults: An Eastern Cultural Perspective",
    "id": 188660,
    "sequence": 451,
    "queryCoordinates": {
      "visualization": [
        -9.035628526325409,
        -6.273549006284602
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "Intelligence analysts must quickly and accurately examine and report on information in multiple modalities, including video, audio, and images. With the rise of Generative AI and deepfakes, analysts face unprecedented challenges, and require effective, reliable, and explainable media detection and analysis tools. This work explores analysts' requirements for deepfake detection tools and explainability features. From a study of 30 practitioners from the United States Intelligence Community, we identified the need for a comprehensive and explainable solution that incorporates a wide variety of methods and supports the production of intelligence reports. In response, we propose a design for an analyst-centered tool, and introduce a digital media forensics ontology to support analysts’ interactions with the tool and understanding of its results. We conducted a study grounded in work-related tasks as an initial evaluation of this approach, and report on its potential to assist analysts and areas for improvement in future work.",
    "title": "Understanding and Empowering Intelligence Analysts: User-Centered Design for Deepfake Detection Tools",
    "id": 188661,
    "sequence": 452,
    "queryCoordinates": {
      "visualization": [
        -1.9479565254429252,
        8.7866640640794
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "We present the walking meditation mat research, leveraging targeted heat to help meditators focus attention inward. The mat, measuring three meters in length, is designed with 10 visual signifiers and 10 corresponding heater pads arranged in a step-by-step pattern. Walking meditation is challenging, as it requires both inward and outward attention. In a qualitative study we studied the walking meditation experience with or without heat, evaluating the impact of the mat’s visual signifiers and the gentle feet-focused targeted heat during the walking experience. Our findings reveal the tension participants experience between external design factors and their internal meditation process. Visual signifiers were more commonly associated with outward attention, dizziness and imbalance, while targeted heat affordances were more commonly associated with attention to bodily sensations, calmness, grounding, and reflection. We conclude with insights regarding the role of targeted heat in balancing inward and outward attention in walking meditation and introspective processes.",
    "title": "The Walking Meditation Mat: Leveraging Targeted Heat Sensation to Guide Attention Inward",
    "id": 188662,
    "sequence": 453,
    "queryCoordinates": {
      "visualization": [
        19.351981847205195,
        5.049831540303159
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "The restoration of ancient Chinese paintings plays an essential role in protection and inheritance of Asian culture. A traditional restoration process consists of four stages: Xi (washing), Jie (separating), Bu (mending), and Quan (completing). However, it is difficult for the public to experience this process due to high professional requirement and time consumption. We conduct a questionnaire survey and interview experts in our formative study. The questionnaire result shows the public express strong interest in virtual restoration. Experts believe virtual restoration is an experience valuable for the public. We introduce Ink-Restorer, a tool designed for experiencing virtual restoration for ancient paintings. Its design follows the traditional restoration process, and it adopts image segmentation and generation techniques to simplify detailed restoration for users. We recruit 60 users to evaluate Ink-Restorer and invite experts to evaluate restoration results. Ink-Restorer significantly improves user experience, cultural understanding, and restoration quality.",
    "title": "Ink Restorer: Virtual Restoration of Ancient Chinese Paintings Inheriting Traditional Restoration Processes",
    "id": 188663,
    "sequence": 454,
    "queryCoordinates": {
      "visualization": [
        -5.6129703636699,
        -9.460156642284703
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study in which participants use an LLM-infused application to answer objective questions, we identify several features of LLM responses that shape users' reliance: explanations (supporting details for answers), inconsistencies in explanations, and sources. Through a large-scale, pre-registered, controlled experiment (N=308), we isolate and study the effects of these features on users' reliance, accuracy, and other measures.We find that the presence of explanations increases reliance on both correct and incorrect responses. However, we observe less reliance on incorrect responses when sources are provided or when explanations exhibit inconsistencies. We discuss the implications of these findings for fostering appropriate reliance on LLMs.",
    "title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies",
    "id": 188664,
    "sequence": 455,
    "queryCoordinates": {
      "visualization": [
        10.65831031959658,
        2.7203715060963702
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "Reminiscence has been shown to provide benefits for older adults, but traditionally relies on personal photos as memory cues and interactions with real people who may not always be available. We present ReminiBuddy, a novel LLM-powered multi-agent conversational system, which allows older adults to engage with two distinct agents—one embodying an older identity and the other a younger identity—while using not only personal photos but also 3D models of generic nostalgic objects as memory cues. Our study, with older adult participants, found that the conversational approach both enjoyable and beneficial for reminiscence. While the younger agent was perceived as more emotionally engaging, the older one fostered greater resonance in content. Personal photos prompted autobiographical memories, whereas 3D generic nostalgic objects evoked shared memories of an era, contributing to a more multifaceted reminiscence experience. We further present design implications for better supporting older adults in reminiscing with LLM-powered conversational agents.",
    "title": "Chorus of the Past: Toward Designing a Multi-agent Conversational Reminiscence System with Digital Artifacts for Older Adults",
    "id": 188665,
    "sequence": 456,
    "queryCoordinates": {
      "visualization": [
        4.619397662556432,
        -1.913417161825452
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "Voice agents can construct meaningful conversations with older adults to offer various benefits, such as providing emotional companionship and assisting with memory recall. However, such conversations often follow the simple turn-taking pattern and lack interruption and backchannel of natural human conversation. Previous research has shown that this rigid turn-taking pattern lacks interactivity and initiative, limiting the flexible communication between older adults and voice agents. To address these issues and create a more natural conversational voice agent, we first conducted a formative study to identify common usage of interruption in the natural conversations of older adults. We then designed an LLM-powered Barge-in agent that supports interruption and backchannel. Our within-subject exploratory study showed that participants felt that conversations with Barge-in agents were more natural, engaging, and fluent than with the No barge-in agent. We further present design implications for creating more natural and human-like voice agents for older adults.",
    "title": "Toward Enabling Natural Conversation with Older Adults via the Design of LLM-Powered Voice Agents that Support Interruptions and Backchannels",
    "id": 188666,
    "sequence": 457,
    "queryCoordinates": {
      "visualization": [
        13.182256689929478,
        -7.1573814038941315
      ]
    }
  },
  {
    "session": "HCI Methods",
    "abstract": "Statistical reporting, especially of effect sizes, is at the root of many methodological issues in quantitative research at CHI. Effect sizes are necessary for assessing practical relevance of results, a-priori power analysis, and meta-analyses, but currently, they are often not reported. Interpretations in the context of the study and the research field are also rare. To aid to researchers in reporting and contextualizing their effect sizes within their research field as well as choosing effect sizes for power analysis, we conducted a meta-study of quantitative CHI papers. We extracted statistics from all quantitative CHI papers published between 2019-2023 (N=1692). Based on effect sizes and the papers' CCS categories, we present effect size distributions in 12 CHI research fields. Through an additional qualitative analysis of 67 quantitative CHI'23 publications, we identify five categories of approaches that researchers take when interpreting effect size: Comparing test-specific values, assigning size labels, using a statistical or methodological reference frame, comparing different observations and interpreting for the big picture. ",
    "title": "Small, Medium, Large? A Meta-Study of Effect Sizes at CHI to Aid Interpretation of Effect Sizes and Power Calculation",
    "id": 188667,
    "sequence": 458,
    "queryCoordinates": {
      "visualization": [
        12.361892829330227,
        -8.496093553872504
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "We present HaptiCoil, an embedded system and interaction method for prototyping low-cost, compact, and customizable wide bandwidth (1-500 Hz) soft haptic buttons. HaptiCoil devices are built using mass-produced, waterproof planar micro-speakers which are adapted to direct energy to the skin using a novel hydraulic coupling mechanism. They can sense force input, using a measurement of self-inductance, and provide output in a single package, yielding a flexible all-in-one button solution. Our devices offer a wider perceptual range of tactile stimuli than industry standard approaches, while maintaining comparable power threshold levels (typical threshold under 40 mW). We detail the construction and underlying principles of our approach, as well as an extensive physical quantification of both input and output. We share psychophysical data on device bandwidth, and show three illustrative examples of how HaptiCoil buttons can implemented in use cases such as spatial computing, digital inking, and remote control. ",
    "title": "HaptiCoil: Soft Programmable Buttons with Hydraulically Coupled Haptic Feedback and Sensing",
    "id": 188668,
    "sequence": 459,
    "queryCoordinates": {
      "visualization": [
        -6.190939493098343,
        -7.8531693088074475
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "This study examines how WhatsApp has evolved from a personal communication tool to a professional platform, focusing on its use by small business owners in India. Initially embraced in smaller, rural communities for its ease of use and familiarity, WhatsApp played a crucial role in local economies. However, as Meta introduced WhatsApp Business with new, formalized features, users encountered challenges in adapting to the more complex and costly platform. Interviews with 14 small business owners revealed that while they adapted creatively, they felt marginalized by the advanced tools. This research contributes to HCI literature by exploring the transition from personal to professional use and introduces the concept of Coercive Professionalization. It highlights how standardization by large tech companies affects marginalized users, exacerbating power imbalances and reinforcing digital colonialism, concluding with design implications for supporting community-based appropriations.\r\n",
    "title": "\"Business on WhatsApp is tough now—but am I really a businesswoman?\" Exploring Challenges with Adapting to Changes in WhatsApp Business",
    "id": 188669,
    "sequence": 460,
    "queryCoordinates": {
      "visualization": [
        -11.839719985018549,
        -1.9547456807350585
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "As Large Language Models become integral to decision-making, optimism about their power is tempered with concern over their errors. Users may over-rely on LLM advice that is confidently stated but wrong, or under-rely due to mistrust. Reliance interventions have been developed to help users of LLMs, but they lack rigorous evaluation for appropriate reliance. We benchmark the performance of three relevant interventions by conducting a randomized online experiment with 400 participants attempting two challenging tasks: LSAT logical reasoning and image-based numerical estimation. For each question, participants first answered independently, then received LLM advice modified by one of three reliance interventions and answered the question again. Our findings indicate that while interventions reduce over-reliance, they generally fail to improve appropriate reliance. Furthermore, people became more confident after making wrong reliance decisions in certain contexts, demonstrating poor calibration. Based on our findings, we discuss implications for designing effective reliance interventions in human-LLM collaboration.",
    "title": "To Rely or Not to Rely? Evaluating Interventions for Appropriate Reliance on Large Language Models",
    "id": 188670,
    "sequence": 461,
    "queryCoordinates": {
      "visualization": [
        10.930365899054106,
        -4.952484357652746
      ]
    }
  },
  {
    "session": "Storytelling and Sense-Making",
    "abstract": "The pervasive use of mobile devices for information consumption makes reading on-the-go an unavoidable daily occurrence, whereby walking creates a natural situational impairment for reading. In this work, we quantify the impact of walking on reading performance and compare automatic system adaptations with user customizations for mitigating these impacts. We collected user interactions and mobile sensor data of reading while walking in a controlled lab study with 45 participants. We found that automatic font size adjustment by viewing distance mitigated the performance degradation from walking, yielding faster reading speed and increased comfort. Furthermore, exposure to the automatic adaptation functionality influences user customization behavior and preferences for reading while walking. We discuss implications and provide design suggestions for personalizing interfaces when reading on-the-go, including blending system recommendation with user customization, offering multiple points of customization through appropriately-timed prompts, and refining recommendations based on observed preferences.",
    "title": "Supporting Mobile Reading While Walking with Automatic and Customized Font Size Adaptations",
    "id": 188671,
    "sequence": 462,
    "queryCoordinates": {
      "visualization": [
        -15.460209067254734,
        12.687865683272916
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "Prototyping large, electronically integrated structures is challenging and often results in unwieldy wiring, weak mechanical properties, expensive iterations, or limited reusability. While many electronics prototyping kits exist for small-scale objects, relatively few methods exist to freely iterate large and sturdy structures with integrated electronics. To address this gap, we present the Voxel Invention Kit (VIK), which uses reconfigurable blocks that assemble into high-stiffness, lightweight structures with integrated electronics. We do this by creating cubic blocks composed of PCBs that carry electrical routing and components and can be (re)configured with simple tools into a variety of structures. To ensure structural stability without expertise, we created a tool to configure structures and simulate applied loads, which we validated with mechanical testing data. Using VIK, we produced devices reconfigured from a shared set of voxels: multiple iterations of a customizable AV lounge seat, a dance floor game, and a force-sensing bridge. ",
    "title": "Voxel Invention Kit: Reconfigurable Building Blocks for Prototyping Interactive Electronic Structures",
    "id": 188672,
    "sequence": 463,
    "queryCoordinates": {
      "visualization": [
        12.115341544103748,
        -10.450765487260433
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "Pedagogical questions are crucial for fostering student engagement and learning. In daily teaching, teachers pose hundreds of questions to assess understanding, enhance learning outcomes, and facilitate the transfer of theory-rich content. However, even experienced teachers often struggle to generate a large volume of effective pedagogical questions. To address this, we introduce TutorCraftEase, an interactive generation system that leverages large language models (LLMs) to assist teachers in creating pedagogical questions. TutorCraftEase enables the rapid generation of questions at varying difficulty levels with a single click, while also allowing for manual review and refinement. In a comparative user study with 39 participants, we evaluated TutorCraftEase against a traditional manual authoring tool and a basic LLM tool. The results show that TutorCraftEase can generate pedagogical questions comparable in quality to those created by experienced teachers, while significantly reducing their workload and time.",
    "title": "TutorCraftEase: Enhancing Pedagogical Question Creation with Large Language Models",
    "id": 188673,
    "sequence": 464,
    "queryCoordinates": {
      "visualization": [
        1.6629392246050894,
        -1.111140466039206
      ]
    }
  },
  {
    "session": "Working with AI",
    "abstract": "With the growing integration of AI into daily life, various technologies have been developed to teach children about AI. However, differences in their designs highlight the need for a thorough understanding of these tools to make the most of current technological resources and guide the effective development of future learning tools. Through a systematic search, we identified 64 different AI learning tools for children and analyzed their design features, including both static design features (i.e., presentation formats and learning content) and interactive design features (i.e., learning activity types and design features that potentially enhance the effectiveness of the activities). Our findings reveal the current trends and gaps in the design of children’s AI learning technologies. Based on these insights, we reflect on future design opportunities and provide recommendations for creating new, effective learning technologies to advance AI education for the next generations.",
    "title": "Technologies for Children’s AI Learning: Design Features and Future Opportunities",
    "id": 188674,
    "sequence": 465,
    "queryCoordinates": {
      "visualization": [
        5.043883547053377,
        18.318276086023058
      ]
    }
  },
  {
    "session": "Design Thinking",
    "abstract": "The online art world is a double-edged sword: the Internet’s vibrant culture of open, cooperative art-sharing also attracts nonconsensual reuse and appropriation. Artists continually navigate supportive and challenging interactions on social platforms, including community-shifting disruptions; the reuse of creative work for training generative AI is only the latest such disruption. Research into creativity support tools (CSTs) often centers artifact-making, leaving the HCI community with few strategies to understand the\r\ndownstream impacts CSTs can make on artifact-sharing. Seeking a framework that captures this, we develop the creativity supportive ecosystem through interviews with 20 online artists, and 8 data “stewards” with experience reusing creative data for training GenAI. We use the CSE to describe how creative communities perceive and respond to disruption, identifying opportunities to empower artists in their collective negotiations with disruptive technologies like GenAI: by centering artists as producers of value, identifying creative and alternative data practices, and empowering inter-community flexibility.",
    "title": "Creativity Supportive Ecosystems: A Framework for Understanding Function and Disruption in Online Art Worlds",
    "id": 188675,
    "sequence": 466,
    "queryCoordinates": {
      "visualization": [
        -9.617956964488624,
        10.173244508476378
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "Black girls and women have long been creators in computing spaces. However, much computing education positions Black girls as workers who execute tasks for others' purposes. Our work takes a different approach by positioning Black girls as technosocial change agents who challenge dominant narratives and construct more liberating identities and social relations as they create new technologies. We draw on data from seven Black girls, ages 9-12, who participated in a 20-hour culturally responsive computing (CRC) camp focused on robotics. Using a thematic analysis approach, we explore how these Black girls demonstrate and enhance their technosocial change agency (TSCA) throughout the camp. We identify themes related to how creating technology helps Black girls refine and fulfill their definitions of technical creators and develop agency through technology creation. We discuss computing education and technology design recommendations within the TSCA framework to support learners' emerging TSCA in future CRC programs.",
    "title": " “I am a Technology Creator”: Black Girls as Technosocial Change Agents in a Culturally-Responsive Robotics Camp",
    "id": 188676,
    "sequence": 467,
    "queryCoordinates": {
      "visualization": [
        2.7144044986507385,
        -9.624552364536473
      ]
    }
  },
  {
    "session": "Interfaces and Interactions for XR",
    "abstract": "Fitts' law is widely used as an evaluation tool for pointing or selection tasks, evolving into diverse applications, including 3D extended reality (XR) environments like virtual, augmented, and mixed reality. Despite standards like ISO 9241:411, the application of Fitts' law varies significantly across studies, complicating comparisons and undermining the reliability of findings in 3D XR research. To address this, we conducted a systematic review of 119 publications, focusing on 122 studies that used Fitts' law in 3D XR user experiments. Our analysis shows that over half of these studies referenced Fitts' law without thoroughly investigating throughput, movement time, or error rate. We performed an in-depth meta-analysis to examine how Fitts' law is incorporated into research. By highlighting trends and inconsistencies, and making recommendations this review aims to guide researchers in designing and performing more effective and consistent Fitts-based studies in 3D XR, enhancing the quality and impact of future research.",
    "title": "A Systematic Review of Fitts’ Law in 3D Extended Reality",
    "id": 188677,
    "sequence": 468,
    "queryCoordinates": {
      "visualization": [
        9.032407769589222,
        -10.696523261502508
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "Accessing auditory information remains challenging for DHH individuals in real-world situations and multiplayer VR interactions. To improve this, we investigated caption designs that specialize in the needs of DHH users in multiplayer VR settings. First, we conducted three co-design workshops with DHH participants, social workers, and designers to gather insights into the specific needs of design directions for DHH users in the context of a room escape game in VR. We further refined our designs with 13 DHH users to determine the most preferred features. Based on this, we developed VRCaptions, a caption prototype for DHH users to better experience multiplayer conversations in VR. We lastly invited two mixed-hearing groups to participate in the VR room escape game with our VRCaptions to validate. The results demonstrate that VRCaptions can enhance the ability of DHH participants to access information and reduce the barrier to communication in VR.",
    "title": "VRCaptions: Design Captions for DHH Users in Multiplayer Communication in VR",
    "id": 188678,
    "sequence": 469,
    "queryCoordinates": {
      "visualization": [
        9.930684569549262,
        -1.1753739745783855
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "Unlike the free exploration of childhood, the demands of daily life reduce our motivation to explore our surroundings, leading to missed opportunities for informal learning. Traditional tools for knowledge acquisition are reactive, relying on user initiative and limiting their ability to uncover hidden interests. Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping). AiGet analyzes real-time user gaze patterns, environmental context, and user profiles, leveraging large language models to deliver personalized, context-aware knowledge with low disruption to primary tasks. In-lab evaluations and real-world testing, including continued use over multiple days, demonstrate AiGet’s effectiveness in uncovering overlooked yet surprising interests, enhancing primary task enjoyment, reviving curiosity, and deepening connections with the environment. We further propose design guidelines for AI-assisted informal learning, focused on transforming everyday moments into enriching learning experiences.",
    "title": "AiGet: Transforming Everyday Moments into Hidden Knowledge Discovery with AI Assistance on Smart Glasses",
    "id": 188679,
    "sequence": 470,
    "queryCoordinates": {
      "visualization": [
        -10.643573670544495,
        -14.516002876814678
      ]
    }
  },
  {
    "session": "Robot and Agent",
    "abstract": "Robot-mediated telepresence promises to facilitate effective social interaction between remote teleoperators and on-site users. However, disparities between the robot's form and the teleoperator's representation cause perceptual conflict in on-site users, degrading interaction quality. We introduce AvatARoid, a novel design that bridges this embodiment gap by superimposing the teleoperator's motion-mapped AR avatar overlay on a humanoid. We evaluated our design in a mixed-method study (n=48) using an immersive simulation where participants interacted with a confederate teleoperator, presented in either (a) a humanoid robot, (b) a humanoid robot with video, or (c) AvatARoid. Results suggest AvatARoid significantly improved teleoperator embodiment for on-site users, particularly enhancing co-location, and control perceptions, and providing richer non-verbal gestures. In contrast, video and baseline conditions often resulted in a pronounced disconnect between the teleoperator and the robot for on-site users. Our study offers new insights into designing novel teleoperator representations to promote social interaction in robot-mediated telepresence.",
    "title": "AvatARoid: A Motion-Mapped AR Overlay to Bridge the Embodiment Gap Between Robots and Teleoperators in Robot-Mediated Telepresence",
    "id": 188680,
    "sequence": 471,
    "queryCoordinates": {
      "visualization": [
        7.289409997582991,
        18.624298695176073
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "Mental-illness stigma is a persistent social problem, hampering both treatment-seeking and recovery. Accordingly, there is a pressing need to understand it more clearly, but analyzing the relevant data is highly labor-intensive. Therefore, we designed a chatbot to engage participants in conversations; coded those conversations qualitatively with AI assistance; and, based on those coding results, built causal knowledge graphs to decode stigma. The results we obtained from 1,002 participants demonstrate that conversation with our chatbot can elicit rich information about people’s attitudes toward depression, while our AI-assisted coding was strongly consistent with human-expert coding. Our novel approach combining large language models (LLMs) and causal knowledge graphs uncovered patterns in individual responses and illustrated the interrelationships of psychological constructs in the dataset as a whole. The paper also discusses these findings’ implications for HCI researchers in developing digital interventions, decomposing human psychological constructs, and fostering inclusive attitudes.",
    "title": "Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs",
    "id": 188681,
    "sequence": 472,
    "queryCoordinates": {
      "visualization": [
        10.190426178318942,
        -6.336814207804423
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "People-centred security is critical for the security of an organisation, but we know that it comes at a cost. Recently the academic literature base has started to focus on how security might be understood and promoted as a facet of the overall culture of an organisation. This work sets out to understand the experiences of employees and management when using an anonymous online discussion platform to discuss cybersecurity policies. Following a 2-week deployment in a large UK educational institution, we found that anonymity helped individuals share their experiences, and that these experiences helped others understand more about the rationale for security policies. However, we also found that anonymity negatively impacted on individuals’ ability to discuss specific problems and follow up on incidents. We discuss the opportunities and challenges of using anonymous discussion platforms in organisations for improving the security culture through social participation and a more transparent listening culture.\r\n",
    "title": "Using Anonymous Discussion Platforms to Support Open Conversations about Cybersecurity in Organisations",
    "id": 188682,
    "sequence": 473,
    "queryCoordinates": {
      "visualization": [
        -4.886212414969551,
        8.72496007072797
      ]
    }
  },
  {
    "session": "Vulnerable Populations",
    "abstract": "This paper examines the use of generic images depicting natural scenes, combined with browsing technologies, in non-verbal interactions with individuals with intellectual disabilities. Current Augmentative and Alternative Communication (AAC) methods often demand extensive learning and memorization of symbolic visuals, creating usability challenges. This case study report examines the potential for adapting the Canvis app, an image-based communication prototype, in real-life scenarios for adults with intellectual disabilities. Through this case study, we identify user challenges and provide design recommendations for improvement. The case study presents observations made during a three-month internship at two community hubs in Queensland, Australia. We highlight that effective communication technology for this group of users must encompass a broader perspective, prioritizing connection, self-expression, and participation rather than merely symbol exchange. The findings suggest that generic image browsing platforms have the potential to enhance communication experiences for users, fostering inclusivity and enabling meaningful engagement with others.",
    "title": "Communication with Individuals with Intellectual Disability Using Generic Images: Exploring Contexts, Requirements, Opportunities, and Challenges",
    "id": 188683,
    "sequence": 474,
    "queryCoordinates": {
      "visualization": [
        -10.162674857624154,
        4.209517756015988
      ]
    }
  },
  {
    "session": "WS33: Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "abstract": "We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI. ",
    "title": "Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "id": 188684,
    "sequence": 475,
    "queryCoordinates": {
      "visualization": [
        -13.08135701042534,
        -9.212931062685525
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "Artificial intelligence (AI)-based decision support systems hold promise for enhancing diagnostic accuracy and efficiency in computational pathology. However, human-AI collaboration can introduce and amplify cognitive biases, like confirmation bias caused by false confirmation when erroneous human opinions are reinforced by inaccurate AI output. This bias may increase under time pressure, a ubiquitous factor in routine pathology, as it strains practitioners' cognitive resources. We quantified confirmation bias triggered by AI-induced false confirmation and examined the role of time constraints in a web-based experiment, where trained pathology experts (n=28) estimated tumor cell percentages. Our results suggest that AI integration fuels confirmation bias, evidenced by a statistically significant positive linear-mixed-effects model coefficient linking AI recommendations mirroring flawed human judgment and alignment with system advice. Conversely, time pressure appeared to weaken this relationship. These findings highlight potential risks of AI in healthcare and aim to support the safe integration of clinical decision support systems.",
    "title": "\"When Two Wrongs Don't Make a Right\" - Examining Confirmation Bias and the Role of Time Pressure During Human-AI Collaboration in Computational Pathology",
    "id": 188685,
    "sequence": 476,
    "queryCoordinates": {
      "visualization": [
        17.044742330911895,
        -5.785910375456929
      ]
    }
  },
  {
    "session": "3D Design and Fabrication",
    "abstract": "Compliant mechanisms enable the creation of compact and easy-to-fabricate devices for tangible interaction. This work explores interconnected compliant mechanisms consisting of multiple joints and rigid bodies to transmit and process displacements as signals that result from physical interactions. As these devices are difficult to design due to their vast and complex design space, we developed a graph-based design algorithm and computational tool to help users program and customize such computational functions and procedurally model physical designs. When combined with active materials with actuation and sensing capabilities, these devices can also render and detect haptic interaction. Our design examples demonstrate the tool’s capability to respond to relevant HCI concepts, including building modular physical interface toolkits, encrypting tangible interactions, and customizing user augmentation for accessibility. We believe the tool will facilitate the generation of new interfaces with enriched affordance.",
    "title": "CompAct: Designing Interconnected Compliant Mechanisms with Targeted Actuation Transmissions",
    "id": 188686,
    "sequence": 477,
    "queryCoordinates": {
      "visualization": [
        -13.326040464736492,
        -10.55540835459271
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "Prior research on the experiences of students with disabilities in higher education has surfaced a number of barriers that prevent full inclusion. Generative artificial intelligence (GenAI) has begun to attract interest for its potential to address longstanding barriers to access. However, little is known about the impact of these tools on the living and learning experiences of post-secondary students with disabilities. As a mixed-abilities team, we investigated student experiences with GenAI tools by collecting survey and interview responses from 62 and 21 students with disabilities, respectively, across two universities to measure students' use of GenAI tools and their perspectives on the impact of these tools in ways related to disability, university support, and sense of belonging. Despite concerns over potential risks of GenAI and unclear university policies, students described GenAI tools as a useful resource for personalizing learning, promoting self-care, and assisting with important self-advocacy work. Guidance demonstrating safe, acceptable uses of GenAI tools, along with clear policies and resources that acknowledge diverse student needs, were desired. We discuss implications of these tools for accessibility and inclusion in higher education.",
    "title": "\"I'd Never Actually Realized How Big An Impact It Had Until Now\": Perspectives of University Students with Disabilities on Generative Artificial Intelligence",
    "id": 188687,
    "sequence": 478,
    "queryCoordinates": {
      "visualization": [
        0.3926596563665962,
        15.995181099139268
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "Some people suggest that deliberately watching the camera during video calls can simulate eye contact and help build trust. In this study, we investigated the effects of simulated eye contact in video calls and job interviews through an experimental study and a survey. Study 1 involved participants in a mock interview as an interviewer, where a confederate interviewee simulated eye contact half the time. The gaze patterns of the participants were tracked to understand the effects. In Study 2, we conducted an online survey to confirm the findings of Study 1 on a larger scale by asking those with experience interviewing to evaluate interviewees based on interview videos, half of which simulated eye contact. The results of both studies indicate that simulated eye contact had little impact on their evaluation compared to common belief. We discuss how the results motivate future work and how computational approaches to correcting eye gaze can be deceptive.",
    "title": "Investigating the Effects of Simulated Eye Contact in Video Call Interviews",
    "id": 188688,
    "sequence": 479,
    "queryCoordinates": {
      "visualization": [
        17.893014088001753,
        1.959603747335362
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "Research on trust in AI is limited to several trustors (e.g., end-users) and trustees (especially AI systems), and empirical explorations remain in laboratory settings, overlooking factors that impact trust relations in the real world. Here, we broaden the scope of research by accounting for the supply chains that AI systems are part of. To this end, we present insights from an in-situ, empirical, study of LLM supply chains. We conducted interviews with 71 practitioners, and analyzed their (collaborative) practices using the lens of trust drawing from literature in organizational psychology.\r\nOur work reveals complex trust dynamics at the junctions of the chains, with interactions between diverse technical artifacts, individuals, or organizations. These junctions might constitute terrain for uncalibrated reliance when trustors lack supply chain knowledge or power dynamics are at play. Our findings bear implications for AI researchers and policymakers to promote AI governance that fosters calibrated trust.",
    "title": "Unpacking Trust Dynamics in the LLM Supply Chain: An Empirical Exploration to Foster Trustworthy LLM Production & Use",
    "id": 188689,
    "sequence": 480,
    "queryCoordinates": {
      "visualization": [
        -4.27335518668874,
        -16.454131257784486
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "Swarm User Interfaces allow dynamic arrangement of user environments through the use of multiple mobile robots, but their operational range is typically confined to a single plane due to constraints imposed by their two-wheel propulsion systems. We present corobos, a proof-of-concept design that enables these robots to cooperatively transition between table (horizontal) and wall (vertical) surfaces seamlessly, without human intervention. Each robot is equipped with a uniquely designed slope structure that facilitates smooth rotation when another robot pushes it toward a target surface. Notably, this design relies solely on passive mechanical elements, eliminating the need for additional active electrical components. We investigated the design parameters of this structure and evaluated its transition success rate through experiments. Furthermore, we demonstrate various application examples to showcase the potential of corobos in enhancing user environments.",
    "title": "corobos: A Design for Mobile Robots Enabling Cooperative Transitions between Table and Wall Surfaces",
    "id": 188690,
    "sequence": 481,
    "queryCoordinates": {
      "visualization": [
        3.9807389066887877,
        -0.3920685613182424
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "Remapping techniques in VR such as repositioning, redirection, and resizing have been extensively studied. Still, interaction designers rarely have the opportunity to use them due to high technical and knowledge barriers. In the paper, we extract common features of 24 existing remapping techniques and develop a high-fidelity immersive authoring tool, namely RemapVR, for rapidly building and experiencing prototypes of remapped space properties in VR that are unperceivable or acceptable to users. RemapVR provides designers with a series of functions for editing remappings and visualizing spatial property changes, mapping relationships between real and virtual worlds, sensory conflicts, etc. Designers can quickly build existing remappings via templates, and author new remappings by interactively recording spatial relations between input trajectory in real world and output trajectory in virtual world. User studies showed that the designs of RemapVR can effectively improve designers' authoring experience and efficiency, and support designers to author remapping prototypes that meet scene requirements and provide good user experience.",
    "title": "RemapVR: An Immersive Authoring Tool for Rapid Prototyping of Remapped Interaction in VR",
    "id": 188691,
    "sequence": 482,
    "queryCoordinates": {
      "visualization": [
        -10.325318635406314,
        -10.880615565184309
      ]
    }
  },
  {
    "session": "3D Design and Fabrication",
    "abstract": "Shape Cast is our novel software tool designed to simplify the creation of plaster molds for ceramic slip casting by automating the 3D modeling process. Instead of needing to model molds, Shape Cast allows artists to input a single 2D profile of the desired pot. Shape Cast uses that to generate ready-to-print 3D molds for plaster, accommodating factors such as clay shrinkage and mold structural requirements. We detail the mold generation process and associated software implementation. We provide case studies demonstrating the capabilities of Shape Cast. We opened a beta version of Shape Cast to the public and 501 users have signed up creating a total of 626 fully finalized 3D models. We detail feedback from questionnaire responses of 17 users.",
    "title": "Crafting the Curve: Automating Plaster Mold Design for Ceramic Slip Casting with Shape Cast",
    "id": 188692,
    "sequence": 483,
    "queryCoordinates": {
      "visualization": [
        15.46020906725473,
        -12.687865683272918
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Recently, an increasing number of news organizations have integrated artificial intelligence (AI) into their workflows, leading to a further influx of AI technologists and data workers into the news industry. This has initiated cross-functional collaborations between these professionals and journalists. Although prior research has explored the impact of AI-related roles entering the news industry, there is a lack of studies on how internal cross-functional collaboration around AI unfolds between AI professionals and journalists within the news industry. Through interviews with 17 journalists, six AI technologists, and three AI workers with cross-functional experience from leading Chinese news organizations, we investigate the practices, challenges, and opportunities for internal cross-functional collaboration around AI in news industry. We first study how these journalists and AI professionals perceive existing internal cross-collaboration strategies. We explore the challenges of cross-functional collaboration and provide recommendations for enhancing future cross-functional collaboration around AI in the news industry.",
    "title": "\"It Might be Technically Impressive, But It’s Practically Useless to us\":  Motivations, Practices, Challenges, and Opportunities for Cross-Functional Collaboration around AI within the News Industry",
    "id": 188693,
    "sequence": 484,
    "queryCoordinates": {
      "visualization": [
        3.5139448781596103,
        -18.672230487899828
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "Computational intelligence is increasingly common in interactive systems in many domains, including health. Health coaching with conversational agents (CA) can reach wide populations, but the level of computational intelligence needed for a positive coaching experience is unclear. We conducted a study with sixteen individuals with diabetes and prediabetes who used a CA for health coaching, T2 Coach. Qualitative interviews revealed that participants saw T2 Coach as reliable in helping them stay on track with self-management, appreciated the flexibility in choosing personally meaningful goals and engaging on their own terms, and felt it provided encouragement and even compared it favorably with human coaches. However, they also noted that coaching experience could be improved with more fluid conversations, more tailoring to their personal preferences and lifestyles, and more sensitivity to specific contexts, all of which require more computational intelligence. We discuss implications and design directions for more intelligent coaching CA in health.",
    "title": "T2 Coach: A Qualitative Study of an Automated Health Coach for Diabetes Self-Management",
    "id": 188694,
    "sequence": 485,
    "queryCoordinates": {
      "visualization": [
        14.950166537251926,
        -13.285048758225646
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "As artificial intelligence (AI) becomes more embedded in personal health technology, its potential to transform health decision-making through personalised recommendations is becoming significant. However, there is limited understanding of how individuals perceive AI-assisted decision-making in the context of personal health. This study investigates the impact of AI-assisted decision-making on trust in physical activity-related health decisions. By employing MoveAI, a GPT-4.0-based physical activity decision-making tool, we conducted a mixed-methods study and conducted an online survey (N=184) and semi-structured interviews (N=24) to explore this dynamic. Our findings emphasise the role of nuanced personal health recommendations and individual decision-making styles in shaping trust in AI-assisted personal health decision-making. This paper contributes to the HCI literature by elucidating the relationship between decision-making styles and trust in the AI-assisted personal health decision-making process and showing the challenges of aligning AI recommendations with individual decision-making preferences.",
    "title": "Selective Trust: Understanding Human-AI Partnerships in Personal Health Decision-Making Process",
    "id": 188695,
    "sequence": 486,
    "queryCoordinates": {
      "visualization": [
        -8.99143399423672,
        -0.39257448628802244
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "Touchless displays often use mid-air gestures to control on-screen cursors for pointer interactions. Area cursors can simplify touchless cursor input by implicitly targeting nearby widgets without the cursor entering the target. However, for displays with dense target layouts, the cursor still has to arrive close to the widget, meaning the benefits of area cursors for time-to-target and effort are diminished. Through two experiments, we demonstrate for the first time that fine-tuning the mapping between hand and cursor movements (control-display gain -- CDG) can address the deficiencies of area cursors and improve the performance of touchless interaction. Across several display sizes and target densities (representative of myriad public displays used in retail, transport, museums, etc), our findings show that the forgiving nature of an area cursor compensates for the imprecision of a high CDG, helping users interact more effectively with smaller and more controlled hand/arm movements.",
    "title": "Everything to Gain: Combining Area Cursors with increased Control-Display Gain for Fast and Accurate Touchless Input",
    "id": 188696,
    "sequence": 487,
    "queryCoordinates": {
      "visualization": [
        4.240636259871296,
        -12.288897595450324
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "Recent work has catalogued a variety of ``dark'' design patterns, including deception, that undermine user intent.  We focus on deceptive ``placebo'' control settings for social media that do not work.  While prior work reported that placebo controls increase feed satisfaction, we add to this body of knowledge by addressing possible placebo mechanisms, and potential side effects and confounds from the original study.  Knowledge of these placebo mechanisms can help predict potential harms to users and prioritize the most problematic cases for regulators to pursue.  In an online experiment, participants (N=762) browsed a Twitter feed with no control setting, a working control setting, or a placebo control setting.  We found a placebo effect much smaller in magnitude than originally reported.  This finding adds another objection to use of placebo controls in social media settings, while our methodology offers insights into finding confounds in placebo experiments in HCI.",
    "title": "Placebo Effect of Control Settings in Feeds Are Not Always Strong",
    "id": 188697,
    "sequence": 488,
    "queryCoordinates": {
      "visualization": [
        9.986568514523636,
        -8.322766926012354
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "The integration of emotion-aware systems in vehicles is accelerated by new technologies, including advancements in AI and ubiquitous sensing technologies. As the automotive industry shifts from technology-centred, feature-driven approaches to human-centred design, this research focuses on how to effectively incorporate emotion features into user-centred design to enhance effective human-vehicle interaction in practices. By conducting an interview study with 31 industrial design practitioners, supplemented by insights from engineers and AI experts involved in the early-stage design and development of novel in-vehicle user interfaces and systems, we examined current practices, and sampled their challenges, attitudes and expectations related to emotion-aware systems. Our findings provide critical insights to the design space of emotion-aware systems from both user and AI perspectives, inform efforts to support design practices in this evolving area, and identify opportunities for future innovation in emotion-aware in-vehicle design. Based on our findings, we propose adaptations to design practices and recommendations for further research.",
    "title": "Emotion-aware Design in Automobiles: Embracing Technology Advancements to Enhance Human-vehicle Interaction",
    "id": 188698,
    "sequence": 489,
    "queryCoordinates": {
      "visualization": [
        9.427934736519957,
        17.6384252869671
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "Technology plays a dual role in our daily lives, both contributing to heightened stress levels and offering potential solutions for stress management. However, the lived experience of stress in everyday contexts remains underexplored, leaving a critical gap in our understanding of how stress manifests and how technology can effectively support stress management. To address this, we conducted user interviews and expert interviews with specialists in psychology, health, and stress research, complemented by an autoethnographic study. Our findings show the complexity of stress as both a subjective experience and a response shaped by socio-technical environments, leading to the construction of the Dual Model for Everyday Stress Technology. This model highlights the paradoxical nature of stress and its management in technology-mediated settings. We identify key directions for future stress-management technology design and research, with implications for creating meaningful, human-centred technologies for managing stress in everyday life.",
    "title": "The Dual Model for Everyday Stress Technology: Understanding the Lived Experience of Data-Driven Stress",
    "id": 188699,
    "sequence": 490,
    "queryCoordinates": {
      "visualization": [
        -10.173244508476378,
        -9.617956964488624
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "Large language model (LLM) systems have been shown to stimulate creative thinking among creators, yet empirical research on whether users can seek inspiration in their everyday lives through these technologies is lacking. This paper explores which attributes of LLMs influence inspiration-seeking processes. Focusing on use cases of travel, cooking, and self-care, we interviewed 20 participants as they explored scenarios of these use cases using LLMs. Thematic analysis revealed that the vast data of LLMs inspires users with unexpected ideas, many of which were highly personalized, and inspired participants towards being motivated to act. Participants were also sensitive to the deficiencies of LLMs, and noted how ethical issues associated with these technologies could negatively impact them applying inspirational ideas into practice. We discuss the behavioral patterns of users actively seeking inspiration via LLMs, and provide design opportunities for LLMs that make the inspiration-seeking process more human-centric.",
    "title": "Seeking Inspiration through Human-LLM Interaction",
    "id": 188700,
    "sequence": 491,
    "queryCoordinates": {
      "visualization": [
        2.7382209514184863,
        -17.790507188419696
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "Recent advancements in AI have significantly enhanced collaboration between humans and writing assistants. However, empirical evidence is still lacking on how this collaboration unfolds in scientific writing, especially considering the variety of tools researchers can use nowadays. We conducted observations and retrospective interviews to investigate how 19 computer science researchers collaborated with intelligent writing assistants while working on their ongoing projects. We adopted a design-in-use lens to analyze the collected data, exploring how researchers adapt writing assistants during their use to overcome challenges and meet their specific needs and preferences. Our findings identify issues such as workflow disruptions and over-reliance on AI, and reveal five distinct design-in-use styles---teaching, resisting, repurposing, orchestrating, and complying---each consisting of different practices used by researchers. This study contributes to understanding the evolving landscape of human-AI co-writing in scientific research and offers insights for designing more effective writing assistants.\r\n",
    "title": "Investigating How Computer Science Researchers Design Their Co-Writing Experiences With AI",
    "id": 188701,
    "sequence": 492,
    "queryCoordinates": {
      "visualization": [
        10.190426178318948,
        6.336814207804416
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "Current tablet-based interfaces for drone operations often impose a heavy cognitive load on pilots and reduce situational awareness by dividing attention between the video feed and the real world. To address these challenges, we designed a heads-up augmented reality (AR) interface that overlays in-situ information to support drone pilots in safety-critical tasks. Through participatory design workshops with professional pilots, we identified key features and developed an adaptive AR interface that dynamically switches between task and safety views to prevent information overload. We evaluated our prototype by creating a realistic building inspection task and comparing three interfaces: a 2D tablet, a static AR, and our adaptive AR design. A user study with 15 participants showed that the AR interface improved access to safety information, while the adaptive AR interface reduced cognitive load and enhanced situational awareness without compromising task performance. We offer design insights for developing safety-first heads-up AR interfaces.",
    "title": "SafeSpect: Safety-First  Augmented Reality Heads-up Display for Drone Inspections",
    "id": 188702,
    "sequence": 493,
    "queryCoordinates": {
      "visualization": [
        -16.408028870510275,
        -11.435759204552241
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "Public administrations provide critical services and manage sensitive data for a country's citizens. Recent phishing campaigns targeting public sector employees highlight their attractiveness as targets. Deploying state-of-the-art authentication technologies, such as FIDO2, can improve overall security. We conducted a mixed-methods study in Germany to understand better the practices and challenges of deploying passwordless authentication in the public sector. First, we conducted an online survey (N=108) among German public sector employees to gain insights into their experiences and challenges. Next, we partnered with an e-government vendor and performed an in-situ experiment. We let 11 employees from the public sector experience FIDO2 under real-world conditions. Our results show that only a minority of our participants were aware of current passwordless authentication procedures. In our experiment, FIDO2-based methods left an overall positive impression. Hierarchical and heterogeneous public sector structures and the need for more technical expertise and equipment were barriers to adoption.",
    "title": "A Qualitative Study of Adoption Barriers and Challenges for Passwordless Authentication in German Public Administrations",
    "id": 188703,
    "sequence": 494,
    "queryCoordinates": {
      "visualization": [
        -11.503208623575302,
        17.569183002134814
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "Mobile sensor data collection in people’s daily lives is essential for understanding fine-grained human behaviors. However, in-the-wild data collection often results in missing data due to participant and system-related issues. While existing monitoring systems in the mobile sensing field provide an opportunity to detect missing data, they fall short in monitoring data across many participants and sensors and diagnosing the root causes of missing data, accounting for heterogeneous sensing characteristics of mobile sensor data. To address these limitations, we undertook a multi-year iterative design process to develop a system for monitoring missing data in mobile sensor data collection. Our final prototype, DataSentry, enables the detection, diagnosis, and addressing of missing data issues across many participants and sensors, considering both within- and between-person variability. Based on the iterative design process, we share our experiences, lessons learned, and design implications for developing advanced missing data management systems.",
    "title": "DataSentry: Building Missing Data Management System for In-the-Wild Mobile Sensor Data Collection through Multi-Year Iterative Design Approach",
    "id": 188704,
    "sequence": 495,
    "queryCoordinates": {
      "visualization": [
        15.388413672113032,
        -9.337918646889399
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "Researchers in Human-Computer Interaction (HCI) have studied the design and use of technologies for sustainability and development, contributing to the subfields of Sustainable HCI and HCI for Development. Increasingly, there have been calls within and outside HCI for a more integrated approach to sustainable development. To identify the potential of such an approach, we present a comprehensive review of HCI scholarship on sustainability and development, combined with an analysis of interviews with researchers working in and across both subfields. Using the lens of political economy, we uncover understandings, critiques, tensions, and considerations toward advancing scholarship at the intersections of sustainability, development, and HCI. We conclude by inviting the larger Special Interest Group on Computer-Human Interaction (SIGCHI)  community to join us in collectively devising pathways for technology-mediated sustainable development.",
    "title": "Sustainability, Development, and Human–Computer Interaction",
    "id": 188705,
    "sequence": 496,
    "queryCoordinates": {
      "visualization": [
        -5.3724716387761475,
        5.927609002839672
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "Information gathering is an important capability that allows chatbots to understand and respond to users' needs, yet the effectiveness of LLM-powered chatbots at this task remains underexplored. Our work investigates this question in the context of clinical pre-consultation, wherein patients provide information to an intermediary before meeting with a physician to facilitate communication and reduce consultation inefficiencies. We conducted a study at a walk-in clinic with 45 patients who interacted with one of three conversational agents: a chatbot, a questionnaire, and a Wizard-of-Oz. We analyzed patients' messages using metrics adapted from Grice's maxims to assess the quality of information gathered at each conversation turn. We found that the Wizard and LLM were more successful than the questionnaire because they modified questions and asked follow-ups when participants provided unsatisfactory answers. However, the LLM did not ask nearly as many follow-up questions as the Wizard, particularly when participants provided unclear answers. ",
    "title": "A Comparative Analysis of Information Gathering by Chatbots, Questionnaires, and Humans in Clinical Pre-Consultation",
    "id": 188706,
    "sequence": 497,
    "queryCoordinates": {
      "visualization": [
        11.483284028786503,
        -3.4834161270535597
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "Driver decision quality in take-overs is critical for effective human-Autonomous Driving System (ADS) collaboration. However, current research lacks detailed analysis of its variations. This paper introduces two metrics--Actual Achieved Gain (AAG) and Optimal Perceived Gain (OPG)--to assess decision quality, with OPG representing optimal decisions and AAG reflecting actual outcomes. Both are calculated as weighted averages of perceived gains and losses, influenced by ADS accuracy. Study 1 (N=315) used a 21-point Thurstone scale to measure perceived gains and losses—key components of AAG and OPG—across typical tasks: route selection, overtaking, and collision avoidance. Studies 2 (N=54) and 3 (N=54) modeled decision quality under varying ADS accuracy and decision time. Results show with sufficient time (>3.5s), AAG converges towards OPG, indicating rational decision-making, while limited time leads to intuitive and deterministic choices. Study 3 also linked AAG-OPG deviations to irrational behaviors. An intervention study (N=8) and a pilot (N=4) employing voice alarms and multi-modal alarms based on these deviations demonstrated AAG's potential to improve decision quality.",
    "title": "Actual Achieved Gain and Optimal Perceived Gain: Modeling Human Take-over Decisions Towards Automated Vehicles' Suggestions",
    "id": 188707,
    "sequence": 498,
    "queryCoordinates": {
      "visualization": [
        -1.9615705608064609,
        0.3901806440322572
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "End-users of augmentative and alternative communication (AAC) have diverse speech, cognitive, and motor abilities. AAC's heterogeneous user groups and persistent usability issues create a challenging and rich design space. Our work takes a value-sensitive design (VSD) approach to develop a stakeholder value framework that describes stakeholders' multi-dimensional roles and values. Our framework is based on (1) an empirical investigation---a survey and interviews---of AAC users and AAC conversation partners and (2) a conceptual investigation---a systematic literature review---of AAC HCI research. Emergent value themes were ease, fulfillment, acceptance, adaptation, safety, performance, autonomy, justice, design fulfillment, and business fulfillment. These themes inform how AAC end-users engage with AAC and how indirect stakeholders, such as AAC technologists, make choices that ultimately impact AAC users. Our stakeholder value framework and rich descriptions of AAC socio-technical barriers can inform AAC designers in making ethically sound decisions that support, not hinder, stakeholder values.",
    "title": "A Stakeholder Value Framework for Augmentative and Alternative Communication",
    "id": 188708,
    "sequence": 499,
    "queryCoordinates": {
      "visualization": [
        -16.633932607670353,
        -3.5088867185306745
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "Co-existing in more-than-human cities requires a shift from the anthropocentric methods of design. This paper details our experiences from a residency in a city park, where we conducted design explorations to share a bench with a Duck. As more-than-human design gains traction, HCI is developing new methods and positionalities. We use Wakkary’s design-with [65] to critically reflect on our process with the Duck. Through the concept of horizontality, we account for a repositioning of the human designer alongside other more-than-human beings, moving away from dominant human perspectives in design processes and becoming posthuman subjects. We contribute with an example of working with horizontality, providing additional nuances and insights. We offer three additional dimensions: spatial, agential, and temporal horizontality. Finally, we discuss ideas to further mobilize the concept and the potential of asking polite questions to non-humans.",
    "title": "May I Share a Park Bench with You? – Horizontalizing through Encounters with the Duck",
    "id": 188709,
    "sequence": 500,
    "queryCoordinates": {
      "visualization": [
        15.87967255357936,
        -1.9585708031874565
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "Biofeedback provides a unique opportunity to intensify tabletop gameplay. It permits new play styles through digital integration while keeping the tactile appeal of physical components. However, integrating biofeedback systems, like heart rate (HR), into game design needs to be better understood in the literature and still needs to be explored in practice. To bridge this gap, we employed a Research through Design (RtD) approach. This included (1) gathering insights from enthusiast board game designers (𝑛 = 10), (2) conducting two participatory design workshops (𝑛 = 20), (3) prototyping game mechanics with experts (𝑛 = 5), and (4) developing the game prototype artifact One Pulse: Treasure Hunter’s.We identify practical design implementation for incorporating biofeedback, particularly related to heart rate, into tabletop games. Thus, we contribute to the field by presenting design trade-offs for incorporating HR into board games, offering valuable insights for HCI researchers and game designers.",
    "title": "Designing Biofeedback Board Games: The Impact of Heart Rate on Player Experience",
    "id": 188710,
    "sequence": 501,
    "queryCoordinates": {
      "visualization": [
        -2.9743345841214315,
        -0.39157857666015394
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Ridgeline plots are frequently employed to visualize the evolution or distributions of multiple series with a pile of overlapping line, area, or bar charts, highlighting the peak patterns. While traditionally viewed as small multiple visualizations, their ridge-like patterns have increasingly attracted graphic designers to create appealing customized ridgeline plots. However, many tools only support creating basic ridgeline plots and overlook their diverse layouts and styles. This paper introduces a comprehensive design space for ridgeline plots, focusing on their varied layouts and expressive styles. We present RidgeBuilder, an intuitive tool for creating expressive ridgeline plots with customizable layouts and styles. In particular, we summarize three goals for refining the layout of ridgeline plots and propose an optimization method. We assess RidgeBuilder's usability and usefulness through a reproduction study and evaluate the layout optimization algorithm through anonymized questionnaires. The effectiveness is demonstrated with a gallery of ridgeline plots created by RidgeBuilder.",
    "title": "RidgeBuilder: Interactive Authoring of Expressive Ridgeline Plots",
    "id": 188711,
    "sequence": 502,
    "queryCoordinates": {
      "visualization": [
        12.852000358697943,
        -1.9560385425721907
      ]
    }
  },
  {
    "session": "Health and Well-being",
    "abstract": "This paper critically examines the machine learning (ML) modeling of humans in three case studies of well-being technologies. Through a critical technical approach, it examines how these apps were experienced in daily life (technology in use) to surface breakdowns and to identify the assumptions about the “human” body entrenched in the ML models (technology design). To address these issues, this paper applies agential realism to decenter foundational assumptions, such as body regularity and health/illness binaries, and speculates more inclusive design and ML modeling paths that acknowledge irregularity, human-system entanglements, and uncertain transitions. This work is among the first to explore the implications of decentering theories in computational modeling of human bodies and well-being, offering insights for more inclusive technologies and speculations toward posthuman-centered ML modeling.",
    "title": "The Centers and Margins of Modeling Humans in Well-being Technologies",
    "id": 188712,
    "sequence": 503,
    "queryCoordinates": {
      "visualization": [
        20.82034208885002,
        2.7410500366210835
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Expression facilitates the externalization of personal experiences and inner states (e.g., thoughts and emotions) embedded in everyday life. Yet, in mental health contexts, expression is often marginalized or systematically and structurally excluded from technology and system design. While HCI scholarship has explored expression in specific settings to advance user experience, a comprehensive understanding of expression remains limited. This limitation constrains the design space for future technologies that support and embrace expression, resulting in a potential lack of authentic experiential data reflecting individuals’ lived experiences embedded in everyday management of mental health. Through a systematic review of $n = 105$ studies, we explore the mediums, populations, and practices of expression in mental health contexts. Our study contributes a nuanced sociotechnical understanding of expression for the HCI community, developing two concepts for enriching expression and offering insights for designing experience-rich technologies that better support expression for everyday mental health management.",
    "title": "Expression-in-action and Expression-on-action: A Systematic Review of Mediums for Expression in Mental Health",
    "id": 188713,
    "sequence": 504,
    "queryCoordinates": {
      "visualization": [
        -12.438238903704216,
        -6.425746102545523
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "As minimally verbal autistic (MVA) children communicate with parents through few words and nonverbal cues, parents often struggle to encourage their children to express subtle emotions and needs and to grasp their nuanced signals. We present AACessTalk, a tablet-based, AI-mediated communication system that facilitates meaningful exchanges between an MVA child and a parent. AACessTalk provides real-time guides to the parent to engage the child in conversation and, in turn, recommends contextual vocabulary cards to the child. Through a two-week deployment study with 11 MVA child-parent dyads, we examine how AACessTalk fosters everyday conversation practice and mutual engagement. Our findings show high engagement from all dyads, leading to increased frequency of conversation and turn-taking. AACessTalk also encouraged parents to explore their own interaction strategies and empowered the children to have more agency in communication. We discuss the implications of designing technologies for balanced communication dynamics in parent-MVA child interaction.",
    "title": "AACessTalk: Fostering Communication between Minimally Verbal Autistic Children and Parents with Contextual Guidance and Card Recommendation",
    "id": 188714,
    "sequence": 505,
    "queryCoordinates": {
      "visualization": [
        3.8277613429288353,
        1.1611387090178493
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "Life cycle assessment (LCA) is a methodology for holistically measuring the environmental impact of a product from initial manufacturing to end-of-life disposal. However, the extent to which LCA informs the design of computing devices remains unclear. To understand how this information is collected and applied, we interviewed 17 industry professionals with experience in LCA or electronics design, systematically coded the interviews, and investigated common themes. These themes highlight the challenge of LCA data collection and reveal distributed decision-making processes where responsibility for sustainable design choices—and their associated costs—is often ambiguous. Our analysis identifies opportunities for HCI technologies to support LCA computation and its integration into the design process to facilitate sustainability-oriented decision-making. While this work provides a nuanced discussion about sustainable design in the information and communication technologies (ICT) hardware industry, we hope our insights will also be valuable to other sectors.\r\n",
    "title": "Incorporating Sustainability in Electronics Design: Obstacles and Opportunities ",
    "id": 188715,
    "sequence": 506,
    "queryCoordinates": {
      "visualization": [
        6.564007126858534,
        19.947777080129764
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": "A plethora of toolkits, checklists, and workshops have been developed to bridge the well-documented gap between AI ethics principles and practice. Yet little is known about effects of such interventions on practitioners. We conducted an ethnographic investigation in a major European city organization that developed and works to integrate an ethics toolkit into city operations. We find that the integration of ethics tools by technical teams destabilises their boundaries, roles, and mandates around responsibilities and decisions. This lead to emotional discomfort and feelings of vulnerability, which neither toolkit designers nor the organization had accounted for. We leverage the concept of moral stress to argue that this affective experience is a core challenge to the successful integration of ethics tools in technical practice. Even in this best case scenario, organisational structures were not able to deal with moral stress that resulted from attempts to implement responsible technology development practices.",
    "title": "\"Why do we do this?\": Moral Stress and the Affective Experience of Ethics in Practice",
    "id": 188716,
    "sequence": 507,
    "queryCoordinates": {
      "visualization": [
        17.25468771955583,
        -10.113147467559703
      ]
    }
  },
  {
    "session": "Data Interpretation and Storytelling",
    "abstract": "Critical thinking skills are increasingly important for comprehending our data-rich society. While museums provide data for discussion, visitors may not naturally question data in such displays due to the inherent authority of a museum. To investigate what factors can help visitors recognize bias in data, we interviewed visitors after they interacted with an augmented reality data map in an interactive data exhibition. Here, we present a qualitative analysis of fifteen semi-structured interviews with visitors who engaged with mapped data from the citizen science platform iNaturalist. The study revealed that 47% of participants were able to recognize bias, and familiarity was found to be a significant factor in this ability. We propose a three-layer framework to understand the cognitive processes of bias recognition in informal learning settings and apply this framework to our data to inform future work for designing displays to promote critical engagement with data in free-choice learning contexts.\r\n",
    "title": "Data Bias Recognition in Museum Settings: Framework Development and Contributing Factors",
    "id": 188717,
    "sequence": 508,
    "queryCoordinates": {
      "visualization": [
        14.74928368654939,
        -11.97742170643115
      ]
    }
  },
  {
    "session": "Robot and Agent",
    "abstract": "Industrial robots become increasingly prevalent, resulting in a growing need for intuitive, comforting human-robot collaboration. We present a user-aware robotic system that adapts to operator behavior in real time while non-intrusively monitoring physiological signals to create a more responsive and empathetic environment. Our prototype dynamically adjusts robot speed and movement patterns to proxemics while measuring operator pupil dilation. Our user study compares this adaptive system to a non-adaptive counterpart, and demonstrates that the adaptive system significantly reduces both perceived and physiologically measured cognitive load while enhancing usability. Participants reported increased feelings of comfort, safety, trust, and a stronger sense of collaboration when working with the adaptive robot. This highlights the potential of integrating real-time physiological data into human-robot interaction paradigms. This novel approach creates more intuitive and collaborative industrial environments where robots effectively ’read’ and respond to human cognitive states, and we feature all data and code for future use.",
    "title": "Real-Time Adaptive Industrial Robots: Improving Safety And Comfort In Human-Robot Collaboration",
    "id": 188718,
    "sequence": 509,
    "queryCoordinates": {
      "visualization": [
        -19.688531361797832,
        -3.5159255986870894
      ]
    }
  },
  {
    "session": "Make it Visible",
    "abstract": "Historical visualizations are a valuable resource for studying the history of visualization and inspecting the cultural context where they were created. When investigating historical visualizations, it is essential to consider contributions from different cultural frameworks to gain a comprehensive understanding. While there is extensive research on historical visualizations within the European cultural framework, this work shifts the focus to ancient China, a cultural context that remains underexplored by visualization researchers. To this aim, we propose a semi-automatic pipeline to collect, extract, and label historical Chinese visualizations. Through the pipeline, we curate ZuantuSet, a dataset with over 71K visualizations and 108K illustrations. We analyze distinctive design patterns of historical Chinese visualizations and their potential causes within the context of Chinese history and culture. We illustrate potential usage scenarios for this dataset, summarize the unique challenges and solutions associated with collecting historical Chinese visualizations, and outline future research directions.",
    "title": "ZuantuSet: A Collection of Historical Chinese Visualizations and Illustrations",
    "id": 188719,
    "sequence": 510,
    "queryCoordinates": {
      "visualization": [
        -2.739313676139587,
        -18.801493573216852
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "Play is pivotal in fostering the emotional, social, and cultural dimensions of urban spaces. While generative AI (GAI) potentially supports playful urban interaction, a balanced and critical approach to the design opportunities and challenges is needed. This work develops iWonder, an image-to-image GAI tool engaging fourteen designers in urban explorations to identify GAI's playful features and create design ideas. Fourteen citizens then evaluated these ideas, providing expectations and critical concerns from a bottom-up perspective. Our findings reveal the dynamic interplay between users, GAI, and urban contexts, highlighting GAI's potential to facilitate playful urban experiences through generative agency, meaningful unpredictability, social performativity, and the associated offensive qualities. We propose design considerations to address citizen concerns and the `tourist metaphor' to deepen our understanding of GAI's impacts, offering insights to enhance cities' socio-cultural fabric. Overall, this research contributes to the effort to harness GAI's capabilities for urban enrichment.",
    "title": "Generative AI as a Playful yet Offensive Tourist: Exploring Tensions Between Playful Features and Citizen Concerns in Designing Urban Play",
    "id": 188720,
    "sequence": 511,
    "queryCoordinates": {
      "visualization": [
        -18.624298695176066,
        7.289409997583002
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "Building technological literacy is an important topic in education today while at the same time, creativity is seen as a desirable skill for professional practice and education alike as it is considered a catalyst for innovation. In this paper, we present a case study where we aim to understand how students in a creative education appropriate technology. We analyze qualitative data collected from students in a STEAM higher education undergraduate program called Art&Technology: a program where students are introduced to an assortment of technological tools including software, programming, digital fabrication and physical prototyping which they employ in creating a variety of artifacts. We analyze how students learn and interact with these technologies by analyzing the collected data through a phenomenological lens of technology appropriation. We contribute with understandings on how technology is appropriated as it transforms from an object to a tool until it finally becomes equipment.",
    "title": "How Students in Creative Educations Appropriate Technology: A phenomenological analysis.",
    "id": 188721,
    "sequence": 512,
    "queryCoordinates": {
      "visualization": [
        -13.709819760008182,
        -13.154498931851766
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "Indirect speech acts (ISAs) are a natural pragmatic feature of human communication, allowing requests to be conveyed implicitly while maintaining subtlety and flexibility. Although advancements in speech recognition have enabled natural language interactions with robots through direct, explicit commands—providing clarity in communication—the rise of large language models presents the potential for robots to interpret ISAs. However, empirical evidence on the effects of ISAs on human-robot collaboration (HRC) remains limited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging a participant and a robot in collaborative physical tasks. Our findings indicate that robots capable of understanding ISAs significantly improve human's perceived robot anthropomorphism, team performance, and trust. However, the effectiveness of ISAs is task- and context-dependent, thus requiring careful use. These results highlight the importance of appropriately integrating direct and indirect requests in HRC to enhance collaborative experiences and task performance.",
    "title": "Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration",
    "id": 188722,
    "sequence": 513,
    "queryCoordinates": {
      "visualization": [
        4.9845866686656395,
        0.3922954786392247
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Ubiquitous computing devices like Augmented Reality (AR) glasses allow countless spontaneous interactions - all serving different goals. AR devices rely on data transfer to personalize recommendations and adapt to the user. Today's consent mechanisms, such as privacy policies, are suitable for long-lasting interactions; however, how users can consent to fast, spontaneous interactions is unclear. We first conducted two focus groups (N=17) to identify privacy-relevant scenarios in AR. We then conducted expert interviews (N=11) with co-design activities to establish effective consent mechanisms. Based on that, we contribute (1) a validated scenario taxonomy to define privacy-relevant AR interaction scenarios, (2) a flowchart to decide on the type of mechanisms considering contextual factors, (3) a design continuum and design aspects chart to create the mechanisms, and (4) a trade-off and prediction chart to evaluate the mechanism. Thus, we contribute a conceptual framework fostering a privacy-preserving future with AR.",
    "title": "Designing Effective Consent Mechanisms for Spontaneous Interactions in Augmented Reality",
    "id": 188723,
    "sequence": 514,
    "queryCoordinates": {
      "visualization": [
        -16.51954149971097,
        9.386412980437576
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "Justice, epistemology, and marginalization are rich areas of study in HCI. And yet, we repeatedly find platforms and algorithms that push communities further into the margins. In this paper, we propose epistemic autonomy--—one’s ability to govern knowledge about themselves---as a necessary HCI paradigm for working with marginalized communities. We establish epistemic autonomy by applying the transfeminine principle of autonomy to the problem of epistemic injustice. To articulate the harm of violating one’s epistemic autonomy, we present six stories from two trans women:  (1) a transfem online administrator and (2) a transfem researcher. We then synthesize our definition of epistemic autonomy in research into a research paradigm. Finally, we present two variants of common HCI methods, autoethnography and asynchronous remote communities, that stem from these beliefs. We discuss how CHI is uniquely situated to champion this paradigm and, thereby, the epistemic autonomy of our research participants.",
    "title": "Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge",
    "id": 188724,
    "sequence": 515,
    "queryCoordinates": {
      "visualization": [
        -0.3924187753808617,
        -5.98715353943162
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "Active transportation is a valuable tool to prevent some of the most common causes of mortality worldwide, but is severely underutilized. The primary factors preventing cyclist adoption are safety concerns, specifically, the fear of collision from automobiles. One solution to address this concern is to direct cyclists to known safe routes to minimize risk and stress, thus making cycling more approachable. However, few localized safety priors are available, hindering safety based routing. Specifically, road user behavior is unknown. To address this issue, we develop a novel handlebar attachment to passively monitor the proximity of passing cars as a an indicator of cycling safety along historically traveled routes. We deploy this sensor with 15 experienced cyclists in a 2 month longitudinal study to source a citywide map of car passing distance. We then compare this signal to both historic collisions and perceived safety reported by experienced and inexperienced cyclists.",
    "title": "ProxiCycle : Passively Mapping Cyclist Safety Using Smart Handlebars for Near-Miss Detection",
    "id": 188725,
    "sequence": 516,
    "queryCoordinates": {
      "visualization": [
        9.38191335922484,
        -3.461170570774934
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "Digital games offer rich social experiences and promote valuable skills, but they fall short in addressing physical inactivity. Exergames, which combine exercise with gameplay, have the potential to tackle this issue. However, current exergames are primarily single-player or competitive. To explore the social benefits of cooperative exergaming, we designed a custom co-located cooperative exergame that features three distinct forms of cooperation: Free (baseline), Coupled, and Concurrent. We conducted a within-participants, mixed-methods study (N=24) to evaluate these designs and their impact on players' enjoyment, motivation, and performance. Our findings reveal that cooperative play improves social experiences. It drives increased team identification and relatedness. Furthermore, our qualitative findings support cooperative exergame play. This has design implications for creating exergames that effectively address players' exercise and social needs. Our research contributes guidance for developers and researchers who want to create more socially enriching exergame experiences.",
    "title": "From Solo to Social: Exploring the Dynamics of Player Cooperation in a Co-located Cooperative Exergame",
    "id": 188726,
    "sequence": 517,
    "queryCoordinates": {
      "visualization": [
        -5.555702330196022,
        -8.314696123025453
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "Plausible findings about futures are inherently difficult to obtain as they require critical, well-informed speculations backed with data. HCI scholars tackle this challenge via user studies wherein futuristic prototypes and other props concretise possible futures for participants. By observing participants' actions, researchers then can 'time travel' to see that future as reality, in action. However, such studies may yield particularised findings, inherent to study’s intricacies, and lack broader plausibility. This paper suggests that triangulation of possible futures may help researchers disentangle particularities from more generalisable findings. We explored this approach by conducting a study on two alternative futures of AI-augmented knowledge work. Some findings emerged in both futures while others were particular to only one or the other. This approach enabled cross-checking of plausibility and simultaneously afforded deeper insight. The paper discusses how triangulating possible futures renders HCI studies more future-proof and provides means for reflective anticipation of possible futures.",
    "title": "Triangulating on Possible Futures: Conducting User Studies on Several Futures Instead of Only One",
    "id": 188727,
    "sequence": 518,
    "queryCoordinates": {
      "visualization": [
        9.280808951595294,
        -14.243124137772186
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "Over the past decades, numerous concepts and prototypes for fostering emotional connections across distance (relatedness technologies) have been proposed. This has made it challenging for researchers and designers in Human-Computer Interaction (HCI) to maintain a comprehensive overview and effectively build on previous work. To address this, we conducted a systematic literature search (PRISMA) and collected 241 concepts and prototypes (2010-2024). We organized this corpus according to key aspects: (1) target population, (2) theoretical grounding, (3) design, (4) evaluation, and (5) ethics. Based on this, we developed the “COmpendium of RElatedness Technologies” (CORE), an open-access, searchable online database that provides researchers and practitioners with a reliable repository to inform future work. In addition, we present a systematic review of the corpus, revealing that despite its long tradition work on relatedness technologies remains characterized by limited theoretical grounding, lack of robust empirical evidence of effects, and insufficient attention to ethical considerations.",
    "title": "Relatedness Technologies: An Online Compendium and Systematic Review",
    "id": 188728,
    "sequence": 519,
    "queryCoordinates": {
      "visualization": [
        20.55728526385062,
        -4.2892916175832765
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "Location privacy leaks can lead to unauthorised tracking, identity theft, and targeted attacks, compromising personal security and privacy. This study explores LLM-powered location privacy leaks associated with photo sharing on social media, focusing on user awareness, attitudes, and opinions. We developed and introduced an LLM-powered location privacy intervention app to 19 participants, who used it over a two-week period. The app prompted users to reflect on potential privacy leaks that a widely available LLM could easily detect, such as visual landmarks & cues that could reveal their location, and provided ways to conceal this information. Through in-depth interviews, we found that our intervention effectively increased users’ awareness of location privacy and the risks posed by LLMs. It also encouraged users to consider the importance of maintaining control over their privacy data and sparked discussions about the future of location privacy-preserving technologies. Based on these insights, we offer design implications to support the development of future user-centred, location privacy-preserving technologies for social media photos.",
    "title": "Raising Awareness of Location Information Vulnerabilities in Social Media Photos using LLMs",
    "id": 188729,
    "sequence": 520,
    "queryCoordinates": {
      "visualization": [
        -12.576703862931764,
        14.241717591081395
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "Inspiration plays an important role in design, yet its specific impact on data visualization design practice remains underexplored. This study investigates how professional visualization designers perceive and use inspiration in their practice. Through semi-structured interviews, we examine their sources of inspiration, the value they place on them, and how they navigate the balance between inspiration and imitation. Our findings reveal that designers draw from a diverse array of sources, including existing visualizations, real-world phenomena, and personal experiences. Participants describe a mix of active and passive inspiration practices, often iterating on sources to create original designs. This research offers insights into the role of inspiration in visualization practice, the need to expand visualization design theory, and the implications for the development of visualization tools that support inspiration and for training future visualization designers.",
    "title": "How Visualization Designers Perceive and Use Inspiration",
    "id": 188730,
    "sequence": 521,
    "queryCoordinates": {
      "visualization": [
        -14.417071934058377,
        13.861747250912718
      ]
    }
  },
  {
    "session": "XR for Diverse Needs",
    "abstract": "Augmented reality (AR) is poised to transform remote communication with realistic user representations authentically simulating in-person interactions in one's own environment. While increased avatar realism is beneficial in various social contexts, as it generally fosters social presence, its impact in intimate interactions is less clear, possibly creating discomfort. We explored how varying avatar realism affects social presence and comfort in AR across different social interactions. Realism preferences were established in an online survey (N=157), informing our subsequent experiment (N=42). Participants engaged in remote AR collaboration and self-disclosure tasks with avatars ranging from abstract to realistic point-cloud. Quantitative and qualitative feedback revealed that higher avatar realism generally enhances social presence and comfort, though preferences can vary. The self-disclosure task increased social presence but reduced comfort compared to the collaboration task. This research provides an empirical analysis of avatar realism, highlighting the benefits of realistic avatars in various scenarios.",
    "title": "Get Real With Me: Effects of Avatar Realism on Social Presence and Comfort in Augmented Reality Remote Collaboration and Self-Disclosure",
    "id": 188731,
    "sequence": 522,
    "queryCoordinates": {
      "visualization": [
        4.289291617583287,
        20.557285263850616
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "Weight perception is crucial for immersive virtual reality (VR) interactions, yet providing weight feedback remains a significant research challenge. We introduce a novel weight simulation technique that leverages electrotactile stimulation to induce slip illusions. These slip illusions occur when users grip an object with less force than a predefined threshold, allowing the device to modulate the grip force and encourage a tighter grip. In our approach, heavier virtual weights correspond to higher required grip forces. We conducted a series of user experiments to validate our technique, confirming that it effectively induces slip illusions. We also investigated the relationship between electrotactile sensations and grip force, and changes in force, demonstrating that this association enhances the weight perception experience. Lastly, we explored the mapping between grip force and perceived weight, observing strong linearity within participants but notable variability between individuals.",
    "title": "Slip-Grip: An Electrotactile Method to Simulate Weight",
    "id": 188732,
    "sequence": 523,
    "queryCoordinates": {
      "visualization": [
        7.990363649641379,
        0.3925413946193441
      ]
    }
  },
  {
    "session": "Visualization and Language Communication",
    "abstract": "Plea bargains are commonly used in the criminal justice system, where they can offer potential benefits to both the prosecution and the defendant. However, research has shown that defendants often engage in poor decision-making, such as accepting the plea even when the trial sentence is likely to be less severe. While previous studies have shown some evidence that uncertainty visualizations can improve decision-making, there is a lack of research on their effectiveness in domain-specific tasks like plea bargain decision-making. In this work, we conduct a series of experiments to explore whether the presence and format of uncertainty impact plea bargain decisions, taking into account time pressure and individual differences. Our findings reveal that these factors can have a significant impact on plea bargain decisions. We also show evidence that communicating uncertainty in the form of text can elicit more optimal decisions under time-pressure conditions.",
    "title": "The Anatomy of a Plea: How Uncertainty, Visualizations & Individual Differences Shape Plea Bargain Decisions",
    "id": 188733,
    "sequence": 524,
    "queryCoordinates": {
      "visualization": [
        14.748823613459319,
        2.7335328823822116
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": "Social activities in long-term care homes help promote residents’ wellbeing, but their effectiveness depends on residents’ engagement. To identify design opportunities for promoting meaningful engagement, we conducted an ethnographic study on organised activities in an Australian aged care home. We observed staff fostered engagement by initiating conversations, weaving residents’ backgrounds into interactions, and adapting activities to residents’ varying abilities. However, challenges included new staff members’ unfamiliarity with residents, multi-tasking, and insufficient support to engage excluded residents. Using a care ethics lens that includes relational, situated and empathetic features of care, we show that meaningful engagement is shaped by the ethical care practices embedded in staff-resident interactions and highlight opportunities for technologies to mitigate barriers hindering staff from providing ethical care in existing activities. These opportunities include: collecting and recording residents’ interests, providing conversation prompts, enhancing activity inclusiveness, and reducing language and cultural barriers.",
    "title": "Meaningful Engagement, Ethical Care, and Design Opportunities: An Ethnographic Study on Social Activities in Long-term Care",
    "id": 188734,
    "sequence": 525,
    "queryCoordinates": {
      "visualization": [
        -8.203107624274459,
        -8.758368872374025
      ]
    }
  },
  {
    "session": "Diversity",
    "abstract": "With efforts to investigate the role of interactivity on user psychology in video games, scholars have demonstrated that interactivity may induce cognitive, emotional, physical (controller and exertional), and social demands of global gamers. However, existing studies are missing Latin American gamers as critical yet understudied gaming communities. Drawing on the interactivity-as-demand model, we conducted a mixed-method online survey to test measurement validity on localized versions of the video game demand scale (VGDS) for Spanish-speaking gamers (N = 195). Results showed that the Spanish-translated scale replicated the a priori five-factor structure of VGDS. Emergent themes from gamers’ comments mirrored VGDS factors, with additional insights into the cognitive demand of creative thinking, emotional demand of feeling nostalgia, physical demand of being precise, and social demand of interacting with non-player characters. These findings provide a pancultural perspective of Spanish-speaking gamers’ perceptions of their gaming while offering nuanced insights into their experiences for future research.",
    "title": "Translation and Validation of The Video Game Demand Scale to Spanish",
    "id": 188735,
    "sequence": 526,
    "queryCoordinates": {
      "visualization": [
        -4.209517756015994,
        -10.162674857624152
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "Effective information support tools are challenging to design for fast-paced, information rich, and difficult to predict circumstances, particularly when information is fragmented and sources are dispersed. To explore, we conducted a field study on handover and the associated information work, which included 40 visits and 75 hours of observation and interviews with doctors in a metropolitan emergency department (ED). Beyond information exchange, we found that handovers highlight doctors' proactive approach by anticipating information needs, managing uncertainties arising from dynamic information, and developing patient care plans through multiple contingencies. Expanding on the idea of handover as a multifaceted process rather than a single event, we reinforce existing calls for greater flexibility emphasising that the ascertainment of pertinent information is an ongoing, adaptive process. This work demonstrates that deciding what constitutes relevant information is a priori indeterminate when designing information systems and support tools in environments such as EDs. We propose the preservation of specific ‘relativities’ of information—such as uncertainty, particularity, incompleteness, and temporality—in designing information support tools for dynamic, critical and multi-disciplinary work environments.",
    "title": "Patient Handover in the Emergency Department Is Not Just a Point Event: Insights for Designing Information Support Tools",
    "id": 188736,
    "sequence": 527,
    "queryCoordinates": {
      "visualization": [
        -18.672230487899828,
        3.5139448781596077
      ]
    }
  },
  {
    "session": "Online Media, Robots, Agents",
    "abstract": "Control and curation of dominant visual culture – rendering who and what is visible – is central to identity formation, particularly for LGBTQ+ communities relying on digital spaces for safe self-expression. In this work, we analyze Instagram as a site of algorithmic visual curation, performing a quantitative analysis of algorithmically mediated image feeds delivered to a gay-coded user. Our persona account exclusively followed \\#gay and \\#instagay feeds, and engaged in content within these discursive spaces to seed algorithmic content promotion to a normative gay user. We present an analysis of skin tone presentations, emoji usage, and engagement metrics alongside analysis of generative outputs of dominant visual trends within the \\#gay search and Explore feeds. We observe content depicting darker-skinned individuals has higher engagement yet less algorithmic promotion relative to lighter skin tones, while hypermasculine and homonormative content is heavily promoted. These results suggest that, while marginalized positionalities have certainly been rendered more visible through social media platforms, this visibility is increasingly contingent on assimilation to normative ideals through algorithmically determined modes that are not necessarily consistent with user choices, preferences, or realities.",
    "title": "Mediating The Marginal: A Quantitative Analysis of Curated LGBTQ+ Content on Instagram",
    "id": 188737,
    "sequence": 528,
    "queryCoordinates": {
      "visualization": [
        11.868224671801231,
        -13.533116534621598
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "AI models are constantly evolving, with new versions released frequently. Human-AI interaction guidelines encourage notifying users about changes in model capabilities, ideally supported by thorough benchmarking. However, as AI systems integrate into domain-specific workflows, exhaustive benchmarking can become impractical, often resulting in silent or minimally communicated updates. This raises critical questions: Can users notice these updates? What cues do they rely on to distinguish between models? How do such changes affect their behavior and task performance? We address these questions through two studies in the context of facial recognition for historical photo identification: an online experiment examining users’ ability to detect model updates, followed by a diary study exploring perceptions in a real-world deployment. Our findings highlight challenges in noticing AI model updates, their impact on downstream user behavior and performance, and how they lead users to develop divergent folk theories. Drawing on these insights, we discuss strategies for effectively communicating model updates in AI-infused systems.",
    "title": "What Lies Beneath? Exploring the Impact of Underlying AI Model Updates in AI-Infused Systems",
    "id": 188738,
    "sequence": 529,
    "queryCoordinates": {
      "visualization": [
        9.928702829192504,
        13.79930650900924
      ]
    }
  },
  {
    "session": "Online Media, Robots, Agents",
    "abstract": "Mainstream media, through their decisions on what to cover and how to frame the stories they cover, can mislead readers without using outright falsehoods. Therefore, it is crucial to have tools that expose these editorial choices underlying media bias. In this paper, we introduce the \\mbd, a tool for researchers, journalists, and news consumers. By integrating large language models, we provide near real-time granular insights into the topics, tone, political lean, and facts of news articles aggregated to the publisher level. We assessed the tool’s impact by interviewing 13 experts from journalism, communications, and political science, revealing key insights into usability and functionality, practical applications, and AI's role in powering media bias tools. We explored this in more depth with a follow-up survey of 150 news consumers. This work highlights opportunities for AI-driven tools that empower users to critically engage with media content, particularly in politically charged environments. ",
    "title": "Media Bias Detector: Designing and Implementing a Tool for Real-Time Selection and Framing Bias Analysis in News Coverage",
    "id": 188739,
    "sequence": 530,
    "queryCoordinates": {
      "visualization": [
        0.3926738492125695,
        19.996144809641297
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q&A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance.",
    "title": "AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning",
    "id": 188740,
    "sequence": 531,
    "queryCoordinates": {
      "visualization": [
        14.139622366382676,
        5.007102888506563
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "This paper introduces PalateTouch, a hands-free earphone interaction system that leverages acoustic sensing technology to detect gestures resulting from the interaction between the tongue and the palate. By transmitting Zadoff-Chu signals and analyzing ear canal transfer function features, PalateTouch can capture subtle ear canal deformation and recognize various palate gestures used for interaction. Our proposed palate touch screening method ensures the system remains unaffected by unintended gestures from daily activities and the calibration mechanism enables our system to achieve user-independent recognition. Using only the earphone's built-in microphone and speaker, our system can distinguish nine gestures with an average F1 score of 0.92 and a false alarm rate of 0.02 across diverse conditions with 16 participants. Additionally, we have enabled real-time functionality and conducted a user study with 11 participants to evaluate PalateTouch's effectiveness in a demo application. The results demonstrate the superior performance and high usability of PalateTouch.",
    "title": "PalateTouch : Enabling Palate as a Touchpad to Interact with Earphones Using Acoustic Sensing",
    "id": 188741,
    "sequence": 532,
    "queryCoordinates": {
      "visualization": [
        5.681580776970631,
        -1.9286367918189762
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "The advancement of Virtual Reality (VR) has expanded 2D user interfaces into 3D space. This change has introduced richer interaction modalities but also brought challenges, especially the lack of haptic feedback in mid-air interactions. Previous research has explored various methods to provide feedback for interface interactions, but most approaches require specialized haptic devices. We introduce haptic retargeting to enable users to control multiple virtual screens in VR using a simple flat pad, which serves as a single physical proxy to support seamless interaction across multiple virtual screens. We conducted user studies to explore the appropriate virtual screen size and positioning under our retargeting method and then compared various drag-and-drop methods for cross-screen interaction. Finally, we compared our method with controller-based interaction in application scenarios.\r\n",
    "title": "ReachPad: Interacting with Multiple Virtual Screens using a Single Physical Pad through Haptic Retargeting",
    "id": 188742,
    "sequence": 533,
    "queryCoordinates": {
      "visualization": [
        -6.988987705124716,
        0.39249313066034336
      ]
    }
  },
  {
    "session": "WS05: New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "abstract": "Explainable AI (XAI) is more than just “opening” the black box — who opens it matters just as much, if not more, as the ways of opening it. Human-centered XAI (HCXAI) advocates that algorithmic transparency alone is not sufficient for making AI explainable. In our fifth CHI workshop on Human-Centered XAI (HCXAI), we shift our focus to new, emerging frontiers of explainability: (1) participatory approaches toward explainability in civic AI applications; (2) addressing hallucinations in LLMs using explainability benchmarks; (3) connecting HCXAI research with Responsible AI practices, algorithmic auditing, and public policy; and (4) improving representation of XAI issues from the Global South. We have built a strong community of HCXAI researchers through our workshop series whose work has made important conceptual, methodological, and technical impact on the field. In this installment, we will push the frontiers of work in HCXAI with an emphasis on operationalizing perspectives sociotechnically.",
    "title": "New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "id": 188743,
    "sequence": 534,
    "queryCoordinates": {
      "visualization": [
        1.1611387090178518,
        -3.827761342928835
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "Understanding eye dominance, the subconscious preference for one eye, has significant implications for 3D user interfaces in VR and AR, particularly in interface design and rendering. \r\nAlthough HCI recognizes eye dominance, little is known about what causes it to switch from one eye to another. \r\nTo explore this, we studied eye dominance in VR, where 28 participants manually aligned a cursor with a distant target across three tasks.\r\nWe manipulated the horizontal viewing angle, the hand used for alignment, and eye movement induced by target behaviour. \r\nOur results confirm the dynamic nature of eye dominance, though with fewer switches than expected and varying influences across tasks. \r\nThis highlights the need for adaptive HCI techniques, which account for shifts in eye dominance in system design, such as gaze-based interaction, visual design, or rendering, and can improve accuracy, usability, and experience.",
    "title": "It’s Not Always the Same Eye That Dominates: Effects of Viewing Angle, Handedness and Eye Movement in 3D",
    "id": 188744,
    "sequence": 535,
    "queryCoordinates": {
      "visualization": [
        3.5116257962902937,
        -17.65413504725815
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "In-game team communication in online multiplayer games has shown the potential to foster efficient collaboration and positive social interactions. Yet players often associate communication within ad hoc teams with frustration and wariness. Though previous works have quantitatively analyzed communication patterns at scale, few have identified the motivations of how a player makes in-the-moment communication decisions. In this paper, we conducted an observation study with 22 League of Legends players by interviewing them during Solo Ranked games on their use of four in-game communication media (chat, pings, emotes, votes). We performed thematic analysis to understand players' in-context assessment and perception of communication attempts. We demonstrate that players evaluate communication opportunities on proximate game states bound by player expectations and norms. Our findings illustrate players' tendency to view communication, regardless of its content, as a precursor to team breakdowns. We build upon these findings to motivate effective player-oriented communication design in online games.",
    "title": "Less Talk, More Trust: Understanding Players' In-game Assessment of Communication Processes in League of Legends",
    "id": 188745,
    "sequence": 536,
    "queryCoordinates": {
      "visualization": [
        8.565056918547306,
        6.902159081189372
      ]
    }
  },
  {
    "session": "WS12: Scaling Distributed Collaboration in Mixed Reality",
    "abstract": "Distributed collaboration in Mixed Reality (MR) promises to revolutionise how people connect across different physical environments, offering experiences akin to face-to-face interactions. However, previous work has mostly focused on enabling this vision in overly simplified settings such as with only two users interacting in identical distributed environments. Scaling current systems to work with large groups and for common real-life scenarios is a persistent challenge that requires addressing multiple tensions. We identified six challenges: 1) supporting locally congruent actions from heterogeneous remote spaces, 2) communicating accurate user behaviours through virtual representation instead of physical bodies, 3) facilitating organic group interactions within limited physical space, 4) maintaining conversational dynamics even in asynchronous exchanges, 5) providing equal access to physical objects for all participants, and 6) enabling efficient task switching within a complex ecology of applications, devices, and accessibility needs. This workshop aims to gather researchers and practitioners to explore actionable strategies for resolving these challenges. Through a mix of presentations, hands-on activities, and group discussions, participants will generate new ideas and develop a research agenda to articulate the future of MR collaboration systems. The workshop outcomes will include a list of concrete next steps for the community to bring distributed MR collaboration at scale.",
    "title": "Scaling Distributed Collaboration in Mixed Reality",
    "id": 188746,
    "sequence": 537,
    "queryCoordinates": {
      "visualization": [
        -12.152097219775916,
        -17.12677824814447
      ]
    }
  },
  {
    "session": "Earable and Hearable",
    "abstract": " We introduce FlexEar-Tips, a dynamic ear tip system designed for the next-generation hearables. The ear tips are controlled by an air pump and solenoid valves, enabling size adjustments for comfort and functionality. FlexEar-Tips includes an air pressure sensor to monitor ear tip size, allowing it to adapt to environmental conditions and user needs. In the evaluation, we conducted a preliminary investigation of the size control accuracy and the minimum amount of variability of haptic perception in the user's ear. We then evaluated the user's ability to identify patterns in the haptic notification system, the impact on the music listening experience, the relationship between the size of the ear tips and the sound localization ability, and the impact on the reduction of humidity in the ear using a model. We proposed new interaction modalities for adaptive hearables and discussed health monitoring, immersive auditory experiences, haptics notifications, biofeedback, and sensing.",
    "title": "FlexEar-Tips: Shape-Adjustable Ear Tips Using Pressure Control",
    "id": 188747,
    "sequence": 538,
    "queryCoordinates": {
      "visualization": [
        -11.97742170643115,
        -14.74928368654939
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "Small businesses need vulnerability assessments to identify and mitigate cyber risks. Cybersecurity clinics provide a solution by offering students hands-on experience while delivering free vulnerability assessments to local organizations. To scale this model, we propose an Open Source Intelligence (OSINT) clinic where students conduct assessments using only publicly available data. We enhance the quality of investigations in the OSINT clinic by addressing the technical and collaborative challenges. Over the duration of the 2023-24 academic year, we conducted a three-phase co-design study with six students. Our study identified key challenges in the OSINT investigations and explored how generative AI could address these performance gaps. We developed design ideas for effective AI integration based on the use of AI probes and collaboration platform features. A pilot with three small businesses highlighted both the practical benefits of AI in streamlining investigations, and limitations, including privacy concerns and difficulty in monitoring progress.",
    "title": "OSINT Clinic: Co-designing AI-Augmented Collaborative OSINT Investigations for Vulnerability Assessment",
    "id": 188748,
    "sequence": 539,
    "queryCoordinates": {
      "visualization": [
        -4.98881767381527,
        3.333421398117615
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "Social virtual reality (SVR) aims to recreate embodied social experiences similar to those offline. However, concerns about privacy and safety have hindered its widespread adoption. This study examines how information disclosure and perceived control over information in SVR are influenced by 1) boundary permeability (e.g., interruptions from an unknown external user) and 2) identifiability of one’s conversation partner (e.g., access to their offline profile). We also explore how different social presence perceptions and privacy concerns may mediate these relationships. Comparing the experiences of participants (n = 94) randomly assigned to four different mock interview scenarios, we find the perceived actorhood of one’s conversation partner mediated the positive relationship between offline profile access and disclosure. Additionally, more permeable environmental boundaries led to significantly lower levels of disclosure. Qualitative responses emphasized SVR’s limitations in saliently conveying nonverbal expressions. Implications for future research and the design of SVR as a viable communication medium are discussed.",
    "title": "Self-Disclosure in Social Virtual Reality: The Influence of Information Management Dynamics, Social Presence, and Privacy Concerns",
    "id": 188749,
    "sequence": 540,
    "queryCoordinates": {
      "visualization": [
        -16.778236307100176,
        2.7369301092840246
      ]
    }
  },
  {
    "session": "XR Interaction",
    "abstract": "This research investigates the use of hybrid user interfaces to enhance text readability in augmented reality (AR) by combining optical see-through head-mounted displays with smartphones. While this integration can improve information legibility, it may also introduce display switching side effects. The extent to which these side effects hinder user experience and when the benefits outweigh drawbacks remain unclear. To address this gap, we conducted an empirical study (N=24) to evaluate how hybrid user interfaces affect AR reading tasks across different content distances, which induce varying levels of display switching. Our findings show that hybrid user interfaces offer significant readability benefits compared to using the HMD only, reducing mental and physical demands when reading text linked to content at closer distances. However, as the distance between displays increases, the compensatory behaviors users adopt to manage increased switching costs negate these benefits, making hybrid user interfaces less effective. Based on these findings, we suggest (1) using smartphones as supplementary displays for text in reading-intensive tasks, (2) implementing adaptive display positioning to minimize switching overhead in such scenarios, and (3) adjusting the smartphone's role based on content distance for less intensive reading tasks. These insights provide guidance for optimizing smartphone integration in hybrid interfaces and enhancing AR systems for reading applications.",
    "title": "AReading with Smartphones: Understanding the Trade-offs between Enhanced Legibility and Display Switching Costs in Hybrid AR Interfaces",
    "id": 188750,
    "sequence": 541,
    "queryCoordinates": {
      "visualization": [
        -13.002551317075602,
        -12.447235004080847
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "Built environments increasingly incorporate new forms of intelligence, creating opportunities for enhancing human interactive experiences with and within building spaces. This scoping review examines design interventions and discourses within the domain of \"Smart Buildings\". The goal is to identify and characterise the type of human experiences that research in this domain aims to address. Using a hybrid deductive-inductive coding approach, we analysed 192 papers related to human experiences and smart buildings from ACM Digital Library and Scopus published between 1996 and 2024. Our analysis revealed 11 distinct \"targeted human experiences\", 20 commonly used \"design mechanisms\" to achieve those design goals, as well as two typologies of \"technological interventions\". Our findings create a foundation for understanding building design research and the range of human experience they entail.",
    "title": "What Do We Design for When We Design \"Smart Buildings\"? - A Scoping Review of Human Experience Design Research in Buildings",
    "id": 188751,
    "sequence": 542,
    "queryCoordinates": {
      "visualization": [
        -3.3860322097366766,
        -6.126563953361277
      ]
    }
  },
  {
    "session": "Well-being and Well-dying",
    "abstract": "Ideations of artificial wombs, robotic nannies, cots with facial recognition and self-driving prams are part of a long history of motivations to use technologies to support, alter or even replace humans in situations of gestation, reproduction and care. Reflecting society’s entangled fantasies about care and often reinforcing cultural tropes about gendered roles, the imagined possibilities about technologies in such sensitive and emotionally charged topics are worth examining. In this paper I present ways in which I have critically explored imaginaries and ideations in spaces related to maternal and infant care, accompanied by a practice of drawing that was fluid, creative, speculative, suggestive and communicative, and enabled an engagement with the complexity of machines and quantifying approaches that exist in a realm abundant with non-numerical and ancestral forms of bodily knowledge. Drawing was also useful in activities with participants, where we collectively discussed and imagined scenarios with technologies for care.",
    "title": "Drawing Maternal Machines and other Fantasies of Care",
    "id": 188752,
    "sequence": 543,
    "queryCoordinates": {
      "visualization": [
        9.032407769589227,
        10.696523261502504
      ]
    }
  },
  {
    "session": "Pointing and Selection",
    "abstract": "Window selection is a fundamental method in desktop environments for interacting with multiple targets, typically performed by successive operations like click-drag-release (i.e., a single sequence of dragging). Although this method is common in GUI interactions, there has been limited research to understand user behavior during window selection. This study explores user behavior and performance during window selection using dragging. We empirically studied the impact of several GUI parameters — including the size, interval, number, and layout of targets — on window selection for multiple targets. Based on well-established existing motor models, we analyzed user behavior in terms of time performance and derived a more suitable model. Additionally, our new prediction model effectively predicted time performance in partially constrained scenarios. This study provides new insights into user behavior during window selection for multiple targets. We hope that our research findings will assist GUI designers, practitioners, and researchers in testing their designs.",
    "title": "Understanding User Behavior in Window Selection using Dragging for Multiple Targets",
    "id": 188753,
    "sequence": 544,
    "queryCoordinates": {
      "visualization": [
        11.483284028786507,
        3.483416127053548
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "Recent advances in large language models (LLMs) are transforming online applications, including search tools that accommodate complex natural language queries and provide direct responses. There are, however, concerns about the veracity of LLM-generated content due to potential for LLMs to \"hallucinate\". In two online experiments, we examined how LLM-based search affects behavior compared to traditional search and explored ways to reduce overreliance on incorrect LLM-based output. Participants assigned to LLM-based search completed tasks more quickly, with fewer but more complex queries, and reported a more satisfying experience. While decision accuracy was comparable when the LLM was correct, users overrelied on incorrect information when the model erred. In a second experiment, a color-coded highlighting system helped users detect errors, improving decision accuracy without affecting other outcomes. These findings suggest that LLM-based search tools have promise as decision aids but also highlight the importance of effectively communicating uncertainty to mitigate overreliance.",
    "title": "Effects of LLM-based Search on Decision Making: Speed, Accuracy, and Overreliance",
    "id": 188754,
    "sequence": 545,
    "queryCoordinates": {
      "visualization": [
        13.002551317075591,
        -12.447235004080857
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "Virtual reality technologies that enhance realism and artificial intelligence (AI) systems that assist human behavior are increasingly interwoven in social applications. However, how these technologies might jointly influence interpersonal coordination remains unclear. We conducted an experiment with 240 participants in 120 pairs who interacted through remote-controlled robot cars in a physical space or virtual cars in a digital space, with or without autosteering assistance, using the chicken game, an established model of interpersonal coordination. We find that both realism and AI assistance help improve user performance but through opposing mechanisms. Real-world contexts enhanced communication, fostering reciprocal actions and collective benefits. In contrast, autosteering assistance diminished the need for interpersonal coordination, shifting participants’ focus towards self-interest. Notably, when combined, the egocentric effects of autosteering assistance outweighed the prosocial effects of realism. The design of HCI systems that involve social coordination will, we believe, need to take such effects into account.",
    "title": "Realism Drives Interpersonal Reciprocity but Yields to AI-Assisted Egocentrism in a Coordination Experiment",
    "id": 188755,
    "sequence": 546,
    "queryCoordinates": {
      "visualization": [
        1.9596037473353654,
        17.893014088001753
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "Virtual Reality (VR) designers and researchers often need to measure emotions and presence as they evolve over time. The experience sampling method (ESM) is a common way to achieve this, however, ESM disrupts the experience and lacks granularity. We propose RetroSketch, a new method for measuring subjective emotions and presence in VR, where users watch back their VR experience and retrospectively sketch a plot of their feelings. RetroSketch leaves the VR experience undisturbed and yields highly granular data, including information about salient events and qualitative descriptions of their feelings. We compared RetroSketch and ESM in a large study (n=140) using five different VR experiences over one-hour sessions. Our results show that RetroSketch and ESM measures are highly correlated with each other, as well as physiological measures indicative of emotion. The correlations are robust across different VR experiences and user demographics. They also highlight the impact of ESM on users' experience.",
    "title": "RetroSketch: A Retrospective Method for Measuring Emotions and Presence in Virtual Reality",
    "id": 188756,
    "sequence": 547,
    "queryCoordinates": {
      "visualization": [
        3.4968706943411703,
        -13.556249309711662
      ]
    }
  },
  {
    "session": "WS08: How do design stories work? Exploring narrative forms of knowledge in HCI",
    "abstract": "Design is storied, and stories are designed. While elements of stories have long been part of the field through methods like personas, scenarios and design fictions, there has been a recent surge of new approaches including fabulations, epics, memoirs, site-writing and design events. In this workshop we aim to understand how stories are built, what narrative traditions they draw from, how they co-constitute research processes and what kind of knowledge can emerge from them. Specifically, we will explore the role of storytelling in HCI, the craft of writing stories, relations between fiction, truth and knowledge and finally the risks, tensions and limitations of writing stories. We will outline an overview of this new wave of stories in HCI and what they are activating and advocating for, build a set of tips, tricks and advice for writing stories and keep track of ongoing issues and open questions for further research.",
    "title": "How do design stories work? Exploring narrative forms of knowledge in HCI",
    "id": 188757,
    "sequence": 548,
    "queryCoordinates": {
      "visualization": [
        -10.470864723162299,
        7.704608487732218
      ]
    }
  },
  {
    "session": "WS39: HCI Across Borders: Building a Collective Vision for the Future",
    "abstract": "The HCI Across Borders (HCIxB) workshop at CHI 2025 will focus on \"Building a Collective Vision for the Future.\" HCIxB has gathered a diverse audience annually by conducting workshops and symposia since CHI 2016. This year, we hope to regroup as a community to reflect on the growth of HCIxB over the past ten years, engage in mentoring sessions for present early career researchers, and collectively form a vision for the future. This full-day hybrid workshop aims to gather researchers and practitioners to explore how we can collectively shape the future of HCI across diverse cultures and geographies. We will have a panel discussion featuring invited speakers sharing insights from a recent HCIxB Book Chapter summarizing our future. Attendees will showcase their research through posters, highlighting HCIxB's trends worldwide, particularly in the Global South. Lastly, we will collaborate to create a vision for our community's future and provide initial resources to future HCIxB organizers.",
    "title": "HCI Across Borders: Building a Collective Vision for the Future",
    "id": 188758,
    "sequence": 549,
    "queryCoordinates": {
      "visualization": [
        15.68799504993456,
        10.71852654580977
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "With the transition to fully autonomous vehicles, non-driving related tasks (NDRTs) become increasingly important, allowing passengers to use their driving time more efficiently. In-car Augmented Reality (AR) gives the possibility to engage in NDRTs while also allowing passengers to engage with their surroundings, for example, by displaying world-fixed points of interest (POIs). This can lead to new discoveries, provide information about the environment, and improve locational awareness. To explore the optimal visualization of POIs using in-car AR, we conducted a field study (N = 38) examining six parameters: positioning, scaling, rotation, render distance, information density, and appearance. We also asked for intention of use, preferred seat positions and preferred automation level for the AR function in a post-study questionnaire. Our findings reveal user preferences and general acceptance of the AR functionality. Based on these results, we derived UX-guidelines for the visual appearance and behavior of location-based POIs in in-car AR.",
    "title": "Blending the Worlds: An evaluation of World-Fixed Visual Appearances in Automotive Augmented Reality",
    "id": 188759,
    "sequence": 550,
    "queryCoordinates": {
      "visualization": [
        -20.996328379167675,
        0.392676195048947
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "User engagement (UE) is widely discussed in HCI articles, but its definition, reliability, and application remain elusive. This research conducts a systematic literature review of 241 articles from 1993 to 2023 to analyze how UE is defined and measured within the domain of HCI. Our findings reveal significant definitional inconsistencies that hinder UE’s practical application in HCI research and system design. Based on our findings, we recommend using UE as a categorical label rather than a unified construct until more systematic frameworks are established. We also highlight the need for divergent views of UE across HCI research communities as a valuable avenue to pursue. This divergent view approach can help HCI researchers focus on specific, measurable aspects of UE that align with specific community practices and norms. Our findings also suggest that until such a framework emerges, researchers should be aware of its limitations when using UE as a research construct. ",
    "title": "What is User Engagement?:  A Systematic Review of 241 Research Articles in Human-Computer Interaction and Beyond",
    "id": 188760,
    "sequence": 551,
    "queryCoordinates": {
      "visualization": [
        16.633932607670356,
        -3.5088867185306656
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Reliable augmented reality (AR) cues can support the resumption of interrupted tasks. We investigated how sub-optimal AR cue reliability (100%, 86%, 64%, or no cue) affected users’ resumption performance and strategies. In a between-subjects experiment, 120\r\nparticipants conducted a physical sorting task including interruptions, and we manipulated AR cue reliability (i.e., the AR cue was present or absent at the end of interruptions). In trials with AR cue, performance with 86% and 64% reliable AR cues was as well as with\r\n100% reliable cues. In trials without AR cue, performance with suboptimal AR cue reliability declined but was still better than with no cue. Cue reliability affected task resumption strategies of the 86% (slow but no increase in errors) and the 64% (fast but increase in errors) reliability groups differently. Our results extend reliability research to interruptions and the observed efficiency-thoroughness trade-offs in resumption strategies provide insight for design",
    "title": "AR Cue Reliability for Interrupted Task Resumption Affects Users' Resumption Strategies and Performance",
    "id": 188761,
    "sequence": 552,
    "queryCoordinates": {
      "visualization": [
        9.992290362407228,
        0.3925981575906861
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "Although the point-and-select interaction method has been shown to lead to user and system-initiated errors, it is still prevalent in VR scenarios. Current solutions to facilitate selection interactions exist, however they do not address the challenges caused by targeting inaccuracy. To reduce the effort required to target objects, we developed a model that quickly detected targeting errors after they occurred. The model used implicit multimodal user behavioral data to identify possible targeting outcomes. Using a dataset composed of 23 participants engaged in VR targeting tasks, we then trained a deep learning model to differentiate between correct and incorrect targeting events within 0.5 seconds of a selection, resulting in an AUC-ROC of 0.9. The utility of this model was then evaluated in a user study with 25 participants that identified that participants recovered from more errors and faster when assisted by the model. These results advance our understanding of targeting errors in VR and facilitate the design of future intelligent error-aware systems.",
    "title": "A Multimodal Approach for Targeting Error Detection in Virtual Reality Using Implicit User Behavior",
    "id": 188762,
    "sequence": 553,
    "queryCoordinates": {
      "visualization": [
        8.923003752364293,
        1.1747357299804642
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "AI systems and tools today can generate human-like expressions on behalf of people. It raises the crucial question about how to sustain human agency in AI-mediated communication. We investigated this question in the context of machine translation (MT) assisted conversations. Our participants included 45 dyads. Each dyad consisted of one new immigrant in the United States, who leveraged MT for English information seeking as a non-native speaker, and one local native speaker, who acted as the information provider. Non-native speakers could influence the English production of their message in one of three ways: labeling the quality of MT outputs, regular post-editing without additional hints, or augmented post-editing with LLM-generated hints. Our data revealed a greater exercise of non-native speakers’ agency under the two post-editing conditions. This benefit, however, came at a significant cost to the dyadic-level communication performance. We derived insights for MT and other generative AI design from our findings. ",
    "title": "Sustaining Human Agency, Attending to Its Cost: An Investigation into Generative AI Design for Non-Native Speakers' Language Use",
    "id": 188763,
    "sequence": 554,
    "queryCoordinates": {
      "visualization": [
        9.754160215099382,
        6.989732362413626
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "Many communities, including the scientific community, develop implicit writing norms. Understanding them is crucial for effective communication with that community. Writers gradually develop an implicit understanding of norms by reading papers and receiving feedback on their writing. However, it is difficult to both externalize this knowledge and apply it to one's own writing. We propose two new writing support concepts that reify document and sentence-level patterns in a given text corpus: (1) an ordered distribution over section titles and (2) given the user's draft and cursor location, many retrieved contextually relevant sentences. Recurring words in the latter are algorithmically highlighted to help users see any emergent norms. Study results (N=16) show that participants revised the structure and content using these concepts, gaining confidence in aligning with or breaking norms after reviewing many examples. These results demonstrate the value of reifying distributions over other authors’ writing choices during the writing process.",
    "title": "CorpusStudio: Surfacing Emergent Patterns In A Corpus Of Prior Work While Writing",
    "id": 188764,
    "sequence": 555,
    "queryCoordinates": {
      "visualization": [
        0.39266415810102573,
        -16.99546453789783
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "We introduce Being The Creek, a mobile augmented reality (MAR) experience that invites participants to take a “first-person” perspective of a historically-significant-creek by lying alongside her and getting attuned to her environment through embodied multisensory engagement. Individuals experience how the world might appear from the Creek’s perspective, from the pre-colonial respect she received from Indigenous peoples, through the industrial period when the Creek was used as a sewer, to a speculative future of collaborative survival despite capitalism. Fifteen participants of our study each experienced a range of emotions while “being” the Creek through temporal and spatial explorations. As participants moved between human-centered and creek-centered perspectives, they explored the Creek’s unique subjectivity and the human-nonhuman power relations, leading them to de-emphasize the stereotypical human-centric stance. We discuss designing mobile experiences that encourage movement beyond human-centric perspectives and encourage “noticing” for more-than-human worlds.",
    "title": "Being The Creek: Mobile Augmented Reality Experience as an Invitation for Exploring More-Than-Human Perspectives",
    "id": 188765,
    "sequence": 556,
    "queryCoordinates": {
      "visualization": [
        7.249440417457253,
        -16.475606624150057
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "This paper characterizes the mental health technology “kits” of individuals managing depression: the specific technologies on their digital devices and physical items in their environments that people turn to as part of their mental health management. We interviewed 28 individuals living across the United States who use bundles of connected tools for both individual and collaborative mental health activities. We contribute to the HCI community by conceptualizing these tool assemblages that people managing depression have constructed over time. We detail categories of tools, describe kit characteristics (intentional, adaptable, available), and present participant ideas for future mental health support technologies. We then discuss what a mental health technology kit perspective means for researchers and designers and describe design principles (building within current toolkits; creating new tools from current self-management strategies; and identifying gaps in people’s current kits) to support depression self-management across an evolving set of tools.",
    "title": "What’s In Your Kit? Mental Health Technology Kits for Depression Self-Management",
    "id": 188766,
    "sequence": 557,
    "queryCoordinates": {
      "visualization": [
        -13.0794851641244,
        4.99270145727238
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "The use of creative writing as training data for large language models (LLMs) is highly contentious and many writers have expressed outrage at the use of their work without consent or compensation. In this paper, we seek to understand how creative writers reason about the real or hypothetical use of their writing as training data. We interviewed 33 writers with variation across genre, method of publishing, degree of professionalization, and attitudes toward and engagement with LLMs. We report on core principles that writers express (support of the creative chain, respect for writers and writing, and the human element of creativity) and how these principles can be at odds with their realistic expectations of the world (a lack of control, industry-scale impacts, and interpretation of scale). Collectively these findings demonstrate that writers have a nuanced understanding of LLMs and are more concerned with power imbalances than the technology itself. ",
    "title": "Creative Writers’ Attitudes on Writing as Training Data for Large Language Models",
    "id": 188767,
    "sequence": 558,
    "queryCoordinates": {
      "visualization": [
        11.977421706431143,
        -14.749283686549393
      ]
    }
  },
  {
    "session": "Technology-Facilitated Family Interaction",
    "abstract": "Screen time is ubiquitous in children's lives and has both positive and negative health impacts. Calls for developmentally appropriate design and restrictions on manipulative design are ongoing, yet children's and parents' perspectives to inform interventions are lacking. This research uses design workshops with children (n=16) and focus groups with their parents (n=17) to understand whether and how digital media could be more health-centered. Participants shared concerns that manipulative design may inhibit screen time limits and transitions, and present age-inappropriate content.  Participants expressed strong interest in health-centered designs incorporating nudges, moderation, and controls. Children's self-generated designs aimed to reduce negative impacts by limiting screen time (e.g., time-related feedback, changed defaults), facilitating transitions (e.g., pause capabilities), minimizing age-inappropriate content (e.g., expanded shared controls), and reducing hurtful experiences (e.g., online video game moderation). To increase positive health impacts, participants suggested promoting physical activity (e.g., suggested screen breaks) within and away from digital media.",
    "title": "`I don't want to watch grown-up stuff': Children's and Parents' Perspectives and Recommendations for Health-Centered Digital Media Design",
    "id": 188768,
    "sequence": 559,
    "queryCoordinates": {
      "visualization": [
        -6.273549006284602,
        9.035628526325409
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "Biased news articles can distort readers' perceptions by presenting information in a way that favors or disfavors a particular point of view. Subtly embedded in the text, these biased news articles can shape our views daily without people even realizing it. To address this issue, we propose BIASsist, an LLM-based approach designed to mitigate bias in news articles. Based on existing research, we defined six types of bias and introduced three assistive components—identification, explanation, and neutralization—to provide a broader range of bias information and enhance readers' bias-awareness. We conducted a mixed-method study with 36 participants to evaluate the effectiveness of BIASsist. The results show participants' bias awareness significantly improved and their interest in identifying bias increased. Participants also tended to engage more actively in critically evaluating articles. Based on these findings, we discuss its potential to improve media literacy and critical thinking in today's information overload era.",
    "title": "BIASsist: Empowering News Readers via Bias Identification, Explanation, and Neutralization",
    "id": 188769,
    "sequence": 560,
    "queryCoordinates": {
      "visualization": [
        3.4441508912858025,
        -8.314915792601582
      ]
    }
  },
  {
    "session": "Education",
    "abstract": "Recognising that much HCI knowledge is built from the perspective of the Global North, this case study advances HCI efforts to understand how technologies, particularly educational technologies and innovation processes, can be understood from and in the Global South, through exploratory methods such as speculative design. We ran two workshops with twenty-four children aged five to eleven in rural schools in Colombia, exploring their perspectives on their education futures. We found that their visions of the future may support HCI practitioners to reconceptualise innovation and temporality in such contexts. We contribute one key principle, one provocation, and one practical learning which HCI researchers interested in decolonialising educational technologies may wish to consider in their own work.",
    "title": "Unsettling 'More Tech' Rhetorics in Educational Technology Research: A Case Study on Participatory Speculative Design in Rural Colombian Schools ",
    "id": 188770,
    "sequence": 561,
    "queryCoordinates": {
      "visualization": [
        -9.381913359224841,
        -3.4611705707749305
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Electronic Textiles (E-textiles), also known as smart textiles, explore the intersection of electronics and textile fabrications, enabling sensing, actuation, and communication functionalities within textile forms. Although recent e-textile research has examined a wide range of fabrication methods and novel materials, the research heavily emphasizes the electronic sensing and actuation aspects yet lacks exploration of the involvement of biological systems. Recent advances in Biological Human-Computer Interaction (Bio-HCI) investigate the interplay between humans, computers, and biological systems, such as using biological materials as design elements or developing intermediate platforms to and from users. My research integrates Bio-HCI with e-textiles through (1) functional, (2) material, and (3) process investigations, focusing on three areas: biofluid sensing for personal healthcare, utilizing biodegradable materials for sustainable e-textiles, and biodesign for novel fabrication methods. My research advances scalable, accessible e-textile production, promoting ecological awareness and expanding the functional potential of e-textiles in wearable technology.",
    "title": "Biological Human-Computer Interaction for Electronic Textiles",
    "id": 188771,
    "sequence": 562,
    "queryCoordinates": {
      "visualization": [
        -5.773321504383234,
        -15.989645362140653
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "Large Language Models (LLMs) have been widely used to support ideation in the writing process. However, whether generating ideas with the help of LLMs leads to idea fixation or idea expansion is unclear. This study examines how different timings of LLM usage - either at the beginning or after independent ideation - affect people's perceptions and ideation outcomes in a writing task. In a controlled experiment with 60 participants, we found that using LLMs from the beginning reduced the number of original ideas and lowered creative self-efficacy and self-credit, mediated by changes in autonomy and ownership. We discuss the challenges and opportunities associated with using LLMs to assist in idea generation. We propose delaying the use of LLMs to support ideation while considering users' self-efficacy, autonomy, and ownership of the ideation outcomes.",
    "title": "Timing Matters: How Using LLMs at Different Timings Influences Writers' Perceptions and Ideation Outcomes in AI-Assisted Ideation",
    "id": 188772,
    "sequence": 563,
    "queryCoordinates": {
      "visualization": [
        19.138806714644176,
        5.805693545089246
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "Feminist self-defense combines physical self-defense with mental strength exercises through role-playing scenarios. It aims to challenge limiting beliefs about women’s abilities to respond to interpersonal violence. We present the experiences from feminist self-defense classes in Sweden and the results of a set of speculative designs that combined contribute to imagine how technology could play a role in experiencing these holistic practices. The goal is to illustrate the potential of embodied interaction design to empower beginner feminist self-defense practitioners. To do so, the study was conducted via two methods: semi-structured interviews with students and teachers, and a participatory speculative design workshop with novice practitioners. The speculative concepts\r\ndemonstrate how design can support the practice of feminist self-defense. Through this study we contribute to the corpus of embodied design interventions, in this case combining design for bodily movements with feminist consciousness raising in relation\r\nto the topic of gender-based violence.",
    "title": "Imagining with the Body: Speculative Designs for Women's Embodied Empowerment in Feminist Self-Defense ",
    "id": 188773,
    "sequence": 564,
    "queryCoordinates": {
      "visualization": [
        0.3924187753808583,
        5.98715353943162
      ]
    }
  },
  {
    "session": "Well-being and Well-dying",
    "abstract": "In an imagined future where plurality and interconnectedness are integral to technology development and innovation, indigenous and cultural philosophies, values, and approaches will take a centre stage in developing effective and inclusive design practices. Instead of summarizing, we invite the readers to step into the unknown with us, into an unusual paper writing and reading journey, exploring the cyclical nature of life and design. We begin, paradoxically, with our sights on the end of a chapter at CHI, and move through the difficult and inexorable, yet necessary, journey through death. The \"end\" being a portal through which to envision the future and re-examine the potential of Human-Computer Interaction.",
    "title": "\"This Journey is Never Truly Over, For the Ball I Carry is Always Moving\": Future Obituaries and End-of-Life First Design",
    "id": 188774,
    "sequence": 565,
    "queryCoordinates": {
      "visualization": [
        1.1771545092012554,
        -16.95919536008319
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "Advances in large language models (LLMs) empower new interactive capabilities for wearable voice interfaces, yet traditional voice-and-audio I/O techniques limit users' ability to flexibly navigate information and manage timing for complex conversational tasks. We developed a suite of gesture and audio-haptic guidance techniques that enable users to control conversation flows and maintain awareness of possible future actions, while simultaneously contributing and receiving conversation content through voice and audio. A 14-participant exploratory study compared our parallelized I/O techniques to a baseline of voice-only interaction. The results demonstrate the efficiency of gestures and haptics for information access, while allowing system speech to be redirected and interrupted in a socially acceptable manner. The techniques also raised user awareness of how to leverage intelligent capabilities. Our findings inform design recommendations to facilitate role-based collaboration between multimodal I/O techniques and reduce users' perception of time pressure when interleaving interactions with system speech.",
    "title": "Gesture and Audio-Haptic Guidance Techniques to Direct Conversations with Intelligent Voice Interfaces",
    "id": 188775,
    "sequence": 566,
    "queryCoordinates": {
      "visualization": [
        -19.688391629423982,
        -7.305288156289775
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "It is common for digital platforms to issue consequences for behaviors that violate Community Standards policies. However, there is limited evidence about the relative effectiveness of consequences, particularly lengths of temporary suspensions. This paper analyzes two massive field experiments (N1 = 511,304; N2 = 262,745) on Roblox that measure the impact of suspension duration on safety- and engagement-related outcomes. The experiments show that longer suspensions are more effective than shorter ones at reducing reoffense rate, the number of consequences, and the number of user reports. Further, they suggest that the effect of longer suspensions on reoffense rate wanes over time, but persists for at least 3 weeks. Finally, they demonstrate that longer suspensions are more effective for first-time violating users. These results have significant implications for theory around digitally-enforced punishments, understanding recidivism online, and the practical implementation of product changes and policy development around consequences.",
    "title": "In Suspense About Suspensions? The Relative Effectiveness of Suspension Durations on a Popular Social Platform",
    "id": 188776,
    "sequence": 567,
    "queryCoordinates": {
      "visualization": [
        16.47560662415004,
        -7.249440417457288
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "The U.S. Cyber Trust Mark is intended to empower consumers and enable security by demand. But is there such a demand? To explore this, we recruited 599 participants and asked them to select their desired smart device using a simulated online marketplace. Participants were informed they would receive their selected light bulbs, and they were divided into five experimental groups based on different versions of the Mark. After the product selections, we surveyed them about their priorities and preferences. We found no significant differences between the groups as a whole. However, the subset of consumers who identified cybersecurity as most important were significantly more likely to select labeled products, spending 16.5\\% more. We detail these differences and preferences, then argue that an awareness program is needed to assist consumers in better understanding the long-term economic benefits of the U.S. Cyber Trust Mark.",
    "title": "Usability, Efficacy, and Acceptability of the U.S. Cyber Trust Mark",
    "id": 188777,
    "sequence": 568,
    "queryCoordinates": {
      "visualization": [
        7.853169308807449,
        6.190939493098339
      ]
    }
  },
  {
    "session": "Design Thinking",
    "abstract": "This paper explores the design and future potential of virtual funerals, enabling both in-person and remote participation, with options to digitally revisit and update the memorial site. While virtual funerals gained prominence during the COVID-19 pandemic and are often seen as temporary, the authors argue that they hold long-term value across different contexts. To investigate future funeral practices, we created a Design Fiction film depicting our concept of virtual funerals in Japan using Diegetic Prototypes–hypothetical technologies that envision a future in which these practices are normalized. Key themes include hybrid attendance, virtual memorial spaces, and technologies that bridge in-person, remote, and revisiting participants. The authors and a professional crew created the film collaboratively to illustrate these speculative elements. This paper details the film’s production, its design rationale, and the broader implications for how HCI design and technology could shape future mourning and memorialization practices.",
    "title": "Designing Virtual Funerals as a Design Fiction: A Film-Based Exploration of Near-Future Memorial Rituals",
    "id": 188778,
    "sequence": 569,
    "queryCoordinates": {
      "visualization": [
        -5.927609002839673,
        -5.3724716387761475
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL.",
    "title": "Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators",
    "id": 188779,
    "sequence": 570,
    "queryCoordinates": {
      "visualization": [
        -7.305288156289772,
        19.688391629423982
      ]
    }
  },
  {
    "session": "WS01: Research Products and Time: When, For How Long, And Then What?",
    "abstract": "This workshop focuses on the temporal dimensions of Research through Design (RtD) in Human-Computer Interaction. Building on the success of previous objects of design workshops at CHI, it explores how time impacts the creation, evolution, and deployment of design artifacts. Participants will discuss long-term and unconventional deployments, addressing methodological, ethical, and organizational challenges. Through hands-on, studio-style critique and collaborative sessions, the workshop aims to generate insights into how temporal aspects of design contribute to knowledge production. The event will also initiate long-term design deployments, with findings to be reported at a follow-up workshop in 2026, marking the 10th anniversary of this series.",
    "title": "Research Products and Time: When, For How Long, And Then What?",
    "id": 188780,
    "sequence": 571,
    "queryCoordinates": {
      "visualization": [
        -3.4909142771668953,
        12.522520413617713
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "Due to the remarkable content generation capabilities, large language models (LLMs) have demonstrated potential in supporting early-stage conceptual design. However, current interaction paradigms often struggle to effectively facilitate multi-round idea exploration and selection, leading to random outputs, unclear iterations, and cognitive overload. To address these challenges, we propose a human-AI co-ideation framework aimed at tracking the evolution of design ideas. This framework leverages a structured idea representation, an analogy-based reasoning mechanism and interactive visualization techniques. It guides both designers and AI to systematically explore design spaces. We also develop a prototype system, IdeationWeb, which integrates an intuitive, mind map-like visual interface and interactive methods to support co-ideation. Our user study validates the framework’s feasibility, demonstrating enhanced collaboration and creativity between humans and AI. Furthermore, we identified collaborative design patterns from user behaviors, providing valuable insights for future human-AI interaction design.",
    "title": "IdeationWeb: Tracking the Evolution of Design Ideas in Human-AI Co-Creation",
    "id": 188781,
    "sequence": 572,
    "queryCoordinates": {
      "visualization": [
        -10.696523261502504,
        9.032407769589225
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "Social play is crucial for children's well-being and development. However, many social play technologies fail to address the specific characteristics and needs of neurodiverse play and often overlook divergent play styles. To address this, we first conducted a co-design study with a neurodiverse group of 7 children (Age 7-8) and, based on insights from these sessions, then developed a prototype, ChromaConnect, that allowed children to express their play style to one another during play. To evaluate ChromaConnect's ability to support neurodiverse social play in different contexts, we observed children using it in both structured and unstructured play settings. Our findings show that ChromaConnect enabled children to create a common language of play, made divergent play modes more visible, and facilitated explicit expression of social play initiation. We discuss how these findings could be used to design `accompanying social play things' that are more inclusive of neurodiverse play characteristics and divergent play styles.",
    "title": "\"It Helps Us Express Our Feelings Without Having To Say Anything\": Exploring Accompanying Social Play Things Designed With and For Neurodiverse Groups of Children",
    "id": 188782,
    "sequence": 573,
    "queryCoordinates": {
      "visualization": [
        10.880615565184305,
        -10.32531863540632
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "Understanding how AI recommendations work can help the younger generation become more informed and critical consumers of the vast amount of information they encounter daily. However, young learners with limited math and computing knowledge often find AI concepts too abstract.\r\nTo address this, we developed Briteller, a light-based recommendation system that makes learning tangible. By exploring and manipulating light beams, Briteller enables children to understand an AI recommender system's core algorithmic building block, the dot product, through hands-on interactions. Initial evaluations with ten middle school students demonstrated the effectiveness of this approach, using embodied metaphors, such as  \"merging light\" to represent addition. To overcome the limitations of the physical optical setup, we further explored how AR could embody multiplication, expand data vectors with more attributes, and enhance contextual understanding.\r\nOur findings provide valuable insights for designing embodied and tangible learning experiences that make AI concepts more accessible to young learners.",
    "title": "Briteller: Shining a Light on AI Recommendations for Children",
    "id": 188783,
    "sequence": 574,
    "queryCoordinates": {
      "visualization": [
        1.17054193209677,
        5.884711682419383
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "Despite the prevalence of digital gifting, designing meaningful and emotionally engaging digital gifts remains a challenge. One promising approach is Hybrid gifting, which combines digital and physical elements to improve the perceived value of gifts and provide opportunities for interpersonalisation. However, there is limited understanding of how hybridity shapes the dynamics of gifting in everyday contexts. To explore this, we developed a connected coffee machine prototype as a technology probe to study how givers personalise hybrid gifts and how recipients experience them. A study with seven pairs in intimate relationships revealed key insights: hybridity fosters slow, deliberate engagement; supports personalisation aligned with daily routines; grants recipients autonomy in receiving gifts; and reveals tensions between giver anxiety and recipient enjoyment. We discuss design implications for hybrid gifting systems that encourage recipients to savour digital gifts through slow, reflective interactions.",
    "title": "Savouring Slow Gifts: Reflection from the Field Study of Hybrid Gifting",
    "id": 188784,
    "sequence": 575,
    "queryCoordinates": {
      "visualization": [
        -9.27612544035285,
        -7.61271940996374
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "UI prototyping often involves iterating and blending elements from examples such as screenshots and sketches, but current tools offer limited support for incorporating these examples. Inspired by the cognitive process of conceptual blending, we introduce a novel UI workflow that allows developers to rapidly incorporate diverse aspects from design examples into work-in-progress UIs. We prototyped this workflow as Misty. Through a exploratory first-use study with 14 frontend developers, we assessed Misty's effectiveness and gathered feedback on this workflow. Our findings suggest that Misty's conceptual blending workflow helps developers kickstart creative explorations, flexibly specify intent in different stages of prototyping, and inspires developers through serendipitous UI blends. Misty demonstrates the potential for tools that blur the boundaries between developers and designers.",
    "title": "Misty: UI Prototyping Through Interactive Conceptual Blending",
    "id": 188785,
    "sequence": 576,
    "queryCoordinates": {
      "visualization": [
        -2.5375731366545815,
        3.0920418134509484
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "A growing body of research investigates how to make captioning experiences more accessible and enjoyable to disabled people. However, prior work has focused largely on English captioning, neglecting the majority of people who are multilingual (i.e., understand or express themselves in more than one language). To address this gap, we conducted semi-structured interviews and diary logs with 13 participants who used multilingual captions for accessibility. Our findings highlight the linguistic and cultural dimensions of captioning, detailing how language features (scripts and orthography) and the inclusion/negation of cultural context shape the accessibility of captions. Despite lack of quality and availability, participants emphasized the importance of multilingual captioning to learn a new language, build community, and preserve cultural heritage. Moving toward a future where all ways of communicating are celebrated, we present ways to orient captioning research to a language justice agenda that decenters English and engages with varied levels of fluency.",
    "title": "Toward Language Justice: Exploring Multilingual Captioning for Accessibility",
    "id": 188786,
    "sequence": 577,
    "queryCoordinates": {
      "visualization": [
        -7.231914344987546,
        -3.4204407474422576
      ]
    }
  },
  {
    "session": "WS23: Sensorimotor Devices: Coupling Sensing and Actuation to Augment Bodily Experience",
    "abstract": "An emerging space in interface research is wearable devices that closely couple their sensing and actuation abilities. A well-known example is MetaLimbs, where sensed movements of the foot are directly mapped to the actuation of supernumerary robotic limbs. These systems are different from wearables focused on sensing, such as fitness trackers, or wearables focused on actuation, such as VR headsets. They are characterized by tight coupling between the user's action and the resulting digital feedback from the device, in time, space, and mode. The properties of this coupling are critical for the user's experience, including the user's sense of agency, body ownership, and experience of the surrounding world. Understanding such systems is an open challenge, which requires knowledge not only of computer science and HCI, but also Psychology, Physiology, Design, Engineering, Cognitive Neuroscience, and Control Theory. This workshop aims to foster discussion between these diverse disciplines and to identify links and synergies in their work, ultimately developing a common understanding of future research directions for systems that intrinsically couple sensing and action.",
    "title": "Sensorimotor Devices: Coupling Sensing and Actuation to Augment  Bodily Experience",
    "id": 188787,
    "sequence": 578,
    "queryCoordinates": {
      "visualization": [
        20.171840307263036,
        -8.78048168486663
      ]
    }
  },
  {
    "session": "Education",
    "abstract": "As emerging technologies disrupt traditional ways of innovating and creating, higher education will require new models of interdisciplinary learning. In this case study, we review the operating model of Conflux Collective, a student-driven organization at Harvard University that facilitates interdisciplinary human-computer interaction (HCI) education through art-tech projects. We then outline our organizational impact,  challenges, and strategic recommendations for designing HCI-inspired organizations. Our findings aim to guide educators, student organizers, and institutions interested in developing similar programs that embrace disciplinary diversity.",
    "title": "Conflux Collective: A Student-Driven Model for HCI Education Through the Lens of Art-Tech",
    "id": 188788,
    "sequence": 579,
    "queryCoordinates": {
      "visualization": [
        1.9530851587973355,
        10.825223247697277
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "Addressing the complexities of conflict-affected regions remains a critical challenge for Human-Computer Interaction (HCI). This paper examines the establishment of computer clubs in Palestinian refugee camps, where efforts to create sustainable interventions weighed against the instability of prolonged conflict. To capture this dynamic, we introduce the notion of ‘adaptive ponds of stability,’ which extends the ‘tech public of erosion’ framework [12]. While the latter emphasizes systemic depletion of socio-technical infrastructures, adaptive ponds of stability highlight efforts to foster temporary spaces of resilience. The clubs became hubs of learning, respite, and collaboration—offering moments of routine and empowerment amidst disruption. Reflecting on this, we advocate for a paradigm shift from sustainability to resilience as the primary design goal in unstable contexts. Our findings emphasize adaptability, local agency, and cultural sensitivity that respond dynamically to context-specific challenges, offering a nuanced approach to advancing HCI interventions in conflict-affected settings.",
    "title": "Designing for Resilience: Fostering Ponds of Stability with Computer Clubs in Palestine",
    "id": 188789,
    "sequence": 580,
    "queryCoordinates": {
      "visualization": [
        -3.517630689399459,
        -20.703291388882953
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "In the context of extensive bank branch closures, and a rapidly ageing population, older adults’ (OAs’) reluctance to adopt digital banking platforms by themselves is concerning. However, many OAs rely on the support of close others (COs) to complete banking activities with them. This support is mostly provided through “unofficial” mechanisms such as sharing online banking credentials, which risk an OA’s privacy and security. This paper replicates a Canadian study with OAs in a UK context and extends it with co-design workshops focused on novel banking solutions for OAs and COs, helping to formalise the role of unofficial proxies within online platforms. Results show that unofficial proxy banking also occurs with COs in a UK context and co-design reveals barriers to OAs’ use of banking technology independently. We discuss recommendations for flexible, easily authenticated and easy to learn digital banking solutions for OAs in the future.",
    "title": "Beyond the 'Unofficial Proxy' - Navigating Technology Support for Older Adults' Banking Activities with Close Others",
    "id": 188790,
    "sequence": 581,
    "queryCoordinates": {
      "visualization": [
        14.417071934058374,
        -13.86174725091272
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "People rely on online information for important life tasks such as managing personal finances and understanding medical symptoms. However, due to its intrinsically language-focused nature, online search poses considerable difficulties for people with language impairments. Currently these difficulties are poorly understood. We report findings from an observation of the information search behavior of 12 people with aphasia. We identify a wide range of difficulties and strategies aimed at combating them, spanning the entire information search process. Findings include previously unreported difficulties and strategies that highlight the importance of designing search technologies to better support the complex needs of people who find language challenging, such as by facilitating word finding cueing strategies, error prevention and recovery, browsing, appropriation, text interpretation and and by decreasing reliance on language competency in general. This has the potential not only to benefit searchers with language impairments, but to make information search easier for all.\r\n",
    "title": "\"The Internet is Hard. Is Words\": Investigating Information Search Difficulties Experienced by People with Aphasia and Strategies for Combatting Them",
    "id": 188791,
    "sequence": 582,
    "queryCoordinates": {
      "visualization": [
        15.705952052691874,
        6.505618350206526
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "We propose an interactive tool that enables reusing printed circuit boards (PCB) as prototyping materials to implement new circuits — this extends the utility of PCBs rather than discards them as e-waste. To enable this, our tool takes a user’s desired circuit schematic and analyzes its components and connections to find methods of creating the user’s circuit on discarded PCBs (e.g., e-waste, old prototypes). In our technical evaluation, we utilized our tool across a diverse set of PCBs and input circuits to characterize how often circuits could be implemented on a different board, implemented with minor interventions (trace-cutting or bodge-wiring), or implemented on a combination of multiple boards — demonstrating how our tool assists with exhaustive matching tasks that a user would not likely perform manually. We believe our tool offers: (1) a new approach to prototyping with electronics beyond the limitations of breadboards and (2) a new approach to reducing e-waste during electronics prototyping.",
    "title": "ProtoPCB: Reclaiming Printed Circuit Board E-waste as Prototyping Material",
    "id": 188792,
    "sequence": 583,
    "queryCoordinates": {
      "visualization": [
        -4.992701457272381,
        13.0794851641244
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "Technological advancements such as LLMs have enabled everyday things to use language, fostering increased anthropomorphism during interactions. This study employs material speculation to investigate how people experience things that express their thoughts, emotions, and intentions. We utilized Areca, an air purifier capable of keeping a diary, and placed it in the everyday spaces of eight participants over three weeks. Weekly interviews were conducted to capture participants’ evolving interactions with Areca, concluding with a session collaboratively speculating on the future of everyday things. Our findings indicate that things expressing thoughts, emotions, and intentions can be perceived as possessing agency beyond mere functionality. While some participants exhibited emotional engagement with Areca over time, responses varied, including moments of detachment. We conclude with design implications for HCI designers, offering insights into how emerging technologies may shape human-thing relationships in complex ways.",
    "title": "Living Alongside Areca: Exploring Human Experiences with Things Expressing Thoughts and Emotions",
    "id": 188793,
    "sequence": 584,
    "queryCoordinates": {
      "visualization": [
        19.965312203694317,
        -1.1774160730237921
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "Rest is a vital aspect of wakefulness. Technology has impacted our ability to rest through its colonisation of our attention, sleep, and recovery. Human-computer interaction researchers and designers have expressed the desire to contribute to human flourishing. However, design to support restful states remains largely tethered to human-centric paradigms. This paper identifies an oversight in human-computer interaction research and recognises rest as a more-than-human phenomenon that emerges through a dynamic interplay of multiple species, technologies, and ecosystems. We discuss this topic through the Daoist concepts of `Yin-Yang' and `Wu-Wei' as theoretical foundations for frameworks that reimagine the future of rest. We critically evaluate anthropocentric approaches to rest by reflecting on how embodied knowledge and practice can serve to bridge relational theories with practice. We propose a manifesto for `More-than-Human Yin-teraction' that outlines design principles foregrounding rest as a dynamic and evolving ecology where regenerative states emerge through the entangled relations between human, nonhuman and natural systems.",
    "title": "The Future of Rest: A More-Than-Human Manifesto ",
    "id": 188794,
    "sequence": 585,
    "queryCoordinates": {
      "visualization": [
        3.420440747442257,
        -7.231914344987547
      ]
    }
  },
  {
    "session": "Perception of Systems",
    "abstract": "In an era marked by rampant online misinformation, artificial intelligence (AI) technologies have emerged as tools to combat this issue. This paper examines the effects of AI-based credibility indicators in people’s online information processing under the social influence from both peers and \"experts''. Via three pre-registered, randomized experiments, we confirm the effectiveness of accurate AI-based credibility indicators to enhance people's capability in judging information veracity and reduce their propensity to share false information, even under the influence from both laypeople peers and experts. Notably, these effects remain consistent regardless of whether experts' expertise is verified, with particularly significant impacts when AI predictions disagree with experts. However, the competence of AI moderates the effects, as incorrect predictions can mislead people. Furthermore, exploratory analyses suggest that under our experimental settings, the impact of the AI-based credibility indicator is larger than that of the expert's. Additionally, AI's influence on people is partially mediated through peer influence, although people automatically discount the opinions of their laypeople peers when seeing an agreement between AI and peers' opinions. We conclude by discussing the implications of utilizing AI to combat misinformation.",
    "title": "Understanding the Effects of AI-based Credibility Indicators When People Are Influenced By Both Peers and Experts",
    "id": 188795,
    "sequence": 586,
    "queryCoordinates": {
      "visualization": [
        -6.552603591233876,
        -18.89612092933756
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Misinformation has been studied with various social media user groups, though not with Deaf and Hard-of-hearing (DHH) individuals. To address this gap, we conducted an interview with 15 DHH participants to explore their lived experiences with misinformation and their perspectives on common moderation and debunking approaches on social media. We found that participants often experience falsehoods, and highlighted examples specific to the DHH community such as misinformation related to American Sign Language (ASL) and Deaf culture. However, moderation interventions and debunking strategies for misinformation specific to DHH topics were lacking. Written warnings may be beneficial as long as they use language appropriate for DHH people with diverse literacy skills.  Participants found visual interventions (e.g., videos) more beneficial as long as they can be appropriately captioned – which is not always the case in practice. Our findings provide practical moderation insights for DHH social media users.",
    "title": "\"I have never seen that for Deaf people's content:\" Deaf and Hard-of-Hearing User Experiences with Misinformation, Moderation, and Debunking on Social Media in the US",
    "id": 188796,
    "sequence": 587,
    "queryCoordinates": {
      "visualization": [
        1.9591327532558624,
        -16.88673440470715
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "Medical education increasingly emphasizes students' ability to apply knowledge in real-world clinical settings, focusing on evidence-based clinical reasoning and differential diagnoses. Problem-based learning (PBL) addresses traditional teaching limitations by embedding learning into meaningful contexts and promoting active participation. However, current PBL practices are often confined to medical instructional settings, limiting students' ability to self-direct and refine their approaches based on targeted improvements. Additionally, the unstructured nature of information organization during analysis poses challenges for record-keeping and subsequent review. Existing research enhances PBL realism and immersion but overlooks the construction of logic chains and evidence-based reasoning. To address these gaps, we designed e-MedLearn, a learner-centered PBL system that supports more efficient application and practice of evidence-based clinical reasoning. Through controlled study (N=19) and testing interviews (N=13), we gathered data to assess the system's impact. The findings demonstrate that e-MedLearn improves PBL experiences and provides valuable insights for advancing clinical reasoning-based learning.",
    "title": "Advancing Problem-Based Learning with Clinical Reasoning for Improved Differential Diagnosis in Medical Education",
    "id": 188797,
    "sequence": 588,
    "queryCoordinates": {
      "visualization": [
        6.552603591233873,
        18.89612092933756
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "Extended Reality (XR) interactions often rely on spatial hand or controller inputs - necessitating dexterous wrist, hand and finger movements including pressing virtual buttons, pinching to select, and performing hand gestures. However, there are scenarios where such dependencies may render XR devices and apps inaccessible to users - from situational/temporary impairments such as encumbrance, to physical motor impairments. In this paper, we contribute to a growing literature considering facial input as an alternative. In a user study (N=20) we systematically evaluate the usability of 53 Facial Action Units in VR, deriving a set of optimal (comfort, effort, performance) FAUs for interaction. We then use these facial inputs to drive and evaluate (N=10) two demonstrator apps: VR locomotion, and AR web browsing, showcasing how close facial interaction can get to existing baselines, and demonstrating that FAUs offer a viable, generalizable input modality for XR devices.",
    "title": "InterFACE: Establishing a Facial Action Unit Input Vocabulary for Hands-Free Extended Reality Interactions, From VR Gaming to AR Web Browsing",
    "id": 188798,
    "sequence": 589,
    "queryCoordinates": {
      "visualization": [
        19.49405237856565,
        -10.197152635012326
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "Much work in HCI has investigated strategies for supporting autonomous self-regulation in social media use (SMU): helping users to control their time online and ensure it serves personally valued outcomes.\r\nHowever, results suggest that the effectiveness and acceptability of these strategies may vary based on individual needs. Recent work has attributed this variation to motivational factors, though we currently lack data to understand how these factors influence self-regulation, user experience and well-being.\r\nWe draw on Self-Determination Theory to analyse autonomous and non-autonomous patterns of motivation in 521 users of social media.\r\nUsing latent profile analysis, we identify 4 ``motivational profiles'' associated with significant differences in need satisfaction, affect, and compulsive engagement. \r\nOur results clarify distinct aspects of autonomy in SMU and identify opportunities to target and personalise design interventions; they suggest autonomous regulation can be associated with better experience and well-being, though not necessarily less time online.",
    "title": "Autonomous Regulation of Social Media Use: Implications for Self-control, Well-Being, and UX",
    "id": 188799,
    "sequence": 590,
    "queryCoordinates": {
      "visualization": [
        8.418439278177681,
        11.186146795015487
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "In this paper, we explore viewers’ strategies in visual problem-solving tasks. We build on the traditional metrics of accuracy and time to better understand the learning that occurs as individuals interact with visualizations. We conducted an in-lab eye-tracking user study with 53 participants from diverse demographic backgrounds. Using questions from the Visualization Literacy Assessment Test (VLAT), we examined participants’ problem-solving strategies. We employed a mixed-methods approach capturing quantitative data on performance and gaze patterns, as well as qualitative data through think-alouds and sketches by participants as they reported on their problem-solving approach. Our analysis reveals not only the various cognitive strategies leading to correct answers but also the nature of mistakes and the conceptual misunderstandings that underlie them. This research contributes to the enhancement of visualization design guidelines by incorporating insights into the diverse strategies and cognitive processes employed by users.",
    "title": "Beyond Time and Accuracy: Strategies in Visual Problem-Solving",
    "id": 188800,
    "sequence": 591,
    "queryCoordinates": {
      "visualization": [
        -1.9585708031874585,
        15.87967255357936
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "Smart home technologies are becoming increasingly common in households with children. While privacy and security concerns have been widely discussed, a critical issue often overlooked is the extensive data harvesting embedded in these smart homes and its manipulative impact on children through algorithmic decision-making. In this paper, we introduce FamiData Hub, a speculative prototype designed to empower families to navigate the datafication of smart homes. Through 17 study sessions—including speculative interviews followed by co-design activities—with 30 children and 25 parents, we found that families face challenges related to smart home datafication, such as the erosion of boundaries in family spaces, loss of control over family norms, and diminished autonomy in data-driven decision-making processes. Our findings offer key design recommendations for rethinking smart home technologies to better safeguard children's data, advocating for respectful, family-centered approaches that challenge the normalization of datafication in domestic life.\r\n",
    "title": "FamiData Hub: A Speculative Design Exploration with Families on Smart Home Datafication",
    "id": 188801,
    "sequence": 592,
    "queryCoordinates": {
      "visualization": [
        -1.173843795642893,
        7.913412079718248
      ]
    }
  },
  {
    "session": "Technology-Facilitated Family Interaction",
    "abstract": "Communication with child patients is challenging due to their developing ability to express emotions and symptoms. Additionally, healthcare providers often have limited time to offer resources to parents. By leveraging AI to facilitate free-form conversations, our study aims to design an AI-driven chatbot to bridge these gaps in child-parent-provider communication. We conducted two studies: 1) design sessions with 12 children with cancer and their parents, which informed the development of our chatbot, ARCH, and 2) an interview study with 15 pediatric care experts to identify potential challenges and refine ARCH's role in pediatric communication. Our findings highlight three key roles for ARCH: providing an expressive outlet for children, offering reassurance to parents, and serving as an assessment tool for providers. We conclude by discussing design considerations for AI-driven chatbots in pediatric communication, such as creating communication spaces, balancing the expectations of children and parents, and addressing potential cultural differences.",
    "title": "Enhancing Pediatric Communication: The Role of an AI-Driven Chatbot in Facilitating Child-Parent-Provider Interaction",
    "id": 188802,
    "sequence": 593,
    "queryCoordinates": {
      "visualization": [
        11.266622499313055,
        -14.037920695671879
      ]
    }
  },
  {
    "session": "Designing, Making, Exploring",
    "abstract": "In this paper, we present a multiple-site case study to illustrate the similarities and differences in cultural game jam design with youth in situated research contexts. The aim is to provide the reader with an insight into the problem space, jam design, outcomes and opportunities of a set of linked, yet individual, studies from several different contexts and countries. The cases provide a platform to think about how game jam studies might be collectively reported and evaluated even when they are carried out in different ways. The contribution is an illustration of differentiated replication in multiple cultural game jam studies with youth in different countries. The reflections on replication and differentiation is of interest for cultural game jam activities to empower youth's cultural participation through technology design.",
    "title": "Cultural Game Jams with Youth: A Multiple-Site Case Study",
    "id": 188803,
    "sequence": 594,
    "queryCoordinates": {
      "visualization": [
        -3.527685057393421,
        -1.885586947303989
      ]
    }
  },
  {
    "session": "Education",
    "abstract": "Practical insights into running co-design projects with children in school, including common problems that arise and how to manage them, are under-reported. We ran four co-design sessions, each with up to fifteen 10-11 year olds, at a UK primary school. In this paper, we reflect on the co-design process in the classroom and highlight six challenges we faced: school access; unfamiliarity with the school; gaining consent/assent; child engagement; behaviour management; and reporting back our findings to stakeholders. For each challenge, we detail how we mitigated it during the workshops, such as associating assent with  specific activities. We also report on further reflections on these issues that occurred after the workshops, facilitated by a focus group with outreach experts and discussions at a workshop with other researchers who co-design with children. The contribution of this paper is to provide practical solutions to challenges faced when co-designing in the classroom. ",
    "title": "Challenges When Co-Designing With Children in the Classroom",
    "id": 188804,
    "sequence": 595,
    "queryCoordinates": {
      "visualization": [
        -16.170760940024522,
        13.39800323259318
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "Product metaphors, which involve creating products that convey meaning through metaphorical associations, are a powerful tool in product design. However, according to our formative study, novice designers often struggle to establish coherent links between target and source, to manage the complexity of diverse mapping possibilities and to balance product usability with metaphorical expression. To address these challenges, we introduce ProductMeta, a creativity support tool designed to support novice designers in exploring and developing metaphorical product designs. ProductMeta incorporates domain knowledge and decomposes the design process into iterative modules and framework-based interfaces, fostering both divergent and convergent thinking. Through user studies, we demonstrate that ProductMeta enables novice designers to generate diverse and contextually relevant design ideas by facilitating structured exploration. We conclude with design implications for human-AI co-creation.",
    "title": "ProductMeta: An Interactive System for Metaphorical Product Design Ideation with Multimodal Large Language Models",
    "id": 188805,
    "sequence": 596,
    "queryCoordinates": {
      "visualization": [
        6.5393673768901355,
        17.83918928399116
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "Nowadays, touch remains essential for emotional conveyance and interpersonal communication as more interactions are mediated remotely. While many studies have discussed the effectiveness of using haptics to communicate emotions, incorporating affect into haptic design still faces challenges due to individual user tactile acuity and preferences. We assessed the conveying of emotions using a two-channel haptic display, emphasizing individual differences. First, 24 participants generated 187 haptic messages reflecting their immediate sentiments after watching 8 emotionally charged film clips. Afterwards, 19 participants were asked to identify emotions from haptic messages designed by themselves and others, yielding 593 samples. Our findings indicate that the ability to decode haptic messages is linked to specific emotional traits, particularly Emotional Competence (EC) and Affect Intensity Measure (AIM). Additionally, qualitative analysis revealed three strategies participants used to create touch messages: perceptive, empathetic, and metaphorical expression.",
    "title": "Haptic Empathy: Investigating Individual Differences in Affective Haptic Communications",
    "id": 188806,
    "sequence": 597,
    "queryCoordinates": {
      "visualization": [
        12.438238903704212,
        6.425746102545527
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Generative AI could enhance scientific discovery by supporting knowledge workers in science organizations. However, the real-world applications and perceived concerns of generative AI use in these organizations are uncertain. In this paper, we report on a collaborative study with a US national laboratory with employees spanning Science and Operations about their use of generative AI tools. We surveyed 66 employees, interviewed a subset (N=22), and measured early adoption of an internal generative AI interface called Argo lab-wide. We have four findings: (1) Argo usage data shows small but increasing use by Science and Operations employees; Common current and envisioned use cases for generative AI in this context conceptually fall into either a (2) copilot or (3) workflow agent modality; and (4) Concerns include sensitive data security, academic publishing, and job impacts. Based on our findings, we make recommendations for generative AI use in science and other organizations.",
    "title": "Generative AI Uses and Risks for Knowledge Workers in a Science Organization",
    "id": 188807,
    "sequence": 598,
    "queryCoordinates": {
      "visualization": [
        14.516002876814685,
        10.643573670544482
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "Health-related artificial intelligence (health AI) systems are being rapidly created, largely without input from racially minoritized communities who experience persistent health inequities and stand to be negatively affected if these systems are poorly designed. Addressing this problematic trend, we critically review prior work focused on the participatory design of health AI innovations (participatory AI research), surfacing eight gaps in this work that inhibit racial health equity and provide strategies for addressing these gaps. Our strategies emphasize that “participation” in design must go beyond typical focus areas of data collection, annotation, and application co-design, to also include co-generating overarching health AI agendas and policies. Further, participatory AI methods must prioritize community-centered design that supports collaborative learning around health equity and AI, addresses root causes of inequity and AI stakeholder power dynamics, centers relationalism and emotion, supports flourishing, and facilitates longitudinal design. These strategies will help catalyze research that advances racial health equity.",
    "title": "Participatory AI Considerations for Advancing Racial Health Equity",
    "id": 188808,
    "sequence": 599,
    "queryCoordinates": {
      "visualization": [
        11.587953327223467,
        -11.032648715793075
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "We consider mobile maps, the everyday smart-device-based programs that locate the user, provide insights into local space, and support wayfinding -- or do they? The authors collectively reflect on past infuriating experiences with failures of mobile maps as pedestrians. We synthesise these thick descriptions, what we call reflective auto-aggro-ethnographies, to identify shortcomings in mobile maps: hidden verticality, missing local detail, incorrect sensor data, and poor pathing. We turn to human-centred design to point out how these shortcomings should be (or, rather, should have been) addressed.",
    "title": "Mobile Maps Continue to Fail Pedestrians: Synthesised Reflective Auto-Aggro-Ethnographies of Walking",
    "id": 188809,
    "sequence": 600,
    "queryCoordinates": {
      "visualization": [
        10.916953881956173,
        7.058336768619221
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "This submission is an edited translation of an article previously published in German.\r\n\r\nParticipatory methods open up research in Human-Computer Interaction (HCI) that aim at involving populations that are not traditionally represented. However, they do not require researchers to actively reflect on power relationships as would be required when aiming for transformative impact. In our case study of MACH’S AUF!, we show how research on accessibility of makerspaces for deaf people allowed us to develop a methodological concept of solidarity driven research that extends classical concepts of participation. \r\nWe show how access to makerspaces has to be understood first and foremost as structured in a socio-technical manner, where communicative access for deaf people has to be provided through sign language. \r\nOur work provides a nuanced understanding of what access to makerspaces might entail from a marginalised perspective, as well as a methodological positionality that may support transformative research endeavours in the future.",
    "title": "From Participation to Solidarity: A Case Study on Access of Maker Spaces from Deaf and Hearing Perspectives",
    "id": 188810,
    "sequence": 601,
    "queryCoordinates": {
      "visualization": [
        -0.3920685613182418,
        -3.9807389066887877
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "UI/UX designers often work under constraints like brand identity, design norms, and industry guidelines. How these constraints impact designers' ideation and exploration processes should be addressed in creativity-support tools for design. Through an exploratory interview study, we identified three designer personas with varying views on having constraints in the ideation process, which guided the creation of UIDEC, a GenAI-powered tool for supporting creativity under constraints. UIDEC allows designers to specify project details, such as purpose, target audience, industry, and design styles, based on which it generates diverse design examples that adhere to these constraints, with minimal need to write prompts. In a user evaluation involving designers representing the identified personas, participants found UIDEC compatible with their existing ideation process and useful for creative inspiration, especially when starting new projects. Our work provides design implications to AI-powered tools that integrate constraints during UI/UX design ideation to support creativity.",
    "title": "Dancing With Chains: Ideating Under Constraints With UIDEC in UI/UX Design",
    "id": 188811,
    "sequence": 602,
    "queryCoordinates": {
      "visualization": [
        -17.484157256638703,
        4.278346061871121
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "The CHI community continually looks to new horizons as we strive to innovate, and central amongst our goals should be a socio-technical future that is demonstrably better than the past. Accordingly, whilst we may look to the past to reflect on our own trajectories as a field, there remains unfulfilled potential in using the lens of history to its fullest capacity. We consider there are opportunities to facilitate research through design not only using our own histories but histories which run counter to our reality. In this paper, we call for the use of alternate histories as provocative design resources in HCI and CSCW research with participants, showing how we leveraged alternate history to explore contemporary matters around public service media and presenting guidance for other researchers to use this approach.",
    "title": "Alt(ernate) CHI: Using Alternate History Artifacts in Research",
    "id": 188812,
    "sequence": 603,
    "queryCoordinates": {
      "visualization": [
        3.386032209736675,
        -6.126563953361278
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Computer-mediated collaboration often relies on symmetrical interactions between users, where all the collaborators use identical devices. However, in some cases, either due to constraints (e.g. users in different environments) or by choice (e.g. using devices with different properties), users engage in asymmetrical interactions. Addressing such asymmetries in heterogeneous systems can be difficult as there has been no systematic analysis of how to define them, or their impact on collaboration. In this paper, we characterize the asymmetries that can arise between users’ interactions within collaborative heterogeneous systems. To this end, we conduct a systematic literature review of asymmetric collaborative systems, coding their properties, including the interaction spaces, their input and output modalities, and shared feedback. We then define the dimensions of asymmetry that emerge from this review. We discuss their impact on collaboration and outline a set of challenges and opportunities for future research.",
    "title": "A Systematic Literature Review to Characterize Asymmetric Interaction in Collaborative Systems",
    "id": 188813,
    "sequence": 604,
    "queryCoordinates": {
      "visualization": [
        8.559961918193554,
        13.517657043995314
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "We make four contributions to lower the overhead of conducting visualisation user studies and promote the reuse and extension of their materials. (i) A declarative Javascript specification lets experimenters describe how studies are assembled from tested visualisations, datasets, tasks and chosen evaluation strategies. (ii) A VisUnit library translates these into sequences of visual stimuli and delivers them to participants. We move away from monolithic evaluation stimuli typical of previous work and construct studies around three ingredients -- visual encodings, datasets, and tasks -- that can be developed independently and recombined flexibly. (iii) This paves the way for developing benchmark data+tasks test-suites as independent, reusable resources to support multiple studies. (iv) Structuring user studies as ``literate'' visualisation notebooks brings together in the open all ingredients necessary for replication and scrutiny:  formal design specification; underlying materials; participant-facing views; and narratives justifying design and supporting reuse. ",
    "title": "VisUnit: Literate Visualisation Studies Assembled from Reusable Test-Suites",
    "id": 188814,
    "sequence": 605,
    "queryCoordinates": {
      "visualization": [
        11.503208623575297,
        17.569183002134814
      ]
    }
  },
  {
    "session": "Living with Dementia or Visual Impairments",
    "abstract": "Blind people have limited opportunities to explore an environment based on their interests. While existing navigation systems could provide them with surrounding information while navigating, they have limited scalability as they require preparing prebuilt maps. Thus, to develop a map-less robot that assists blind people in exploring, we first conducted a study with ten blind participants at a shopping mall and science museum to investigate the requirements of the system, which revealed the need for three levels of detail to describe the surroundings based on users' preferences. Then, we developed WanderGuide, with functionalities that allow users to adjust the level of detail in descriptions and verbally interact with the system to ask questions about the environment or to go to points of interest. The study with five blind participants revealed that WanderGuide could provide blind people with the enjoyable experience of wandering around without a specific destination in their minds.",
    "title": "WanderGuide: Indoor Map-less Robotic Guide for Exploration by Blind People",
    "id": 188815,
    "sequence": 606,
    "queryCoordinates": {
      "visualization": [
        10.162674857624154,
        4.2095177560159875
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "Data is one of the foundational aspects of making Artificial Intelligence (AI) work as intended. As large language models  (LLMs) become the epicenter of AI, it is crucial to understand better how the datasets that maintain such models are created. The emergent nature of LLMs makes it critical to understand the challenges practitioners developing Gen AI technologies face to design alternatives for better responding to Gen AI's ethical issues. In this paper, we provide such understanding by reporting on 25 interviews with practitioners who handle data in three distinct development stages of different LLMs. Our contributions are (1) empirical evidence of how uncertainty, data practices, and reliance mechanisms change across LLMs' development cycle; (2) how the unique qualities of LLMs impact data practices and their implications for the future of Gen AI technologies; and (3) provide three opportunities for HCI researchers interested in supporting practitioners developing Gen AI technologies.",
    "title": "Emerging Data Practices: Data Work in the Era of Large Language Models",
    "id": 188816,
    "sequence": 607,
    "queryCoordinates": {
      "visualization": [
        13.39800323259319,
        -16.17076094002451
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "Video game onboarding faces the challenge of teaching game mechanics in a fun and engaging way. Artificial intelligence (AI) solutions have become a quick fix to help users understand technology. However, little is known about how AI supports player onboarding in video games. To address this knowledge gap, this research explores player perspectives on AI-supported onboarding. We conducted a qualitative user study (n=20) to investigate player expectations, attitudes, and concerns about AI-supported learning experiences. Players learn primarily through the lived experience of a game and value personalized guidance during onboarding. Participants emphasized the importance of maintaining control over how AI is used during onboarding and the freedom to choose their support level. Our results suggest that players want future AI-supported onboarding systems to prioritize their agency, encourage active learning, and maintain transparency throughout the learning process. We contribute to game design research by proposing balanced, player-centric AI-supported onboarding experiences in video games.",
    "title": "Support Autonomy: Exploring Player Perspectives on AI-Supported Onboarding in Video Games",
    "id": 188817,
    "sequence": 608,
    "queryCoordinates": {
      "visualization": [
        12.071118839071428,
        15.946413075454142
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "Learning creative hands-on skills, like origami, can be difficult for beginners. Conventional instructional methods often fail to support the experiential aspect of learning with timely and personalized feedback. Despite recent advancement of AI and Extended Reality in many fields, there is a lack of research on supporting learning in creative hands-on tasks. We investigate an AI-augmented Mixed Reality approach for learning hands-on creative tasks by introducing Origami Sensei as an approach for learning origami. Origami Sensei identifies the current step and relative locations of the paper using origami detection models, and projects real-time, personalized instructions directly onto the paper. We conducted a user study (n=18) comparing it with traditional video tutorials. Our findings show that participants prefer Origami Sensei, and it increases task efficiency and learner engagement. We introduce design insights for developing AI-augmented MR systems and highlight the potential for extending this approach to other creative hands-on tasks.",
    "title": "Origami Sensei: A Mixed Reality AI-Assistant",
    "id": 188818,
    "sequence": 609,
    "queryCoordinates": {
      "visualization": [
        -3.956074890600413,
        4.511038844873864
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "This paper introduces Friction, a novel interface designed to scaffold novice writers in reflective feedback-driven revisions. Effective revision requires mindful reflection upon feedback, but the scale and variability of feedback can make it challenging for novice writers to decipher it into actionable, meaningful changes. Friction leverages large language models to break down large feedback collections into manageable units, visualizes their distribution across sentences and issues through a co-located heatmap, and guides users through structured reflection and revision with adaptive hints and real-time evaluation. Our user study (N=16) showed that Friction helped users allocate more time to reflective planning, attend to more critical issues, develop more actionable and satisfactory revision plans, iterate more frequently, and ultimately produce higher-quality revisions, compared to the baseline system. These findings highlight the potential of human-AI collaboration to foster a balanced approach between maximum efficiency and deliberate reflection, supporting the development of creative mastery.",
    "title": "Friction: Deciphering Writing Feedback into Writing Revisions through LLM-Assisted Reflection",
    "id": 188819,
    "sequence": 610,
    "queryCoordinates": {
      "visualization": [
        -14.627356091256491,
        6.483861024079839
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "Improving standing balance is critical for preventing falls and ensuring the well-being of older adults. In this paper, we present Invisible Light Touch (ILT), a mid-air haptic feedback application designed to improve standing balance by utilizing the light touch effect, a well-documented phenomenon in medical research. The light touch effect refers to improved balance when a person lightly touches a surface, such as a wall or handrail, with a force of 1 N or less. We replicate this effect utilizing focused ultrasound to create a tactile point in mid-air. When users interact with this invisible tactile point, they experience the light touch effect, which subsequently improves their balance. We conducted a pilot study with 29 participants and a user study with 25 older adults, evaluating the balance improvement by measuring the center of pressure trajectory. The results confirmed that standing balance improved significantly when using the ILT.",
    "title": "Invisible Light Touch: Standing Balance Improvement by Mid-Air Haptic Feedback",
    "id": 188820,
    "sequence": 611,
    "queryCoordinates": {
      "visualization": [
        15.705952052691876,
        -6.505618350206523
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "With the rise of online learning, many novice tutors lack experience engaging students remotely. We introduce TutorUp, a Large Language Model (LLM)-based system that enables novice tutors to practice engagement strategies with simulated students through scenario-based training. Based on a formative study involving two surveys (N1=86, N2=102) on student engagement challenges, we summarize scenarios that mimic real teaching situations. To enhance immersion and realism, we employ a prompting strategy that simulates dynamic online learning dialogues. TutorUp provides immediate and asynchronous feedback by referencing tutor-students online session dialogues and evidence-based teaching strategies from learning science literature. In a within-subject evaluation (N=16), participants rated TutorUp significantly higher than a baseline system without simulation capabilities regarding effectiveness and usability. Our findings suggest that TutorUp provides novice tutors with more effective training to learn and apply teaching strategies to address online student engagement challenges. ",
    "title": "TutorUp: What If Your Students Were Simulated? Training Tutors to Address Engagement Challenges in Online Learning",
    "id": 188821,
    "sequence": 612,
    "queryCoordinates": {
      "visualization": [
        -2.739313676139587,
        18.801493573216852
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "As artificial intelligence (AI) continues to transform the modern workplace, generative AI (GenAI) has emerged as a prominent tool capable of augmenting work processes. Defined by its ability to create or modify content, GenAI differs significantly from traditional machine learning models that classify, recognize, or predict patterns from existing data. This study explores the role of GenAI in shaping perceptions of AI’s contribution and how these perceptions influence both creators’ internal assessments of their work and their anticipation of external evaluators’ assessments. Our research develops and empirically tests a structural model through a between-subjects experiment, revealing that the role GenAI plays in the work process significantly impacts perceived enhancements in work quality and effort relative to human input. Additionally, we identify a critical trade-off between fostering worker assessments of creativity and managing perceived external assessments of the work’s value.",
    "title": "How the Role of Generative AI Shapes Perceptions of Value in Human-AI Collaborative Work",
    "id": 188822,
    "sequence": 613,
    "queryCoordinates": {
      "visualization": [
        1.9606357775119634,
        -20.90827365776381
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "Despite many HCI studies of diverse factors shaping users’ navigation experiences, how to design navigation systems to be adaptable to all of these factors remains a challenge. To address this challenge, we study general variations in users’ intended navigation experiences. Based on 30 interviews, we find that interactions with navigation apps can be subsumed under three “modes”: follow, modify, and background. For each mode of interaction, we highlight users’ key motivations, interactions with apps, and challenges. We propose these modes as higher-level concepts for exploring how to enable the details of navigation support to be adaptable to users’ generally intended navigation experiences. We discuss broader implications for issues of efficiency and overreliance in our experience of the physical environments through navigation apps.",
    "title": "Modes of Interaction with Navigation Apps",
    "id": 188823,
    "sequence": 614,
    "queryCoordinates": {
      "visualization": [
        -19.996144809641297,
        -0.3926738492125658
      ]
    }
  },
  {
    "session": "Visualization and Language Communication",
    "abstract": "Metacognition, or the awareness and regulation of one's own cognitive processes, allows individuals to take command of their learning and decision making in various contexts. In tasks that require problem-solving and adaptive learning,  individuals with heightened metacognitive awareness tend to outperform others, as they are better equipped to regulate cognition, leading to more effective processes. On the other hand, visualization research facilitates exploration and decision making with data. We posit that metacognitive frameworks that examine how individuals think about their own thinking processes can likewise enhance visualization processes. In this paper, we review metacognition literature from the cognitive and learning science to identify opportunities in visualization to improve people's ability to reason with data. We propose the use of a metacognitive framework, serving as a starting point to inspire future research to improve visualization practices and outcomes.",
    "title": "A Novel Lens on Metacognition in Visualization",
    "id": 188824,
    "sequence": 615,
    "queryCoordinates": {
      "visualization": [
        -10.000264194352853,
        -14.966453021445806
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "In a 'digital by default’ society, essential services must be accessed online. This opens users to digital deception not only from criminal fraudsters but from a range of actors in a marketised digital economy. Using grounded empirical research from northern England, we show how supposedly 'trusted' actors, such as governments, (re)produce the insecurities and harms that they seek to prevent. Enhanced by a weakening of social institutions amid a drive for efficiency and scale, this has built a constricted, unpredictable digital channel. We conceptualise this as a ''snipers' alley''. Four key snipers articulated by participants' lived experiences are examined: 1) Governments; 2) Business; 3) Criminal Fraudsters; and 4) Friends and Family to explore how snipers are differentially experienced and transfigure through this constricted digital channel. We discuss strategies to re-configure the alley, and how crafting and adopting opportunity models can enable more equitable forms of security for all.",
    "title": "Friend or Foe? Navigating and Re-configuring ``Snipers' Alley''",
    "id": 188825,
    "sequence": 616,
    "queryCoordinates": {
      "visualization": [
        -7.05833676861923,
        -10.916953881956168
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "With the rapid development and release of generative AI (genAI) applications, policy discourses primarily take place on an expert level. Little space is given to laypeople - who have to adapt to and adopt the genAI innovations - to share their opinions and experiences. Addressing this gap, we organized 6h/3.5h laypeople dialogues in Nigeria, Japan, and Germany in July and August 2024. During the dialogues, participants discussed what a desirable future in light of genAI development could look like in one of three contexts: education, public service, and arts & culture. Participants explored the consequences of technology deployment, assessed the risks, mapped stakeholders, and derived measures to achieve a desirable goal. This study contributes to policy debates on genAI by providing recommendations derived from participants' identified requirements and suggested measures for genAI to create value and to foster a socially desirable future. We reflect on the results through a cross-national lens.",
    "title": "Initiating the Global AI Dialogues: Laypeople Perspectives on the Future Role of genAI in Society from Nigeria, Germany and Japan",
    "id": 188826,
    "sequence": 617,
    "queryCoordinates": {
      "visualization": [
        8.496093553872495,
        12.361892829330234
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "What-if analysis (WIA) is essential for data-driven decision-making, allowing users to assess how changes in variables impact outcomes and explore alternative scenarios. Existing WIA research primarily supports the workflows of data scientists and analysts, and largely overlooks business professionals who engage in WIA through non-technical means. To bridge this gap, we conduct a two-part user study with 22 business professionals across marketing, sales, product, and operations roles. The first study examines their existing WIA practices, tools, and challenges. Findings reveal that business professionals perform many WIA techniques independently using rudimentary tools due to various constraints. We then implement representative WIA techniques in a visual analytics prototype and use it as a probe to conduct a follow-up study evaluating business professionals' practical use of the techniques. Results show that these techniques improve decision-making efficiency and confidence while underscoring the need for better support in data preparation, risk assessment, and domain knowledge integration. Finally, we offer design recommendations to enhance future business analytics systems.",
    "title": "What-if Analysis for Business Professionals: Current Practices and Future Opportunities",
    "id": 188827,
    "sequence": 618,
    "queryCoordinates": {
      "visualization": [
        1.1767073490094664,
        13.95046091764667
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "Providing haptic feedback for soft, deformable objects is challenging, requiring complex mechanical hardware combined with modeling and rendering software.\r\nAs an alternative, we advance the concept of self-haptics, where the user's own body delivers physical feedback, to convey dynamically varying softness in VR.\r\nSkin can exhibit different levels of contact softness by altering the biomechanical state of the body.\r\nWe propose SkinHaptics, a device-free approach that changes the states of musculoskeletal structures and virtual hand-object representations.\r\nIn this study, we conduct three experiments to demonstrate SkinHaptics.\r\nUsing the same scale, we measure skin softness across various hand poses and contact points and evaluate the just noticeable difference in skin softness.\r\nWe investigate the effect of hand-object representations on self-haptic interactions.\r\nOur findings indicate that the visual representations have a significant influence on the embodiment of a self-haptic hand, and the degree of the hand embodiment strongly affects the haptic experience.",
    "title": "SkinHaptics: Exploring Skin Softness Perception and Virtual Body Embodiment Techniques to Enhance Self-Haptic Interactions",
    "id": 188828,
    "sequence": 619,
    "queryCoordinates": {
      "visualization": [
        4.286183061301,
        -19.535317626417452
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "Uncertainty inherently exists in the autonomous decision-making process of robots. Involving humans in resolving this uncertainty not only helps robots mitigate it but is also crucial for improving human-robot interactions. However, in public urban spaces filled with unpredictability, robots often face heightened uncertainty without direct human collaborators. This study investigates how robots can engage bystanders for assistance in public spaces when encountering uncertainty and examines how these interactions impact bystanders' perceptions and attitudes towards robots. We designed and tested a speculative `peephole' concept that engages bystanders in resolving urban robot uncertainty. Our design is guided by considerations of non-intrusiveness and eliciting initiative in an implicit manner, considering bystanders' unique role as non-obligated participants in relation to urban robots. Drawing from field study findings, we highlight the potential of involving bystanders to mitigate urban robots' technological imperfections to both address operational challenges and foster public acceptance of urban robots. Furthermore, we offer design implications to encourage bystanders' involvement in mitigating the imperfections.",
    "title": "Peek into the `White-Box': A Field Study on Bystander Engagement with Urban Robot Uncertainty",
    "id": 188829,
    "sequence": 620,
    "queryCoordinates": {
      "visualization": [
        -6.126563953361277,
        -3.3860322097366775
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "Older adults often struggle to meet their psychological needs due to retirement and living alone. Recent studies suggest that games featuring emotional challenge (EC) can help fulfill basic psychological needs such as autonomy, competence, and relatedness by facilitating emotional exploration. However, it remains unclear whether older adults can benefit from EC games, whether they find this genre enjoyable, and how these games should be designed to better meet their needs. This work explores older adults’ experiences and perceptions of playing EC games through two studies. The first study involved playing Detroit: Become Human, revealing that older adults derived multifaceted psychological experiences from playing the game. The second study involved a custom-designed game scenario tailored to older adults, demonstrating that meaningful choices significantly influenced autonomy need satisfaction. Based on these findings, we offer five design guidelines for developing EC games that satisfy psychological needs of older adults.",
    "title": "Emotionally Challenging Games Can Satisfy Older Adults' Psychological Needs: From Empirical Study to Design Guidelines",
    "id": 188830,
    "sequence": 621,
    "queryCoordinates": {
      "visualization": [
        15.764442278223058,
        -2.7353902201648284
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "The emergence of AI Image Generators (AIGs) has transformed image creation, making it more accessible to generate customized images from simple text prompts. While HCI research has explored the applications of text-to-image generation, the role of AIGs in visual content creation workflow remains relatively underexplored. To address this, we conducted in-depth interviews with 26 end users who had experience across 14 different AIGs and investigated users’ adoption and perceptions of AIGs and AI’s role throughout the entire workflow. Key factors examined include user goals, initial vision, tool integration, and decision-making. Our results indicated that functional goals often drive cross-tool integration to achieve desired outcomes, while in use cases motivated by recreational goals, the usage of AIGs influences the social implications of image sharing. We concluded with four distinct use cases, each highlighting how AIGs are integrated at different stages of the creative process based on varying user goals and visions.",
    "title": "Understanding User Perceptions and the Role of AI Image Generators in Image Creation Workflows",
    "id": 188831,
    "sequence": 622,
    "queryCoordinates": {
      "visualization": [
        5.718219597103946,
        12.778965710858465
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "To ensure that technology serves as a tool for empowerment rather than oppression, Human-Computer Interaction (HCI) scholars have examined the ethical considerations of HCI research to explore pathways that inspire social change. In this work, we consider post-secondary education as one such pathway to social change. We engaged in a qualitative content analysis of the course, Introduction to Social Justice Informatics, with 47 students to understand how students developed knowledge of social justice and what sociotechnical tools facilitated their learning. We found that course materials coupled with peer discussion and reflective practice contributed to their development of critical consciousness. We discuss the significance of critical consciousness as a grounding theoretical approach within a social justice computing curriculum and the role of hope within social justice efforts and the workplace. We conclude by providing collectivist design strategies to nurture hope in the workplace. ",
    "title": "Embracing Social Justice within a Computing Curriculum to Foster Social Change",
    "id": 188832,
    "sequence": 623,
    "queryCoordinates": {
      "visualization": [
        -8.01497666206281,
        18.323759142342723
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "Community and organizational policies are typically designed in a top-down, centralized fashion, with limited input from impacted stakeholders. This can result in policies that are misaligned with community needs or perceived as illegitimate. How can we support more collaborative, participatory approaches to policy design? In this paper, we present PolicyCraft, a system that structures collaborative policy design through case-grounded deliberation. Building on past research that highlights the value of concrete cases in establishing common ground, PolicyCraft supports users in collaboratively proposing, critiquing, and revising policies through discussion and voting on cases. A field study across two university courses showed that students using PolicyCraft reached greater consensus and developed better-supported course policies, compared with those using a baseline system that did not scaffold their use of concrete cases. Reflecting on our findings, we discuss opportunities for future HCI systems to help groups more effectively bridge between abstract policies and concrete cases.",
    "title": "PolicyCraft: Supporting Collaborative and Participatory Policy Design through Case-Grounded Deliberation",
    "id": 188833,
    "sequence": 624,
    "queryCoordinates": {
      "visualization": [
        -1.111140466039204,
        1.6629392246050907
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Workplace incivility—low-intensity deviant behavior that violates norms of mutual respect—harms workers, though social support can alleviate this. Both incivility and support-seeking are shaped by the communication environment, which has been profoundly altered by remote and hybrid work, yet the outcomes of these changes are not well understood. Using surveys and interviews, we investigated USA remote and hybrid workers' experiences with three types of cyber incivility (hostility, gossip, and exclusion), and follow-up support. We found cyber incivility experiences are more common among workers who spend more time at the office, and among women than men. We also discover that digital communication tools reduce some harms but exacerbate others, and that support-seeking is effective but harder to access remotely. Based on these findings, we propose implications for digital communication tools and policies to reduce cyber incivility and improve support access, fostering a more respectful and supportive remote work environment.",
    "title": "Understanding Cyber Hostility, Gossip, Exclusion, and Social Support in Remote and Hybrid Work Settings: Benefits and Challenges of Remote Work",
    "id": 188834,
    "sequence": 625,
    "queryCoordinates": {
      "visualization": [
        16.633932607670353,
        3.5088867185306754
      ]
    }
  },
  {
    "session": "Pointing and Selection",
    "abstract": "Free-hand interactions have been widely deployed for AR/VR interfaces to promote a natural and seamless interaction experience. Among various types of hand interactions, microgestures are still limited in supporting discrete inputs and in lacking a continuous interaction theme. To this end, we propose a new pointing technique, T2IRay, which enables continuous indirect pointing through microgestures for continuous spatial input. We employ our own local coordinate system based on the thumb-to-index finger relationship to map the computed raycasting direction for indirect pointing in a virtual environment. Furthermore, we examine various mapping methodologies and collect thumb-click behaviors to formulate thumb-to-index microgesture design guidelines to foster continuous, reliable input. We evaluate the design parameters for mapping indirect pointing with acceptable speed, depth, and range. We collect and analyze the characteristics of click behaviors for future implementation. Our research demonstrates the potential and practicality of free-hand micro-finger input methods for advancing future interaction paradigms.",
    "title": "T2IRay: Design of Thumb-to-Index based Indirect Pointing for Continuous and Robust AR/VR Input",
    "id": 188835,
    "sequence": 626,
    "queryCoordinates": {
      "visualization": [
        14.56898217659937,
        -15.124310177258659
      ]
    }
  },
  {
    "session": "Well-being and Tracking",
    "abstract": "Health information technologies are transforming how mental healthcare is paid for through value-based care programs, which tie payment to data quantifying care outcomes. But, it is unclear what outcomes data these technologies should store, how to engage users in data collection, and how outcomes data can improve care. Given these challenges, we conducted interviews with 30 U.S.-based mental health clinicians to explore the design space of health information technologies that support outcomes data specification, collection, and use in value-based mental healthcare. Our findings center clinicians’ perspectives on aligning outcomes data for payment programs and care; opportunities for health technologies and personal devices to improve data collection; and considerations for using outcomes data to hold stakeholders including clinicians, health insurers, and social services financially accountable in value-based mental healthcare. We conclude with implications for future research designing and developing technologies supporting value-based care across stakeholders involved with mental health service delivery.",
    "title": "Designing Technologies for Value-based Mental Healthcare: Centering Clinicians' Perspectives on Outcomes Data Specification, Collection, and Use",
    "id": 188836,
    "sequence": 627,
    "queryCoordinates": {
      "visualization": [
        -12.52252041361771,
        3.4909142771669006
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "Social virtual reality (VR) platforms offer unique features that can foster interpersonal relationships that are \"closer than real.\" This study investigates how these platform features influence friendship dynamics in social VR. Through semi-structured interviews with 23 Japanese VRChat users, we explored the characteristics of close relationships formed in social VR, the processes of relationship development, and the role of platform features in shaping these dynamics. Our findings reveal that social VR facilitates a form of selective self-presentation and co-presence through embodied avatars and rich environmental contexts, which can lead to rapid and intense friendship formation. Users reported developing close bonds without relying on real-life background information, instead focusing on perceived familiarity and compatibility within the virtual space, highlighted by the avatar's appearance. Further, platform features such as ``join'' functions that allow users to teleport to friends' locations,  were assigned special meanings by users, contributing to developing friendships.",
    "title": "\"Closer than Real\": How Social VR Platform Features Influence Friendship Dynamics",
    "id": 188837,
    "sequence": 628,
    "queryCoordinates": {
      "visualization": [
        -9.465832400385247,
        8.91055649035552
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "Every interaction has become uncanny. Discourse, the pattern of interactions between two parties, has moved into a space on the boundaries of self and other.   We identify the Uncanny Discourse to bring these concepts together to further human-computer interaction research.  Interactions, whether mediated by information and communication technologies or not, have always been necessarily between two spaces.  Now, the diametric conflict of those two spaces has become at once obvious and unsettlingly unknown.  Interaction has become real and synthetic; informing and deceiving; and clear and cryptic. Sliding between these spaces is uncanny.\r\n\r\nWe raise a challenge for researchers in interaction - face the uncanny. Incorporate it in your design, in your research. And intentionally choose between strengthening the uncanny and mitigating it.\r\n",
    "title": "Uncanny Discourse: A New Space for Research in Interaction",
    "id": 188838,
    "sequence": 629,
    "queryCoordinates": {
      "visualization": [
        8.758368872374021,
        -8.203107624274462
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Although intended to foster spontaneous interactions among workers, a typical open-plan office layout cannot mitigate visual, acoustic, or privacy-related distractions that originate from unplanned meetings. \r\nAs office workers often refrain from tackling these issues by manually demarcating or physically relocating to a more suitable subspace that is enclosed by movable partitions, we hypothesise that these subspaces could instead be robotically manifested. This study therefore evaluated the perceived impact of two mobile robotic partitions that were wizarded to jointly manifest an enclosed subspace, to: 1) either `mitigate' or `intervene' in the distractions caused by spontaneous face-to-face or remote meetings; or 2) either `gesturally' or `spatially' nudge a distraction-causing worker to relocate.\r\nOur findings suggest how robotic furniture should interact with office workers with and through transient space, and autonomously balance the distractions not only for each individual worker but also for multiple workers sharing the same workspace.",
    "title": "Manifesting Architectural Subspaces with Two Mobile Robotic Partitions to Facilitate Spontaneous Office Meetings",
    "id": 188839,
    "sequence": 630,
    "queryCoordinates": {
      "visualization": [
        10.173244508476383,
        -9.617956964488618
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "Given the widespread presence of screens during meals, the notion that digital engagement is inherently incompatible with mindfulness. We demonstrate how the strategic design of digital content can enhance two core aspects of mindful eating: slow eating and food awareness. Our research unfolded in three sequential studies: (1). Zoom Eating Study: Contrary to the assumption that video-watching leads to distraction and overeating, this study revealed that subtle video speed manipulations—can promote slower eating (by 15.31%) and controlled food intake (by 9.65%) while maintaining meal satiation and satisfaction. (2). Co-design workshop: Informed the development of ViFeed, a video playback system strategically incorporating subtle speed adjustments and glanceable visual cues. (3). Field Study: A week-long deployment of ViFeed in daily eating demonstrated its efficacy in fostering food awareness, food appreciation, and sustained engagement. By bridging the gap between ideal mindfulness practices and screen-based behaviors, this work offers insights for designing digital-wellbeing interventions that align with, rather than against, existing habits.",
    "title": "ViFeed: Promoting Slow Eating and Food Awareness through Strategic Video Manipulation during Screen-Based Dining",
    "id": 188840,
    "sequence": 631,
    "queryCoordinates": {
      "visualization": [
        18.379691860083827,
        10.158096629210037
      ]
    }
  },
  {
    "session": "WS17: Human-Centered Evaluation and Auditing of Language Models",
    "abstract": "The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues and guide future model development, responsible evaluation and auditing of LLMs are essential. This workshop aims to address the current \"evaluation crisis\" in LLM research and practice by bringing together HCI and AI researchers and practitioners to rethink LLM evaluation and auditing from a human-centered perspective. The workshop will explore topics around understanding stakeholders' needs and goals with evaluation and auditing LLMs, establishing human-centered evaluation and auditing methods, developing tools and resources to support these methods, building community and fostering collaboration. By soliciting papers, organizing invited keynote and panel, and facilitating group discussions, this workshop aims to develop a future research agenda for addressing the challenges in LLM evaluation and auditing. Following a successful first iteration of this workshop at CHI 2024, we introduce the theme of \"mind the context\" for this second iteration, where participants will be encouraged to tackle the challenges and nuances of LLM evaluation and auditing in specific contexts.",
    "title": "Human-Centered Evaluation and Auditing of Language Models",
    "id": 188841,
    "sequence": 632,
    "queryCoordinates": {
      "visualization": [
        -8.565056918547304,
        6.902159081189375
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "Traditional AI-assisted decision-making systems often provide fixed recommendations that users must either accept or reject entirely, limiting meaningful interaction—especially in cases of disagreement. To address this, we introduce Human-AI Deliberation, an approach inspired by human deliberation theories that enables dimension-level opinion elicitation, iterative decision updates, and structured discussions between humans and AI. At the core of this approach is Deliberative AI, an assistant powered by large language models (LLMs) that facilitates flexible, conversational interactions and precise information exchange with domain-specific models. Through a mixed-methods user study, we found that Deliberative AI outperforms traditional explainable AI (XAI) systems by fostering appropriate human reliance and improving task performance. By analyzing participant perceptions, user experience, and open-ended feedback, we highlight key findings, discuss potential concerns, and explore the broader applicability of this approach for future AI-assisted decision-making systems.",
    "title": "Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making",
    "id": 188842,
    "sequence": 633,
    "queryCoordinates": {
      "visualization": [
        -11.032648715793073,
        -11.587953327223468
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "Immersive technologies are capable of transporting people to distant or inaccessible environments that they might not otherwise visit. Practitioners and researchers alike are discovering new ways to replicate and enhance existing tourism experiences using virtual reality, yet few controlled experiments have studied how users perceive virtual tours of real-world locations. In this paper we present an initial exploration of a new system for virtual tourism, measuring the effects of real-time experiences and storytelling on presence, place attachment, and user memories of the destination. Our results suggest that narrative plays an important role in inducing presence within and attachment to the destination, while livestreaming can further increase place attachment while providing flexible, tailored experiences. We discuss the design and evaluation of our system, including feedback from our tourism partners, and provide insights into current limitations and further opportunities for virtual tourism.",
    "title": "Virtual Voyages: Evaluating the Role of Real-Time and Narrated Virtual Tours in Shaping User Experience and Memories",
    "id": 188843,
    "sequence": 634,
    "queryCoordinates": {
      "visualization": [
        -15.38841367211304,
        -9.337918646889381
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "Mobile Augmented Reality (AR) offers a powerful way to provide spatially-aware guidance for real-world applications. In many cases, these applications involve the configuration of a camera or articulated subject, asking users to navigate several spatial degrees of freedom (DOF) at once. Most guidance for such tasks relies on decomposing available DOF into subspaces that can be more easily mapped to simple 1D or 2D visualizations. Unfortunately, different factorizations of the same motion often map to very different visual feedback, and finding the factorization that best matches a user’s intuition can be difficult. We propose an interactive approach that infers rotational degrees of freedom from short user demonstrations. Users select one or two DOFs at a time by demonstrating a small range of motion, which we use to learn a rotational frame that best aligns with user control of the object. We show that deriving visual feedback from this inferred learned rotational frame leads to improved task completion times on 6DOF guidance tasks compared to standard default reference frames used in most mixed reality applications.",
    "title": "ARticulate: Interactive Visual Guidance for Demonstrated Rotational Degrees of Freedom in Mobile AR",
    "id": 188844,
    "sequence": 635,
    "queryCoordinates": {
      "visualization": [
        1.1753739745783724,
        -9.930684569549262
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "Blind or low-vision (BLV) screen-reader users have a significantly limited experience interacting with desktop websites compared to non-BLV, i.e., sighted users. This digital divide is exacerbated by the incapability to browse the web spatially—an affordance that leverages spatial reasoning, which sighted users often rely on. In this work, we investigate the value of and opportunities for BLV screen-reader users to browse websites spatially (e.g., understanding page layouts). We additionally explore at-scale website layout understanding as a feature of desktop screen readers. We created a technology probe, WebNExt, to facilitate our investigation. Specifically, we conducted a lab study with eight participants and a five-day field study with four participants to evaluate spatial browsing using WebNExt. Our findings show that participants found spatial browsing intuitive and fulfilling, strengthening their connection to the design of web pages. Furthermore, participants envisioned spatial browsing as a step toward reducing the digital divide.",
    "title": "\"It Brought Me Joy\": Opportunities for Spatial Browsing in Desktop Screen Readers",
    "id": 188845,
    "sequence": 636,
    "queryCoordinates": {
      "visualization": [
        21.410336646256873,
        -5.0593956846593855
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "This study explores users’ perceptions of integrating a personal data store to enhance personalized recommendations within a streaming service. Using a research-through-design approach and guided by Human Data Interaction principles (legibility, agency, and negotiability), we developed an enhanced streaming service prototype. This prototype was evaluated by experts (n=5), refined, and then used in two focus groups (n=19) to gauge participants’ reactions to the personal data store integration and their willingness to share different data types for enhanced personalized streaming recommendations. The focus groups revealed mixed reactions to the personal data store, with users weighing curiosity against concerns. However, many of the implemented data transparency and control features helped to mitigate these doubts. By linking our findings to existing literature, we developed a set of design recommendations to help businesses and guide future research in building personal data store applications, further advancing the field of Human Data Interaction.",
    "title": "Exploring Users’ Perspectives on a Solid-Enabled Personal Data Store Enhanced Streaming Service",
    "id": 188846,
    "sequence": 637,
    "queryCoordinates": {
      "visualization": [
        -20.179263760847093,
        5.813545739921831
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "What if our clothes could capture our body motion accurately? This paper introduces Flexible Inertial Poser (FIP), a novel motion-capturing system using daily garments with two elbow-attached flex sensors and four Inertial Measurement Units (IMUs). To address the inevitable sensor displacements in loose wearables which degrade joint tracking accuracy significantly, we identify the distinct characteristics of the flex and inertial sensor displacements and develop a Displacement Latent Diffusion Model and a Physics-informed Calibrator to compensate for sensor displacements based on such observations, resulting in a substantial improvement in motion capture accuracy. We also introduce a Pose Fusion Predictor to enhance multimodal sensor fusion. Extensive experiments demonstrate that our method achieves robust performance across varying body shapes and motions, significantly outperforming SOTA IMU approaches with a 19.5% improvement in angular error, a 26.4% improvement in elbow angular error, and a 30.1% improvement in positional error. FIP opens up opportunities for ubiquitous human-computer interactions and diverse interactive applications such as Metaverse, rehabilitation, and fitness analysis. Our project page can be seen at https://fangjw-0722.github.io/FIP.github.io/",
    "title": "FIP: Endowing Robust Motion Capture on Daily Garment by Fusing Flex and Inertial Sensors",
    "id": 188847,
    "sequence": 638,
    "queryCoordinates": {
      "visualization": [
        -0.39257448628802516,
        -8.99143399423672
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators' plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors' efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.",
    "title": "PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale",
    "id": 188848,
    "sequence": 639,
    "queryCoordinates": {
      "visualization": [
        -1.943841439226113,
        -7.760250025556352
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "Video components are a central element of user interfaces that deliver content in a signed language (SL), but the potential of video components extends beyond content accessibility. SL videos may be designed as user interface elements: layered with interactive features to create navigation cues, page headings, and menu options. To be effective for signing users, novel SL video-rich interfaces require informed design choices across many parameters. To align with the specific needs and shared conventions of the Deaf community and other ASL-signers in this context, we present a user study involving deaf ASL-signers who interacted with an array of designs for SL video elements. Their responses offer some insights into how the Deaf community may perceive and prefer video elements to be designed, positioned, and implemented to guide user experiences. \r\nThrough a qualitative analysis, we take initial steps toward understanding deaf ASL-signers’ perceptions of a set of emerging design principles, paving the way for future SL-centric user interfaces containing customized video elements and layouts with primary consideration for signed language-related usage and requirements.",
    "title": "Perceptions and Preferences: Deaf ASL-Signing Users' Insights on Video Elements, Styles and Layouts",
    "id": 188849,
    "sequence": 640,
    "queryCoordinates": {
      "visualization": [
        -2.7369301092840215,
        16.778236307100176
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "Self-directed learning of computational skills online poses significant challenges, particularly the lack of effective tools for tracking progress and fostering reflection. To address this, we designed and implemented MILESTONES, a semi-automated self-monitoring tool that tracks online learning sessions and organizes web resources through three visual overviews: Time Pulse, Cue-Connect, and Sortify. In a week-long field deployment study (N=17), learners found MILESTONES intuitive and effective, even without prior experience with self-monitoring. The on-demand visual overviews encouraged learners to pause, reflect, and adjust their learning habits to better align with their goals. These overviews further fostered micro-reflections - brief, spontaneous reflections during learning. We also explored the role of a companion journal, which, although used inconsistently, helped learners form and reflect on their goals after learning sessions. Our findings contribute insights for designing learner-centered semi-automatic self-monitoring tools that can cater to diverse learning needs.",
    "title": "MILESTONES: The Design and Field Evaluation of a Semi-Automated Tool for Promoting Self-Directed Learning Among Online Learners",
    "id": 188850,
    "sequence": 641,
    "queryCoordinates": {
      "visualization": [
        -3.496870694341175,
        13.55624930971166
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "Serious games, particularly board games, have long been employed in production management education to teach various concepts. While they have demonstrated educational effectiveness, their integration with emerging Industry 4.0 technologies remains limited. Furthermore, there is a lack of empirical research on how industry practitioners apply these digitization technologies in the workplace. To bridge this gap, we designed a course that integrates digital technologies into a traditional board game. We conducted two studies to evaluate both knowledge gains within the classroom and knowledge transfer back into the manufacturing industry. Our results show an improved understanding of the synergies between production management principles and Industry 4.0 technologies, as well as the real-world challenges students face when attempting to transfer this knowledge. Our work contributes pedagogical and practical perspectives on how technology-enhanced serious games can extend learning in and beyond the classroom.",
    "title": "\"It's impressive, but in practice ...\": Experiencing a Realistic Digital Transformation in and Beyond the Classroom",
    "id": 188851,
    "sequence": 642,
    "queryCoordinates": {
      "visualization": [
        -15.124310177258652,
        -14.568982176599379
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "Community health workers (CHWs) provide last-mile healthcare services but face challenges due to limited medical knowledge and training. This paper describes the design, deployment, and evaluation of ASHABot, an LLM-powered, experts-in-the-loop, WhatsApp-based chatbot to address the information needs of CHWs in India. Through interviews with CHWs and their supervisors and log analysis, we examine factors affecting their engagement with ASHABot, and ASHABot's role in addressing CHWs' informational needs. We found that ASHABot provided a private channel for CHWs to ask rudimentary and sensitive questions they hesitated to ask supervisors. CHWs trusted the information they received on ASHABot and treated it as an authoritative resource. CHWs' supervisors expanded their knowledge by contributing answers to questions ASHABot failed to answer, but were concerned about demands on their workload and increased accountability. We emphasize positioning LLMs as supplemental fallible resources within the community healthcare ecosystem, instead of as replacements for supervisor support.\r\n",
    "title": "ASHABot: An LLM-Powered Chatbot to Support the Informational Needs of Community Health Workers",
    "id": 188852,
    "sequence": 643,
    "queryCoordinates": {
      "visualization": [
        9.930684569549262,
        1.1753739745783764
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "As computer-mediated communication tools have evolved from beepers to 2G cell phones, and now to today's smartphones, people have consistently embraced these technologies to maintain relationships and enhance the convenience of their daily lives. However, while contemporary communication technologies clearly diverge from their traditional roles, few studies have critically examined their effects, particularly in relation to communication quality and relationships. To address what contemporary technologies may have overlooked, our study revisits retro communication technologies—specifically, the beeper. We recreated the beeper experience through BeeperRedux, a mobile application, and conducted a two-week deployment study involving ten groups. Our findings highlight three valuable aspects of retro communication technologies: fostering sincerity, restoring recipients' autonomy over their communication, and prioritizing offline engagement. In the discussion, we present design guidelines for improving technology-mediated communication and offer methodological reflections on recreating obsolete technology to empirically explore past experiences.",
    "title": "Back to the 1990s, BeeperRedux!:  Revisiting Retro Technology to Reflect Communication Quality and Experience in the Digital Age",
    "id": 188853,
    "sequence": 644,
    "queryCoordinates": {
      "visualization": [
        4.952484357652732,
        -10.930365899054113
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "Online fraud substantially harms individuals and seniors are disproportionately targeted. While family is crucial for seniors, little research has empirically examined how they protect seniors against fraud. To address this gap, we employed an inductive thematic analysis of 124 posts and 16,872 comments on RedNote (Xiaohongshu), exploring the family support ecosystem for senior-targeted online fraud in China. We develop a taxonomy of senior-targeted online fraud from a familial perspective, revealing younger members often spot frauds hard for seniors to detect, such as unusual charges. Younger family members fulfill multiple safeguarding roles, including preventative measures, fraud identification, fraud persuasion, loss recovery, and education. They also encounter numerous challenges, such as seniors' refusal of help and considerable mental and financial stress. Drawing on these, we develop a conceptual framework to characterize family support in senior-targeted fraud, and outline implications for researchers and practitioners to consider the broader stakeholder ecosystem and cultural aspects.",
    "title": "\"Auntie, Please Don't Fall for Those Smooth Talkers\": How Chinese Younger Family Members Safeguard Seniors from Online Fraud",
    "id": 188854,
    "sequence": 645,
    "queryCoordinates": {
      "visualization": [
        -19.811386808871546,
        2.740246833639361
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "Deadnaming is the act of referring to a transgender person by a name they no longer identify with. When carried out by administrative technologies, deadnaming can be a strategy of control which demands legible and singular identification. Interfaces that introduce 'lived name' fields are insufficient at best and violent at worst, as demonstrated by a close read of the University of California Gender Recognition and Lived Name Policy; under the guise of a solution, they produce arbitrary binaries and force trans people to fulfill the impossible task of making themselves readable to an opaque system. By embracing the mutability of names, trans people reveal points of breakdown which allow HCI researchers to envision alternative technologies focused on glitching, evasion, and multiplicity rather than surveillance and presumed accuracy.",
    "title": "Name is a Required Field: Politics of Deadnaming in Administrative Systems",
    "id": 188855,
    "sequence": 646,
    "queryCoordinates": {
      "visualization": [
        8.7866640640794,
        -1.9479565254429259
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "Social difficulties have become an increasingly serious issue among older adults. For older adults, regular self-disclosure is essential for maintaining mental health and building close relationships. Leveraging conversational agents to encourage self-disclosure in older adults has shown increasing potential. Understanding how LLM-based agents can influence and stimulate self-disclosure across different topics is crucial for designing future agents tailored to older users. This study introduces Disclosure-Agent, an LLM-based conversational agent, and examines its impact on self-disclosure in older adults through a user study involving 20 participants, 8 topics, and two interactive interfaces equipped with Disclosure-Agent. The findings provide valuable insights into how LLM-based agents can promote self-disclosure in older adults and offer design recommendations for future elderly-oriented conversational agents.",
    "title": "Exploring the Design of LLM-based Agent in Enhancing Self-disclosure Among the Older Adults",
    "id": 188856,
    "sequence": 647,
    "queryCoordinates": {
      "visualization": [
        1.6629392246050905,
        1.1111404660392044
      ]
    }
  },
  {
    "session": "Decision Making",
    "abstract": "In addition to ensuring patient safety during anesthetic inductions, anesthesiologists must document clinical interventions and administer drugs. This is a time-consuming and low priority task, which harms the documentation quality of anesthetic protocols. In this case study, we demonstrate how speech-based artificial intelligence (AI) assistants that leverage closed-loop communication can increase documentation quality. An evaluation in 40 scenarios in a medical high-fidelity simulator indicated that the AI documentation assistant facilitated earlier data entry and increased documentation precision. However, despite the objective advantages for data quality and patient safety, anesthesiologists experienced a higher temporal demand with the system. With this study, we contribute qualitative insights of how the AI documentation assistant benefited anesthesiologists' work style and affected their interactions within the team. Future research should aim to design AI assistants that enforce communication clarity while considering their impact on team dynamics.",
    "title": "Evaluating an AI Documentation Assistant for Anesthesiology Teams",
    "id": 188857,
    "sequence": 648,
    "queryCoordinates": {
      "visualization": [
        13.709819760008182,
        13.154498931851766
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "Today’s graphical user interfaces tend to be either simple but limited, or powerful but overly complex. In order to combine power and simplicity, we introduce Substrates, which act as “places for interaction” where users can manipulate objects of interest in a principled and predictable way. Substrates structure and contain data, enforce user-defined constraints among objects and manage dependencies with other substrates. Users can “tune” and “tweak” these relationships, “curry” specialized tools or abstract relationships into interactive templates. We first define substrates and provide in-depth descriptions with examples of their key characteristics. After explaining how Substrates extend the concept of Instrumental Interaction, we apply a Generative Theory of Interaction approach to analyze and critique existing interfaces and then show how using the concepts of Instruments and Substrates inspired novel design ideas in three graduate-level HCI courses. We conclude with a discussion and directions for future work.",
    "title": "Interaction Substrates: Combining Power and Simplicity in Interactive Systems",
    "id": 188858,
    "sequence": 649,
    "queryCoordinates": {
      "visualization": [
        -4.9845866686656395,
        0.3922954786392253
      ]
    }
  },
  {
    "session": "Workplace Interactions and Wellbeing",
    "abstract": "Playing games has been shown to be an effective method of post-work recovery. Previous research has shown that gameplay with high cognitive involvement is effective for recovery. This finding conflicts with models of mental workload (MWL), which suggest that people feel best when cycling between high and low MWL. To unpack the relationship between recovery and mental workload, we designed a lab experiment where 40 participants experienced different combinations of high and low MWL while undertaking both work tasks and recovery gameplay, and we collected both self-report and physiological (fNIRS) data. Results showed that high and low MWL games created different impacts on recovery, depending on the MWL of the prior work task. While fNIRS measurements of MWL varied as expected during work tasks, experience of MWL when playing games was not evident in the prefrontal cortex. We conclude by discussing the relationship between mental workload and theories of recovery.",
    "title": "Work Hard, Play Harder: Intense Games Enable Recovery from High Mental Workload Tasks",
    "id": 188859,
    "sequence": 650,
    "queryCoordinates": {
      "visualization": [
        7.983097498603993,
        -4.15573751911531
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "This paper offers new perspectives for More-Than-Human (MTH) design and Human-Computer-Interaction (HCI) by rethinking technoscientific logics of temporality. To do this, we draw on alternative logics such as Hydrofeminism, interlocutor and autobiographical accounts, and Leaky Cups—a set of willfully dysfunctional data-enabled artefacts that leak in response to local water data. In doing so, it repositions more-than-human agency not as a passive conduit merely mediating human experiences but as a force capable of creating change and ethics through non-progressivist care labor. By engaging with these ideas, this work critiques and disrupts normative assumptions about progress, openness, fluidity, and objectivity in MTH research and design, and presents productive tensions that challenge dominant temporal frameworks.",
    "title": "Leaky Cups: Tinkering with Hydrofeminist Temporalities for HCI",
    "id": 188860,
    "sequence": 651,
    "queryCoordinates": {
      "visualization": [
        13.993278136992087,
        -15.658485462546475
      ]
    }
  },
  {
    "session": "Robot and Agent",
    "abstract": "Large language model-based AI companions are increasingly viewed by users as friends or romantic partners, leading to deep emotional bonds. However, they can generate biased,  discriminatory, and harmful outputs. Recently, users are taking the initiative to address these harms and re-align AI companions. We introduce the concept of user-driven value alignment, where users actively identify, challenge, and attempt to correct AI outputs they perceive as harmful, aiming to guide the AI to better align with their values. We analyzed 77 social media posts about discriminatory AI statements and conducted semi-structured interviews with 20 experienced users. Our analysis revealed six common types of discriminatory statements perceived by users, how users make sense of those AI behaviors, and seven user-driven alignment strategies, such as gentle persuasion and anger expression. We discuss implications for supporting user-driven value alignment in future AI systems, where users and their communities have greater agency.",
    "title": "User-Driven Value Alignment: Understanding Users' Perceptions and Strategies for Addressing Biased and Discriminatory Statements in AI Companions",
    "id": 188861,
    "sequence": 652,
    "queryCoordinates": {
      "visualization": [
        -6.989732362413621,
        9.754160215099386
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "Previous research on interactive technology design has often focused on individual aspects of marginalized identities and their impact on technology use. However, there is a growing need to adopt a more holistic approach that considers how multiple, intersecting aspects of marginalized identities shape technology engagement across various contexts. In this qualitative case study, we investigate the communication experiences of LGBTQIA+ individuals with disabilities within romantic relationships, focusing on the role of technology in facilitating connection, intimacy, and joy. Our findings emphasize the dynamic experiences of early disability disclosure, the transformation of vulnerability into opportunities for authentic connection, and the co-creation of communication practices tailored to the relationship's needs. We advocate for inclusive technologies that adapt to evolving intersectional experiences, advocating for assistive technology (AT) that supports communication while nurturing emotional and relational well-being. Moreover, drawing on the concept of interdependence, we show how access is co-created in LGBTQIA+ romantic relationships, challenging the traditional views of AT as specialized tools.",
    "title": "\"Like a Love Language\": Understanding Communication in Disabled LGBTQIA+ Romantic Relationships",
    "id": 188862,
    "sequence": 653,
    "queryCoordinates": {
      "visualization": [
        -7.231914344987547,
        3.4204407474422562
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "Large language models (LLMs) can empower teachers to build pedagogical conversational agents (PCAs) customized for their students. As students have different prior knowledge and motivation levels, teachers must review the adaptivity of their PCAs to diverse students. Existing chatbot reviewing methods (e.g., direct chat and benchmarks) are either manually intensive for multiple iterations or limited to testing only single-turn interactions. We present TeachTune, where teachers can create simulated students and review PCAs by observing automated chats between PCAs and simulated students. Our technical pipeline instructs an LLM-based student to simulate prescribed knowledge levels and traits, helping teachers explore diverse conversation patterns. Our pipeline could produce simulated students whose behaviors correlate highly to their input knowledge and motivation levels within 5% and 10% accuracy gaps. Thirty science teachers designed PCAs in a between-subjects study, and using TeachTune resulted in a lower task load and higher student profile coverage over a baseline.",
    "title": "TeachTune: Reviewing Pedagogical Agents Against Diverse Student Profiles with Simulated Students",
    "id": 188863,
    "sequence": 654,
    "queryCoordinates": {
      "visualization": [
        6.989732362413627,
        9.754160215099382
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "It is often argued that effective human-centered explainable artificial intelligence (XAI) should resemble human reasoning. However, empirical investigations of how concepts from cognitive science can aid the design of XAI are lacking. Based on insights from cognitive science, we propose a framework of explanatory modes to analyze how people frame explanations, whether mechanistic, teleological, or counterfactual. Using the complex safety-critical domain of autonomous driving, we conduct an experiment consisting of two studies on (i) how people explain the behavior of a vehicle in 14 unique scenarios ($N_1=54$) and (ii) how they perceive these explanations ($N_2=382$), curating the novel Human Explanations for Autonomous Driving Decisions (HEADD) dataset. Our main finding is that participants deem teleological explanations significantly better quality than counterfactual ones, with perceived teleology being the best predictor of perceived quality. Based on our results, we argue that explanatory modes are an important axis of analysis when designing and evaluating XAI and highlight the need for a principled and empirically grounded understanding of the cognitive mechanisms of explanation. The HEADD dataset and our code are available at: \\url{https://datashare.ed.ac.uk/handle/10283/8930}.",
    "title": "People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior: Insights from Cognitive Science for Explainable AI",
    "id": 188864,
    "sequence": 655,
    "queryCoordinates": {
      "visualization": [
        13.921391857739383,
        7.886371075676543
      ]
    }
  },
  {
    "session": "WS36: Digital communication moving beyond human-centric replication",
    "abstract": "This agenda-setting workshop will bring together HCI researchers and designers with colleagues from sociology, media and communications to generate an interdisciplinary research agenda for digital communication beyond human-centric replication. It argues that the dominance of a human-centric replication paradigm in digital communication is problematic, constraining, limits digital innovation, and continues to unquestionably place humans at the centre of digital futures with negative social implications for modes of digital communication and how we relate to one another. This workshop will explore and foster alternative visions of digital communication, drawing inspiration from animal and plant sensory worlds (through inspirational talks, hands-on-activities, discussion) to generate ideas towards a new way of thinking and working in sensorial immersion beyond the human-centric. We will address key research opportunities and challenges and build the foundations for a road-map for this novel area of research.",
    "title": "Digital communication moving beyond human-centric replication",
    "id": 188865,
    "sequence": 656,
    "queryCoordinates": {
      "visualization": [
        -13.950460917646668,
        1.1767073490094704
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "Cultural background influences aesthetic web design preferences, and aesthetic design impacts accessible design. However, limited research has focused on this intersection of cultural background and accessible web design. With the majority of HCI and design resources originating from the Global North, we investigated the conflicts experienced due to the cultural background of digital designers from the Global South and current web accessibility guidelines. We conducted a design activity and interview study with 10 designers from five countries in the Global South to identify how current web accessibility guidelines conflict with our participants' cultural design preferences. We found there are specific cultural challenges encountered in accessible web design, both at the design level (e.g., typography and color scheme) and within broader societal contexts (e.g., designer-client interactions). Our paper also offers suggestions from our participants to make the accessible design process more culturally inclusive by improving the web accessibility resources to become culturally customized and engaging more cultural perspectives in accessibility research and education.",
    "title": "Investigating the Intersection of Cultural Design Preferences and Web Accessibility Guidelines with Designers from the Global South",
    "id": 188866,
    "sequence": 657,
    "queryCoordinates": {
      "visualization": [
        -1.957892883300774,
        14.871672920607155
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "While current chat-based AI assistants primarily operate reactively, responding only when prompted by users, there is significant potential for these systems to proactively assist in tasks without explicit invocation, enabling a mixed-initiative interaction. This work explores the design and implementation of proactive AI assistants powered by large language models. We first outline the key design considerations for building effective proactive assistants. As a case study, we propose a proactive chat-based programming assistant that automatically provides suggestions and facilitates their integration into the programmer's code. The programming context provides a shared workspace enabling the assistant to offer more relevant suggestions. We conducted a randomized experimental study examining the impact of various design elements of the proactive assistant on programmer productivity and user experience. Our findings reveal significant benefits of incorporating proactive chat assistants into coding environments, while also uncovering important nuances that influence their usage and effectiveness.\r\n",
    "title": "Need Help? Designing Proactive AI Assistants for Programming",
    "id": 188867,
    "sequence": 658,
    "queryCoordinates": {
      "visualization": [
        13.154498931851764,
        13.709819760008182
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "By leveraging quantum-mechanical properties like superposition, entanglement, and interference, quantum computing (QC) offers promising solutions for problems that classical computing has not been able to solve efficiently, such as drug discovery, cryptography, and physical simulation. Unfortunately, adopting QC remains difficult for potential users like QC beginners and application-specific domain experts, due to limited theoretical and practical knowledge, the lack of integrated interface-wise support, and poor documentation. For example, to use quantum computers, one has to convert conceptual logic into low-level codes, analyze quantum program results, and share programs and results. To support the wider adoption of QC, we, as designers and QC experts, propose interaction techniques for QC through design iterations. These techniques include writing quantum codes conceptually, comparing initial quantum programs with optimized programs, sharing quantum program results, and exploring quantum machines. We demonstrate the feasibility and utility of these techniques via use cases with high-fidelity prototypes.",
    "title": "Toward Human-Quantum Computer Interaction: Interface Techniques for Usable Quantum Computing",
    "id": 188868,
    "sequence": 659,
    "queryCoordinates": {
      "visualization": [
        14.950166537251937,
        13.285048758225633
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "An important challenge in interactive machine learning, particularly in subjective or ambiguous domains, is fostering bi-directional alignment between humans and models. Users teach models their concept definition through data labeling, while refining their own understandings throughout the process. To facilitate this, we introduce MOCHA, an interactive machine learning tool informed by two theories of human concept learning and cognition. First, it utilizes a neuro-symbolic pipeline to support Variation Theory-based counterfactual data generation. By asking users to annotate counterexamples that are syntactically and semantically similar to already-annotated data but predicted to have different labels, the system can learn more effectively while helping users understand the model and reflect on their own label definitions. Second, MOCHA uses Structural Alignment Theory to present groups of counterexamples, helping users comprehend alignable differences between data items and annotate them in batch. We validated MOCHA's effectiveness and usability through a lab study with 18 participants.",
    "title": "Supporting Co-Adaptive Machine Teaching through Human Concept Learning and Cognitive Theories",
    "id": 188869,
    "sequence": 660,
    "queryCoordinates": {
      "visualization": [
        11.357676325861577,
        -15.231650878252282
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "Computational notebooks, widely used for ad-hoc analysis and often shared with others, can be difficult to understand because the standard linear layout is not optimized for reading. In particular, related text, code, and outputs may be spread across the UI making it difficult to draw connections. In response, we introduce InterLink, a plugin designed to present the relationships between text, code, and outputs, thereby making notebooks easier to understand. In a formative study, we identify pain points and derive design requirements for identifying and navigating relationships among various pieces of information within notebooks. Based on these requirements, InterLink features a new layout that separates text from code and outputs into two columns. It uses visual links to signal relationships between text and associated code and outputs and offers interactions for navigating related pieces of information. In a user study with 12 participants, those using InterLink were 13.6% more accurate at finding and integrating information from complex analyses in computational notebooks. These results show the potential of notebook layouts that make them easier to understand.\r\n",
    "title": "InterLink: Linking Text with Code and Output in Computational Notebooks",
    "id": 188870,
    "sequence": 661,
    "queryCoordinates": {
      "visualization": [
        11.993575049716387,
        -0.39262899386131367
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "Auditory sense is the primary channel for people with blind and low vision (BLV) to access information. This paper aims to understand the productization of individual voices of BLV voice actors in the audiobook industry. We conducted online semi-interviews with the BLV voice actors in China (N = 13) and gained insights into the workflow through offline observations. Interviews indicate that the ability to match job requirements, social benefits, and accessible support are key factors that draw BLV people into this field. They acquire vocal techniques, actively showcase their voices, and adapt their career paths as needed. Social support is crucial for their continued employment, as well as disclosing their BLV identities as appropriate. Observations reveal that BLV people utilize text processing tools, Screen Reader(SR) speed control, and keyboard shortcuts to transform an invisible script into a coherent and emotionally nuanced voice recording. We investigate how BLV people harness their potential through intensive voice acting while listening to SR, and proficient keyboard skills for software access.",
    "title": "Voice by the Non-sighted: Practices and Challenges of Audiobook Voice Actors with Blind and Low Vision in China  ",
    "id": 188871,
    "sequence": 662,
    "queryCoordinates": {
      "visualization": [
        -15.705952052691876,
        -6.505618350206524
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "This paper introduces the Robotability Score (R), a novel metric that quantifies the suitability of urban environments for autonomous robot navigation. Through expert interviews and surveys, we identify and weigh key features contributing to R for wheeled robots on urban streets. Our findings reveal that pedestrian density, crowd dynamics and pedestrian flow are the most critical factors, collectively accounting for 28% of the total score. Computing robotability across New York City yields significant variation; the area of highest R is 3.0 times more \"robotable'' than the area of lowest R. Deployments of a physical robot on high and low robotability areas show the adequacy of the score in anticipating the ease of robot navigation. This new framework for evaluating urban landscapes aims to reduce uncertainty in robot deployment while respecting established mobility patterns and urban planning principles, contributing to the discourse on harmonious human-robot environments.\r\n",
    "title": "The Robotability Score: Enabling Harmonious Robot Navigation on Urban Streets",
    "id": 188872,
    "sequence": 663,
    "queryCoordinates": {
      "visualization": [
        -4.227000575054808,
        -11.230871121087906
      ]
    }
  },
  {
    "session": "WS32: Maternal Machines: Imagining Experiences in Perinatal Care",
    "abstract": "Perinatal care is a term that broadly refers to the period of time from pregnancy up to a year after giving birth. Imaginaries, fictional scenarios, patents and actual designs to support affected stakeholders during this period reflect how this topic has for a long time fed into society’s dreams, fears and desires about care. Smart monitors of infants’ sleep, respiration, heart rate or temperature, cots with facial recognition, swing chairs that are ‘Alexa compatible’, chatbots for postpartum depression, ‘maternal’ Alexas or nanny robots are examples of the potentials that this topic offers for imagining scenarios for care and wellbeing. Often rich with insights about societal dreams, fears and desires about what we would like technologies to do for us, imagined scenarios can also indicate ways in which we regard those already engaged in roles of care, echoing cultural and gendered tropes. As AI and related technologies increasingly become entangled in situations of care, the imagined possibilities in contexts of such complex, sensitive and emotionally charged spaces are worth examining, whilst interrogating how HCI technologies in perinatal care could expand beyond quantifiable data and tap into sensorial, non-numerical forms of knowledge.\r\nIn this workshop, we will look at ideated scenarios with technologies related to maternal and infant care in contemporary, historical and cultural contexts including those from Japan, and we will create our own imagined scenarios of care. Through a mixture of activities that include presentations, drawing, hands-on interactions and group conversations we will discuss opportunities and implications in the design of technologies for maternal/parental and infant care around the perinatal period. Our imagined scenarios will explore in particular two interrelated themes in the research: non-numerical forms of knowledge and touch.\r\n",
    "title": "Maternal Machines: Imagining Experiences in Perinatal Care",
    "id": 188873,
    "sequence": 664,
    "queryCoordinates": {
      "visualization": [
        2.7393136761395933,
        18.801493573216852
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "We present a qualitative study that investigates the implications of current and near-future AI deployment for home care workers (HCWs), an overlooked group of frontline healthcare workers. Through interviews with 22 HCWs, care agency staff, and worker advocates, we find that HCWs do not understand how AI works, how their data can be used, or why AI systems might retain their information. HCWs are unaware that AI is already being utilized in their work, primarily via algorithmic shift-matching systems adopted by agencies. Participants detail the risks AI poses in sensitive care settings for HCWs, patients, and agencies, including threats to workers' autonomy and livelihoods, and express concerns that workers will be held accountable for AI mistakes, with the burden of proving AI's decisions incorrect falling on them. Considering these risks, participants advocate for new regulations and democratic governance structures that protect workers and control AI deployment in home care work.",
    "title": "\"Who is running it?\" Towards Equitable AI Deployment in Home Care Work",
    "id": 188874,
    "sequence": 665,
    "queryCoordinates": {
      "visualization": [
        -4.112821953545772,
        6.861828880002177
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "Personally identifiable information (PII) is a fundamental concept in privacy research and regulations. Understanding users' perspectives on PII is critical, as their understanding of PII can significantly affect their privacy decisions and practices. While much research has explored users’ privacy perceptions and disclosure preferences regarding PII, less attention has been focused on how users internally define and conceptualize PII. In this study, we conducted interviews with 32 participants to investigate their conceptualization and understanding of PII, using period and fertility tracking apps as the context. Our findings reveal how users perceive the processes and contexts through which personal information, by becoming identifiable, transitions into PII, as well as concerns about data sharing and misuse in these apps. We conclude by advocating for addressing the misalignment between users' perceptions of PII and the regulatory protections and privacy designs surrounding it.",
    "title": "Understanding Users' Perception of Personally Identifiable Information",
    "id": 188875,
    "sequence": 666,
    "queryCoordinates": {
      "visualization": [
        -17.484157256638706,
        -4.278346061871116
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Effective training is essential for enhancing users' ability to detect phishing attempts. Personalised training offers huge potential to more closely align training content with individuals' needs and skill levels. In an online study, we assigned N=342 participants to personalised training or a random training variant to compare their effectiveness. The personalisation was based on a phishing proficiency score calculated from factors such as detection ability, knowledge, and security attitude. After training, the participants demonstrated greater proficiency, with an increased ability to detect phishing emails and higher security attitudes. These effects were most pronounced in the personalised condition, demonstrating the potential of personalisation to improve training outcomes. Overall, personalised training levelled the playing field, efficiently bringing all groups, regardless of their initial proficiency, to a comparable and desired post-training phishing proficiency level. Finally, we derived recommendations for designing personalised phishing training content and assigning users to suitable training programmes.",
    "title": "It's a Match - Enhancing the Fit between Users and Phishing Training through Personalisation",
    "id": 188876,
    "sequence": 667,
    "queryCoordinates": {
      "visualization": [
        -10.643573670544484,
        14.516002876814685
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "Block-building activities are crucial for developing children's spatial reasoning and mathematical skills, yet parents often lack the expertise to guide these activities effectively. BrickSmart, a pioneering system, addresses this gap by providing spatial language guidance through a structured three-step process: Discovery & Design, Build & Learn, and Explore & Expand. This system uniquely supports parents in 1) generating personalized block-building instructions, 2) guiding parents to teach spatial language during building and interactive play, and 3) tracking children's learning progress, altogether enhancing children's engagement and cognitive development. In a comparative study involving 12 parent-child pairs children aged 6-8 years) for both experimental and control groups, BrickSmart demonstrated improvements in supportiveness, efficiency, and innovation, with a significant increase in children's use of spatial vocabularies during block play, thereby offering an effective framework for fostering spatial language skills in children.",
    "title": "BrickSmart: Leveraging Generative AI to Support Children's Spatial Language Learning in Family Block Play",
    "id": 188877,
    "sequence": 668,
    "queryCoordinates": {
      "visualization": [
        -3.9560748906004144,
        -4.511038844873863
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "Communication between government agencies and not-for-profits (NFPs) within the local funding sector typically require the writing and submitting of long-form text-based reports. \r\nThese processes are time and resource intensive and require skill in written communication, placing a significant administrative burden on the small, already under-resourced organisations who interact with programs.\r\nNFP's now have the technical literacy to create rich video content, but little is understood about how video could be used instead of, or alongside traditional written reports. \r\nWe present findings from a novel funding acquittal (final report) process that we designed for a government grant programme to explore the affordances of video from the perspective of the grantee.\r\nWe discuss the affordances of structured short-form video to overcome the barriers faced by organisations during these reporting processes.\r\nWe present design considerations for digitally mediated processes that could support the media augmentation of these established workflows.",
    "title": "More Than ‘ticking-a-box’: The Affordances of Short-form Video for Community Reporting to Government",
    "id": 188878,
    "sequence": 669,
    "queryCoordinates": {
      "visualization": [
        14.585548805965146,
        -3.5016804578385914
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "Fingerspelling is a critical part of American Sign Language (ASL) recognition and has become an accessible optional text entry method for Deaf and Hard of Hearing (DHH) individuals. In this paper, we introduce SpellRing, a single smart ring worn on the thumb that recognizes words continuously fingerspelled in ASL. SpellRing uses active acoustic sensing (via a microphone and speaker) and an inertial measurement unit (IMU) to track handshape and movement, which are processed through a deep learning algorithm using Connectionist Temporal Classification (CTC) loss. We evaluated the system with 20 ASL signers (13 fluent and 7 learners), using the MacKenzie-Soukoref Phrase Set of 1,164 words and 100 phrases. Offline evaluation yielded top-1 and top-5 word recognition accuracies of 82.45% (±9.67%) and 92.42% (±5.70%), respectively. In real-time, the system achieved a word error rate (WER) of 0.099 (±0.039) on the phrases. Based on these results, we discuss key lessons and design implications for future minimally obtrusive ASL recognition wearables.",
    "title": "SpellRing: Recognizing Continuous Fingerspelling in American Sign Language using a Ring",
    "id": 188879,
    "sequence": 670,
    "queryCoordinates": {
      "visualization": [
        10.325318635406305,
        -10.880615565184318
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "Video descriptions are crucial for blind and low vision (BLV) users to access visual content. However, current artificial intelligence models for generating descriptions often fall short due to limitations in the quality of human annotations within training datasets, resulting in descriptions that do not fully meet BLV users' needs. To address this gap, we introduce VideoA11y, an approach that leverages multimodal large language models (MLLMs) and video accessibility guidelines to generate descriptions tailored for BLV individuals. Using this method, we have curated VideoA11y-40K, the largest and most comprehensive dataset of 40,000 videos described for BLV users. Rigorous experiments across 15 video categories, involving 347 sighted participants, 40 BLV participants, and seven professional describers, showed that VideoA11y descriptions outperform novice human annotations and are comparable to trained human annotations in clarity, accuracy, objectivity, descriptiveness, and user satisfaction. We evaluated models on VideoA11y-40K using both standard and custom metrics, demonstrating that MLLMs fine-tuned on this dataset produce high-quality accessible descriptions. Code and dataset are available at \\url{https://people-robots.github.io/VideoA11y/}.",
    "title": "VideoA11y: Method and Dataset for Accessible Video Description",
    "id": 188880,
    "sequence": 671,
    "queryCoordinates": {
      "visualization": [
        9.624552364536473,
        2.7144044986507425
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "Although current generative AI (GenAI) enables designers to create novel images, its focus on text-based and whole-image interaction limits expressive engagement with visual materials. Based on the design concept of deconstruction and reconstruction of digital visual attributes for visual prompts, we present FusAIn, a GenAI prompt composition tool that lets designers create personalized pens by loading them with objects or attributes such as color or texture. GenAI then fuses the pen's contents to create new images. Extracting and reusing inspirational material matches designers' existing work practices, making GenAI more contextualized for professional design. A study with 12 designers shows how FusAIn improves their ability to define visual details at different levels that are difficult to express with current GenAI prompts. Pen-based interaction lets them maintain fine-grained control over generated results, increasing GenAI image's editability and reusability. We discuss the benefits of \"composition as prompts\" and directions for future research.",
    "title": "FusAIn: Composing Generative AI Visual Prompts Using Pen-based Interaction",
    "id": 188881,
    "sequence": 672,
    "queryCoordinates": {
      "visualization": [
        -10.782766458220001,
        -16.844344674325733
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "Generative text-to-image models are disrupting the lives of creative professionals. Specifically, illustrators are threatened by models that claim to extract and reproduce their style. Yet, research on style transfer has rarely focused on their perspectives. We provided four illustrators with a model fine-tuned to their style and conducted semi-structured interviews about the model’s successes, limitations, and potential uses. Evaluating their output, artists reported that style transfer successfully copies aesthetic fragments but is limited by content-style disentanglement and lacks the crucial emergent quality of their style. They also deemed the others’ copies more successful. Understanding the results of style transfer as “boundary objects,” we analyze how they can simultaneously be considered unsuccessful by artists and poised to replace their work by others. We connect our findings to critical HCI frameworks, demonstrating that style transfer, rather than merely a Creativity Support Tool, should also be understood as a supply chain optimization one.",
    "title": "Copying style, Extracting value: Illustrators’ Perception of AI Style Transfer and its Impact on Creative Labor",
    "id": 188882,
    "sequence": 673,
    "queryCoordinates": {
      "visualization": [
        17.893014088001753,
        -1.9596037473353725
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "Generative AI is revolutionizing content creation and has the potential to enable real-time, personalized educational experiences. We investigated the effectiveness of converting textbook chapters into AI-generated podcasts and explored the impact of personalizing these podcasts for individual learner profiles. We conducted a 3x3 user study with 180 college students in the United States, comparing traditional textbook reading with both generalized and personalized AI-generated podcasts across three textbook subjects. The personalized podcasts were tailored to students’ majors, interests, and self-described instructional preferences. Our findings show that students found the AI-generated podcast format to be more enjoyable than textbooks and that personalized podcasts led to significantly improved learning outcomes, although this was subject-specific. These results highlight that AI-generated podcasts can offer an engaging and effective modality transformation of textbook material, with personalization enhancing content relevance. We conclude with design recommendations for leveraging AI in education, informed by student feedback.",
    "title": "PAIGE: Examining Learning Outcomes and Experiences with Personalized AI-Generated Educational Podcasts",
    "id": 188883,
    "sequence": 674,
    "queryCoordinates": {
      "visualization": [
        12.44723500408084,
        -13.002551317075609
      ]
    }
  },
  {
    "session": "Input and Modeling",
    "abstract": "Eye motion tracking plays a vital role in many applications such as human-computer interaction (HCI), virtual reality, and disease detection. Camera-based eye tracking, albeit accurate and easy to use, may raise privacy concerns and appear to be unreliable in poor lighting conditions. In this paper, we present RadEye, a radar system capable of detecting fine-grained human eye motions from a distance. RadEye is realized through an integrated hardware and software design. It customizes a sub-6GHz FMCW radar so as to detect millimeter-level eye movement while extending its detection range using low frequency. It further employs a deep neural network (DNN) to refine the detection accuracy through camera-guided supervisory training. We have built a prototype of RadEye. Extensive experimental results show that it achieves 90% accuracy when detecting human eye rotation directions (up, down, left, and right) in various scenarios.",
    "title": "RadEye: Tracking Eye Motion Using FMCW Radar",
    "id": 188884,
    "sequence": 675,
    "queryCoordinates": {
      "visualization": [
        -0.39229547863922787,
        -4.9845866686656395
      ]
    }
  },
  {
    "session": "Physical and Tangible",
    "abstract": "This paper presents a field study conducted in a distribution warehouse of a supermarket chain, Colruyt Group, in Belgium. It focuses on workers’ acceptance of autonomous mobile robots (AMRs) with anthropomorphic features. The robots were developed by an on-site technical team, and our research team of social scientists was consulted to explore workers’ perspectives. We compared four versions of the robot (without any features, with a name, with eyes and with a display) using mixed methods, including ethnography, interviews and surveys. Collecting data via periodic surveys proved challenging since the warehouse employees were busy during peak seasons (high workload) and due to technical issues with the robots. These factors necessitated a more flexible approach. Nonetheless, our study provided valuable insights that were considered during the robot implementation. In this case study, we summarise the results, lessons learned, and suggestions that could help navigate future field studies in industrial environments.",
    "title": "Introducing Robots in a Warehouse: Lessons Learned from a Field Study at a Supermarket Chain",
    "id": 188885,
    "sequence": 676,
    "queryCoordinates": {
      "visualization": [
        -2.7203715060963782,
        -10.658310319596579
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "Alternative Research Outcomes (AROs) go beyond traditional academic publications, taking diverse forms such as documentaries, DIY tutorials, or exhibitions. With growing recognition of the need for more inclusive and contextually appropriate research dissemination, AROs are particularly relevant in HCI and design research. Yet, little has been discussed on why it is important to work on AROs. What are key qualities of AROs? How can the HCI community benefit from learning more about creating AROs? By analyzing six case studies, we propose four qualities of AROs and demonstrate how they emerge in the timeline of a research project. We argue AROs can be adapted to diverse audience needs and share research insights that may extend beyond the original research goals. Our work contributes to a deeper understanding of how AROs can support inclusive research dissemination practices, enabling HCI researchers to engage broader audiences and extend the relevance of their work.",
    "title": "Translating HCI Research to Broader Audiences: Motivation, Inspiration, and Critical Factors on Alternative Research Outcomes",
    "id": 188886,
    "sequence": 677,
    "queryCoordinates": {
      "visualization": [
        6.564007126858534,
        -19.947777080129764
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "Conversational agents have been used to support student learning for some time, but the emergence of Large Language Models (LLMs) poses a novel opportunity to enhance their capabilities in collaborative settings. LLM-powered agents can provide timely interventions in collaborative conversations when a teacher is unable to assist the students. However, the use of LLMs in such tools raises many ethical questions and concerns, especially for use with young, impressionable populations. In this work, we present the human-centered design and evaluation of an LLM-based agent aimed to facilitate small group collaboration in middle- and high-school classrooms. Fifty-eight groups of dyads and triads (145 participants), aged 12-17, collaborated in a jigsaw activity and were assigned to be assisted by our agent or not. The results showed decreased self-reported ratings of social loafing and increased use of language related to respectful collaboration in interactions with the agent compared to those without.  ",
    "title": "Piecing Together Teamwork: A Responsible Approach to an LLM-based Educational Jigsaw Agent",
    "id": 188887,
    "sequence": 678,
    "queryCoordinates": {
      "visualization": [
        10.555408354592718,
        -13.326040464736488
      ]
    }
  },
  {
    "session": "Living with Dementia or Visual Impairments",
    "abstract": "Professional caregivers want to provide feelings of security and comfort to people with dementia in advanced care, but limited resources frequently restrict professional caregivers from doing so. One potential solution to make social, non-verbal connections with people in advanced dementia care is the use of artifacts that offer comfort and stimulating tactile experiences. In this study, we explored the role of two design artifacts, the Mano Quilt, a weighted blanket, and the Mano Fold, a foldable pillow, in supporting caregivers to increase feelings of comfort and security in people with advanced dementia through warmth. In a field study, we collected data through observations of 26 residents with dementia who interacted with the two artifacts and 17 interviews with their formal caregivers in three care organizations. We reveal which aesthetic and material qualities evoke haptic and bodily experiences such as presence, comfort, and activity and how the artifacts support existing caregiving practices. We encourage future researchers to design to enrich the senses as an aesthetic experience and provide emotional support and companionship to increase well-being for people with advanced dementia.",
    "title": "Mano: Designing for Tactile Experiences in Advanced Dementia Care",
    "id": 188888,
    "sequence": 679,
    "queryCoordinates": {
      "visualization": [
        -16.143709347588388,
        7.961196423942024
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "Uncertainty is inherent in science built on previous results. In geoscience, for instance, researchers analyzing volcanic deposits assess the uncertainty around past deposit classifications. To aid this assessment, we followed a design by immersion approach to co-design uncertainty visualizations. We observed that besides visualizing it, it is challenging even to define what constitutes uncertainty, as how researchers understand and process uncertainty evolves. This motivated us to reach other members of the community to better understand how they integrate uncertainty in their work. Informed by a series of interviews, we first redesigned our visualization system and then introduced it as a technology probe to a broader community of geoscientists. Our results highlight that uncertainty in science is malleable and that visualization systems should be designed with this malleability in mind.\r\nThrough a set of design implications, we advocate for visualizations that promote user agency and flexibility in defining and processing uncertainty.\r\n\r\n\r\n",
    "title": "Uncertainty in Science is Malleable. Advocating for User-Agency in Defining Uncertainty in Visualizations: a Case Study in Geology",
    "id": 188889,
    "sequence": 680,
    "queryCoordinates": {
      "visualization": [
        16.23921596258436,
        5.0287040995215975
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "Viewers desire to watch video content with subtitles in various font sizes according to their viewing environment and personal preferences. Unfortunately, because a chunk of the subtitle—a segment of the text corpus displayed on the screen at once—is typically constructed based on one specific font size, text truncation or awkward line breaks can occur when different font sizes are utilized. While existing methods address this problem by reconstructing subtitle chunks based on maximum character counts, they overlook synchronization of the display time with the content, often causing misaligned text. We introduce OptiSub, a fully automated method that optimizes subtitle segmentation to fit any user-specified font size while ensuring synchronization with the content. Our method leverages the timing of speech pauses within the video for synchronization. Experimental results, including a user study comparing OptiSub with previous methods, demonstrate its effectiveness and practicality across diverse font sizes and input videos.",
    "title": "OptiSub: Optimizing Video Subtitle Presentation for Varied Display and Font Sizes via Speech Pause-Driven Chunking",
    "id": 188890,
    "sequence": 681,
    "queryCoordinates": {
      "visualization": [
        9.741720724952748,
        -11.406089484000471
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "We introduce PropType, an interactive interface that transforms everyday objects into typing surfaces within an Augmented Reality (AR) environment. Users can interact with nearby props, such as cups, water bottles, boxes, and various other objects, utilizing them as on-the-go keyboards. To develop PropType, we conducted three studies. The first study involved observing users to understand how they naturally engage with prop surfaces for typing. The second study assessed the reachability and efficiency of touch input across four props with different sizes and shapes. Based on these insights, we designed customized keyboard layouts for each prop. In the third study, we evaluated typing performance using PropType, achieving an average typing speed of up to 26.1 words per minute (WPM) with 2.2% corrected error rate (CER) and 1.1% uncorrected error rate (UER). Finally, we present a PropType editing tool that allows users to customize keyboard layouts and visual effects for prop-based typing.",
    "title": "PropType: Everyday Props as Typing Surfaces in Augmented Reality",
    "id": 188891,
    "sequence": 682,
    "queryCoordinates": {
      "visualization": [
        9.986568514523647,
        8.322766926012344
      ]
    }
  },
  {
    "session": "Diversity and Inclusiveness",
    "abstract": "Even well-intentioned researchers may engage in health equity tourism (HET). We describe our two-year engagement with under-resourced community sites to provide insights into fostering genuine commitments to remedying health disparities. To explore implications for mobile health (mHealth) design for Black older adults with low income, we employed reflexive, qualitative methods based on outreach activity and semi-structured interviews with 25 community members. Our analysis highlights the importance of accessible self-learning opportunities to nurture technological interest. Our findings also suggest varying loci of control in health, and that mistrust motivates informal support networks and mHealth usage. Based on our work, we provide actionable recommendations for HCI researchers to mitigate HET. In addition, we reframe our findings through a social-ecological perspective to better understand the interplays between technology and health, and generate insights into how mHealth design can better serve under-resourced communities.",
    "title": "“We Have to Be Advocates for Ourselves”: A Social-Ecological Approach to Mobile Health Design with Black Older Adults Living with Diabetes",
    "id": 188892,
    "sequence": 683,
    "queryCoordinates": {
      "visualization": [
        -5.656760841911974,
        -10.58305517218026
      ]
    }
  },
  {
    "session": "Spatial Interactions",
    "abstract": "Proper placement of sensors and actuators is one of the key factors when designing spatial and proxemic interactions. However, current physical computing tools do not effectively support placing components in three-dimensional space, often forcing designers to build and test prototypes without precise spatial configuration. To address this, we propose the concept of spatial physical computing and present SpatIO, an XR-based physical computing toolkit that supports a continuous end-to-end workflow. SpatIO consists of three interconnected subsystems: SpatIO Environment for composing and testing prototypes with virtual sensors and actuators, SpatIO Module for converting virtually placed components into physical ones, and SpatIO Code for authoring interactions with spatial visualization of data flow. Through a comparative user study with 20 designers, we found that SpatIO significantly altered workflow order, encouraged broader exploration of component placement, enhanced spatial correlation between code and components, and promoted in-situ bodily testing.",
    "title": "SpatIO: Spatial Physical Computing Toolkit Based on Extended Reality",
    "id": 188893,
    "sequence": 684,
    "queryCoordinates": {
      "visualization": [
        -8.050839743998983,
        -7.4955973355328
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "Although awareness of and urgency around the environmental impact of energy consumption in digital infrastructures such as data centers are gradually increasing, many academic efforts still struggle to translate research into practical, real-world applications for reducing digital carbon footprints. Recent studies have highlighted incorporating environmental interventions such as sustainable interaction design (SID) into digital product development practices holds significant potential to reduce their carbon footprint, but integrating sustainability perspectives into everyday design and development practices remains limited in the industry. In this study, we report on the results of in-depth interviews with eight practitioners who have attempted to embed environmental interventions into their practices, capturing their experiences that highlight complex challenges and motivational enablers within the organizational context. Based on these findings, we propose implications for the broader engagement in sustainability-centered design and development practices that resonate with the organizational complexities.",
    "title": "Understanding Practical Challenges and Enablers for Embedding Environmental Perspectives in Digital Product Design and Development",
    "id": 188894,
    "sequence": 685,
    "queryCoordinates": {
      "visualization": [
        -18.99594191897069,
        -0.39267112332353465
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "In this work, we explore explicit Large Language Model (LLM)-powered support for the iterative design of computer programs. Program design, like other design activity, is characterized by navigating a space of alternative problem formulations and associated solutions in an iterative fashion. LLMs are potentially powerful tools in helping this exploration; however, by default, code-generation LLMs deliver code that represents a particular point solution. This obscures the larger space of possible alternatives, many of which might be preferable to the LLM’s default interpretation and its generated code. We contribute an IDE that supports program design through generating and showing new ways to frame problems alongside alternative solutions, tracking design decisions, and identifying implicit decisions made by either the programmer or the LLM. In a user study, we find that with our IDE, users combine and parallelize design phases to explore a broader design space---but also struggle to keep up with LLM-originated changes to code and other information overload. These findings suggest a core challenge for future IDEs that support program design through higher-level instructions given to LLM-based agents: carefully managing attention and deciding what information agents should surface to program designers and when.",
    "title": "Beyond Code Generation: LLM-supported Exploration of the Program Design Space",
    "id": 188895,
    "sequence": 686,
    "queryCoordinates": {
      "visualization": [
        3.48341612705355,
        11.483284028786507
      ]
    }
  },
  {
    "session": "Interfaces and Interactions for XR",
    "abstract": "Extended Reality (XR)-enabled headsets that overlay digital content onto the physical world, are gradually finding their way into our daily life. This integration raises significant concerns about privacy and access control, especially in shared spaces where XR applications interact with everyday objects. Such issues remain subtle in the absence of widespread applications of XR and studies in shared spaces are required for a smooth progress. This study evaluated a prototype system facilitating natural language policy creation for flexible, context-aware access control of personal objects. We assessed its usability, focusing on balancing precision and user effort in creating access control policies. Qualitative interviews and task-based interactions provided insights into users' preferences and behaviors, informing future design directions. Findings revealed diverse user needs for controlling access to personal items in various situations, emphasizing the need for flexible, user-friendly access control in XR-enhanced shared spaces that  respects boundaries and considers social contexts.",
    "title": "Transparent Barriers: Natural Language Access Control Policies for XR-Enhanced Everyday Objects",
    "id": 188896,
    "sequence": 687,
    "queryCoordinates": {
      "visualization": [
        -6.42566025184516,
        4.765594435939465
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "The more-than-human turn in HCI has explored entanglements with non-human others that include animals, plants, and technologies. Building on this agenda, this work constructs more-than-human (MTH) entanglements through the lens of queer non-binary, human/non-human entanglements of land and body. By fabulating an autofiction (fiction based on personal experience) titled Bog Girl – this work explores the way non-binary lands of wetlands, and non-binary bodies, share similar experiences of being cut (literally and metaphorically) by bifurcating logics in medical and agricultural settings. However, these experiences allow for new human/land animations, entanglements, grieving, and healing, ultimately, imagining non-binary grounds for design. The work contributes 1) new considerations of the generative and designerly potential storytelling and fiction in more-than-human research 2) queer embodied approaches to MTH work in HCI 3) and non-binary ethics for MTH design that imagine pluriversal bodily consent and paths to entangled healing. ",
    "title": "Fabulating Bog Girl: Queer Entanglements of Body and Land Histories in More-than-Human AutoFiction and Design",
    "id": 188897,
    "sequence": 688,
    "queryCoordinates": {
      "visualization": [
        17.790507188419692,
        2.7382209514185005
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Online, visual artists have more places than ever to routinely share their creative work and connect with other artists. These interactions support the routine enactment of creative identity in artists and provide inspirational opportunities for artists. As creative work shifts online, interactions between artists and routines around how these artists get inspired to do creative work are mediated by and through the logics of the online platforms where they take place. In an interview study of 22 artists, this paper explores the interplay between the development of artists' creative identities and the, at times, contradictory practices they have around getting inspired. We find platforms which support the disciplined practice of creative work while supporting spontaneous moments of inspiration, play an increasing role in passive approaches to searching for inspiration, and foster numerous small community spaces for artists to negotiate their creative identities. We discuss how platforms can better support and embed mechanisms for inspiration into their infrastructures into their design and platform policy.",
    "title": "Infrastructures for Inspiration: The Routine of Creative Identity Through Inspiration on the Creative Internet",
    "id": 188898,
    "sequence": 689,
    "queryCoordinates": {
      "visualization": [
        -14.139622366382675,
        5.007102888506568
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "This deaf-led work critically explores Deaf Tech, challenging conventional understandings of technologies 'for' deaf people as merely assistive and accessible, since these understandings are predominantly embedded in medical and audist ideologies. By employing participatory speculative workshops, deaf participants from different European countries envisioned technologies on Eyeth - a mythical planet inhabited by deaf people - centered on their perspectives and curiosities. The results present a series of alternative socio-technical narratives that illustrate qualitative aspects of technologies desired by deaf people. This study advocates for expanding the scope of deaf technological landscapes, emphasizing the needs of establishing deaf-centered HCI, including the development of methods and concepts that truly prioritize deaf experiences in the design of technologies intended for their use.",
    "title": "Speculating Deaf Tech: Reimagining Technologies Centering Deaf People",
    "id": 188899,
    "sequence": 690,
    "queryCoordinates": {
      "visualization": [
        -12.687865683272907,
        15.460209067254741
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Adaptive AR assistance can automatically trigger content to support users based on their context. Such intelligent automation offers many benefits but also alters users' degree of control, which is seldom explored in existing research. In this paper, we compare high- and low-agency control in AR-assisted construction assembly to understand the role of user agency. We designed cognitive and physical assembly scenarios and conducted a lab study (N=24), showing that low-agency control reduced mental workloads and perceived autonomy in several tasks. A follow-up domain expert study with trained carpenters (N=8) contextualised these results in an ecologically valid setting. Through semi-structured interviews, we examined the carpenters' perspectives on AR support in their daily work and the trade-offs of automating interactions. Based on these findings, we summarise key design considerations to inform future adaptive AR designs in the context of timber construction. ",
    "title": "Who is in Control? Understanding User Agency in AR-assisted Construction Assembly",
    "id": 188900,
    "sequence": 691,
    "queryCoordinates": {
      "visualization": [
        -5.043883547053371,
        -18.318276086023058
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "With increasing social mobility and an aging society, more older adults in China are migrating to new cities, known as “older drifters”. Due to fewer social connections and cultural adaptation, they face negative emotions such as loneliness and depression. While reminiscence-based interventions have been used to improve older adults' psychological well-being, challenges such as the lack of tangible materials and limited social resources constrain the feasibility of traditional reminiscence approaches for older drifters. To address this challenge, we designed RemiHaven, a personalized reminiscence support tool based on a two-phase formative study. It integrates “In-Town” and “Out-of-Town” peer agents to enhance personalization, engagement, and emotional resonance in the reminiscence process powered by Multimodal Large Language Models (MLLMs). Our evaluations show RemiHaven's strengths in supporting reminiscence while identifying potential challenges. We conclude by offering insights for the future design of reminiscence support tools for older migrants.",
    "title": "RemiHaven: Integrating \"In-Town\" and \"Out-of-Town\" Peers to Provide Personalized Reminiscence Support for Older Drifters",
    "id": 188901,
    "sequence": 692,
    "queryCoordinates": {
      "visualization": [
        17.569183002134814,
        -11.5032086235753
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "The film industry exerts significant economic and cultural influence, and its rapid development is contingent upon the expertise of industry professionals, underscoring the critical importance of film-shooting education. However, this process typically necessitates multiple practice in complex professional venues using expensive equipment, presenting a significant obstacle for ordinary learners who struggle to access such training environments. Despite VR technology has already shown its potential in education, existing research has not addressed the crucial learning component of replicating the shooting process. Moreover, the limited functionality of traditional controllers hinder the fulfillment of the educational requirements. Therefore, we developed VAction VR system, combining high-fidelity virtual environments with a custom-designed controller to simulate the real-world camera operation experience. The system’s lightweight design ensures cost-effective and efficient deployment. Experiment results demonstrated that VAction significantly outperforms traditional methods in both practice effectiveness and user experience, indicating its potential and usefulness in film-shooting education.",
    "title": "VAction: A Lightweight and Integrated VR Training System for Authentic Film-Shooting Experience",
    "id": 188902,
    "sequence": 693,
    "queryCoordinates": {
      "visualization": [
        1.1772563261425748,
        17.96146061829486
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "In India, topics related to sexual and reproductive health (SRH) are rarely discussed openly due to stigma. Cervical cancer, a part of this SRH sphere, is the second most common cancer among women in India, yet its awareness remains low. To understand the attitudes towards SRH, we designed a Cervical cancer awareness tutorial in Virtual Reality and collected data from 66 participants across genders and life stages (single, married, and married with children) through interviews, self-reported emotions, and physiological sensor data. Our findings revealed an acute lack of knowledge about self-body anatomy and a need for creating health literacy. Our participants appreciated receiving detailed information despite the presence of explicit imagery and advocated that critical health information should not be moderated. We offer recommendations to the HCI community for teaching cervical cancer and suggest extending these approaches to enhance education on similar critical SRH issues in India.",
    "title": "“But I Won’t Say That It Was Bad Seeing a Real Vagina\": Understanding Perspectives toward Learning Sensitive-Critical Health Topic",
    "id": 188903,
    "sequence": 694,
    "queryCoordinates": {
      "visualization": [
        9.928702829192504,
        -13.79930650900924
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "Children's increasing use of social video platforms like YouTube and TikTok raises safety concerns for parents, yet little research explores how they mediate their children's social video consumption. Previous studies often treat online harms and benefits as outcomes of parental mediation, overlooking how these factors affect parental mediation or how these effects vary with parents’ self-efficacy. To address these gaps, we surveyed 285 parents and found that perceived content informativeness value and content-inherent harm increase mediation, while entertainment value and creator trustworthiness decrease it. Parents’ self-efficacy—digital literacy and confidence in understanding their children's consumption—and children's consumption frequency significantly moderate these effects. These findings lead us to discuss how parental mediation differs between traditional media and social video platforms, where parents perform a more complex benefit-harm analysis due to competing effects of perceived harms and benefits. We propose strategies for enhancing parents’ self-efficacy and platform-parent collaboration in children's online safety.",
    "title": "Weighing Benefits and Harms: Parental Mediation on Social Video Platforms",
    "id": 188904,
    "sequence": 695,
    "queryCoordinates": {
      "visualization": [
        -13.99449276936274,
        -0.3926475878621606
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "Design aesthetics, predominantly concerned with artefact’s form and experience, has significantly shaped the evolution of design and HCI. As design practices expand to incorporate living organisms and embrace posthumanist shifts, traditional human-centered aesthetics increasingly fall short in addressing nonhuman experiences and the ethical and ecological complexities of more-than-human entanglements. Responding to the absence of overarching guidance for moving beyond traditional aesthetics, this paper systematically reviews more-than-human aesthetic perspectives within and beyond HCI and design. We first examine contemporary critical aesthetic discourse across disciplines such as art, geography, and human-animal interaction, identifying three key orientations that move away from human-centric aesthetics---phenomenologically, ontologically, and conceptually. We then review artefact-oriented publications in HCI and design venues to offer concrete examples of how these perspectives can be navigated, interpreted, combined, and applied in practice. This paper contributes a critical framework to inspire and challenge designers as they engage with aesthetics in more-than-human design.",
    "title": "Aesthetics in Designing with the Living: A Systematic Review of Critical Perspectives and Artefacts",
    "id": 188905,
    "sequence": 696,
    "queryCoordinates": {
      "visualization": [
        -1.9603428065912267,
        -19.903694533443936
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "Non-verbal signals, including co-speech gestures, play a vital role in human communication by conveying nuanced meanings beyond verbal discourse. While researchers have explored co-speech gestures in human-like conversational agents, limited attention has been given to non-humanoid alternatives. In this paper, we propose using swarm robotic systems as conversational agents and introduce a foundational set of swarm-based co-speech gestures, elicited from non-technical users and validated through an online study. This work outlines the key software and hardware requirements to advance research in co-speech gesture generation with swarm robots, contributing to the future development of social robotics and conversational agents.",
    "title": "User-defined Co-speech Gesture Design with Swarm Robots",
    "id": 188906,
    "sequence": 697,
    "queryCoordinates": {
      "visualization": [
        -2.6951188271377595,
        -7.5323525214641665
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "Advances in artificial intelligence (AI) offer the potential for chatbots to support public health monitoring by automating tasks traditionally performed by frontline workers. While introducing AI impacts public agency workers across decision-making, administration, and monitoring roles, the perceptions of workers regarding these technologies and their actual impact on labor are underexplored. We examine the case of CareCall, a large language model (LLM)-driven chatbot used to monitor socially isolated individuals, by interviewing 21 public agency workers across 13 sites involved in its adoption and rollout. We find that CareCall helped expand public reach but increased burdens on frontline workers due to insufficient resources and new labor demands, such as handling lapses in user engagement. We discuss how implementing LLM-driven chatbots in public health contexts can complicate decision-makers' articulation work and impose additional maintenance work on frontline workers. We recommend AI chatbots in this space leverage public infrastructure and incorporate fallback mechanisms. ",
    "title": "Understanding Public Agencies' Expectations and Realities of AI-Driven Chatbots for Public Health Monitoring",
    "id": 188907,
    "sequence": 698,
    "queryCoordinates": {
      "visualization": [
        -12.447235004080852,
        -13.0025513170756
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "There are many tools and technologies for making art with code, each embodying distinct values and affordances. Within this landscape, creative coding educators must evaluate how different tools map onto their own principles and examine the potential impacts of those choices on students' learning and artistic development. Understanding the values guiding these decisions is critical, as they reflect insights about these contexts, communities, and pedagogies. We explore these values through semi-structured interviews with (N=12) creative coding educators and toolbuilders. We identify three major themes: slowness (how friction can make room for reflection), politics (including the lasting effects of particular technologies), and joy (or the capacity for playful engagement). The lessons and priorities voiced by our participants offer valuable, transferable perspectives---like preferring community building (such as through documentation) over techno-solutionism. We demonstrate application of these critical lenses to two tool design areas (accessibility and AI assistance).",
    "title": "Slowness, Politics, and Joy: Values That Guide Technology Choices in Creative Coding Classrooms",
    "id": 188908,
    "sequence": 699,
    "queryCoordinates": {
      "visualization": [
        -15.611234080616455,
        3.5056198425099208
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "Educators and policymakers are increasingly trying to control youth access to technology in the classroom, while simultaneously working to deploy technology for purposes of surveillance and behavioral control. While many scholars have explored the implications of intensifying dataveillance and disciplinary practices deployed by teachers in K-12 schooling, few have investigated how students’ visions of technology deployment and use might align or diverge from those of designers and teachers. Using the resulting data from participatory design workshops and ethnographic research with students and staff in alternative hybrid schools, we explore students’ concepts of future technologies for the classroom and how these artifacts reflect student perceptions of safety and good behavior. Rather than simply accepting or resisting the role of technology in discipline and punishment as presented by technology creators, wherein disciplinary decisions are made by teachers using technology, students actively respond to these narratives to increase the objectivity and accuracy of punishment. The results of this work show how visions of future technology can sometimes reify new forms of power and other times respond to unmet student needs to exert control in the classroom.",
    "title": "Student Agency and Punishment Logics in Imagined Future Classroom Technologies",
    "id": 188909,
    "sequence": 700,
    "queryCoordinates": {
      "visualization": [
        21.996495261950074,
        0.39267822833461336
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "Interactive Digital Testimonies (IDTs) allow users to learn virtually about the life stories of contemporary witnesses as recounted by the witnesses themselves. Although several IDTs have been created in recent years, there is little empirical research on their effects on users. We investigated how different levels of visual modality (audio-only, audio-visual 2D, audio-visual stereoscopic 3D) affect user perception by conducting two separate mixed-methods studies: A 2x2 between-subjects study comparing audio-only with audio-visual 2D in in-person and online settings (n = 82) and a within-subjects study comparing audio-visual 2D with audio-visual stereoscopic 3D (n = 51). We found that audio-visual 2D improves user experience, immersion, and perceived authenticity over audio-only versions. Audio-visual 3D IDTs are more authentic and immersive than audio-visual 2D IDTs, however, this is diminished by a less comfortable interaction. Our findings broaden empirical research on user perception of realistic Embodied Conversational Agents and help guide future thanatosensitive designs.",
    "title": "Effects of Visual Modality on Conversations with Interactive Digital Testimonies: Preparing for the Post-Witness Era",
    "id": 188910,
    "sequence": 701,
    "queryCoordinates": {
      "visualization": [
        7.343225094356855,
        6.788007455329417
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Phishing attacks become increasingly sophisticated in targeting humans and exploiting cognitive biases, e.g., through inducing authority or urgency. Previous approaches to user training focused on URL warnings, textual, or click-based training, yielding mixed results. For more interactive training, uncoupled from users’ screens, we explore the potential of Augmented Reality (AR) technologies to enhance phishing detection. Through visual representations of biases that attackers typically exploit and gesture-based interactions with them, the training aims to enable users to counteract cognitive biases by increasing awareness and suspicion. In a laboratory study with N=117 users, we evaluated phishing detection rates, user interaction with, and feedback on the AR-based training in comparison with a click-based variant and a control condition. Our results show that interactive phishing training addressing cognitive biases increased detection rates by 33% and that interactive elements were well perceived. AR technologies further enhance the training.",
    "title": "Stop the Clock - Counteracting Bias Exploited by Attackers through an Interactive Augmented Reality Phishing Training",
    "id": 188911,
    "sequence": 702,
    "queryCoordinates": {
      "visualization": [
        -8.583452556734041,
        2.70635219553846
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "Expressing design intent using natural language prompts requires designers to verbalize the ambiguous visual details concisely, which can be challenging or even impossible. To address this, we introduce Brickify, a visual-centric interaction paradigm — expressing design intent through direct manipulation on design tokens. Brickify extracts visual elements (e.g., subject, style, and color) from reference images and converts them into interactive and reusable design tokens that can be directly manipulated (e.g., resize, group, link, etc.) to form the visual lexicon. The lexicon reflects users’ intent for both what visual elements are desired and how to construct them into a whole. We developed Brickify to demonstrate how AI models can interpret and execute the visual lexicon through an end-to-end pipeline. In a user study, experienced designers found Brickify more efficient and intuitive than text-based prompts, allowing them to describe visual details, explore alternatives, and refine complex designs with greater ease and control.",
    "title": "Brickify: Enabling Expressive Design Intent Specification through Direct Manipulation on Design Tokens",
    "id": 188912,
    "sequence": 703,
    "queryCoordinates": {
      "visualization": [
        -3.4441508912858074,
        8.31491579260158
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "Global variables lie at the root of many programmer complaints about computational notebooks.While programmers in other environments often address these barriers with function scopes, notebook programmers use functions less often. Analyzing the interaction between user behaviors, the programming language, and the notebook environment, we propose one possible explanation: that functions interfere with using notebooks in the exploratory ways users value. For example, because partial functions are not parseable, they cannot be run in isolation, so programmers cannot split function bodies across cells to iteratively tweak and rerun the last few lines. To explore how to offer non-global scopes without hampering exploratory notebook interactions, we built Pagebreaks, a small language construct for adding scopes around multiple Jupyter Notebook cells. In an in-situ study, we explored how programmers used Pagebreaks to manage variables with non-global scopes but also to visually and conceptually organize programs in a way akin to functions.",
    "title": "Pagebreaks: Multi-Cell Scopes in Computational Notebooks",
    "id": 188913,
    "sequence": 704,
    "queryCoordinates": {
      "visualization": [
        6.861828880002176,
        -4.112821953545775
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Participatory data physicalisation (PDP) is recognised for its potential to support data-driven decisions among stakeholders who collaboratively construct physical elements into commonly insightful visualisations. \r\nLike all participatory processes, PDP is however influenced by underlying power dynamics that might lead to issues regarding extractive participation, marginalisation, or exclusion, among others.\r\nWe first identified the decisions behind these power dynamics by developing an ontology that synthesises critical theoretical insights from both visualisation and participatory design research, which were then \r\nsystematically applied unto a representative corpus of 23 PDP artefacts. \r\nBy revealing how shared decisions are guided by different agendas, this paper presents three contributions: \r\n1) a cross-disciplinary ontology that facilitates the systematic analysis of existing and novel PDP artefacts and processes; which leads to\r\n2) six PDP agendas that reflect the key power dynamics in current PDP practice, revealing the diversity of orientations towards stakeholder participation in PDP practice; and\r\n3) a set of critical considerations that should guide how power dynamics can be balanced, such as by reflecting on how issues are represented, data is contextualised, participants express their meanings, and how participants can dissent with flexible artefact construction.\r\nConsequently, this study advances a feminist research agenda by guiding researchers and practitioners in openly reflecting on and sharing responsibilities in data physicalisation and participatory data visualisation.",
    "title": "Disentangling the Power Dynamics in Participatory Data Physicalisation",
    "id": 188914,
    "sequence": 705,
    "queryCoordinates": {
      "visualization": [
        -10.93697331949087,
        1.1758463372162438
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "Smart glasses hold immense potential, but existing input methods often hinder their seamless integration into everyday life. Touchpads integrated into the smart glasses suffer from limited input space and precision; voice commands raise privacy concerns and are contextually constrained; vision-based or IMU-based gesture recognition faces challenges in computational cost or privacy concerns. We present FingerGlass, an interaction technique for smart glasses that leverages side-mounted fingerprint sensors to capture fingerprint images. With a combined CNN and LSTM network, FingerGlass identifies finger identity and recognizes four types of gestures (nine in total): sliding, rolling, rotating, and tapping. These gestures, coupled with finger identification, are mapped to common smart glasses commands, enabling comprehensive and fluid text entry and application control. A user study reveals that FingerGlass represents a promising step towards a fresh, discreet, ergonomic, and efficient input interaction with smart glasses, potentially contributing to their wider adoption and integration into daily life.",
    "title": "FingerGlass: Enhancing Smart Glasses Interaction via Fingerprint Sensing",
    "id": 188915,
    "sequence": 706,
    "queryCoordinates": {
      "visualization": [
        -3.9807389066887873,
        0.3920685613182433
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "We present a multisensory virtual reality (VR) system that enables users to experience concurrent visual, auditory, and haptic feedback, featuring semantic classification of events from sound, sound-to-haptic conversion, and full-body haptic effects. This concept is applied to enhance the user experience of virtual reality (VR) gameplay. The system utilizes a Long-Short-Term Memory (LSTM) model to classify game sounds and detect key events such as gunfire, explosions, and hits. These events are translated into full-body haptic patterns through a haptic suit, providing users with realistic and immersive haptic experiences. The system operates with low latency, ensuring the seamless synchrony between sound and haptic feedback. Evaluations through user studies demonstrate significant improvements in user experience compared to traditional sound-to-haptic methods, emphasizing the importance of accurate sound classification and well-designed haptic effects.",
    "title": "Real-time Semantic Full-Body Haptic Feedback Converted from Sound for Virtual Reality Gameplay",
    "id": 188916,
    "sequence": 707,
    "queryCoordinates": {
      "visualization": [
        -9.928702829192497,
        -13.799306509009245
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "This paper presents Pointer Assistant, a novel human-AI interaction technique for on-screen tasks. The design features a chatbot displayed as an extra mouse pointer, alongside the user's, which proactively gives feedback on user actions while directing them to relevant areas on the screen and responding to the user's direct chat messages. The effectiveness of the design's key characteristics, pointer form and proactivity, was investigated in a study involving 220 participants in a financial budget planning task. Results demonstrated that the pointer design and interaction reduced task load while improving satisfaction with the experience, and increased the number of budget categories ideated during the task compared to the traditional passive chat log design. Participants viewed Pointer Assistant as a fun, innovative, and helpful visual guide while noting that its assertiveness can be improved. Future developments could offer even further enhancements to the user experience of human-AI collaboration and task outcomes.",
    "title": "Talk to the Hand: an LLM-powered Chatbot with Visual Pointer as Proactive Companion for On-Screen Tasks",
    "id": 188917,
    "sequence": 708,
    "queryCoordinates": {
      "visualization": [
        5.78591037545691,
        17.0447423309119
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "Computing systems are increasingly designed to adapt to users' cognitive states and mental models. Yet, cognitive biases affect how humans form such models and, therefore, they can impact their interactions with computers. To better understand this interplay, we conducted a scoping review to chart how Human-Computer Interaction (HCI) researchers study cognitive biases. Our findings show that computing systems not only have the potential to induce and amplify cognitive biases but also can be designed to steer users' behaviour and decision-making by capitalising on biases. We describe how HCI researchers develop algorithms and sensing methods to detect and quantify the effects of cognitive biases and discuss how we can use their understanding to inform system design. In this paper, we outline a research agenda for more theory-grounded research and highlight ethical issues when researching and designing computing systems with cognitive biases in mind as they affect real-world behaviour.",
    "title": "How Do HCI Researchers Study Cognitive Biases? A Scoping Review",
    "id": 188918,
    "sequence": 709,
    "queryCoordinates": {
      "visualization": [
        1.9134171618254492,
        4.619397662556434
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "Audio-media, such as radio and podcasts, are a vital means to engage with global events, access education, or offer entertainment. However, for people with complex communication needs, such as aphasia, there can be accessibility challenges. While accessibility research has largely focused on audiovisual media, little work has considered audio-media, particularly for users with complex communication needs. To address this gap, we undertook six co-design workshops with 10 people with aphasia to re-imagine access to audio-media. We uncover how our co-designers perceive audio-media as more than a tool, but a part of daily intimacies; shaping social relationships and contributing to therapeutic recovery. Through a Research-through-Design process culminating in one low-fidelity and three high-fidelity technology probes that embody novel accessibility interventions, our findings further challenge conventional approaches to audio-media accessibility and signal new directions for future design.",
    "title": "Sounds Accessible: Envisioning Accessible Audio Media Futures with People with Aphasia",
    "id": 188919,
    "sequence": 710,
    "queryCoordinates": {
      "visualization": [
        7.837478470739233,
        12.789602465311383
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "We introduce iGripper, a handheld haptic controller designed to render stiffness feedback for gripping and clamping both rigid and elastic objects in virtual reality. iGripper directly adjusts physical stiffness by using a small linear actuator to modify the spring’s position along a lever arm, with feedback force generated by the spring's reaction to the user's input. This enables iGripper to render stiffness from zero to any specified value, determined by the spring's inherent stiffness. Additionally, a blocking mechanism is designed to provide fully rigid feedback to enlarge the rendering range. Compared to active controllers, iGripper offers a broad range of force and stiffness feedback without requiring high-power actuators. Unlike many passive controllers, which provide only braking force, iGripper, as a semi-active controller, delivers controllable elastic force feedback. We present the iGripper’s design, performance evaluation, and user studies, comparing its realism with a commercial impedance-type grip device.",
    "title": "iGripper: A Semi-Active Handheld Haptic VR Controller Based on Variable Stiffness Mechanism",
    "id": 188920,
    "sequence": 711,
    "queryCoordinates": {
      "visualization": [
        13.921391857739382,
        -7.886371075676548
      ]
    }
  },
  {
    "session": "With AI",
    "abstract": "While there is much focus on interventions to foster ethical reflection in the design process of AI, there is less focus on fostering ethical reflection for (end)users. Yet, with the rise of genAI, AI technologies are no longer confined to expert users; non-experts are widely using these technologies. In this case study in a governmental organization in the Netherlands, we investigated a bottom-up approach to foster ethical reflection on the use of genAI tools. An approach of guided experimentation, including an intervention with a serious game, allowed civil servants to experiment, to understand the technology and its associated risks. The case study demonstrates that this approach enhances the awareness of possibilities and limitations, and the ethical considerations, of genAI usage. By analyzing usage statistics, we estimated the organization's energy consumption. ",
    "title": "Empowering Civil Servants: Fostering Ethical Reflection on GenAI Use through Experimentation and a Serious Game",
    "id": 188921,
    "sequence": 712,
    "queryCoordinates": {
      "visualization": [
        19.947777080129764,
        6.564007126858534
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "This study investigates the relationship between the HEXACO personality traits and text entry behaviors in composition and transcription tasks. By analyzing metrics such as entry speed, accuracy, editing efforts, and readability, we identified correlations between specific traits and text entry performance. In composition, honesty-humility and agreeableness were the strongest predictors, correlating significantly with composition time, text length, and editing efforts. In transcription, openness, honesty-humility, and agreeableness influenced performance, though no single trait consistently predicted all metrics. Interestingly, extraversion did not show strong correlations in either task, despite its established link to composition performance in academic contexts. These findings suggest that personality traits affect text entry behavior differently depending on the task, with creative tasks like composition being shaped by distinct traits compared to repetitive tasks like transcription. This research provides valuable insights into the relationship between personality and text entry, opening avenues for personalizing interaction systems based on individual traits.",
    "title": "Exploring the Impacts of HEXACO Personality Traits on Text Composition and Transcription",
    "id": 188922,
    "sequence": 713,
    "queryCoordinates": {
      "visualization": [
        13.517657043995312,
        -8.559961918193556
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "Studying health-related misinformation, so far, has mostly focused on general “fearmongering” content spread on social media. The Supreme Court’s overturn of Roe v. Wade highlighted the need to study abortion misinformation as health-related content that could have criminal implications for users. In response to this need, we conducted a study with 60 TikTok users about the way they conceptualize, assess, and respond to misleading abortion videos. Half of our participants saw political intent behind the spread of health-related misinformation driven towards a “fear of criminalization.” Prior to Roe v. Wade, our participants encountered videos discussing the legal ramifications of abortion, but post-Roe v. Wade, they saw videos suggesting herbal alternative treatments for pregnancy termination. Roughly 30% of our participants believed in the safety and efficacy of these otherwise scientifically debunked “alternative abortion treatments,” even in the presence of a debunking label attached to a self-administering abortion video.",
    "title": "User Experiences with Abortion Misinformation on TikTok: Encounters, Assessment Strategies, and Response",
    "id": 188923,
    "sequence": 714,
    "queryCoordinates": {
      "visualization": [
        16.14370934758838,
        -7.96119642394204
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "Many transgender (and cisgender) people experience gender euphoria -- satisfaction and relief caused by self-actualization and gender congruence -- a term that has been overlooked by the design community. Video games create intense experiences involving identities, bodies, and social interaction, providing opportunities to empower people through gender euphoria. We develop themes for creating and supporting gender euphoria in games within the Design, Dynamics, Experience Game Design Framework from a reflexive thematic analysis of 25 games, with an in-depth analysis of four of them. The analysis combines the authors' positionalities as trans gamers with close reading and content analysis of the games, employing perspectives from critical discourse analysis. We contribute an operational understanding of gender euphoria to support design, in-depth case studies of particularly euphoric game experiences, and identify themes that designers and researchers can use to develop new games and analyze existing ones.",
    "title": "Designed & Discovered Euphoria: Insights from Trans-Femme Players' Experiences of Gender Euphoria in Video Games",
    "id": 188924,
    "sequence": 715,
    "queryCoordinates": {
      "visualization": [
        -1.9596037473353713,
        -17.893014088001753
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "Queer Joy is conceptualised as a form of resistance to oppression by celebrating queerness in the face of adversity. This research aimed to centre queer joy and understand how it is expressed and may be facilitated in online spaces. To do this we conducted a survey with 100 UK participants who indicated they identified as LGBTQ+ on the online recruitment platform Prolific. We asked a series of open and closed questions in an online survey to investigate 1) what queer joy looks like on social media 2) how queer joy content is engaged with on social media 3) which platforms are perceived to facilitate queer joy and 4) how queer people protect their privacy online. The results suggested that to facilitate queer joy online, platforms should allow flexible self expression and community engagement, while allowing for granular control over privacy and the audience such content is shown to.",
    "title": "Queer Joy on Social Media: Exploring the Expression and Facilitation of Queer Joy in Online Platforms",
    "id": 188925,
    "sequence": 716,
    "queryCoordinates": {
      "visualization": [
        14.291588819128242,
        -7.193781274473712
      ]
    }
  },
  {
    "session": "Technology in Education",
    "abstract": "While AI's potential in education and professional sports is widely recognized, its application in K-12 physical education (PE) remains underexplored with significant opportunities for innovation. This study aims to address this gap by engaging 17 in-service secondary school PE teachers in group ideation workshops to explore potential AI applications and challenges in PE classes. Participants envisioned AI playing multidimensional roles, such as an operational assistant, personal trainer, group coach, and evaluator, as solutions to address unique instructional and operational challenges in K-12 PE classes. These roles reflected participants’ perspectives on how AI could enhance class management, deliver personalized feedback, promote balanced team activities, and streamline performance assessments. Participants also highlighted critical considerations for AI integration, including the need to ensure robust student data security and privacy measures, minimize the risk of over-reliance on AI for instructional decisions, and accommodate the varying levels of technological proficiency among PE teachers. Our findings provide valuable insights and practical guidance for AI developers, educators, and policymakers, offering a foundation for the effective integration of AI into K-12 PE curricula to enhance teaching practices and student outcomes.\r\n",
    "title": "Exploring K-12 Physical Education Teachers’ Perspectives on Opportunities and Challenges of AI Integration through Ideation Workshops",
    "id": 188926,
    "sequence": 717,
    "queryCoordinates": {
      "visualization": [
        -14.56898217659937,
        -15.124310177258659
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "Mobility aids (e.g., canes, crutches, and wheelchairs) are crucial for people with mobility disabilities; however, pervasive dissatisfaction with these aids keeps usage rates low. Through semi-structured interviews with 17 mobility aid users, mostly under the age of 30, we identified specific sources of dissatisfaction among younger users of mobility aids, uncovered community-based solutions for these dissatisfactions, and explored ways these younger users wanted to improve mobility aids. We found that users sought customizable, reconfigurable, multifunctional, and more aesthetically pleasing mobility aids. Participants' feedback guided our prototyping of tools/accessories, such as laser cut decorative skins, hot-swappable physical interface modules, and modular canes with custom 3D-printed handles. These prototypes were then the focus of additional co-design sessions where six returning participants offered suggestions for improvements and provided feedback on their usefulness and usability. Our findings highlight that many mobility aid users have the desire, ability, and need to customize and improve their aids in different ways compared to older adults. We propose various solutions and design guidelines to facilitate the modifications of mobility aids.",
    "title": "\"A Tool for Freedom\": Co-Designing Mobility Aid Improvements Using Personal Fabrication and Physical Interface Modules with Primarily Young Adults",
    "id": 188927,
    "sequence": 718,
    "queryCoordinates": {
      "visualization": [
        -16.519541499710975,
        -9.386412980437573
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "Tracking continuous 2D sequential handwriting trajectories accurately using a single IMU ring is extremely challenging due to the significant displacement between the IMU's wearing position and the location of the tracked fingertip. We propose WritingRing, a system that uses a single IMU ring worn at the base of the finger to support natural handwriting input and provide real-time 2D trajectories. To achieve this, we first built a handwriting dataset using a touchpad and an IMU ring (N=20). Next, we improved the LSTM model by incorporating streaming input and a TCN network, significantly enhancing accuracy and computational efficiency, and achieving an average trajectory accuracy of 1.63mm. Real-time usability studies demonstrated that the system achieved 88.7% letter recognition accuracy and 68.2% word recognition accuracy, which reached 84.36% when restricting the output to words within a vocabulary of size 3000. WritingRing can also be embedded into existing ring systems, providing a natural and real-time solution for various applications.",
    "title": "WritingRing: Enabling Natural Handwriting Input with a Single IMU Ring",
    "id": 188928,
    "sequence": 719,
    "queryCoordinates": {
      "visualization": [
        7.913412079718248,
        -1.173843795642892
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "A rapidly emerging research community at the intersection of sport and human-computer interaction (SportsHCI) explores how technology can support physically active humans, such as athletes. At highly competitive levels, coaching staff play a central role in the athlete experience by using data to enhance performance, reduce injuries, and foster team success. However, little is known about the practices and needs of these coaching staff. We conducted five focus groups with 17 collegiate coaching staff across three women’s teams and two men’s teams at an elite U.S. university. Our findings show that coaching staff selectively use data with the goal of balancing performance goals, athlete emotional well-being, and privacy. This paper contributes design recommendations to support coaching staff in operating across the data life cycle through gathering, sharing, deciding, acting, and assessing data as they aim to support team success and foster the well-being of student-athletes. ",
    "title": "Coach, Data Analyst, and Protector: Exploring Data Practices of Collegiate Coaching Staff",
    "id": 188929,
    "sequence": 720,
    "queryCoordinates": {
      "visualization": [
        -16.776141647090373,
        -6.5238846891066276
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "Initiating joint attention (JA) is a fundamental first step in social interactions. In sighted individuals, it relies predominantly on visual cues, such as gaze and hand gestures. These features can reduce opportunities for blind and visually impaired (BVI) and sighted people to interact. Understanding the strategies to navigate these challenges is necessary to develop technology that can facilitate more inclusive JA. To address this, we conducted a longitudinal case study of five children with mixed visual abilities engaging in activities rich with JA opportunities. In a teacher-led classroom, the children experimented with the use of an AI-powered headset designed to support BVI people in social situations. Interaction analysis established that situational complexity affects the children’s responses to initiation attempts. Furthermore, the headset adds to this complexity, affecting the frequency and reactions to attempts to initiate JA. The findings informed the creation of a JA initiation framework and suggestions for future design.",
    "title": "\"Put Your Hands Up\": How Joint Attention Is Initiated Between Blind Children And Their Sighted Peers",
    "id": 188930,
    "sequence": 721,
    "queryCoordinates": {
      "visualization": [
        16.1175365452339,
        10.061064342953467
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "Quadratic Surveys (QSs) elicit more accurate preferences than traditional methods like Likert-scale surveys. However, the cognitive load associated with QSs has hindered their adoption in digital surveys for collective decision-making. We introduce a two-phase \"organize-then-vote'' QS to reduce cognitive load. As interface design significantly impacts survey results and accuracy, our design scaffolds survey takers' decision-making while managing the cognitive load imposed by QS. In a 2x2 between-subject in-lab study on public resource allotment, we compared our interface with a traditional text interface across a QS with 6 (short) and 24 (long) options. Two-phase interface participants spent more time per option and exhibited shorter voting edit distances. We qualitatively observed shifts in cognitive effort from mechanical operations to constructing more comprehensive preferences. We conclude that this interface promoted deeper engagement, potentially reducing satisficing behaviors caused by cognitive overload in longer QSs. This research clarifies how human-centered design improves preference elicitation tools for collective decision-making.",
    "title": "Organize, Then Vote: Exploring Cognitive Load in Quadratic Survey Interfaces",
    "id": 188931,
    "sequence": 722,
    "queryCoordinates": {
      "visualization": [
        12.361892829330236,
        8.496093553872493
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "Existing approaches for color-concept association typically rely on query-based image referencing, and color extraction from image references. However, these approaches are effective only for common concepts, and are vulnerable to unstable image referencing and varying image conditions. Our formative study with designers underscores the need for primary-accent color compositions and context-dependent colors (e.g., 'clear' vs. 'polluted' sky) in design. In response, we introduce a generative approach for mining semantically resonant colors leveraging images generated by text-to-image models. Our insight is that contemporary text-to-image models can resemble visual patterns from large-scale real-world data. The framework comprises three stages: concept instancing produces generative samples using diffusion models, text-guided image segmentation identifies concept-relevant regions within the image, and color association extracts primarily accompanied by accent colors. Quantitative comparisons with expert designs validate our approach's effectiveness, and we demonstrate the applicability through cases in various design scenarios and a gallery.",
    "title": "GenColor: Generative Color-Concept Association in Visual Design",
    "id": 188932,
    "sequence": 723,
    "queryCoordinates": {
      "visualization": [
        6.386309944090403,
        -11.323208259941705
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "In Virtual Reality (VR), rendering realistic forces is crucial for immersion, but traditional vibrotactile feedback fails to convey force sensations effectively. Studies of asymmetric vibrations that elicit pseudo forces show promise but are inherently tied to unwanted vibrations, reducing realism. Leveraging sensory attenuation to reduce the perceived intensity of self-generated vibrations during user movement, we present a novel algorithm that couples asymmetric vibrations with user motion, which mimics self-generated sensations. Our psychophysics study with 12 participants shows that motion-coupled asymmetric vibration attenuates the experience of vibration (equivalent to a \\textasciitilde 30\\% reduction in vibration-amplitude) while preserving the experience of force, compared to continuous asymmetric vibrations (state-of-the-art). We demonstrate the effectiveness of our approach in VR through three scenarios: shooting arrows, lifting weights, and simulating haptic magnets. Results revealed that participants preferred forces elicited by motion-coupled asymmetric vibration for tasks like shooting arrows and lifting weights. \r\nThis research highlights the potential of motion-coupled asymmetric vibrations, offers new insights into sensory attenuation, and advances force rendering in VR.",
    "title": "Motion-Coupled Asymmetric Vibration for Pseudo Force Rendering in Virtual Reality",
    "id": 188933,
    "sequence": 724,
    "queryCoordinates": {
      "visualization": [
        19.996144809641297,
        0.392673849212566
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "Replying to formal emails is time-consuming and cognitively demanding, as it requires crafting polite phrasing and providing an adequate response to the sender's demands. Although systems with Large Language Models (LLMs) were designed to simplify the email replying process, users still need to provide detailed prompts to obtain the expected output. Therefore, we propose and evaluate an LLM-powered question-and-answer (QA)-based approach for users to reply to emails by answering a set of simple and short questions generated from the incoming email. We developed a prototype system, ResQ, and conducted controlled and field experiments with 12 and 8 participants. Our results demonstrated that the QA-based approach improves the efficiency of replying to emails and reduces workload while maintaining email quality, compared to a conventional prompt-based approach that requires users to craft appropriate prompts to obtain email drafts. We discuss how the QA-based approach influences the email reply process and interpersonal relationship dynamics, as well as the opportunities and challenges associated with using a QA-based approach in AI-mediated communication.",
    "title": "Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions",
    "id": 188934,
    "sequence": 725,
    "queryCoordinates": {
      "visualization": [
        -0.3926679306220986,
        17.995716487438365
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "Drones are increasingly being deployed to assist firefighting crews in their missions, with the technology being chosen based on availability, rather than aligned with their specific needs. This phenomenon is exacerbated in the Global South, where infrastructure is scarce and where specific processes and user needs have to be adequately mapped to successfully introduce new technologies. We conducted semi-structured interviews with firefighting professionals (N=15) from Thailand, covering their prior experience with drones, challenges they encounter in their job, and how they envision this technology could better support them in the future. Our findings describe users’ technological needs and their expectations in terms of interaction and collaboration with drones. We identified specific challenges in Thailand that hinder the deployment of drone technology, including mismatches in technical and financial decisions. Furthermore, participants advocated for sharing physical systems between fire departments. We conclude with design considerations for drones in resource-limited firefighting contexts.",
    "title": "Firefighting with Drone Assistance: User Needs and Design Considerations for Thailand",
    "id": 188935,
    "sequence": 726,
    "queryCoordinates": {
      "visualization": [
        4.267404119598375,
        15.420417052727037
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "To interact with Augmented Reality (AR) content while walking, the user interfaces (UIs) need to move along with the user without distracting their field of view. This paper investigates on-hand reference frames for AR interaction while walking. First, we conduct a user study evaluating six on-hand reference frames. Results show that the Pinch Grip With Offset (PGWO), which anchors UIs to the pinch grip while floating at a distance, outperforms other on-hand reference frames regarding speed, accuracy, workload, and user preference. Next, we conduct a follow-up study to compare PGWO’s performance with head and torso reference frames, commonly used in previous studies, to see whether PGWO’s benefits hold up against well-established reference frames. Results revealed better performance and higher user preference for PGWO than both reference frames. Finally, we present design recommendations for developing future AR systems that are more efficient and user-friendly for on-the-go interaction.",
    "title": "HAI-AR: Exploring Hand-Anchored Interfaces in Augmented Reality while Walking",
    "id": 188936,
    "sequence": 727,
    "queryCoordinates": {
      "visualization": [
        19.996144809641297,
        -0.392673849212566
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "Protocol reverse engineering (ProtocolREing) consists of taking streams of network data and inferring the communication protocol. ProtocolREing is critical task in malware and system security analysis. Several ProtocolREing automation tools have been developed, however, in practice, they are not used because they offer limited interaction. Instead, reverse engineers (ProtocolREs) perform this task manually or use less complex visualization tools. To give ProtocolREs the power of more complex automation, we must first understand ProtocolREs processes and information and interaction needs to design better interfaces.\r\n\r\nWe interviewed 16 ProtocolREs, presenting a paper prototype ProtocolREing automation interface, and ask them to discuss their approach to ProtocolREing while using the tool and suggest missing information and interactions. We designed our prototype based on existing ProtocolREing tool features and prior reverse engineering research's usability guidelines. We found ProtocolREs follow a flexible, hypothesis-driven process and identified multiple information and interaction needs when validating the automation's inferences. We provide suggestions for future interaction design.",
    "title": "An Investigation of Interaction and Information Needs for Protocol Reverse Engineering Automation",
    "id": 188937,
    "sequence": 728,
    "queryCoordinates": {
      "visualization": [
        19.903694533443936,
        -1.9603428065912278
      ]
    }
  },
  {
    "session": "Workplace Interactions and Wellbeing",
    "abstract": "Automation is reshaping the gig economy, raising urgent concerns about worker displacement. With the global rise in gig workers, there is an increasing urgency for HCI and design research to focus on the impact of designing automation technologies on labor dynamics. This study introduces speculative job design research to probe alternative opportunities for gig workers in an automated future, engaging 20 workers in the process. Guided by Feminist HCI, we performed reflexive thematic analysis to uncover gig workers' views on automation technology, human labor, speculative jobs, and their concerns about the future of work. We highlighted how workers see labor exploitation as a competitive asset over machines, urging that future platform designs must not perpetuate this. Notably, through speculative job design and conversation with workers, we proposed labor design, suggesting labor as a designable material to help address unfair labor dynamics in technology design. Our research offers potential insights and directions for addressing labor tensions in the evolving sociotechnical landscape.",
    "title": "Speculative Job Design: Probing Alternative Opportunities for Gig Workers in an Automated Future",
    "id": 188938,
    "sequence": 729,
    "queryCoordinates": {
      "visualization": [
        17.484157256638706,
        4.278346061871115
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "Advancements in computational agents will enable them to act as surrogates for users in online communication, promising enhanced productivity by supporting multitasking. This capability may be especially powerful when combined with human control, allowing users to retain agency while achieving better performance than either human or agent alone. However, it remains unclear how people might leverage this technology to multitask effectively. We present a study with 18 dyads exploring how users employ automated responses to support an arithmetic task while staying engaged in a voice call. Participants multitasked with a conversational agent under three levels of autonomy: none, shared, and full. Our findings indicate that fully automated systems can maintain conversational engagement, enabling users to multitask effectively. Surprisingly, shared autonomy hindered this ability. Based on our results, we discuss implications for designing shared autonomy in conversations, highlighting new considerations and challenges.",
    "title": "Conversational Agents on Your Behalf: Opportunities and Challenges of Shared Autonomy in Voice Communication for Multitasking",
    "id": 188939,
    "sequence": 730,
    "queryCoordinates": {
      "visualization": [
        3.386032209736679,
        6.126563953361276
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "The democratic and emancipatory principles underpinning Participatory Design (PD) set PD methodology apart from other user-oriented design methodologies associated with Human-Computer Interaction. In turning PD principles into practice, PD facilitators play a vital role. However, at present, there is a lack of understanding regarding skills relevant to enacting the role. To address this issue, we present the results from an interview study involving fourteen respondents with considerable PD facilitation experience. The analysis of the interviews uncovered six facilitation skills of perceived relevance: openness, patience, empathy, attentiveness, responsiveness, and adaptiveness. The significance of each skill, as expressed by respondents, is accounted for. We further discuss the composition of skills in the derived skill set, possible implications of missing skills, and how the findings complement relevant existing work. Drawing on the findings, the paper offers an empirically based qualitative understanding of what constitutes skillful PD facilitation.",
    "title": "Facilitation Skills in Participatory Design",
    "id": 188940,
    "sequence": 731,
    "queryCoordinates": {
      "visualization": [
        13.285048758225635,
        14.950166537251935
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "Access to sexual and reproductive health information remains a challenge in many communities globally, due to cultural taboos and limited availability of healthcare providers. Public health organizations are increasingly turning to Large Language Models (LLMs) to improve access to timely and personalized information. However, recent HCI scholarship indicates that significant challenges remain in incorporating context awareness and mitigating bias in LLMs. In this paper, we study the development of a culturally-appropriate LLM-based chatbot for reproductive health with underserved women in urban India. Through user interactions, focus groups, and interviews with multiple stakeholders, we examine the chatbot’s response to sensitive and highly contextual queries on reproductive health. Our findings reveal strengths and limitations of the system in capturing local context, and complexities around what constitutes ``culture''. Finally, we discuss how local context might be better integrated, and present a framework to inform the design of culturally-sensitive chatbots for community health.",
    "title": "\"Kya family planning after marriage hoti hai?\": Integrating Cultural Sensitivity in an LLM Chatbot for Reproductive Health",
    "id": 188941,
    "sequence": 732,
    "queryCoordinates": {
      "visualization": [
        -0.39264758786216486,
        -13.99449276936274
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "Social media has become a primary information source, with platforms evolving from text-based to multi-modal environments that include images and videos. While richer media modalities enhance user engagement, they also increase the spread and perceived credibility of misinformation. Most interventions to counter misinformation on social media are text-based, which may lack the persuasive power of richer modalities. This study explores whether the effectiveness of misinformation correction varies by modality, and if certain modalities of misinformation are better countered by a specific correction modality. We conducted a survey-based experiment where participants rated the credibility of misinformation tweets before and after exposure to corrections, across all combinations of text, images and video modalities. Our findings suggest that corrections are most effective when their modality richness matches that of the original misinformation. We discuss factors affecting the perceived credibility of corrections and offer strategies to optimise misinformation correction.",
    "title": "The Influence of Content Modality on Perceptions of Online Misinformation",
    "id": 188942,
    "sequence": 733,
    "queryCoordinates": {
      "visualization": [
        -2.7249151564124854,
        -11.686523751328002
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "In the context of computational thinking tasks, which often require problem-solving and critical thinking skills, awareness of a partner’s actions can play a significant role in fostering a balanced collaboration. Understanding how awareness influences mixed-\r\nvisual ability group collaboration in a tangible environment can provide insights into inclusive design for learning environments. To address this issue, we ran a user study where 6 mixed-visual ability pairs engaged in a tangible programming activity. The study\r\nhad three experimental conditions, representing 3 different levels of awareness. Our findings reveal that while pre-existing power dynamics heavily influenced collaboration, workspace awareness feedback was essential in fostering engagement and improving\r\ncommunication for both children. This paper highlights the need for designing inclusive collaborative programming systems that account for workspace awareness and individual abilities, offering insights into more effective and balanced collaborative environments.",
    "title": "Awareness in Collaborative Mixed-Visual Ability Tangible Programming Activities",
    "id": 188943,
    "sequence": 734,
    "queryCoordinates": {
      "visualization": [
        -5.55570233019602,
        8.314696123025453
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "This paper systematized existing knowledge on cybersecurity and privacy game-based approaches, exploring their goals, scope, and evaluation methods. Our review of 93 academic papers revealed that these approaches serve multiple purposes and target diverse player types. We identified 11 key aspects of cybersecurity and privacy that these approaches addressed, such as threats, defensive strategies, and data privacy. Additionally, we analyzed the effectiveness evaluation methods of these approaches, emphasizing the connections between evaluation techniques, types of data used, and their alignment with the approaches' goals. We also summarized the aspects of user experience evaluated in the literature and the types of questions used to capture these experiences. Reflecting on these methods, we provide guidance for future research and practice in designing and evaluating game-based approaches. Finally, we identify key gaps and propose opportunities to enhance user understanding, foster adaptability, and address emerging cybersecurity and privacy challenges.",
    "title": "Systemization of Knowledge (SoK): Goals, Coverage, and Evaluation in Cybersecurity and Privacy Games",
    "id": 188944,
    "sequence": 735,
    "queryCoordinates": {
      "visualization": [
        -4.267404119598373,
        15.420417052727037
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "Hackathons have become popular collaborative events for accelerating the development of creative ideas and prototypes. There are several case studies showcasing creative outcomes across domains such as industry, education, and research. However, there are no large-scale studies on creativity in hackathons which can advance theory on how hackathon formats lead to creative outcomes. We conducted a computational analysis of 193,353 hackathon projects. By operationalizing creativity through usefulness and novelty, we refined our dataset to 10,363 projects, allowing us to analyze how participant characteristics, collaboration patterns, and hackathon setups influence the development of creative projects. The contribution of our paper is twofold: We identified means for organizers to foster creativity in hackathons. We also explore the use of large language models (LLMs) to augment the evaluation of creative outcomes and discuss challenges and opportunities of doing this, which has implications for creativity research at large.",
    "title": "How Do Hackathons Foster Creativity? Towards Automated Evaluation of Creativity at Scale",
    "id": 188945,
    "sequence": 736,
    "queryCoordinates": {
      "visualization": [
        -4.765594435939465,
        -6.42566025184516
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "Generative AI (AI) has become ubiquitous in both daily and professional life, with emerging research demonstrating its potential as a tool for accessibility. Neurodivergent people, often left out by existing accessibility technologies, develop their own ways of navigating normative expectations. GAI offers new opportunities for access, but it is important to understand how neurodivergent “power users”—successful early adopters—engage with it and the challenges they face. Further, we must understand how marginalization and intersectional identities influence their interactions with GAI. Our autoethnography, enhanced by privacy-preserving GAI-based diaries and interviews, reveals the intricacies of using GAI to navigate normative environments and expectations. Our findings demonstrate how GAI can both support and complicate tasks like code-switching, emotional regulation, and accessing information. We show that GAI can help neurodivergent users to reclaim their agency in systems that diminish their autonomy and self-determination. However, challenges such as balancing authentic self-expression with societal conformity, alongside other risks, create barriers to realizing GAI's full potential for accessibility.",
    "title": " Autoethnographic Insights from Neurodivergent GAI \"Power Users\"",
    "id": 188946,
    "sequence": 737,
    "queryCoordinates": {
      "visualization": [
        -14.656546221839262,
        -8.613109359986627
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "Dark patterns are deceptive strategies that recent work in human-computer interaction (HCI) has captured throughout digital domains, including social networking sites (SNSs). While research has identified difficulties among people to recognise dark patterns effectively, few studies consider vulnerable populations and their experience in this regard, including people with attention deficit hyperactivity disorder (ADHD), who may be especially susceptible to attention-grabbing tricks. Based on an interactive web study with 135 participants, we investigate SNS users' ability to recognise and avoid dark patterns by comparing results from participants with and without ADHD. In line with prior work, we noticed overall low recognition of dark patterns with no significant differences between the two groups. Yet, ADHD individuals were able to avoid specific dark patterns more often. Our results advance previous work by understanding dark patterns in a realistic environment and offer insights into their effect on vulnerable populations.",
    "title": "A Comparative Study of How People With and Without ADHD Recognise and Avoid Dark Patterns on Social Media",
    "id": 188947,
    "sequence": 738,
    "queryCoordinates": {
      "visualization": [
        11.688145478950535,
        -5.690980167149431
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "Neurotypical modes of existence and interaction are enforced through traditional social norms, compelling individuals who diverge from these norms, such as those who are neurodivergent, to conform through ``masking.'' Technology research and design often also ascribe to these conventional norms, creating technology that reinforces neurodivergent people's need to mask. In this research, we turn to neurodivergent communities online to develop an understanding of masking behaviors. We adopt a two-tiered research approach consisting of a qualitative thematic analysis of TikTok videos and a survey questionnaire. Through this work, we initiate discussion on the complexities of neurodivergent masking as a pervasive social adaptation. We urge HCI researchers to critically reframe intervention design and research practices that may either perpetuate or seek to address masking. ",
    "title": "\"Ultimately, it's a matter of safety, and resisting ostracization\": Understanding Neurodivergent Masking with Online Communities",
    "id": 188948,
    "sequence": 739,
    "queryCoordinates": {
      "visualization": [
        9.276125440352839,
        -7.612719409963751
      ]
    }
  },
  {
    "session": "WS35: Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "abstract": "Rapid advancements in and adoption of frontier AI systems have amplified the need for AI governance measures across the public sector, academia, and industry. Prior work in technical AI governance has proposed agendas for governing technical components in AI development, such as data, models, and compute. However, recent calls for more sociotechnical approaches recognize the critical role of social infrastructures surrounding technical ones in shaping governance decisions and efforts. While scholars and practitioners have advocated for sociotechnical AI governance, concrete research directions in this area are only beginning to emerge. This workshop aims to gather the expertise of researchers in HCI and adjacent disciplines to chart promising paths forward for sociotechnical AI governance. To make problems in this area more tangible, we outline four core governance challenges for contributions: anticipating high-priority risks to address with governance, identifying where to focus governance efforts and who should lead those efforts, designing appropriate interventions and tools to implement governance actions in practice, and evaluating the effectiveness of these interventions and tools in context. Through papers, panel discussions, keynotes, and collaborative drafting of a research agenda, this workshop will build community and empower actionable efforts to tackle AI governance through a sociotechnical lens.",
    "title": "Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "id": 188949,
    "sequence": 740,
    "queryCoordinates": {
      "visualization": [
        10.782766458220008,
        16.84434467432573
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "Cultural differences influence how cyclists and drivers interact, affecting global autonomous vehicle (AV) adoption. AV-cyclist interfaces are needed to clarify AV intentions and resolve ambiguities when no human driver is present. These must adapt across cultures and road infrastructure. We conducted the first cross-cultural AV-cyclist user study across Stockholm (high segregation of cyclists from drivers), Glasgow (some segregation), and Muscat (no segregation). Cyclists used an AR simulator to cycle in physical space and experienced three holistic AV-cyclist interfaces. These integrated multiple interfaces into a larger ecosystem, e.g., a smartwatch synchronised with on-vehicle eHMI. Interfaces communicated AV location, intentions, or both. Riders from all cities preferred combined AV location and intention information but used it differently. Stockholm cyclists focused on location, validating intentions with driving behaviour. Glasgow riders valued both cues equally. Muscat cyclists trusted interfaces, prioritising intentions without relying on driving behaviour. These insights are key for global AV adoption.",
    "title": "Around the World in 60 Cyclists: Evaluating Autonomous Vehicle-Cyclist Interfaces Across Cultures",
    "id": 188950,
    "sequence": 741,
    "queryCoordinates": {
      "visualization": [
        6.4256602518451595,
        4.765594435939467
      ]
    }
  },
  {
    "session": "AI-Assisted Creativity",
    "abstract": "With the rise of AI technologies and their growing influence in the screenwriting field, understanding the opportunities and concerns related to AI's role in screenwriting is essential for enhancing human-AI co-creation. Through semi-structured interviews with 23 screenwriters, we explored their creative practices, attitudes, and expectations in collaborating with AI for screenwriting. Based on participants' responses, we identified the key stages in which they commonly integrated AI, including story structure and plot development, screenplay text, goal and idea generation, and dialogue. Then, we examined how different attitudes toward AI integration influence screenwriters' practices across various workflow stages and their broader impact on the industry. Additionally, we categorized their expected assistance using four distinct roles of AI: actor, audience, expert, and executor. Our findings provide insights into AI's impact on screenwriting practices and offer suggestions on how AI can benefit the future of screenwriting.",
    "title": "Understanding Screenwriters' Practices, Attitudes, and Future Expectations in Human-AI Co-Creation",
    "id": 188951,
    "sequence": 742,
    "queryCoordinates": {
      "visualization": [
        -17.994965681044434,
        -8.728184813466838
      ]
    }
  },
  {
    "session": "Technology in Education",
    "abstract": "The interdisciplinary field of Human-Computer Interaction (HCI) thrives on productive engagement with different domains, yet this engagement often breaks due to idiosyncratic writing styles and unfamiliar concepts. Inspired by the dialogic model of abstract metaphors, as well as the potential of Large Language Models (LLMs) to produce on-demand support, we investigate the use of metaphors to facilitate engagement between Science and Technology Studies (STS) and System HCI. Our reflective-style survey with early-career HCI researchers (N=48) reported that limited prior exposure to STS research can hinder perceived openness of the work, and ultimately interest in reading. The survey also revealed that metaphors enhance likelihood to continue reading STS papers, and alternative perspectives can build critical thinking skills to mitigate potential risks of LLM-generated metaphors. We lastly offer a specified model of metaphor exchange (within this generative context) that incorporates alternative perspectives to construct shared understanding in interdisciplinary engagement.",
    "title": "Towards Dialogic and On-Demand Metaphors for Interdisciplinary Reading",
    "id": 188952,
    "sequence": 743,
    "queryCoordinates": {
      "visualization": [
        -5.219495154182159,
        4.664426045664028
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "In emerging \"driver-less\" automated vehicles (AVs), the intuitive communication that exists between human drivers and passengers no longer exists, which can lead to reduced trust and acceptance in passengers if they are unclear about what the AV intends to do. This paper contributes the foundational understanding of how passengers naturally decode drivers' non-verbal cues about their intended action to inform intuitive Human-Machine Interface (HMI) designs that try to emulate those cues. Our study investigates what cues passengers perceive, their saliency, and interpretation through a mixed-method approach combining field observations, experience sampling, and auto-confrontation interviews with 30 driver-passenger pairs. Analysis of posture, head/eye movements, and vestibular sensations revealed four categories of intention cues: awareness, interaction, vestibular, and habitual. These findings provide empirical foundations for designing AV interfaces that mirror natural human communication patterns. We discuss implications for designing anthropomorphic HMIs that could enhance trust, predictability, and user experience in AVs.",
    "title": "Decoding Driver Intention Cues: Exploring Non-verbal Communication for Human-Centered Automotive Interfaces",
    "id": 188953,
    "sequence": 744,
    "queryCoordinates": {
      "visualization": [
        -1.960342806591213,
        19.90369453344394
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "In Affective computing, recognizing users' emotions accurately is the basis of affective human–computer interaction. Understanding users' interoception contributes to a better understanding of individually different emotional abilities, which is essential for achieving inter-individually accurate emotion estimation. However, existing interoception measurement methods, such as the heart rate discrimination task, have several limitations, including their dependence on a well-controlled laboratory environment and precision apparatus, making monitoring users' interoception challenging. This study aims to determine other forms of data that can explain users' interoceptive or similar states in their real-world lives and propose a novel hypothetical concept \"cyberoception,\" a new sense (1) which has properties similar to interoception in terms of the correlation with other emotion-related abilities, and (2) which can be measured only by the sensors embedded inside commodity smartphone devices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild hybrid experiment reveal a specific cyberoception type \"Turn On.\" (users' subjective sensory perception about the frequency of turning-on behavior on their smartphones)\r\n",
    "title": "Cyberoception: Finding A Painlessly-Measurable New Sense In The Cyberworld Towards Emotion-awareness In Computing",
    "id": 188954,
    "sequence": 745,
    "queryCoordinates": {
      "visualization": [
        -7.760250025556352,
        -1.9438414392261105
      ]
    }
  },
  {
    "session": "With AI",
    "abstract": "Recent advances in AI technologies, including large language models, have enabled the widespread deployment of automated meeting minute generation at a commercial scale. However, many users continue to take minutes manually. To understand the factors behind this gap, we conducted a case study on a start-up company providing a commercial meeting analysis service. Through detailed observations of the development process over three years and workshops with their designers and developers, we identified key challenges, including discrepancies between user expectations and AI-generated summaries, as well as difficulties in balancing user interaction with automation. Importantly, our study sheds light on factors that have been less emphasized in previous HCI literature, such as the learning curve associated with adopting new technologies for an enterprise product. These insights spotlight the challenges in achieving an effective collaboration between rapidly evolving AI and users, suggesting the increasingly important role of HCI.",
    "title": "AI for Meeting Minutes: Promises and Challenges in Designing Human-AI Collaboration on a Production SaaS Platform",
    "id": 188955,
    "sequence": 746,
    "queryCoordinates": {
      "visualization": [
        7.24944041745727,
        16.475606624150046
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "Historically, anatomical education has utilised physical models; researchers are now looking to Augmented Reality (AR) to deliver more engaging learning experiences. While there are clear educational advantages to AR, most systems lack the cognitive benefits afforded by physical models. Our work explores the potential of combining physical anatomical models and AR. We first present a design space exploring the interplay between the two. From this, we created a tangible AR system utilising a physical vertebrae model for learning spinal anatomy and axial spondyloarthritis progression. We conducted a study (n=39) to evaluate its benefits for knowledge improvement and retention, compared with a virtual AR and screen-based version. We found no difference in learning outcomes, however, the physical model improved participants' learning experience. We then conducted an expert evaluation with clinicians to explore opportunities for using tangible AR in clinical practice. Results highlight potential benefits for patient understanding, and challenges surrounding accessibility.",
    "title": "Investigating the Benefits of Physical Models for Anatomical Education in Augmented Reality",
    "id": 188956,
    "sequence": 747,
    "queryCoordinates": {
      "visualization": [
        2.380060020873705,
        -1.826284287026163
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "Pass-through technologies are promising for mixed reality (MR) systems. Therefore, various MR applications operating in pass-through devices emerged in diverse domains, such as education and healthcare. However, research on the everyday use of pass-through devices remains limited, despite it blending real and virtual environments.\r\nThis study explores the user experience of pass-through devices in people's daily tasks. We conducted a field study with 16 participants and analyzed data from eight daily tasks. For in-depth analysis, we employed three measures in terms of quantitative, qualitative, and bio-signal. As a result, we found that participants felt differently in terms of immersion, collision anxiety, and workload. Findings suggest that pass-through devices are not yet fully ready for integration into daily life. However, the potential for widespread adoption exists as the technology continues to advance. Finally, we offer guidelines and considerations to improve the usability of pass-through devices for everyday use.",
    "title": "\"Through the Looking Glass, and What We Found There\": A Comprehensive Study of User Experiences with Pass-Through Devices in Everyday Activities",
    "id": 188957,
    "sequence": 748,
    "queryCoordinates": {
      "visualization": [
        20.179263760847093,
        -5.813545739921833
      ]
    }
  },
  {
    "session": "With AI",
    "abstract": "LLMs have shown promise in replicating human-like behavior in crowdsourcing tasks that were previously thought to be exclusive to human abilities. However, current efforts focus mainly on simple atomic tasks. We explore whether LLMs can replicate more complex crowdsourcing pipelines. We find that modern LLMs can simulate some of crowdworkers' abilities in these ``human computation algorithms,'' but the level of success is variable and influenced by requesters' understanding of LLM capabilities, the specific skills required for sub-tasks, and the optimal interaction modality for performing these sub-tasks. We reflect on human and LLMs' different sensitivities to instructions, stress the importance of enabling human-facing safeguards for LLMs, and discuss the potential of training humans and LLMs with complementary skill sets. Crucially, we show that replicating crowdsourcing pipelines offers a valuable platform to investigate 1) the relative LLM strengths on different tasks (by cross-comparing their performances on sub-tasks) and 2) LLMs' potential in complex tasks, where they can complete part of the tasks while leaving others to humans.",
    "title": "LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs",
    "id": 188958,
    "sequence": 749,
    "queryCoordinates": {
      "visualization": [
        5.690980167149415,
        -11.688145478950544
      ]
    }
  },
  {
    "session": "WS34: Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "abstract": "Trained and optimized for typical and fluent speech, speech AI works poorly for people with speech diversities, often cutting them off from speaking and misinterpreting their speech. The increasing deployment of speech AI in automated phone menus, AI-conducted job interviews, and everyday devices poses tangible risks to people with speech diversities. To mitigate these risks, this workshop aims to build a multidisciplinary coalition and set the research agenda for fair and accessible speech AI. Bringing together a broad group of academics and practitioners with diverse perspectives including HCI, AI, and other relevant fields such as disability studies, speech language pathology, and law, this workshop will establish a shared understanding of the technical challenges for fair and accessible speech AI, as well as its ramifications in design, user experience, policy, society. In addition, the workshop will invite and highlight first-person accounts from people with speech diversities, facilitating direct dialogues and collaboration between speech AI developers and the impacted communities. The key outcomes of this workshop include a summary paper that synthesizes our leanings and outlines the roadmap for improving speech AI for people with speech diversities, as well as a community of scholars, practitioners, activists, and policy makers interested in drivings progress in this domain.",
    "title": "Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "id": 188959,
    "sequence": 750,
    "queryCoordinates": {
      "visualization": [
        5.036922252557856,
        17.280897378946715
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "Designing vibrotactile experiences collaboratively requires communicating using multiple senses. This is challenging in remote scenarios as designers need to effectively express and communicate their intention while iteratively building and refining experiences, ideally in real-time. We formulate design considerations for collaborative haptic design tools, and propose CollabJam, a collaborative prototyping suite enabling remote synchronous design of vibrotactile experiences for on-body applications. We first outline CollabJam’s features and present a technical evaluation. Second, we use CollabJam to understand communication and design patterns used during haptic experience design. We performed an in-depth design evaluation spanning four sessions in which four pairs of participants designed and reviewed vibrotactile experiences remotely. A qualitative content analysis revealed how multi-sensory communication is essential to convey ideas, how stimulating the tactile sense can interfere with personal boundaries, and how freely placing actuators on the skin can provide both benefits and challenges.",
    "title": "CollabJam: Studying Collaborative Haptic Experience Design for On-Body Vibrotactile Patterns",
    "id": 188960,
    "sequence": 751,
    "queryCoordinates": {
      "visualization": [
        5.059395684659376,
        -21.410336646256876
      ]
    }
  },
  {
    "session": "Data Interpretation and Storytelling",
    "abstract": "Viewers tend to underestimate correlation in positively correlated scatterplots. However, systematically changing the size and opacity of scatterplot points can bias estimates upwards, correcting for this underestimation. Here, we examine whether the application of these visualisation techniques goes beyond a simple perceptual effect and could actually influence beliefs about information from trusted news sources. We present a fully-reproducible study in which we demonstrate that scatterplot manipulations that are able to correct for the correlation underestimation bias can also induce stronger levels of belief change compared to conventional scatterplots presenting identical data. Consequently, we show that novel visualisation techniques can be used to drive belief change, and suggest future directions for extending this work with regards to altering attitudes and behaviours.",
    "title": "Effects of Alternative Scatterplot Designs on Belief",
    "id": 188961,
    "sequence": 752,
    "queryCoordinates": {
      "visualization": [
        11.839719985018547,
        -1.954745680735079
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "Social online games like Minecraft and Roblox have become increasingly integral to children's daily lives. Our study explores how children aged 8 to 13 create and customize avatars in these virtual environments. Through semi-structured interviews and gameplay observations with 48 participants, we investigate the motivations behind children's avatar-making. Our findings show that children's avatar creation is motivated by self-representation, experimenting with alter ego identities, fulfilling social needs, and improving in-game performance. In addition, designed monetization strategies play a role in shaping children's avatars. We identify the ''wardrobe effect,'' where children create multiple avatars but typically use only one favorite consistently. We discuss the impact of cultural consumerism and how social games can support children's identity exploration while balancing self-expression and social conformity. This work contributes to understanding how avatar shapes children's identity growth in social online games.",
    "title": "Understanding Children's Avatar Making in Social Online Games",
    "id": 188962,
    "sequence": 753,
    "queryCoordinates": {
      "visualization": [
        0.39267619504895923,
        -20.996328379167675
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "We describe an artist residency program in which three professional American Indian potters experiment with the use of clay 3D printing in their practice. The artists navigate the opportunities and risks involved in blending 3D printing with Pueblo pottery. In our analysis, we introduce and examine three aspects of digital fabrication that impact professional practice: the practical, creative and conceptual. Practically, a digital fabrication machine may improve or worsen efficiency. Creatively, a machine can both expand and constrain the kinds of work artists can make. Finally, a machine can be conceptually significant; the use of the machine can change what a piece means and how it is perceived. We found that clay 3D printers: 1) are labor intensive to operate and do not improve efficiency; 2) can present new and compelling creative opportunities; 3) are conceptually fraught. The use of a 3D printer can profoundly change the way work is received and valued. We discuss the entangled mix of opportunity and risk that these aspects of clay 3D printing present.",
    "title": "American Indian Pottery and Clay 3D Printing: An Exploration of Opportunities and Risks in Professional Practice",
    "id": 188963,
    "sequence": 754,
    "queryCoordinates": {
      "visualization": [
        5.0438835470533645,
        -18.31827608602306
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "Non-consensual intimate media (NCIM) presents internet-scale harm to individuals who are depicted. One of the most powerful tools for requesting its removal is the Digital Millennium Copyright Act (DMCA). However, the DMCA was designed to protect copyright holders rather than to address the problem of NCIM. Using a dataset of more than 54,000 DMCA reports and over 85 million infringing URLs spanning over a decade, this paper evaluates the efficacy of the DMCA for NCIM takedown. Results show that for non-commercial requests, while more than half of URLs are deindexed from Google Search within 48 hours, the actual removal of content from website hosts is much slower. The median infringing URL takes more than 45 days to be removed from website hosts, and only 5.39% URLs are removed within the first 48 hours. Additionally, the most frequently reported domains for non-commercial NCIM are smaller websites, not large platforms. We stress the need for new laws that ensure a shorter time to takedown that are enforceable across big and small platforms alike.",
    "title": "A Law of One's Own: The Inefficacy of the DMCA for Non-Consensual Intimate Media",
    "id": 188964,
    "sequence": 755,
    "queryCoordinates": {
      "visualization": [
        7.70460848773221,
        -10.470864723162304
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "As social service robots become commonplace, it is essential for them to effectively interpret human signals, such as verbal, gesture, and eye gaze, when people need to focus on their primary tasks to minimize interruptions and distractions. Toward such a socially acceptable Human-Robot Interaction, we conducted a study (N=24) in an AR-simulated context of a coffee chat. Participants elicited social cues to signal intentions to an anthropomorphic, zoomorphic, grounded technical, or aerial technical robot waiter when they were speakers or listeners. Our findings reveal common patterns of social cues over intentions, the effects of robot morphology on social cue position and conversational role on social cue complexity, and users' rationale in choosing social cues. We offer insights into understanding social cues concerning perceptions of robots, cognitive load, and social context. Additionally, we discuss design considerations on approaching, social cue recognition, and response strategies for future service robots.",
    "title": "Signaling Human Intentions to Service Robots: Understanding the Use of Social Cues during In-Person Conversations",
    "id": 188965,
    "sequence": 756,
    "queryCoordinates": {
      "visualization": [
        19.965312203694317,
        1.1774160730237806
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "This paper explores flexibility in platform-mediated work through a multi-sited ethnographic study of delivery workers' \"flexible scheduling\" in three European countries: Denmark, Finland, and Malta. While workers generally value the ability to schedule flexibly, this flexibility is constrained by structural factors such as piece-rate remuneration, demand fluctuations, surge pricing, and income dependency. The constraints result in markedly different experiences across the different instantiations of the same, standardised delivery platform: workers in Denmark benefit from the system, in Finland workers face seasonal precarity, and in Malta workers endure exploitative cycles of long hours and low pay. The findings demonstrate how the same platform's standardised design can produce divergent outcomes in local contexts. The paper highlights the need for platform designers and regulators to balance the benefits of flexible scheduling with its trade-offs, ensuring that flexibility supports worker well-being as the flexible platforms manifest locally. ",
    "title": "“Flexible Platforms? An Ethnographic Study of Flexible Scheduling in Platform-Mediated Delivery",
    "id": 188966,
    "sequence": 757,
    "queryCoordinates": {
      "visualization": [
        -20.38252791652121,
        -5.0549535835884365
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "Bodily fluids associated with the menstruating body are often disregarded in the design of menstrual-tracking technologies despite their potential to provide valuable knowledge about the menstrual cycle. We prototyped a finger-worn sensor that measures vaginal fluid conductivity, which fluctuates throughout the cycle, and brought it into conversation with people through two speculative workshops (18 people), four fabrication workshops (17 people), and a deployment study where participants brought the sensor into their daily lives (7 people). We unpack that taking a material and sensory approach to intimate tracking nurtures a feminist way of sensing while creating tensions around how we want to know our bodies—tensions around how, where, and when to touch the body, hygiene, data storage, interpretation practices, and labor. With epistemological commitments to feminist materialist and posthuman theory, we invite designers to embrace these tensions.",
    "title": "Toward Feminist Ways of Sensing the Menstruating Body",
    "id": 188967,
    "sequence": 758,
    "queryCoordinates": {
      "visualization": [
        18.801493573216852,
        -2.7393136761395884
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "In this study, we introduce the Conversation Progress Guide (CPG), a system designed for text-based conversational AI interactions that provides a visual interface to represent progress.\r\nUsers often encounter failures when interacting with conversational AI, which can negatively affect their self-efficacy—an individual's belief in their capabilities, reducing their willingness to engage with these services. \r\nThe CPG offers visual feedback on task progress, providing users with mastery experiences, a key source of self-efficacy. \r\nTo evaluate the system's effectiveness, we conducted a user study assessing how the integration of the CPG influences user engagement and self-efficacy. \r\nResults demonstrate that users interacting with a conversational AI enhanced by the CPG showed significant improvements in self-efficacy measures compared to those using a conventional conversational AI.",
    "title": "Conversation Progress Guide : UI System for Enhancing Self-Efficacy in Conversational AI",
    "id": 188968,
    "sequence": 759,
    "queryCoordinates": {
      "visualization": [
        8.054906928824348,
        -20.472383211731298
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "This PhD research investigates human-nature engagement through an HCI lens, focusing on water as both a medium and a metaphor for designing interactive systems. Employing a research-through-design approach, the study explores water’s sensory, ecological, and symbolic properties by developing water-based technologies, such as ultrasonic water manipulation, to prototype scenarios of calm and meaningful interaction. Complementing this, ethnographic studies with coastal and urban water communities will examine human-water relationships, exploring how cultural practices and environmental challenges inform situated knowledge. The research aims to generate actionable design implications for technologies that foster meaningful human-nature engagement, with an emphasis on promoting sustainable practices and enhancing individual wellbeing.\r\n",
    "title": "Water as a Collaborative Medium: Rethinking Human-Nature Engagement",
    "id": 188969,
    "sequence": 760,
    "queryCoordinates": {
      "visualization": [
        -1.9606357775119614,
        20.90827365776381
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "Fully autonomous teams of LLM-powered AI agents are emerging that collaborate to perform complex tasks for users. What challenges do developers face when trying to build and debug these AI agent teams? In formative interviews with five AI agent developers, we identify core challenges: difficulty reviewing long agent conversations to localize errors, lack of support in current tools for interactive debugging, and the need for tool support to iterate on agent configuration. Based on these needs, we developed an interactive multi-agent debugging tool, AGDebugger, with a UI for browsing and sending messages, the ability to edit and reset prior agent messages, and an overview visualization for navigating complex message histories. In a two-part user study with 14 participants, we identify common user strategies for steering agents and highlight the importance of interactive message resets for debugging. Our studies deepen understanding of interfaces for debugging increasingly important agentic workflows.",
    "title": "Interactive Debugging and Steering of Multi-Agent AI Systems",
    "id": 188970,
    "sequence": 761,
    "queryCoordinates": {
      "visualization": [
        -11.993575049716387,
        -0.3926289938613091
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "The widespread use of image tables presents significant accessibility challenges for blind and low vision (BLV) people, limiting their access to critical data. Despite advancements in artificial intelligence (AI) for interpreting image tables, current solutions often fail to consider the specific needs of BLV users, leading to a poor user experience. To address these issues, we introduce TableNarrator, an innovative system designed to enhance the accessibility of image tables. Informed by accessibility standards and user feedback, TableNarrator leverages AI to generate alternative text tailored to the cognitive and reading preferences of BLV users. It streamlines access through a simple interaction mode and offers personalized options. Our evaluations, from both technical and user perspectives, demonstrate that TableNarrator not only provides accurate and comprehensive table information but also significantly enhances the user experience for BLV people.",
    "title": "TableNarrator: Making Image Tables Accessible to Blind and Low Vision People",
    "id": 188971,
    "sequence": 762,
    "queryCoordinates": {
      "visualization": [
        -11.739952735240914,
        -12.295263713085188
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "The video gaming industry offers richer experiences through increasingly complex game mechanics, often hindering learnability. This research explores integrating an LLM-based chatbot, “Daisy,” in Stardew Valley, a narrative-rich role-playing game where learnability is critical. Over three weeks, 24 participants—14 new and 10 experienced players—engaged in a diary study and post-interviews. Analysis of diaries, chat logs, gameplay videos, and interviews revealed three themes: seeking information support, playing with chatbots, and addressing practical challenges. Findings show Daisy’s potential to enhance learnability through natural conversations, fostering immersion and emotional engagement, though issues like hallucinations and context awareness require improvement. This work highlights preliminary insights for integrating LLMs into narrative-rich games.",
    "title": "Development of an LLM-Based Chatbot to Support Learnability in Stardew Valley: A Diary Study Approach",
    "id": 188972,
    "sequence": 763,
    "queryCoordinates": {
      "visualization": [
        -17.25468771955584,
        -10.113147467559687
      ]
    }
  },
  {
    "session": "XR Interaction",
    "abstract": "Desktop environments can integrate augmented reality (AR) head-worn devices to support 3D representations, visualizations, and interactions in a novel yet familiar setting. As users navigate across the dual realities---desktop and AR---a way to move 3D objects between them is needed. \r\nWe devise three baseline transition techniques based on common approaches in the literature and evaluate their usability and practicality in an initial user study (N=18). \r\nAfter refining both our transition techniques and the surrounding technical setup, we validate the applicability of the overall concept for real-world activities in an expert user study (N=6). \r\nIn it, computational chemists followed their usual desktop workflows to build, manipulate, and analyze 3D molecular structures, but now aided with the addition of AR and our transition techniques. \r\nBased on our findings from both user studies, we provide lessons learned and takeaways for the design of 3D object transition techniques in desktop + AR environments.",
    "title": "Traversing Dual Realities: Investigating Techniques for Transitioning 3D Objects between Desktop and Augmented Reality Environments",
    "id": 188973,
    "sequence": 764,
    "queryCoordinates": {
      "visualization": [
        -4.835696475121412,
        7.590523012315972
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "Virtual reality (VR) allows to embody avatars. Coined the Proteus effect, an avatar's visual appearance can influence users' behavior and perception. Recent work suggests that athletic avatars decrease perceptual and physiological responses during VR exercise. However, such effects can fail to occur when users do not experience avatar ownership and identification. While customized avatars increase body ownership and identification, it is unclear whether they improve the Proteus effect. We conducted a study with 24 participants to determine the effects of athletic and non-athletic avatars that were either customized or randomly assigned. We developed a customization editor to allow creating customized avatars. We found that customized avatars reduced perceived exertion. We also found that athletic avatars decreased heart rate while holding weights, however, only when being customized. Results indicate that customized avatars can positively influence users during physical exertion. We discuss the utilization of avatar customization in VR exercise systems.",
    "title": "Investigating the Impact of Customized Avatars and the Proteus Effect during Physical Exercise in Virtual Reality",
    "id": 188974,
    "sequence": 765,
    "queryCoordinates": {
      "visualization": [
        6.080311868540941,
        -6.635496031291118
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "In contrast to design tools for graphics and audio generation from text prompts, haptic design tools lag behind due to challenges in constructing large-scale, high-quality datasets including vibrations and text descriptions. To address this gap, we propose ChatHAP, a conversational haptic system for designing vibrations. ChatHAP integrates various haptic design approaches using a large language model, including generating vibrations using signal parameters, navigating through libraries, and modifying existing vibrations. To further improve vibration navigation, we present an algorithm that adaptively learns user preferences for vibration features. A user study with novices (n=20) demonstrated that ChatHAP can serve as a practical design tool, and the proposed algorithm significantly reduced task completion time (38%), prompt quantity (25%), and verbosity (36%). The study found ChatHAP easy-to-use and identified requirements for chat-based haptic design as well as features for further improvement. Finally, we present key findings with ChatHAP and discuss implications for future work.",
    "title": "ChatHAP: A Chat-Based Haptic System for Designing Vibrations through Conversation",
    "id": 188975,
    "sequence": 766,
    "queryCoordinates": {
      "visualization": [
        -8.923003752364295,
        -1.174735729980462
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "Kuddi is a haptic data physicalisation in the form of a soft pillow which combines 12 inflatable pockets to dynamically touch and be touched in relation to the changing menstruating body. This paper presents the soma design process that led to Kuddi's design, as well as Kuddi's evaluation through an auto-ethnographic approach, where the first author lived with Kuddi for two menstrual cycles. The resulting dataset was analysed by the research team using a narrative-led approach. Based on this analysis, we present five thick descriptions that capture how the experience of living with Kuddi led to a changing relation with menstrual pain. We contribute a design case of a haptic data physicalisation intended to touch the body and discuss how the material and interaction design choices embodied in Kuddi led to data visceralisation - a way of feeling data in ways which promote new somatic knowledge and experience. ",
    "title": "Becoming One with Kuddi: Touching Data through an Intimate Data Physicalisation",
    "id": 188976,
    "sequence": 767,
    "queryCoordinates": {
      "visualization": [
        -1.662939224605091,
        -1.111140466039204
      ]
    }
  },
  {
    "session": "Health and Well-being",
    "abstract": "Remote patient monitoring can significantly enhance post-operative home recovery for cancer patients, yet its effectiveness is often hindered by low patient engagement. Reassurance has been identified as a key factor in improving engagement. Our study explored how cancer patients seek reassurance through a Patient Public Involvement workshop with former patients. This involved developing personas for participants to navigate reassurance scenarios and share their post-operative experiences. Based on this, we co-created a reassurance journey map to illustrate when reassurance is needed, the behaviours patients use to seek it, and how it can be effectively provided. Our findings highlight three key design principles: the limitations of digital technology in offering reassurance, the personalised nature of reassurance, and the need for holistic integration. These are intended to inform the design of reassurance-focused RPM systems that better support cancer patients during home recovery. Practical design recommendations are also provided for developers and clinicians.",
    "title": "Co-Creating Reassurance Journey Maps to Foster Engagement in Remote Patient Monitoring for Post-Operative Cancer Care",
    "id": 188977,
    "sequence": 768,
    "queryCoordinates": {
      "visualization": [
        1.1773424979433027,
        -18.963487670851496
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "Despite recognizing that Large Language Models (LLMs) can generate inaccurate or unacceptable responses, universities are increasingly making such models available to their students. Existing university policies defer the responsibility of checking for correctness and appropriateness of LLM responses to students and assume that they will have the required knowledge and skills to do so on their own. In this work, we conducted a series of user studies with students (N=47) from a large North American public research university to understand if and how they critically engage with LLMs. Our participants evaluated an LLM provided by the university in a quasi-experimental setup; first by themselves, and then with a scaffolded design probe that guided them through an end-user auditing exercise. Qualitative analysis of participant think-aloud and LLM interaction data showed that students without basic AI literacy skills struggle to conceptualize and evaluate LLM biases on their own. However, they transition to focused thinking and purposeful interactions when provided with structured guidance. We highlight areas where current university policies may fall short and offer policy and design recommendations to better support students.",
    "title": "\"Here the GPT made a choice, and every choice can be biased\": How Students Critically Engage with LLMs through End-User Auditing Activity",
    "id": 188978,
    "sequence": 769,
    "queryCoordinates": {
      "visualization": [
        17.0447423309119,
        5.785910375456909
      ]
    }
  },
  {
    "session": "Health and Well-being",
    "abstract": "Image-based sexual abuse (IBSA) refers to the nonconsensual creating, taking, or sharing of intimate images, including threats to share intimate images. Despite the significant harms of IBSA, there is limited data on its prevalence and how it affects different identity or demographic groups. This  study examines prevalence of, impacts from, and responses to IBSA via a survey with over 16,000 adults in 10 countries. More than 1 in 5 (22.6%) respondents reported an experience of IBSA. Victimization rates were higher among LGBTQ+ and younger respondents. Although victimized at similar rates, women reported greater harms and negative impacts from IBSA than men.  Nearly a third (30.9%) of victim-survivors did not report or disclose their experience to anyone. We provide large-scale, granular, baseline data on prevalence in a diverse set to aid in the development of effective interventions that address the  experiences and intersectional identities of victim-survivors'.",
    "title": "Prevalence and Impacts of Image-Based Sexual Abuse Victimization: A Multinational Study",
    "id": 188979,
    "sequence": 770,
    "queryCoordinates": {
      "visualization": [
        11.406089484000457,
        -9.741720724952762
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "Mobile health applications show promise for scalable physical activity promotion but are often insufficiently personalized. In contrast, health coaching offers highly personalized support but can be prohibitively expensive and inaccessible. This study draws inspiration from health coaching to explore how large language models (LLMs) might address personalization challenges in mobile health. We conduct formative interviews with 12 health professionals and 10 potential coaching recipients to develop design principles for an LLM-based health coach. We then built GPTCoach, a chatbot that implements the onboarding conversation from an evidence-based coaching program, uses conversational strategies from motivational interviewing, and incorporates wearable data to create personalized physical activity plans. In a lab study with 16 participants using three months of historical data, we find promising evidence that GPTCoach gathers rich qualitative information to offer personalized support, with users feeling comfortable sharing concerns. We conclude with implications for future research on LLM-based physical activity support.",
    "title": "GPTCoach: Towards LLM-Based Physical Activity Coaching",
    "id": 188980,
    "sequence": 771,
    "queryCoordinates": {
      "visualization": [
        15.98964536214065,
        5.773321504383243
      ]
    }
  },
  {
    "session": "Storytelling and Sense-Making",
    "abstract": "With a growing interest in immersive data storytelling, there is an opportunity to explore story presentation and navigation techniques in virtual reality (VR) that can engage audiences as much as data story techniques have on conventional displays. We propose and explore “strolly”telling, a novel data storytelling technique that maps the story progression with the user/audience’s physical locomotion. Inspired by the conventional web-based technique for scrolling-based stories (i.e. scrollytelling), our technique tightly\r\ncouples the user’s position in physical space to the animation frame of the data story. This technique leverages the natural tendency of humans to \"walk and talk\" while telling a story and requires users to engage with the content actively. This work defines strollytelling,\r\ndesign considerations, and a preliminary process for designing a strollytelling experience. A user study comparing strollytelling with virtual locomotion found that strollytelling was preferred by most participants and had higher self-reported immersion. We conclude with opportunities for strollytelling within the immersive data storytelling landscape.",
    "title": "Strollytelling: Coupling Animation with Physical Locomotion to Explore Immersive Data Stories",
    "id": 188981,
    "sequence": 772,
    "queryCoordinates": {
      "visualization": [
        15.87967255357936,
        1.9585708031874591
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "Driven by the vision of everyday haptics, the HCI community is advocating for “design touch first” and investigating “how to touch well.” However, a gap remains between the exploratory nature of haptic design and technical reproducibility. We present Shape-Kit, a hybrid design toolkit embodying our “crafting haptics” metaphor, where hand touch is transduced into dynamic pin-based sensations that can be freely explored across the body. An ad-hoc tracking module captures and digitizes these patterns. Our study with 14 designers and artists demonstrates how Shape-Kit facilitates sensorial exploration for expressive haptic design. We analyze how designers collaboratively ideate, prototype, iterate, and compose touch experiences and show the subtlety and richness of touch that can be achieved through diverse crafting methods with Shape-Kit. Reflecting on the findings, our work contributes key insights into haptic toolkit design and touch design practices centered on the “crafting haptics” metaphor. We discuss in-depth how Shape-Kit’s simplicity, though remaining constrained, enables focused crafting for deeper exploration, while its collaborative nature fosters shared sense-making of touch experiences.",
    "title": "Shape-Kit: A Design Toolkit for Crafting On-Body Expressive Haptics",
    "id": 188982,
    "sequence": 773,
    "queryCoordinates": {
      "visualization": [
        1.9585708031874605,
        15.87967255357936
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "Today’s mapping tools fail to address the varied experiences of different mobility device users. This paper presents a large-scale online survey exploring how five mobility groups—users of canes, walkers, mobility scooters, manual wheelchairs, and motorized wheelchairs—perceive sidewalk barriers and differences therein. Using 52 sidewalk barrier images, respondents evaluated their confidence in navigating each scenario. Our findings (N=190) reveal variations in barrier perceptions across groups, while also identifying shared concerns. To further demonstrate the value of this data, we showcase its use in two custom prototypes: a visual analytics tool and a personalized routing tool. Our survey findings and open dataset advance work in accessibility-focused maps, routing algorithms, and urban planning.",
    "title": "Accessibility for Whom? Perceptions of Mobility Barriers Across Disability Groups and Implications for Designing Personalized Maps",
    "id": 188983,
    "sequence": 774,
    "queryCoordinates": {
      "visualization": [
        -1.1774793919810262,
        20.96696311537415
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "Smartphones are integral to modern life, yet research highlights the cognitive drawbacks associated with their mere presence. While physically removing them can mitigate these effects, it is often inconvenient and may heighten anxiety due to prolonged separation. To address this, we use holographic augmented reality (AR) displays to visually diminish distractions with two interventions: 1) Visual Camouflage, which disguises the smartphone with a hologram that matches its size and blends with the background, making it less noticeable, and 2) Visual Substitution, which occludes the smartphone with a contextually relevant hologram, like books on a desk. In a study with 60 participants, we compared cognitive performance with the smartphone nearby, remote, and visually diminished by our AR interventions. Our findings show that the interventions significantly reduce cognitive impairment, with effects comparable to physically removing the smartphone. The adaptability of our approach opens new avenues to manage visual distractions in daily life.",
    "title": "DiminishAR: Diminishing Visual Distractions via Holographic AR Displays",
    "id": 188984,
    "sequence": 775,
    "queryCoordinates": {
      "visualization": [
        0.39229547863922604,
        -4.9845866686656395
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "Walking on inclined surfaces is common in some Virtual Reality (VR) scenarios, for instance, when moving between floors of a building, climbing a tower, or ascending a virtual mountain. Existing approaches enabling realistic walking experiences in such settings typically require the user to use bulky walking-in-place hardware or to walk in a physical area. Addressing this challenge, we present RedirectedStepper, a locomotion technique leveraging a novel device based on a mini exercise stepper to provide realistic VR staircase walking experiences by alternating the tilt of the two stepper pedals.\r\nRedirectedStepper employs a new exponential mapping function to visually morph the user's real foot motion to a corresponding curved path in the virtual environment (VE).\r\nCombining this stepper and the visual mapping function provides an in-place locomotion technique allowing users to virtually ascend an infinite staircase or slope while walking-in-place (WIP). We conducted three within-subject user studies (n=36) comparing RedirectedStepper with a WIP locomotion technique using the Kinect. Our studies indicate that RedirectedStepper improves the users' sense of realism in walking on staircases in VR. Based on a set of design implications derived from the user studies, we developed SnowRun, a VR exergame application, demonstrating the use of the RedirectedStepper concept.",
    "title": "RedirectedStepper: Exploring Walking-In-Place Locomotion in VR  Using a Mini Stepper for Ascents",
    "id": 188985,
    "sequence": 776,
    "queryCoordinates": {
      "visualization": [
        -6.080311868540943,
        -6.635496031291114
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "AI agents are increasingly tasked with making proactive suggestions in online spaces where groups collaborate, yet risk being unhelpful or even annoying if they fail to match group preferences or behave in socially inappropriate ways. \r\nFortunately, group spaces have a rich history of prior interactions and affordances for social feedback that can support grounding an agent's generations to a group's interests and norms. \r\nWe present Social-RAG, a workflow for socially grounding agents that retrieves context from prior group interactions, selects relevant social signals, and feeds them into a language model to generate messages in a socially aligned manner. \r\nWe implement this in \\textsc{PaperPing}, a system for posting paper recommendations in group chat, leveraging social signals determined from formative studies with 39 researchers.\r\nFrom a three-month deployment in 18 channels reaching 500+ researchers, we observed PaperPing posted relevant messages in groups without disrupting their existing social practices, fostering group common ground. \r\n",
    "title": "Social-RAG: Retrieving from Group Interactions to Socially Ground AI Generation",
    "id": 188986,
    "sequence": 777,
    "queryCoordinates": {
      "visualization": [
        2.7249151564124707,
        -11.686523751328007
      ]
    }
  },
  {
    "session": "XR Interaction",
    "abstract": "Authoring site-specific outdoor augmented reality (AR) experiences requires a nuanced understanding of real-world context to create immersive and relevant content. Existing ex-situ authoring tools typically rely on static 3D models to represent spatial information. However, in our formative study (n=25), we identified key limitations of this approach: models are often outdated, incomplete, or insufficient for capturing critical factors such as safety considerations, user flow, and dynamic environmental changes. These issues necessitate frequent on-site visits and additional iterations, making the authoring process more time-consuming and resource-intensive. To mitigate these challenges, we introduce CoCreatAR, an asymmetric collaborative mixed reality authoring system that integrates the flexibility of ex-situ workflows with the immediate contextual awareness of in-situ authoring. We conducted an exploratory study (n=32) comparing CoCreatAR to an asynchronous workflow baseline, finding that it enhances engagement, creativity, and confidence in the authored output while also providing preliminary insights into its impact on task load. We conclude by discussing the implications of our findings for integrating real-world context into site-specific AR authoring systems.",
    "title": "CoCreatAR: Enhancing Authoring of Outdoor Augmented Reality Experiences Through Asymmetric Collaboration",
    "id": 188987,
    "sequence": 778,
    "queryCoordinates": {
      "visualization": [
        -8.657797840548993,
        -15.78108160273513
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "Advancements in large language models (LLMs) are sparking a proliferation of LLM-powered user experiences (UX). In product teams, designers often craft UX to meet user needs, but it is unclear how they engage with LLMs as a novel design material. Through a formative study with 12 designers, we find that designers seek a translational process that enables design requirements to shape and be shaped by LLM behavior, motivating a need for designerly adaptation to facilitate this translation. We then built Canvil, a Figma widget that operationalizes designerly adaptation. We used Canvil as a probe to study designerly adaptation in a group-based design study (N=17), finding that designers constructively iterated on both adaptation approaches and interface designs to enhance end-user interaction with LLMs. Furthermore, designers identified promising collaborative workflows for designerly adaptation. Our work opens new avenues for processes and tools that foreground designers' human-centered expertise when developing LLM-powered applications.",
    "title": "Canvil: Designerly Adaptation for LLM-Powered User Experiences",
    "id": 188988,
    "sequence": 779,
    "queryCoordinates": {
      "visualization": [
        6.573900852678033,
        -20.994852406701007
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "Understanding how different user groups interact and perceive material selection for interactive markers in mobile augmented reality (MAR) games is essential for effective design. This study uses a qualitative approach, incorporating interviews and workshops to examine the preferences and behaviours of designers (N=6) and children (N=8). Designers highlighted the importance of using versatile and environmentally sustainable materials that can be customised for various games. Meanwhile, children’s interactions with these materials revealed challenges such as decision-making pressure and reliance on peer collaboration to navigate unfamiliar materials. The study identified five critical considerations for selecting materials: simplification, customisation, sustainability, balanced creativity, and collaboration. Our results show that while designers prioritise creative potential, user engagement is influenced by material ease and collaboration. This study provides key insights into the design considerations for MAR games, suggesting aligning designer expectations with actual user behaviour for creating successful and immersive MAR experiences.",
    "title": "Exploring the Fit: Analysing Material Selection for Interactive Markers in MAR Games through Co-Design",
    "id": 188989,
    "sequence": 780,
    "queryCoordinates": {
      "visualization": [
        -20.90827365776381,
        -1.9606357775119645
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "To protect consumer privacy, the California Consumer Privacy Act (CCPA) requires businesses to provide consumers with a straightforward way to opt out of the sale and sharing of their personal information. However, the control that businesses enjoy over the opt-out process allows them to impose hurdles on consumers aiming to opt out, including by employing dark patterns. Motivated by the enactment of the California Privacy Rights Act (CPRA), which strengthens the CCPA and explicitly forbids certain dark patterns in the opt-out process, we investigate how dark patterns are used in opt-out processes and assess their compliance with CCPA regulations. Our research on 330 CCPA-subject websites reveals that these websites employ a variety of dark patterns. Some of these patterns are explicitly prohibited under the CCPA; others seem to take advantage of legal loopholes. ",
    "title": "Dark Patterns in the Opt-Out Process and Compliance with the California Consumer Privacy Act (CCPA)",
    "id": 188990,
    "sequence": 781,
    "queryCoordinates": {
      "visualization": [
        5.681580776970634,
        1.9286367918189695
      ]
    }
  },
  {
    "session": "Vibration Vibes",
    "abstract": "Spatialized vibrotactile feedback systems deliver tactile information by placing multiple vibrotactile actuators on the body. As increasing numbers of actuators are required to adequately convey information in complicated applications, haptic designers find it difficult to create such systems due to limited scalability of existing toolkits. We propose VibraForge, an open-source vibrotactile toolkit that supports up to 128 vibrotactile actuators. Each actuator is encapsulated within a self-contained vibration unit and driven by its own microcontroller. By leveraging a chain-connection method, each unit receives independent vibration commands from a control unit, with fine-grained control over intensity and frequency. We also designed a GUI Editor to expedite the authoring of spatial vibrotactile patterns. Technical evaluation showed that vibration units reliably reproduced audio waveforms with low-latency and high-bandwidth data communication. Case studies of a phonemic tactile display, virtual reality fitness training, and drone teleoperation demonstrated the potential usage of VibraForge within different domains. A usability study with non-expert users highlighted the low technical barrier and customizability of the toolkit.",
    "title": "VibraForge: A Scalable Prototyping Toolkit For Creating Spatialized Vibrotactile Feedback Systems",
    "id": 188991,
    "sequence": 782,
    "queryCoordinates": {
      "visualization": [
        -8.314696123025454,
        -5.55570233019602
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "Human-Computer Interaction and Human-Robot Interaction researchers have developed various reminiscence technologies for older adults, but the focus of such work has mostly been on making the technology usable and improving older adults' memory recall. Our study of a robot facilitating reminiscence through conversations about personal photographs with 20 older adults uncovered a less discussed aspect of such interactions: reminiscence can evoke both \\textit{bitter} and \\textit{sweet} emotions. Without adequate emotional sensitivity, the robot sometimes responded inappropriately, requiring researchers to intervene in the interaction to address misunderstandings.\r\nTo understand how to better address these challenges, we conducted a follow-up co-design workshop with 7 older adults to explore how the robot could better support managing bittersweet emotions. Through reflexive thematic analysis of the two studies, this paper identifies factors that trigger bittersweet emotions during reminiscence with a robot and provides strategies for technology to manage these emotions during such interactions. This research highlights the importance of addressing emotional experiences in the design of reminiscence technology. It also raises ethical concerns about the emotional vulnerability of deploying one-on-one AI technologies for older adults. ",
    "title": "Bittersweet Snapshots of Life: Designing to Address Complex Emotions in a Reminiscence Interaction between Older Adults and a Robot",
    "id": 188992,
    "sequence": 783,
    "queryCoordinates": {
      "visualization": [
        9.46375449179886,
        -18.746662394115837
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "Social robots are a class of emerging smart consumer electronics devices that promise sophisticated experiences featuring emotive capabilities, artificial intelligence, conversational interaction, and more. With unique risk factors like emotional attachment, little is known on how social robots communicate these promises to consumers and whether they adequately deliver upon them within their overall product experiences prior to and during user interaction.\r\n\r\nAnimated by a consumer protection lens, this paper systematically investigates manufacturer claims made for four commercially available social robots, evaluating these claims against the provided user experience and consumer reviews.\r\nWe find that social robots vary widely in the manner and extent to which they communicate intelligent features and the supposed benefits of these features, while consumer perspectives similarly include a wide range of perceptions on robot and AI performance, capabilities, and product frustrations.We conclude by discussing social robots' unique characteristics and propensities for consumer risk, and consider implications for key stakeholders like regulators, developers, and researchers of social robots.",
    "title": "Promises, Promises: Understanding Claims Made in Social Robot Consumer Experiences",
    "id": 188993,
    "sequence": 784,
    "queryCoordinates": {
      "visualization": [
        1.177479391981033,
        -20.966963115374146
      ]
    }
  },
  {
    "session": "Working with AI",
    "abstract": "Public libraries in the U.S. are increasingly facing labor shortages, tight budgets, and overworked staff, creating a pressing need for conversational agents to assist patrons. The democratization of generative AI has empowered public service professionals to develop AI agents by leveraging large language models. To understand the needs of non-AI library professionals in creating their own conversational agents, we conducted semi-structured interviews with library professionals (n=11) across the U.S. Insights from these interviews informed the design of EvalignUX, a prototype tool that enables non-AI experts to create conversational agents without coding skills. We then conducted think-aloud sessions and follow-up interviews to evaluate the prototype experience and identify the key evaluation criteria emphasized by library professionals (n=12) when developing conversational agents. Our findings highlight how these professionals perceive the prototype experience and reveal five essential evaluation criteria: interpreting user intent, faithful paraphrasing, proper alignment with authoritative sources, tailoring the tone of voice, and handling unknown answers effectively. These insights provide valuable guidance for designing AI-supported \"end-user AI creation tools\" in public service domains beyond libraries. ",
    "title": "Evaluating Non-AI Experts' Interaction with AI: A Case Study In Library Context",
    "id": 188995,
    "sequence": 785,
    "queryCoordinates": {
      "visualization": [
        -8.322766926012344,
        9.986568514523647
      ]
    }
  },
  {
    "session": "Diversity",
    "abstract": "It is increasingly acknowledged that simply presenting users with corrective information is unlikely to produce the desired effects against misinformation. As such, the need for systematic use of behavioral theory is increasingly acknowledged, and behavioral interventions against misinformation are rising. This paper presents a scoping review of digital behavioral interventions countering misinformation, inquiring into their behavioral objectives, theoretical foundations, design and evaluation practices, and the factors that were empirically proven, or speculated, to contribute to interventions' failure. Among others, we identify 17 distinct behavioral objectives, organized into three stages of the online news cycle: composition, amplification and consumption, 24 theoretical frameworks employed in designing these interventions, and nine reasons of failure. We synthesize the findings into a set of design cards with the goal of guiding intervention designers during concept ideation and refinement, and highlight areas for future research.",
    "title": "Behavior Change Interventions Combating Online Misinformation: A Scoping Review",
    "id": 188996,
    "sequence": 786,
    "queryCoordinates": {
      "visualization": [
        4.88621241496955,
        8.72496007072797
      ]
    }
  },
  {
    "session": "WS04: Defining a UX Research Point of View (POV)",
    "abstract": "A User Experience Research Point of View (UXR PoV) is a perspective based on data, evidence, and insight that shapes how you observe, interpret, and represent the needs of your target users. We need to equip UX Practitioners with the essential tools needed to develop and articulate a persuasive PoV. Our mission is to support professionals in preparing and establishing a compelling narrative that aligns with the needs of their stakeholders. We are developing a UXR playbook that defines a set of plays and instructions for practitioners to build, establish, and land a compelling UX Research POV. The proposed workshop offers an opportunity to hear from HCI Researchers, UX Research professionals and cross-functional partners involved in design processes to extend the foundations already laid and create a more detailed UXR POV playbook. ",
    "title": "Defining a UX Research Point of View (POV)",
    "id": 188997,
    "sequence": 787,
    "queryCoordinates": {
      "visualization": [
        -1.9615705608064609,
        -0.3901806440322567
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "As governments increasingly adopt Artificial Intelligence (AI) across different application sectors, advocates argue that it will create new disruptions by democratizing access, improving accuracy, and lowering costs. In practice, uncritical adoption of AI tools has been shown to cause significant harms. Our study uses a historical lens to examine the uptake of AI in climate risk management through a study of climate and disaster risk modeling. These techniques originated in the insurance industry, but are now incorporated into many climate and disaster governance processes. Using the concept of `insurance logics', we demonstrate that many of the original aspects of disaster risk modeling remain despite the transfer of risk assessment tools from the insurance industry to the public sector and new techniques made possible by AI. This highlights technological continuity, rather than disruption, as a key driver of contemporary risk modeling practice. Doing so helps to unsettle problematic, though challenging to identify, aspects of supposedly disruptive technologies and create possibilities for alternatives.",
    "title": "Hype versus Historical Continuity: Situating the Rise of AI in Climate and Disaster Risk Modeling",
    "id": 188998,
    "sequence": 788,
    "queryCoordinates": {
      "visualization": [
        -3.5088867185306647,
        -16.633932607670356
      ]
    }
  },
  {
    "session": "Pointing and Selection",
    "abstract": "This paper investigates multi-selection in XR interfaces based on eye and hand interaction. We propose enabling multi-selection using different variations of techniques that combine gaze with a semi-pinch gesture, allowing users to select multiple objects, while on the way to a full-pinch. While our exploration is based on the semi-pinch mode for activating a quasi-mode, we explore four methods for confirming subselections in multi-selection mode, varying in effort and complexity: dwell-time (SemiDwell), swipe (SemiSwipe), tilt (SemiTilt), and non-dominant hand input (SemiNDH), and compare them to a baseline technique. In the user study, we evaluate their effectiveness in reducing task completion time, errors, and effort. The results indicate the strengths and weaknesses of each technique, with SemiSwipe and SemiDwell as the most preferred methods by participants. We also demonstrate their utility in file managing and RTS gaming application scenarios. This study provides valuable insights to advance 3D input systems in XR.",
    "title": "PinchCatcher: Enabling Multi-selection for Gaze+Pinch",
    "id": 188999,
    "sequence": 789,
    "queryCoordinates": {
      "visualization": [
        18.99594191897069,
        0.3926711233235317
      ]
    }
  },
  {
    "session": "CS Education and Security",
    "abstract": "Tangible programming engages children through hands-on and collaborative learning but often lacks integration with widely used programming platforms, which limits their extensibility and relevance in existing educational contexts. To address this, we propose Tangible-MakeCode (T-MC), a system that combines physical coding blocks with MakeCode. T-MC enables students, including beginners in coding, to design and program interactive wireless communication projects. Students assemble the blocks, capture an image with a webcam, and convert it into code for the MakeCode, which they can simulate and upload to their micro: bit boards. We describe the iterative design of T-MC, informed by participatory design workshops with 53 children and feedback from expert interviews with six teachers. A pilot study with 21 children (ages 12–14; 𝐹 = 11, 𝑀 = 10) demonstrates that T-MC is an engaging and inclusive tool that empowers beginners to contribute to team projects by providing an accessible platform for prototyping ideas.",
    "title": "Tangible-MakeCode: Bridging Physical Coding Blocks with a Web-Based Programming Interface for Collaborative and Extensible Learning",
    "id": 189000,
    "sequence": 790,
    "queryCoordinates": {
      "visualization": [
        14.417071934058377,
        13.861747250912718
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "Ceramics provide a rich domain for exploring craft, fabrication, and diverse material textures that enhance tangible interaction. In this work, we explored slip-casting, a traditional ceramic technique where liquid clay is poured into a porous plaster mold that absorbs water from the slip to form a clay body. We adapted this process into an approach we called Resist Slip-Casting. By selectively masking the mold’s surface with stickers to vary its water absorption rate, our approach enables makers to create ceramic objects with intricate textured surfaces, while also allowing the customization of a single mold for different outcomes. In this paper, we detail the resist slip-casting process and demonstrate its application by crafting a range of tangible interfaces with customizable visual symbols, tactile features, and decorative elements. We further discuss our approach within the broader conversation in HCI on fabrication machines that promote creative collaboration between humans, materials, and tools.",
    "title": "Slip Casting as a Machine for Making Textured Ceramic Interfaces",
    "id": 189001,
    "sequence": 791,
    "queryCoordinates": {
      "visualization": [
        6.273549006284601,
        -9.035628526325409
      ]
    }
  },
  {
    "session": "Interfaces and Interactions for XR",
    "abstract": "The promise of Extended Reality (XR) in education is significant but one size does not fit all learning contexts and student preferences. Varied content with different immersion levels is hence beneficial, but creating XR content remains daunting for educators using conventional tools. This paper introduces XRAuthor, a web-based authoring tool designed to empower educators to create varying immersive learning content - ranging from conventional video to interactive animations and full-fledged VR - all from a single authoring experience with a webcam. Through online one-to-one workshops with 14 educators, we found strong endorsement for the new authoring workflow enabled by XRAuthor. Participants also found that the varied interactive exercises automatically generated by the tool aligned well with effective pedagogical practices. High ease of use and efficiency were identified as crucial attributes of XRAuthor. The design knowledge facilitated by XRAuthor underscores the potential of such tool designs to democratize XR content creation for learning.",
    "title": "Educator Perceptions of XRAuthor: An Accessible Tool for Authoring Learning Content with Different Immersion Levels",
    "id": 189002,
    "sequence": 792,
    "queryCoordinates": {
      "visualization": [
        10.643573670544477,
        -14.516002876814692
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "Digital technologies in Human-Computer Interaction (HCI) have the potential to support the development and well-being of Deaf and Hard of Hearing (DHH) children. Yet, there has yet to be a systematic review of the field. A shared understanding of current research is needed to develop a future vision. In this review, we analyzed 42 papers from the ACM Digital Library and the top 20 HCI Conferences and Journals, spanning the past 24 years, to investigate the trends, methods, and the level of inclusion of DHH children. Our review reveals that sign language learning platforms dominate the current technological effort. Moreover, children are not yet fully involved in the design process of these technologies and are mostly considered users and testers. We also capture a gap in integrating Deaf culture and child development in prior research. We conclude by critically examining literature gaps and offering guidance for future research.",
    "title": "Digital Technologies for Deaf and Hard of Hearing Children: a Systematic Review, Critical Reflections, and Future Research Directions",
    "id": 189003,
    "sequence": 793,
    "queryCoordinates": {
      "visualization": [
        1.8855869473039912,
        3.5276850573934198
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Large Language Models (LLMs) are seemingly infiltrating every domain, and the legal context is no exception. In this paper, we present the results of three experiments (total N = 288) that investigated lay people's willingness to act upon, and their ability to discriminate between, LLM- and lawyer-generated legal advice. In Experiment 1, participants judged their willingness to act on legal advice when the source of the advice was either known or unknown. When the advice source was unknown, participants indicated that they were significantly more willing to act on the LLM-generated advice. The result of the source unknown condition was replicated in Experiment 2. Intriguingly, despite participants indicating higher willingness to act on LLM-generated advice in Experiments 1 and 2, participants discriminated between the LLM- and lawyer-generated texts significantly above chance-level in Experiment 3. Lastly, we discuss potential explanations and risks of our findings, limitations and future work.",
    "title": "Objection Overruled! Lay People can Distinguish Large Language Models from Lawyers, but still Favour Advice from an LLM",
    "id": 189004,
    "sequence": 794,
    "queryCoordinates": {
      "visualization": [
        9.035628526325407,
        -6.273549006284605
      ]
    }
  },
  {
    "session": "WS38: Technology Mediated Caregiving For Older Adults Aging in Place",
    "abstract": "The caregiving environment for an older adult aging in place includes a network of caregivers working with the older adult to support their needs and maintain independence. As older adults experience cognitive and functional changes, their caregiving network expands to include spouses or siblings (who are often older adults themselves), children, friends, neighbors and community members—each bringing unique values, expectations, and goals. In this network of care, technology-enabled support offers the potential to mediate care responsibilities, such as coordinating activities and assisting with everyday tasks. However, designing these systems requires addressing value tensions among caregivers, cultural norms around aging, participatory research practices and balancing autonomy with safety concerns for older adults in later life. This workshop brings together researchers and practitioners to discuss (1) opportunities and challenges for designing technological systems for caregiving for older adults; (2) longitudinal interactions with these systems as older adults progress through stages of functional and cognitive changes; (3) potential for such systems to support caregivers while centering older adults' privacy and autonomy needs; and (4) the influence of cultural norms on caregiving and technology use.",
    "title": "Technology Mediated Caregiving For Older Adults Aging in Place",
    "id": 189005,
    "sequence": 795,
    "queryCoordinates": {
      "visualization": [
        13.993278136992082,
        15.658485462546478
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "Users hold their mobile phones at varying distances depending on their posture, the application being used, and the task's nature. Without considering such variation when designing UI target sizes limits the applicability of gaze selection for everyday interaction with mobile devices. Towards this end, we conducted a user study (N=24) to investigate the implications of different target sizes and viewing across different screen regions. While larger targets generally improve accuracy and decrease precision, accuracy is significantly higher in the horizontal than in the vertical direction. This subsequently led us to find that increasing the tracking area in the vertical direction only, while maintaining the same visual target size, significantly improves accuracy. This suggests that visually smaller targets with larger vertical tracking areas enhance accuracy. Based on our results, we present concrete design guidelines for developers to optimise target sizes on gaze-enabled mobile devices to improve accuracy across varying user-to-screen distances.",
    "title": "Stretch Gaze Targets Out: Experimenting with Target Sizes for Gaze-Enabled Interfaces on Mobile Devices",
    "id": 189006,
    "sequence": 796,
    "queryCoordinates": {
      "visualization": [
        -6.45766645212444,
        -13.538779265247904
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "This paper introduces TelePulse, a system integrating biomechanical simulation with electrical muscle stimulation (EMS) to provide precise haptic feedback for robot teleoperation tasks in virtual reality (VR). TelePulse has two components: a physical simulation part that calculates joint torques based on real-time force data from remote manipulators, and an electrical stimulation part that converts these torques into muscle stimulation. Two experiments were conducted to evaluate the system. The first experiment assessed the accuracy of EMS generated through biomechanical simulations by comparing it with electromyography (EMG) data during force-directed tasks, while the second experiment evaluated the impact of TelePulse on teleoperation performance during sanding and drilling tasks. The results suggest that TelePulse provided more accurate stimulation across all arm muscles, thereby enhancing task performance and user experience in the teleoperation environment. In this paper, we discuss the effect of TelePulse on teleoperation, its limitations, and areas for future improvement.",
    "title": "TelePulse: Enhancing the Teleoperation Experience through Biomechanical Simulation-Based Electrical Muscle Stimulation in Virtual Reality",
    "id": 189007,
    "sequence": 797,
    "queryCoordinates": {
      "visualization": [
        -1.1705419320967692,
        5.884711682419383
      ]
    }
  },
  {
    "session": "3D Design and Fabrication",
    "abstract": "Authoring 3D scenes is a central task for spatial computing applications. Competing visions for lowering existing barriers are (1) focus on immersive, direct manipulation of 3D content or (2) leverage AI techniques that capture real scenes (3D Radiance Fields such as, NeRFs, 3D Gaussian Splatting) and modify them at a higher level of abstraction, at the cost of high latency. We unify the complementary strengths of these approaches and investigate how to integrate generative AI advances into real-time, immersive 3D Radiance Field editing.\r\nWe introduce Dreamcrafter, a VR-based 3D scene editing system that: (1) provides a modular architecture to integrate generative AI algorithms; (2) combines different levels of control for creating objects, including natural language and direct manipulation; and (3) introduces proxy representations that support interaction during high-latency operations. \r\nWe contribute empirical findings on control preferences and discuss how generative AI interfaces beyond text input enhance creativity in scene editing and world building.",
    "title": "Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs",
    "id": 189008,
    "sequence": 798,
    "queryCoordinates": {
      "visualization": [
        -4.835696475121418,
        -7.59052301231597
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "Deceptive design patterns manipulate people into actions to which they would otherwise object. Despite growing research on deceptive design patterns, limited research examines their interplay with accessibility and visual accessibility technology (e.g., screen readers, screen magnification, braille displays). We present an interview and diary study with 16 people who use visual accessibility technology to better understand experiences with accessibility and deceptive design. We report participant experiences with six deceptive design patterns, including designs that are intentionally deceptive and designs where participants describe accessibility barriers unintentionally manifesting as deceptive, together with direct and indirect consequences of deceptive patterns. We discuss intent versus impact in accessibility and deceptive design, how access barriers exacerbate harms of deceptive design patterns, and impacts of deceptive design from a perspective of consequence-based accessibility. We propose that accessibility tools could help address deceptive design patterns by offering higher-level feedback to well-intentioned designers.",
    "title": "Inaccessible and Deceptive: Examining Experiences of Deceptive Design with People Who Use Visual Accessibility Technology",
    "id": 189009,
    "sequence": 799,
    "queryCoordinates": {
      "visualization": [
        -10.15809662921003,
        -18.37969186008383
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "Children born in the digital era are facing increasing privacy risks and the need to control privacy in various contexts, suggesting an urgent need to enhance their privacy literacy. While previous research focuses on developing children's privacy literacy by delivering privacy knowledge, it remains unclear how children process the knowledge and apply it in various privacy situations. Furthermore, children's desire for privacy controls remains understudied. To fill the gap, we conducted two five-day co-design workshops with 11 children (ages 6-11). We uncovered children's sophisticated expectations of everyday privacy management, such as staying aware of their privacy situations, strong authentication methods, and minimal privacy exposure. We further discovered that children translated their privacy knowledge to privacy practices through an iterative reflection and action process. We discussed key considerations to support children's privacy literacy development by leveraging this process and offered implications for children-friendly privacy design. ",
    "title": "From Knowledge to Practice: Co-Designing Privacy Controls with Children",
    "id": 189010,
    "sequence": 800,
    "queryCoordinates": {
      "visualization": [
        -16.99546453789783,
        0.3926641581010234
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "Meditation and mind-body practices offer many benefits for both mental and physical well-being. Recently, social virtual reality (VR) has emerged as a promising platform to support well-being activities. While Human-Computer Interaction (HCI) research has explored technologies for meditation, little is known about how users appropriate social VR for meditation, particularly group practice, and how it shapes their experiences. To bridge this gap, we interviewed 13 regular social VR meditators to explore their practices, perceived benefits, and challenges. We found that meditators utilized platform features to engage in community-driven group practices, manage session flow, employ avatars and body tracking for kinetic practices, and experiment with novel forms of meditation. Participants reported benefits and challenges related to the individual and social aspects of their meditation experiences. Based on these findings, we discuss the implications of using social VR for meditation, including how avatars and virtual others positively affect the practice, as well as emerging tensions and opportunities.",
    "title": "Meditating Together: Practices, Benefits and Challenges of Meditation on Social Virtual Reality",
    "id": 189011,
    "sequence": 801,
    "queryCoordinates": {
      "visualization": [
        -7.2240318786181685,
        15.388741450057196
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "Sleep diaries are essential self-reporting tools for understanding children's sleep patterns, but maintaining sustained engagement and high-quality self-reporting remains challenging. While voice input has been explored in child-computer interaction research as a method to improve engagement, limited evidence exists regarding its effectiveness in supporting sustained self-reporting over time. To address this gap, we conducted a five-day field study with 20 children aged seven to twelve, using a multimodal sleep diary that integrated both voice and text input modalities. Our findings reveal that voice input significantly supports younger children in maintaining engagement over five days, though their response quality remains lower than that of older children. Two distinct response quality patterns over time also emphasize the importance of accounting for individual differences in task performance. Furthermore, input modality preferences varied by age: older children consistently favored text input, while younger children generally preferred voice input over time. These results highlight the potential of incorporating voice input into text-based sleep diaries to better accommodate the diverse needs of children, enhancing both sustained engagement and response quality. Future studies with longer observation periods are needed to validate and extend these findings.",
    "title": "\"Did you sleep well?\": A Multimodal Sleep Diary for Sustained Self-Reporting by Children",
    "id": 189012,
    "sequence": 802,
    "queryCoordinates": {
      "visualization": [
        8.322766926012333,
        -9.986568514523656
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "My PhD research explores the simultaneous integration of me-\r\nchanical and electrical functionalities in mechanical components\r\nsuch as gears, linkages, and springs, which I define as “hybrid func-\r\ntional identities.” The focus is on transforming these components\r\ninto non-intrusive sensors and active elements that maintain struc-\r\ntural integrity while providing electrical capabilities like sensing,\r\nenergy harvesting, and communication. I establish a framework\r\nfor hybrid functional identities by examining common mechani-\r\ncal elements and their associated motions—rotational, linear, and\r\nreciprocal—along with force-based interactions like stretching, com-\r\npression, and torsion. This analysis identifies essential electrical\r\nfunctionalities that complement these mechanical behaviors. Build-\r\ning on this foundation, I investigate modular mechanical build-\r\ning blocks that support diverse mechanical and electrical interac-\r\ntion primitives using a unified geometric structure. Ultimately, I\r\naim to create an interconnected system where hybrid mechanical-\r\nelectrical components function autonomously and communicate\r\nthrough an embedded wireless network.",
    "title": "Design and Fabrication of Hybrid Functional Identities for Mechanical Elements",
    "id": 189013,
    "sequence": 803,
    "queryCoordinates": {
      "visualization": [
        4.2733551866887485,
        -16.454131257784482
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "Advancements in artificial intelligence-powered search engines have enhanced the efficiency of online health information searches by generating direct answers to queries using top-ranked featured snippets (FS). However, such functionalities may contribute to health anxiety, particularly when the displayed results are distressing. This study investigated the effect of algorithmic transparency (AT) explanations (absence vs. presence) on mitigating FS-triggered health anxiety. The results of an online experiment (N = 206) yielded two key findings: First, participants exposed to AT explanations detailing the selection process of FS experienced reduced trust in the search engine and distressing results, which subsequently alleviated health anxiety. Second, the moderating effect of pre-existing cyberchondria on the relationship between AT explanations and trust was observed, but only within a limited threshold. Overall, the findings empirically validate AT explanations as an effective approach to mitigate FS-induced health anxiety. Theoretical and practical implications are discussed.",
    "title": "How the Algorithmic Transparency of Search Engines Influences Health Anxiety: The Mediating Effects of Trust in Online Health Information Search",
    "id": 189014,
    "sequence": 804,
    "queryCoordinates": {
      "visualization": [
        1.1772563261425626,
        -17.961460618294865
      ]
    }
  },
  {
    "session": "Auditory UI",
    "abstract": "Perfume and fragrance have captivated people for centuries across different cultures. Inspired by the ephemeral nature of sprayable olfactory interactions and experiences, we explore the potential of applying a similar interaction principle to the auditory modality. In this paper, we present SoundMist, a sonic interaction method that enables users to generate ephemeral auditory presences by physically dispersing a liquid into the air, much like the fading phenomenon of fragrance. We conducted a study to understand the experiential factors inherent in sprayable sound interaction and held an ideation workshop to identify potential design spaces or opportunities that this interaction could shape. Our findings, derived from thematic analysis, suggest that physically sprayable sound interaction can induce experiences related to four key factors—materiality of sound produced by dispersed liquid particles, different sounds entangled with each liquid, illusive perception of temporally floating sound, and enjoyment derived from blending different sounds—and can be applied to artistic practices, safety indications, multisensory approaches, and emotional interfaces.",
    "title": "Sprayable Sound: Exploring the Experiential and Design Potential of Physically Spraying Sound Interaction",
    "id": 189015,
    "sequence": 805,
    "queryCoordinates": {
      "visualization": [
        -2.7410500366210844,
        -20.82034208885002
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "Personal informatics helps individuals understand themselves, but it often struggles to capture non-conscious behaviors such as stress responses, habitual actions, and communication styles. Incorporating social aspects into PI systems offers new perspectives on self-understanding, yet prior research has largely focused on unidirectional approaches that center benefits on the primary tracker. To address this gap, we introduce the Peerspective study, which explores reciprocal tracking---a bidirectional practice where two participants observe and provide feedback to each other, fostering mutual self-understanding and collaboration. In a week-long study with eight peer dyads, we explored how reciprocal observation and feedback influence self-awareness and interpersonal relationships. Our findings reveal that reciprocal tracking not only helps participants uncover blind spots and expand their self-concepts but also enhances empathy, deepens communication, and promotes sustained engagement. We discuss key facilitators and challenges of integrating reciprocity into personal informatics systems and offer design considerations for supporting collaborative tracking in everyday contexts.",
    "title": "Peerspective: A Study on Reciprocal Tracking for Self-awareness and Relational Insight",
    "id": 189016,
    "sequence": 806,
    "queryCoordinates": {
      "visualization": [
        3.5139448781596108,
        18.672230487899828
      ]
    }
  },
  {
    "session": "WS03: Future of Money and HCI",
    "abstract": "Money and financial activities reflect social connections and societal norms. Collaborative financial activities and decision-making are highly common in our day-to-day activities. However, existing financial technologies (fintech) are often limited to individual-centric approaches and goals. Recent HCI work has repeatedly noted the need for creating new interaction strategies and design paradigms to better support our financial behaviors, habits, and goals. However, there has not been much concrete work yet, specifically when it comes to supporting collaborative behaviors and social norms that underpin much of our daily financial activities. In this in-person workshop, we will bring together an interdisciplinary group of researchers interested in reshaping the current landscape of digital money and fintech with a focus on social and collaborative interactions. Specifically, we will identify limitations of existing fintech approaches and potential strategies to address these limitations. We will also discuss key challenges for fintech design and development, including collaboration, privacy, agency, trust, and accessibility. The workshop will lead to identifying novel HCI research and implementation directions focusing on the future of financial technologies.",
    "title": "Future of Money and HCI",
    "id": 189017,
    "sequence": 807,
    "queryCoordinates": {
      "visualization": [
        -11.900300104368531,
        -9.131421435130806
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "How do technical actors respond to critique by developing novel technologies? In this paper, we follow the actors that have positioned themselves as critics of technology; we examine the inspirations and sources of their critical capacities and; we trace the development of concrete technological artifacts designed to respond to those critiques. To illustrate our approach, we outline the case of digital cameras tuned to capture diverse human skin tones, a technical response to long-standing critiques of whiteness bias in photography. Our investigative approach synthesizes three theoretical threads: the sociology of critical capacities, the anthropology of ethics, and studies of valuation. To trace the arc of technical responses to critique: (i) inspect the conditions under which actors are, or are not, capacitated to be critical; (ii) the conditions in which critiques are communicated, disputed, modified, furthered or ignored; and (iii) trace how matters of concern are materialized in technical outcomes.",
    "title": "Technical Responses To Critique: The Case Of Skin Tone",
    "id": 189018,
    "sequence": 808,
    "queryCoordinates": {
      "visualization": [
        12.783990009183132,
        -16.66042014611594
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "TableCanoniser is a declarative grammar and interactive system for constructing relational tables from messy tabular inputs such as spreadsheets. We propose the concept of axis alignment to categorise input types and characterise the expanded scope of our system relative to existing tools. The declarative grammar consists of match conditions, which specify repeating patterns of input cells, and extract operations, which specify how matched values map to the output table. In the interactive interface, users can specify match and extract patterns by interacting with an input table, or author more advanced specifications in the coding panel. To refine and verify specifications, users interact with grammar-based provenance visualisations such as linked highlighting of input and output values, tree-based visualisation of matching patterns, and a mini-map overview of matched instances of patterns with annotations showing where cells are extracted to. We motivate and illustrate our work with real-world usage scenarios and workflows.",
    "title": "TableCanoniser: Interactive Grammar-Powered Transformation of Messy, Non-Relational Tables to Canonical Tables",
    "id": 189019,
    "sequence": 809,
    "queryCoordinates": {
      "visualization": [
        2.7284543268430212,
        12.710449912821009
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "Since the emergence of generative AI, creative workers have spoken up about the career-based harms they have experienced arising from this new technology. A common theme in these accounts of harm is that generative AI models are trained on workers' creative output without their consent and without giving credit or compensation to the original creators.\r\n\r\nThis paper reports findings from 20 interviews with creative workers in three domains: visual art and design, writing, and programming. We investigate the gaps between current AI governance strategies, what creative workers want out of generative AI governance, and the nuanced role of creative workers' consent, compensation and credit for training AI models on their work. Finally, we make recommendations for how generative AI can be governed and how operators of generative AI systems might more ethically train models on creative output in the future.",
    "title": "Governance of Generative AI in Creative Work: Consent, Credit, Compensation, and Beyond",
    "id": 189020,
    "sequence": 810,
    "queryCoordinates": {
      "visualization": [
        -5.785910375456913,
        -17.0447423309119
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "Mobile navigation applications are good at providing efficient navigation instructions. However, they currently lack the capability to facilitate free exploration. \r\nTherefore, users are limited to encountering only places close to the shortest paths, neglecting places that could diversify navigation and foster spatial learning. \r\nTo better understand what characteristics places have that users like to explore we collected a dataset with a mobile application that encourages free exploration using gamification (n = 39, t = 455 days, 106.50 km2). Using OpenStreetMap data, we found highly frequented freely explored places comprising office, educational, retail, touristic and commercial places. When comparing the characteristics of the freely explored places to those along the shortest path, those categories were different. Based on our findings, we propose that implementing more diverse routing algorithms can enhance navigation diversity, improve spatial learning, and optimise the utilisation of urban spaces for travel.",
    "title": "Describing Explored Places through OpenStreetMap Data",
    "id": 189021,
    "sequence": 811,
    "queryCoordinates": {
      "visualization": [
        11.503208623575308,
        -17.569183002134807
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "This work sheds light on whether and how creative writers' needs are met by existing research and commercial writing support tools (WST). We conducted a need finding study to gain insight into the writers' process during creative writing through a qualitative analysis of the response from an online questionnaire and Reddit discussions on \\textit{r/Writing}. Using a systematic analysis of 115 tools and 67 research papers, we map out the landscape of how digital tools facilitate the writing process. Our triangulation of data reveals that research predominantly focuses on the writing activity and overlooks pre-writing activities and the importance of visualization. We distill 10 key takeaways to inform future research on WST and point to opportunities surrounding underexplored areas. Our work offers a holistic and up-to-date account of how tools have transformed the writing process, guiding the design of future tools that address writers' evolving and unmet needs.",
    "title": "Making the Write Connections: Linking Writing Support Tools with Writer Needs",
    "id": 189022,
    "sequence": 812,
    "queryCoordinates": {
      "visualization": [
        1.1762056839547292,
        11.942216720066362
      ]
    }
  },
  {
    "session": "Visualization and Language Communication",
    "abstract": "Incorporating data facts, which are natural language descriptions of data patterns, alongside visualizations can guide readers and enhance the visibility of data patterns. However, data facts might also induce confirmation bias in visual analysis. We conducted a series of crowdsourced experiments to explore the biasing effects of data facts. Our findings show that the presentation style, strength, and alignment of data facts with pre-existing beliefs significantly impact confirmation bias. Data facts that support prior beliefs can exacerbate confirmation bias, whereas those that refute an individual's beliefs can mitigate it. This effect is amplified when data facts are used in combination with visual annotations. Data facts describing variable correlations are perceived to be more compelling than ones describing average values and are associated with higher levels of confirmation bias. We underscore the persuasive influence of data facts in visualizations and caution against their indiscriminate use in efforts to mitigate bias.",
    "title": "Confirmation Bias: The Double-Edged Sword of Data Facts in Visual Data Communication",
    "id": 189023,
    "sequence": 813,
    "queryCoordinates": {
      "visualization": [
        8.203107624274452,
        -8.758368872374032
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "This study explores how Pakistani mothers, as primary caregivers, navigate the use and non-use of screen media-based devices (SMDs) in their parenting practices. Grounded in the uses and gratifications theory, we explore how mothers seek specific gratifications through their children's use of SMDs, and how unmet needs prompt them to adopt strategies for limiting SMD use. Through an analysis of interview and survey data, we present and discuss different patterns of SMD use among mothers, emphasizing their needs for religious education, cultural enrichment, family bonding, and early learning. These findings reveal a trend toward value-driven SMD use. We further compare these strategies with global digital parenting practices and identify opportunities for designing culturally relevant technological solutions to support digital parenting in this space.  \r\n\r\n",
    "title": "Understanding Pakistani Mothers’ Use and Non-Use of Screen Media-based Devices: Gratifications, Strategies, and Design Implications",
    "id": 189024,
    "sequence": 814,
    "queryCoordinates": {
      "visualization": [
        4.2406362598713025,
        12.288897595450322
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "Supernumerary robotic limbs are robotic structures integrated closely with the user's body, which augment human physical capabilities and necessitate seamless, naturalistic human-machine interaction. For effective assistance in physical tasks, enabling SRLs to hand over objects to humans is crucial. Yet, designing heuristic-based policies for robots is time-consuming, difficult to generalize across tasks, and results in less human-like motion. When trained with proper datasets, generative models are powerful alternatives for creating naturalistic handover motions. We introduce 3HANDS, a novel dataset of object handover interactions between a participant performing a daily activity and another participant enacting a hip-mounted SRL in a naturalistic manner. 3HANDS captures the unique characteristics of SRL interactions: operating in intimate personal space with asymmetric object origins, implicit motion synchronization, and the user’s engagement in a primary task during the handover. To demonstrate the effectiveness of our dataset, we present three models: one that generates naturalistic handover trajectories, another that determines the appropriate handover endpoints, and a third that predicts the moment to initiate a handover. In a user study (N=10), we compare the handover interaction performed with our method compared to a baseline. The findings show that our method was perceived as significantly more natural, less physically demanding, and more comfortable.",
    "title": "3HANDS Dataset: Learning from Humans for Generating Naturalistic Handovers with Supernumerary Robotic Limbs",
    "id": 189025,
    "sequence": 815,
    "queryCoordinates": {
      "visualization": [
        11.323208259941703,
        6.386309944090406
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Ultrasound assessments are key in assessing traumatic injuries to the human body during urgent medical emergencies. Obtaining proficiency in conducting ultrasound assessments is challenging, and relies on hands-on, individually instructed training provided by a scarce number of ultrasound experts. We investigate how to support medical students’ learning of ultrasound assessment through visual augmentations. By enhancing the learning process, we seek to support medical students in reaching higher proficiency in ultrasound assessments. We followed an ultrasound assessment course to identify the primary challenges faced by medical students learning to conduct ultrasound assessments. Based on our findings, we designed four distinct visual augmentations in collaboration with a course educator that guide students in achieving better ultrasound image quality.We evaluated these visual augmentations in a mixed-method study with 15 medical students. Our findings provide insights on the use of digital technology in supporting clinical training, and the possibilities of bridging existing training practices.",
    "title": "Visual Augmentations for Ultrasound Assessment Training of Medical Students",
    "id": 189026,
    "sequence": 816,
    "queryCoordinates": {
      "visualization": [
        18.318276086023058,
        -5.043883547053372
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "Many narratives around AI systems promise a utopian vision of empowerment, inclusivity, and democratization, yet there remains a gap in how to concretely pursue such a promise. In this paper, we review and analyze a curated set of AI-driven healthcare products, leveraging sociologist Ruth Levitas' three distinct but interrelated forms of utopian thinking—archaeology, ontology, and architecture. We contribute to HCI's Human-AI Interaction agenda by applying this theory to critically examine how AI technologies embed societal ideals, shape user identities, and project alternative futures. This allows us to consider the values and users these systems illustrate as images of the \r\n``good society.'' In doing so, we also make visible the normativity and repetitive nature of technology hype cycles and raise important questions about the future these technologies are shaping. ",
    "title": "Architecting Utopias: How AI in Healthcare Envisions Societal Ideals and Human Flourishing",
    "id": 189027,
    "sequence": 817,
    "queryCoordinates": {
      "visualization": [
        -16.66042014611594,
        12.783990009183128
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Data wrangling is a time-consuming and challenging task in the early stages of a data science pipeline. However, existing tools often fail to effectively interpret user intent. We propose Dango, a mixed-initiative multi-agent system that helps users generate data wrangling scripts. Compared to existing tools, Dango enhances user communication of intent by: (1) allowing users to demonstrate on multiple tables and use natural language prompts in a conversation interface, (2) enabling users to clarify their intent by answering LLM-posed multiple-choice clarification questions, and (3) providing multiple forms of feedback such as step-by-step NL explanations and data provenance to help users evaluate the data wrangling scripts. In a within-subjects, think-aloud study (n=38), the results show that Dango's features can significantly improve intent clarification, accuracy, and efficiency in data wrangling tasks.",
    "title": "Dango: A Mixed-Initiative Data Wrangling System using Large Language Model",
    "id": 189028,
    "sequence": 818,
    "queryCoordinates": {
      "visualization": [
        -15.42041705272704,
        -4.267404119598372
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "This work examines spatial anchoring strategies to position augmented reality guidance during surgery. We consider three strategies: anchoring to the Patient, the surgical Tool, and the Surgeon's head. These strategies were evaluated in a first experiment involving 24 non-professional participants, using two guidance techniques: 3D Trajectory and 2D Crosshair. For 3D Trajectory, Patient and Tool anchoring were more precise than Surgeon anchoring, and Patient anchoring was the most preferred. For 2D Crosshair, no significant effect of anchoring strategies on precision was observed. However, participants preferred Patient and Surgeon anchoring. A second experiment with 6 surgeons confirmed the first experiment's results. For 3D trajectory, Tool anchoring proved more precise than Patient anchoring, despite surgeons' preference for Patient anchoring. These findings contribute to empirical evidence for the design of surgical AR guidance, with potential applications for similar, less critical tasks.",
    "title": "An Evaluation of Spatial Anchoring to position AR Guidance in Arthroscopic Surgery",
    "id": 189029,
    "sequence": 819,
    "queryCoordinates": {
      "visualization": [
        8.05083974399898,
        -7.495597335532802
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "Generative AI has the potential to assist people with completing various tasks, but increased productivity is not guaranteed due to challenges such as uncertainty in output quality and unclear processing time. Through an online crowdsourced experiment (N=508), leveraging a “paint by numbers” task to simulate properties of GenAI assistance, we explore how, and how well, users make decisions on whether to use or not use automation to maximize their productivity given varying waiting times and output quality. We observed gaps between user’s actual choices and their optimal choices and characterized these gaps as the “gulf of impatience” and the “gulf of overreliance”. We also distilled strategies that participants adopted when making their decisions. We discuss design considerations in supporting users to make more informed decisions when interacting with GenAI tools and make these tools more useful for improving users’ task performance, productivity and satisfaction.",
    "title": "To Use or Not to Use: Impatience and Overreliance When Using Generative AI Productivity Support Tools",
    "id": 189030,
    "sequence": 820,
    "queryCoordinates": {
      "visualization": [
        -14.627356091256491,
        -6.483861024079835
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "Machine learning (ML) is increasingly used in healthcare practices, due to its potential to support personalization, diagnostic and prediction, automatization, and increase effectiveness. In physiotherapy, most existing ML solutions suggest replacing the physiotherapist, neglecting the complexity of their skills and practice. We articulate an alternative to the design of ML technology for physiotherapy: one that emphasizes the relational aspects of the practice and offers personalized support to physiotherapists and patients alike. Based on domain studies and design explorations with physiotherapists, interaction designers and ML experts, we present 1) insights on physiotherapy's in-clinic and out-of-clinic looped structure, 2) opportunities and requirements to integrate ML in that loop, and 3) a conceptual interactive ML-based infrastructure that exploits those opportunities. Our work widens current ML developmental aims for physiotherapy, proposing a vision that encodes sustainable sociotechnical relationships in healthcare practices.",
    "title": "Towards Personalized Physiotherapy through Interactive Machine Learning: A Conceptual Infrastructure Design for In-Clinic and Out-of-Clinic Support ",
    "id": 189031,
    "sequence": 821,
    "queryCoordinates": {
      "visualization": [
        9.741720724952756,
        11.406089484000463
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "Anxiety and depression rates in Computer Science (CS) students are double those of other undergraduates and 5-10 times higher than the general population. However, factors contributing to the elevated mental health issues in CS students remain unknown. To bridge this gap, we conducted need-finding interviews (N=20), which revealed that the complexity of debugging, along with imposter syndrome, are key contributors to stress and burnout. Participants expressed openness toward and feature preferences in a computer-based Personal Informatics (PI) tool to facilitate self-reflection. In response, we developed EmotionStream, an algorithm-assisted PI tool that provides both contextual and emotional insights based on individual behaviors. We found that participants rated their experience with the tool highly. Post-hoc analysis revealed that emotional states, augmented with contextual cues, show promise of predicting real-time stress. Based on our findings, we provide design implications for future PI tools to support CS student mental well-being.",
    "title": "\"I spent 14 hours debugging just one assignment\": Toward Computer-Mediated Personal Informatics for Computer Science Student Mental Health",
    "id": 189032,
    "sequence": 822,
    "queryCoordinates": {
      "visualization": [
        20.703291388882953,
        -3.5176306893994607
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "This study will investigate ethical and privacy concerns surrounding the increasing use of border screening technologies, such as biometric identification and emotion recognition, in the UK. While these technologies aim to enhance security, they often perpetuate systemic biases, disproportionately affecting immigrant communities from non-Western and marginalized regions. By conducting semi-structured interviews with immigrants and volunteers from London-based civil society organizations, the research will capture personal experiences and highlight the ethical challenges of these surveillance practices. The study will also include interviews with border personnel, developers, and security practitioners responsible for designing and implementing these technologies to shed light on the complex intersection of policy, technology design, and execution at the border, revealing how exclusionary frameworks are embedded in these systems. Finally, the study aims to develop a decolonial, responsible technology framework, rethinking the design and use of border control mechanisms for their just and inclusive organization.",
    "title": "Understanding Border Control Technologies -Towards Decolonial and Responsible Constructs For Immigrant Populations",
    "id": 189033,
    "sequence": 823,
    "queryCoordinates": {
      "visualization": [
        -16.84434467432573,
        10.782766458220008
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": "Explainable AI (XAI) is concerned with how to make AI models more understandable to people. To date these explanations have predominantly been technocentric - mechanistic or productivity oriented. This paper introduces the Explainable AI for the Arts (XAIxArts) manifesto to provoke new ways of thinking about explainability and AI beyond technocentric discourses. Manifestos offer a means to communicate ideas, amplify unheard voices, and foster reflection on practice. To supports the co-creation and revision of the XAIxArts manifesto we combine a World Café style discussion format with a living manifesto to question four core themes: 1) Empowerment, Inclusion, and Fairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4) Openness. Through our interactive living manifesto experience we invite participants to actively engage in shaping this XIAxArts vision within the CHI community and beyond.",
    "title": "XAIxArts Manifesto: Explainable AI for the Arts",
    "id": 189034,
    "sequence": 824,
    "queryCoordinates": {
      "visualization": [
        6.523884689106612,
        -16.77614164709038
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "People often capture memories through photos, screenshots, and videos. While existing AI-based tools enable querying this data using natural language, they only support retrieving individual pieces of information like certain objects in photos, and struggle with answering more complex queries that involve interpreting interconnected memories like sequential events.  We conducted a one-month diary study to collect realistic user queries and generated a taxonomy of necessary contextual information for integrating with captured memories. We then introduce OmniQuery, a novel system that is able to answer complex personal memory-related questions that require extracting and inferring contextual information. OmniQuery augments individual captured memories through integrating scattered contextual information from multiple interconnected memories.\r\nGiven a question, OmniQuery retrieves relevant augmented memories and uses a large language model (LLM) to generate answers with references. In human evaluations, we show the effectiveness of OmniQuery with an accuracy of 71.5%, outperforming a conventional RAG system by winning or tying for 74.5% of the time.",
    "title": "OmniQuery: Contextually Augmenting Captured Multimodal Memories to Enable Personal Question Answering",
    "id": 189035,
    "sequence": 825,
    "queryCoordinates": {
      "visualization": [
        14.95376000599692,
        -1.1768864359176843
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "In the digital information ecosystem, clicks serve as a crucial gateway to fact-checking, yet the essential challenge extends beyond this to fostering cognitive shifts that update entrenched false beliefs. This study investigates effective interventions aimed at encouraging users vulnerable to misinformation, particularly those who tend to avoid incongruent facts, to examine their false beliefs. We conducted an online experiment with 627 participants, comparing metacognitive and ranking interventions. Both interventions successfully improved click behavior, with the metacognitive intervention increasing belief-examining clicks by 14 percentage points and the ranking intervention by 33 percentage points. However, only the metacognitive intervention significantly promoted users' examination of misinformation. This finding underscores the importance of interventions that go beyond merely influencing easily measurable clicks to facilitating thoughtful engagement with fact-checking content. We discuss implications for designing strategies to enhance online fact-checking engagement and mitigate misinformation's societal impact.",
    "title": "Beyond Click to Cognition: Effective Interventions for Promoting Examination of False Beliefs in Misinformation",
    "id": 189036,
    "sequence": 826,
    "queryCoordinates": {
      "visualization": [
        10.158096629210041,
        -18.379691860083824
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "Augmented Reality (AR) promises to enhance daily office activities involving numerous textual documents, slides, and spreadsheets by expanding workspaces and enabling more direct interaction. However, there is a lack of systematic understanding of how knowledge workers can manage multiple documents and organize, explore, and compare them in AR environments. Therefore, we conducted a user-centered design study (N = 21) using predefined spatial document layouts in AR to elicit interaction techniques, resulting in 790 observation notes. Thematic analysis identified various interaction methods for aggregating, distributing, transforming, inspecting, and navigating document collections. Based on these findings, we propose a design space and distill design implications for AR document arrangement systems, such as enabling body-anchored storage, facilitating layout spreading and compressing, and designing interactions for layout transformation. To demonstrate their usage, we developed a rapid prototyping system and exemplify three envisioned scenarios. With this, we aim to inspire the design of future immersive offices.",
    "title": "Documents in Your Hands: Exploring Interaction Techniques for Spatial Arrangement of Augmented Reality Documents",
    "id": 189037,
    "sequence": 827,
    "queryCoordinates": {
      "visualization": [
        5.796577139375428,
        18.094189494621475
      ]
    }
  },
  {
    "session": "Perception of Systems",
    "abstract": "Machine learning models deployed locally on social media applications are used for features, such as face filters which read faces in-real time, and they expose sensitive attributes to the apps. However, the deployment of machine learning models, e.g., when, where, and how they are used, in social media applications is opaque to users. We aim to address this inconsistency and investigate how social media user perceptions and behaviors change once exposed to these models. We conducted user studies (N=21) and found that participants were unaware to both what the models output and when the models were used in Instagram and TikTok, two major social media platforms. In response to being exposed to the models' functionality, we observed long term behavior changes in 8 participants. Our analysis uncovers the challenges and opportunities in providing transparency for machine learning models that interact with local user data.",
    "title": "\"Impressively Scary:\" Exploring User Perceptions and Reactions to Unraveling Machine Learning Models in Social Media Applications",
    "id": 189038,
    "sequence": 828,
    "queryCoordinates": {
      "visualization": [
        -1.9509032201612866,
        -9.807852804032303
      ]
    }
  },
  {
    "session": "Health and Well-being",
    "abstract": "The mobile health market is rapidly developing, but few apps follow evidence-based guidelines. Literature recommends personalized systems grounded in behavioral science, involving healthcare professionals in design to maximize effectiveness. To address this, we propose a metamodel to guide designers. This article discusses its application to low back pain self-management, focusing on four patient profiles: Unmotivated, Cautious, Depressed, and Confident. We evaluated the app over one month with 60 users. Of these, 32 users received a version of the application tailored to their profile, and 28 users received a version of the application without tailoring (no recommendations or motivational messages). We assessed user experience, engagement and psychological characteristics involved in the behavior change process. Results showed satisfactory user experience, impact of tailoring on user behavior and features to reduce fears and false beliefs and increase self-efficacy. Further efforts are needed to increase user engagement and observe an impact on long-term behavior.",
    "title": "Evaluation of a Tailored Mobile Application for Self-Management of Low Back Pain: Towards a Metamodel for Designing Behavior Change Technologies",
    "id": 189039,
    "sequence": 829,
    "queryCoordinates": {
      "visualization": [
        -14.748823613459317,
        2.7335328823822156
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "Analyzing data subgroups is a common data science task to build intuition about a dataset and identify areas to improve model performance. However, subgroup analysis is prohibitively difficult in datasets with many features, and existing tools limit unexpected discoveries by relying on user-defined or static subgroups. We propose exploratory subgroup analysis as a set of tasks in which practitioners discover, evaluate, and curate interesting subgroups to build understanding about datasets and models. To support these tasks we introduce Divisi, an interactive notebook-based tool underpinned by a fast approximate subgroup discovery algorithm. Divisi's interface allows data scientists to interactively re-rank and refine subgroups and to visualize their overlap and coverage in the novel Subgroup Map. Through a think-aloud study with 13 practitioners, we find that Divisi can help uncover surprising patterns in data features and their interactions, and that it encourages more thorough exploration of subtypes in complex data.",
    "title": "Divisi: Interactive Search and Visualization for Scalable Exploratory Subgroup Analysis",
    "id": 189040,
    "sequence": 830,
    "queryCoordinates": {
      "visualization": [
        13.799306509009245,
        -9.928702829192497
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "Increased AI use in software development raises concerns about AI-generated code security. We investigated the impact of security prompts, insecure AI suggestion warnings, and the use of password storage guidelines (OWASP, NIST) on the security behavior of software developers when presented with insecure AI assistance. In an online lab setting, we conducted a study with 76 freelance developers who completed a password storage task divided into four conditions. Three conditions included a manipulated ChatGPT-like AI assistant, suggesting an insecure MD5 implementation. We found a high level of trust in AI-generated code, even when insecure suggestions were presented. While security prompts, AI warnings, and guidelines improved security awareness, 32% of those notified about insecure AI recommendations still accepted weak implementation suggestions, mistakenly considering it secure and often expressing confidence in their choice. Based on our results, we discuss security implications and provide recommendations for future research.",
    "title": "Exploring the Impact of Intervention Methods on Developers’ Security Behavior in a Manipulated ChatGPT Study",
    "id": 189041,
    "sequence": 831,
    "queryCoordinates": {
      "visualization": [
        -9.081431738250815,
        -4.186597375374277
      ]
    }
  },
  {
    "session": "Lessons Learned from Real Experience",
    "abstract": "Communities of practice operate by developing, sharing, and formalizing concepts together -- collective meaning-making -- thereby enabling all their community members to work together effectively. In the context of Wikipedia, these concepts include article quality, vandalism, and other subjective aspects of collective work. AI and machine learning have proven to be powerful tools for facilitating collaboration at scale by modeling and applying shared concepts. We examine meaning-making in parallel with aligning AI behavior. We describe a case study of modeling the quality of articles in Dutch Wikipedia using an AI model, while engaging in a meaning-making process with Dutch Wikipedians. This case blurs the line between social governance and how meaning is reshaped in an AI model. Based on the case study, we present the Collective Meaning Cycle, a framework that describes the bidirectional relationship between modeling and meaning-making. We also provide implications for the practice of participatory AI design.",
    "title": "Collective Meaning Cascades but Strange Ducks Swim Upstream: Facilitating Collective Meaning-making through Co-development of AI Models",
    "id": 189042,
    "sequence": 832,
    "queryCoordinates": {
      "visualization": [
        5.555702330196023,
        8.314696123025453
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "Algorithms have played a central role in personalized recommendations on social media. However, they also present significant obstacles for content creators trying to predict and manage their audience reach. This issue is particularly challenging for marginalized groups seeking to maintain safe spaces. Our study explores how women on Xiaohongshu (rednote), a recommendation-driven social platform, proactively re-appropriate hashtags (e.g., #宝宝辅食, Baby Supplemental Food) by using them in posts unrelated to their literal meaning. The hashtags were strategically chosen from topics that would be uninteresting to the male audience they wanted to block. Through a mixed-methods approach, we analyzed the practice of hashtag re-appropriation based on 5,800 collected posts and interviewed 24 active users from diverse backgrounds to uncover users' motivations and reactions towards the re-appropriation. This practice highlights how users can reclaim agency over content distribution on recommendation-driven platforms, offering insights into self-governance within algorithmic-centered power structures.",
    "title": "Hashtag Re-Appropriation for Audience Control on Recommendation-Driven Social Media Xiaohongshu (rednote)",
    "id": 189043,
    "sequence": 833,
    "queryCoordinates": {
      "visualization": [
        21.968464057116034,
        1.1775342760195342
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "Handheld-style head-mounted displays (HMDs) are becoming increasingly popular as a convenient option for onsite exhibitions. However, they lack established practices for basic interactions, particularly pointing methods. Through our formative study involving practitioners, we discovered that controllers and hand gestures are the primary pointing methods being utilized. Building upon these findings, we conducted a usability study to explore seven different pointing methods, incorporating insights from the formative study and current virtual reality (VR) practices. The results showed that while controllers remain a viable option, hand gestures are not recommended. Notably, dwell time-based methods, which are not fast and are not commonly recognized by practitioners, demonstrate high usability and user confidence, particularly for inexperienced VR users. We recommend the use of dwell-based methods for onsite exhibition contexts. This research provides insights for the adoption of handheld-style HMDs, laying the groundwork for improving user interaction in exhibition environments, thereby potentially enhancing visitor experiences.",
    "title": "Understanding Usability of VR Pointing Methods with a Handheld-style HMD for Onsite Exhibitions",
    "id": 189044,
    "sequence": 834,
    "queryCoordinates": {
      "visualization": [
        10.886443496351887,
        -19.117671092492873
      ]
    }
  },
  {
    "session": "Technology in Education",
    "abstract": "Online education — given the enhanced access for diverse populations and flexible participation — has been a topic of interest for many computer science and learning science researchers. The sudden shift to online settings during the COVID-19 Emergency Remote Teaching (ERT) provided a valuable opportunity to examine the use of educational technologies on a global scale with various digital readiness skills, beyond many past works that relied on small lab studies. Following a PRISMA-inspired methodology grounded on Moore’s three types of classroom interaction, this descriptive review investigates 22 empirical research papers published during the COVID-19 ERT era focused on higher-education online classrooms. We explore the empirical evidence reported in the collected corpus, and given how ERT remains a likely future occurrence, we suggest key directions for future research, including a new learning paradigm that centralizes and augments Learner-Content interaction to balance between flexibility and structure of online learning.",
    "title": "Interactions Beyond the Pandemic: Lessons Learned from Large-scale Emergency Remote Teaching in Higher Education",
    "id": 189045,
    "sequence": 835,
    "queryCoordinates": {
      "visualization": [
        2.537573136654582,
        3.0920418134509475
      ]
    }
  },
  {
    "session": "Learning and Inspiring, Safety and Security",
    "abstract": "Human visual attention is susceptible to social influences. In education, peer effects impact student learning, but their precise role in modulating attention remains unclear. To this end, we have developed an online education system that provides visual feedback to students based on the area of interest sharing of peer students' gaze patterns. Our experiment (N=311) suggested that although peer attention manipulated students' gaze, individuals adapted their viewing strategies rather than always mirroring peer focus. Furthermore, intentionally guiding students' gaze along the lecture pace did not always improve learning outcomes. Instead, students able to adaptively adjust their focus based on personal needs showed enhanced performance. These findings elucidate how peer visual attention shapes students' gaze patterns, deepening understanding of peer influence on learning. They also offer insights into designing adaptive online learning interventions leveraging peer attention modelling to optimize student attentiveness and learning success.\r\n",
    "title": "PeerEdu: Bootstrapping Online Learning Behaviors via Asynchronous Area of Interest Sharing from Peer Gaze",
    "id": 189046,
    "sequence": 836,
    "queryCoordinates": {
      "visualization": [
        1.937848579973941,
        -6.7264212536156975
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "Data augmentation is crucial to make machine learning models more robust and safe. However, augmenting data can be challenging as it requires generating diverse data points to rigorously evaluate model behavior on edge cases and mitigate potential harms. Creating high-quality augmentations that cover these \"unknown unknowns\" is a time- and creativity-intensive task. In this work, we introduce Amplio, an interactive tool to help practitioners navigate \"unknown unknowns\" in unstructured text datasets and improve data diversity by systematically identifying empty data spaces to explore. Amplio includes three human-in-the-loop data augmentation techniques: Augment with Concepts, Augment by Interpolation, and Augment with Large Language Model. In a user study with 18 professional red teamers, we demonstrate the utility of our augmentation methods in helping generate high-quality, diverse, and relevant model safety prompts. We find that Amplio enabled red teamers to augment data quickly and creatively, highlighting the transformative potential of interactive augmentation workflows.",
    "title": "Exploring Empty Spaces: Human-in-the-Loop Data Augmentation",
    "id": 189047,
    "sequence": 837,
    "queryCoordinates": {
      "visualization": [
        -2.678784026555632,
        -6.467156727579006
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "Financial technologies have reshaped how many individuals manage daily financial activities, introducing new ways to interact with traditional financial products. Given the swift adoption of these technologies, shared language and conceptual frameworks are needed to better represent emerging methods of financial collaboration, hopefully leading to informed design and research. We provide the first in-depth analysis of 31 consumer-facing financial applications that provide support for budgeting, payments, and long-term planning to identify how sharing is mechanized at the system level. Our analysis offers sharing dimensions and patterns that depict the diversity of how existing applications support, or actively hinder, participation in financial sharing. Reflecting on our analysis, we highlight the need for more granular information for consumers and advocates to promote healthy financial sharing practices.",
    "title": "In the Balance: Insights from Collaborative Financial Technologies",
    "id": 189048,
    "sequence": 838,
    "queryCoordinates": {
      "visualization": [
        0.39266415810101857,
        16.99546453789783
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "Accumulating a life history is a valuable resource for understanding self and reflecting on personal historical experience, which could be developed through diary writing. To facilitate the recording of past events in a diary, we designed and implemented Rebulb, a system that enables users to engage with reflective questions about proud moments and document memories evoked for accumulating one's life history. Our four-month field study with three participants showed that users intentionally and spontaneously recalled vague and wide memories during their daily activity and then concretized these memories by writing them down in a journal. The study also revealed that regardless of whether the memories were positive or negative, the current state of the user played a crucial role in how these memories were processed and reflected upon. Our finding imply consideration in designing a tool for supporting the recall and documentation of past experiences.",
    "title": "Journey to My Past: Exploring and Journaling Past Memories Evoked by Questions Framed as Proud Moments",
    "id": 189049,
    "sequence": 839,
    "queryCoordinates": {
      "visualization": [
        4.511038844873864,
        3.956074890600413
      ]
    }
  },
  {
    "session": "Make it Visible",
    "abstract": "Data visualizations are increasingly seen as socially constructed, with several recent studies positing that perceptions and interpretations of visualization artifacts are shaped through complex sets of interactions between members of a community. However, most of these works have focused on audiences and researchers, and little is known about if and how practitioners account for the socially constructed framing of data visualization. In this paper, we study and analyze how visualization practitioners understand the influence of their beliefs, values, and biases in their design processes and the challenges they experience. In 17 semi-structured interviews with designers working with race and gender demographic data, we find that a complex mix of factors interact to inform how practitioners approach their design process---including their personal experiences, values, and their understandings of power, neutrality, and politics. Based on our findings, we suggest a series of implications for research and practice in this space.",
    "title": "The Social Construction of Visualizations: Practitioner Challenges and Experiences of Visualizing Race and Gender",
    "id": 189050,
    "sequence": 840,
    "queryCoordinates": {
      "visualization": [
        14.241717591081395,
        12.576703862931764
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "A growing body of work in Ethical AI attempts to capture human moral judgments through simple computational models. The key question we address in this work is whether such simple AI models capture the critical nuances of moral decision-making by focusing on the use case of kidney allocation. We conducted twenty interviews where participants explained their rationale for their judgments about who should receive a kidney. We observe participants: (a) value patients' morally-relevant attributes to different degrees; (b) use diverse decision-making processes, citing heuristics to reduce decision complexity; (c) can change their opinions; (d) sometimes lack confidence in their decisions (e.g., due to incomplete information); and (e) express enthusiasm and concern regarding AI assisting humans in kidney allocation decisions. Based on these findings, we discuss challenges of computationally modeling moral judgments as a stand-in for human input, highlight drawbacks of current approaches, and suggest future directions to address these issues.\r\n",
    "title": "Can AI Model the Complexities of Human Moral Decision-making? A Qualitative Study of Kidney Allocation Decisions",
    "id": 189051,
    "sequence": 841,
    "queryCoordinates": {
      "visualization": [
        5.018907846382262,
        15.192450889488587
      ]
    }
  },
  {
    "session": "Accessibility",
    "abstract": "Despite the advances made in assistive technologies for people with visual impairments, challenges remain in unfamiliar public spaces such as shopping malls, museums, and transit hubs. First-time visitors often face difficulties in navigating these environments independently, so they seek both safety and ease. To address this issue, we developed AI Suitcase, a navigation robot that resembles a conventional suitcase. By holding its handle, users are guided safely to their destinations while receiving real-time information about their surroundings, promoting mobility and independence for individuals with visual impairments. This paper presents the results of field trials from a pilot study in a commercial complex, daily operations at a museum, and an outdoor pilot test, involving more than 2,200 participants, a quarter of whom are visually impaired. Positive feedback and interest in using navigational robots in daily life suggest the potential of this technology. The challenges encountered during these trials, which are crucial for practical deployment, are also discussed.",
    "title": "Field Trials of Autonomous Navigation Robot for Visually Impaired People",
    "id": 189052,
    "sequence": 842,
    "queryCoordinates": {
      "visualization": [
        11.357676325861576,
        15.231650878252282
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "Videoconferencing has become a ubiquitous medium for collaborative work. It does suffer however from various drawbacks such as zoom fatigue. This paper addresses the quality of user experience by exploring an enhanced system concept with the capability of conveying gaze and attention. Gazing Heads is a round-table virtual meeting concept that uses only a single screen per participant. It enables direct eye contact, and signals gaze via controlled head rotation. The technology to realise this novel concept is not quite mature though, so we built a camera-based simulation for four simultaneous videoconference users. We conducted a user study comparing Gazing Heads with a conventional “Tiled View” video conferencing system, for 20 groups of 4 people, on each of two tasks. The study found that head rotation clearly conveys gaze and strongly enhances the perception of attention. Measurements of turn-taking behaviour did not differ decisively between the two systems (though there were significant differences between the two tasks). A novel insight in comparison to prior studies is that there was a significant increase in mutual eye contact with Gazing Heads, and that users clearly felt more engaged, encouraged to participate and more socially present. Overall, participants expressed a clear preference for Gazing Heads. These results suggest that fully implementing the Gazing Heads concept, using modern computer vision technology as it matures, could significantly enhance the experience of videoconferencing.",
    "title": "Gazing Heads: Investigating Gaze Perception in Video-Mediated Communication",
    "id": 189053,
    "sequence": 843,
    "queryCoordinates": {
      "visualization": [
        -0.39018064403225733,
        -1.9615705608064606
      ]
    }
  },
  {
    "session": "Designing, Making, Exploring",
    "abstract": "This project explores the integration of mass customization and 3D printing in eyewear design to develop an aesthetically fitting system that harmonizes eyeglass frames with individual facial features. Utilizing human-computer interaction, the system leverages user facial data for personalized frame selection and adjustments, addressing significant knowledge gaps in the current market. It designs a co-creation service to enhance user engagement throughout the customization process, emphasizing the importance of user feedback in driving design decisions. Key lessons learned include the critical role of aesthetical experience in user choice, the need for intuitive navigation to mitigate choice overload, and the value of iterative design through user interaction. The project highlights the potential of combining traditional eyewear design with modern technology to create personalized, functional, and aesthetically pleasing products. In this way, it paves the way for future research in integrating artificial intelligence and machine learning for even more refined customization experiences.",
    "title": "Human-Computer Interaction for the Mass Customization of 3D-Printed Eyewear: Designing an Aesthetically Fitting System and Its Co-creation Services",
    "id": 189054,
    "sequence": 844,
    "queryCoordinates": {
      "visualization": [
        -2.7382209514185005,
        17.790507188419692
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "While research on trust in human-AI interactions is gaining recognition, much work is conducted in lab settings that, therefore, lack ecological validity and often omit the trust development perspective. We investigated a real-world case in which logistics experts had worked with an AI system for several years (in some cases since its introduction). Through thematic analysis, three key themes emerged: First, although experts clearly point out AI system imperfections, they still showed to develop trust over time. Second, however, inconsistencies and frequent efforts to improve the AI system disrupted trust development, hindering control, transparency, and understanding of the system. Finally, despite the overall trustworthiness, experts overrode correct AI decisions to protect their colleagues’ well-being. By comparing our results with the latest trust research, we can confirm empirical work and contribute new perspectives, such as understanding the importance of human elements for trust development in human-AI scenarios.",
    "title": "Good Performance Isn't Enough to Trust AI: Lessons from Logistics Experts on their Long-Term Collaboration with an AI Planning System",
    "id": 189055,
    "sequence": 845,
    "queryCoordinates": {
      "visualization": [
        9.460156642284707,
        5.612970363669895
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "During the conflict in Northern Ireland known as “the Troubles”, audio recordings of 10 controversial political groups were banned by the British government from being broadcast. Interestingly, video recordings of these people were instead overdubbed by paid actors, implying that the political figures’ original voices were somehow more convincing, legitimate or sexy than the actors. This study uses AI-generated audio to examine whether this censorship method affects opinions of political dissidents. We carried out a between-subjects experimental study (n = 636), where we compared three different types of AI-generated vocal manipulations with unedited footage of two well-known Northern Irish politicians. We found a significant negative effect of voice manipulation on perceived charisma, legitimization and credibility. Participants also voiced strong disapproval and concern at the idea of using AI to revoice historical footage. We discuss implications of AI assisted audio and video translation of politically sensitive media.",
    "title": "I Was Never in the AI.R.A: an Experimental Study on the Use of Manipulated Audio for the Censorship of Political Dissidents",
    "id": 189056,
    "sequence": 846,
    "queryCoordinates": {
      "visualization": [
        14.966453021445805,
        -10.000264194352853
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "Leveraging the integration of visual and proprioceptive cues, research has uncovered various perception thresholds in VR that can be exploited to support haptic feedback for grasping. While previous studies have explored individual dimensions, such as size, the combined effect of multiple geometric properties on perceptual illusions remains poorly understood. We present a two-alternative forced choice study investigating the perceptual interplay between object size and taper angle. We introduce an illusion space model, providing detailed insights into how physical and virtual object configurations affect human perception. Our insights reveal how, for example, as virtual sizes increase, users perceive that taper angles increase, and as virtual angles decrease, users overestimate sizes. We provide a mathematical model of the illusion space, and an associated tool, which can be used as a guide for the design of future VR haptic devices and for proxy object selections.",
    "title": "Illusion Spaces in VR: The Interplay Between Size and Taper Angle Perception in Grasping",
    "id": 189057,
    "sequence": 847,
    "queryCoordinates": {
      "visualization": [
        -4.619397662556434,
        -1.9134171618254483
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "As blind and low-vision (BLV) players engage more deeply with games, accessibility features have become essential. While some research has explored tools and strategies to enhance game accessibility, the specific experiences of these players with mobile games remain underexamined. This study addresses this gap by investigating how BLV users experience mobile games with varying accessibility levels. Through interviews with 32 experienced BLV mobile players, we explore their perceptions, challenges, and strategies for engaging with mobile games. Our findings reveal that BLV players turn to mobile games to alleviate boredom, achieve a sense of accomplishment, and build social connections, but face barriers depending on the game's accessibility level. We also compare mobile games to other forms of gaming, highlighting the relative advantages of mobile games, such as the inherent accessibility of smartphones. This study contributes to understanding BLV mobile gaming experiences and provides insights for enhancing accessible mobile game design.",
    "title": "How Users Who are Blind or Low Vision Play Mobile Games: Perceptions, Challenges, and Strategies",
    "id": 189058,
    "sequence": 848,
    "queryCoordinates": {
      "visualization": [
        4.282572564300324,
        18.51106621001346
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "Developing and simulating 3D prototypes is crucial in product conceptual design for ideation and presentation. Traditional methods often keep physical and virtual prototypes separate, leading to a disjointed prototype workflow. In addition, acquiring high-fidelity prototypes is time-consuming and resource-intensive, distracting designers from creative exploration. Recent advancements in generative artificial intelligence (GAI) and extended reality (XR) provided new solutions for rapid prototype transition and mixed simulation. We conducted a formative study to understand current challenges in the traditional prototype process and explore how to effectively utilize GAI and XR ability in prototype. Then we introduced FusionProtor, a mixed-prototype tool for component-level 3D prototype transition and simulation. We proposed a step-by-step generation pipeline in FusionProtor, effectively transiting 3D prototypes from physical to virtual and low- to high-fidelity for rapid ideation and iteration. We also innovated a component-level 3D creation method and applied it in XR environment for the mixed-prototype presentation and interaction. We conducted technical and user experiments to verify FusionProtor’s usability in supporting diverse designs. Our results verified that it achieved a seamless workflow between physical and virtual domains, enhancing efficiency and promoting ideation. We also explored the effect of mixed interaction on design and critically discussed its best practices for HCI community.",
    "title": "FusionProtor: A Mixed-Prototype Tool for Component-level Physical-to-Virtual 3D Transition and Simulation",
    "id": 189059,
    "sequence": 849,
    "queryCoordinates": {
      "visualization": [
        -18.898634622151608,
        1.960002402654785
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "Creating expressive and realistic motion animations is a challenging task. Generative artificial intelligence (AI) models have emerged to address this challenge, offering the capability to synthesize human motion animations from text prompts. However, the effective integration of AI-generated motion into professional designer workflows remains uncertain. This study proposes MoWa, an authoring tool designed to refine AI-generated human motions to meet professional standards. A formative study with six professional motion designers identified the strengths and weaknesses of AI-generated motions. To address these weaknesses, MoWa utilizes latent space to enhance the expressiveness of motions, making them suitable for use in professional workflows. A user study involving twelve professional motion designers was conducted to evaluate MoWa's effectiveness in refining AI-generated motions. The results indicated that MoWa streamlines the motion design process and improves the quality of the outcomes. These findings suggest that incorporating latent space into motion design tasks can improve efficiency.",
    "title": "MoWa: An Authoring Tool for Refining AI-Generated Human Avatar Motions Through Latent Waveform Manipulation",
    "id": 189060,
    "sequence": 850,
    "queryCoordinates": {
      "visualization": [
        -1.1611387090178498,
        -3.8277613429288353
      ]
    }
  },
  {
    "session": "Understanding and Working with Algorithms",
    "abstract": "There are inevitably delays between user actions and system responses, which can increase task completion times. However, it remains unclear whether this is solely due to waiting times and compensation strategies, or whether users further slow down their actions because these delays become integrated into their cognitive action structures, as suggested by cognitive psychological theories. To explore this, we examined the effects of repeated exposure to delays during point-and-click tasks. Our findings demonstrate that longer system response delays significantly slow down users' actions, even before they experience the delayed feedback from the current input. This suggests that the user's cognitive system anticipates delays based on previous interactions and adjusts actions accordingly. These results emphasize the importance of minimizing systematic delays to maintain optimal user performance and highlight the potential for system properties to become embedded in users' cognitive action structures.",
    "title": "Cognitive Integration of Delays: Anticipated System Delays Slow Down User Actions",
    "id": 189061,
    "sequence": 851,
    "queryCoordinates": {
      "visualization": [
        -1.9479565254429254,
        -8.7866640640794
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "Content creation allows many online social media users to support\r\nthemselves financially through creativity. The “creator economy”\r\nempowers individuals to create content (i.e. lifestyle, fitness, beauty)\r\nabout their interests, hobbies and daily life. Social media platforms\r\nin turn moderate content (e.g., banning accounts, flagging and re-\r\nporting videos) to create safer online communities. However, Black\r\nwomen, femme, and non-binary people content creators have seen\r\ntheir content disproportionately suppressed, thus limiting their\r\nsuccess on the platform. In this paper, we investigate Black femme\r\ncontent creators’ (BFCC) theories about how their identities impact\r\nboth how they create content and how that content is subsequently\r\nmoderated. In our findings, we share the perceptions participants\r\nfelt the algorithm constrains Black creators to. We build upon Crit-\r\nical Technocultural Discourse studies and algorithmic folk theories\r\nattributed to Black women and non-binary content creators to ex-\r\nplore how Black joy can be prioritized online to resist algorithmic\r\nmonoliths.",
    "title": " Why Can’t Black Women Just Be?: Black Femme Content Creators Navigating Algorithmic Monoliths",
    "id": 189062,
    "sequence": 852,
    "queryCoordinates": {
      "visualization": [
        16.880991484315757,
        -14.107874627542552
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "Speech-language pathologists (SLPs) provide support to children with speech and language difficulties through delivering evaluation, assessment, and interventions. Despite growing research on how Artificial Intelligence (AI) can support SLPs, there is limited research examining how AI can assist SLPs in delivering equitable care to culturally and linguistically diverse (CLD) children with disabilities. Through interviews with 15 SLPs and a two-part survey study with 13 SLPs, we report on SLP challenges in delivering responsive care to CLD children with disabilities (i.e., unrepresentative materials, unreliable translation, insufficient support for language variations), areas for AI-based support, evaluations of how available AI performs in addressing these challenges, and bias assessments of AI-generated materials. We discuss implications of contextually unaware AI, the range of care in AI-prompting, tensions and tradeoffs of AI-based support, and honoring diverse representations in AI-generated materials. We offer considerations for SLPs using AI-based tools and general-purpose AI in their practice.",
    "title": "Exploring AI-Based Support in Speech-Language Pathology for Culturally and Linguistically Diverse Children",
    "id": 189063,
    "sequence": 853,
    "queryCoordinates": {
      "visualization": [
        16.17076094002452,
        -13.398003232593183
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "AI development is shaped by academics and industry leaders---let us call them ``influencers''---but it is unclear how their views align with those of the public. To address this gap, we developed an interactive platform that served as a data collection tool for exploring public views on AI, including their fears, hopes, and overall sense of hopefulness. We made the platform available to 330 participants representative of the U.S. population in terms of age, sex, ethnicity, and political leaning, and compared their views with those of 100 AI influencers identified by Time magazine. The public fears AI getting out of control, while influencers emphasize regulation, seemingly to deflect attention from their alleged focus on monetizing AI's potential. Interestingly, the views of AI influencers from underrepresented groups such as women and people of color often differ from the views of underrepresented groups in the public.",
    "title": "The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform",
    "id": 189064,
    "sequence": 854,
    "queryCoordinates": {
      "visualization": [
        7.612719409963746,
        9.276125440352843
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "Presentation software still holds barriers to independent creation for blind and visually impaired users (BVIs) due to its visual-centric interface. To address this gap, we introduce I-Scratch, a multimodal system which empowers BVIs to independently create, explore, and edit PowerPoint slides. We initially designed I-Scratch to tackle the practical challenges faced by BVIs and refined I-Scratch to improve its usability and accessibility through iterative participatory sessions involving a blind user. I-Scratch integrates a graphical tactile display with auditory guidance for multimodal feedback, simplifies the user interface, and leverages AI technologies for visual assistance in image generation and content interpretation. A user study with ten BVIs demonstrated that I-Scratch enables them to produce visually coherent and aesthetically pleasing slides independently, achieving 91.25% of full and partial successes with a CSI score of 85.07. We present five guidelines and future directions to support the creative work of BVIs using presentation software.",
    "title": "I-Scratch: Independent Slide Creation With Auditory Comment and Haptic Interface for the Blind and Visually Impaired",
    "id": 189065,
    "sequence": 855,
    "queryCoordinates": {
      "visualization": [
        -10.838231749957641,
        17.987015665034882
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "Violence is a significant public health issue. Interventions to reduce violence rely on data about where incidents occur. Cities have historically used incomplete law enforcement crime data, but many are shifting toward data collected from hospital patients via the Cardiff Model to form a more complete understanding of violence. Still, location data is wrought with issues related to completeness, quality, and privacy. For example, if a patient feels that sharing a detailed location may present them with additional risks, such as undesired police involvement or retaliatory violence, they may be unwilling or unable to share. Consequently, survivors of violence who are the most vulnerable may remain the most at risk. We have designed a user interface and mapping algorithm to confront these challenges and conducted an experiment with emergency department patients. The results indicate a significant improvement in location data obtained using the interface compared to the existing screening interview.",
    "title": "Interaction Techniques for Providing Sensitive Location Data of Interpersonal Violence with User-Defined Privacy Preservation",
    "id": 189066,
    "sequence": 856,
    "queryCoordinates": {
      "visualization": [
        10.936973319490871,
        1.1758463372162404
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Suicide is a complex phenomenon wherein, in addition to the individual impacted, its effects seep into many lives including those of their caregivers. Caregivers seek help everywhere but face unique challenges including limited access to timely resources and personal mental health struggles. Mobile health apps offer a promising solution, but addressing caregivers’ specific needs remains a concern. We present LifeLink, a persuasive mobile app to support caregivers of individuals experiencing suicidal thoughts. The app was developed in three stages. First, we reviewed 80 existing suicide prevention apps. Second, we designed a low-fidelity prototype of LifeLink using the Persuasive System Design model and refined it through a study conducted with 45 caregivers. Finally, incorporating evidence-based strategies and caregiver feedback, we developed and evaluated LifeLink in another study with 50 caregivers. Results show that LifeLink is user-friendly, engaging, elicits positive user experience and effectively empowers caregivers. LifeLink usage was associated with improved mental wellbeing, increased mental health literacy, and a more supportive environment. Our findings highlight the importance of involving caregivers in the design process. We offer recommendations for designers and researchers developing impactful persuasive technology for suicide prevention and for those working in related areas.",
    "title": "\"Bring them back to life\": LifeLink Application for Caregivers Dealing with Suicidality",
    "id": 189067,
    "sequence": 857,
    "queryCoordinates": {
      "visualization": [
        5.805693545089241,
        -19.13880671464418
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "Regulatory shifts are increasingly placing the onus on online service providers such as digital game developers and platforms to ensure that their services do not harm children. This creates an urgent need to examine how children experience and conceptualize harm in digital contexts, which may differ from adult-driven perceptions of harm. In this paper, we present the results of a study into children’s experiences with game monetization which included a ‘think-aloud’ method in which children were given an AU$20 voucher to spend. Through our participants’ (aged 7-14) vernacular of feeling ‘scammed’ or ‘tricked’, we argue that children experience harm principally through being misled or deceived by monetization features, rather than being due to what parents perceive as a misattribution of value toward digital items or overspending. Based on these results, we make game design recommendations to minimize children’s harmful experiences with game monetization strategies.",
    "title": "“They’re Scamming Me”: How Children Experience and Conceptualize Harm in Game Monetization",
    "id": 189068,
    "sequence": 858,
    "queryCoordinates": {
      "visualization": [
        1.8855869473039903,
        -3.52768505739342
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "This paper examines the potential for localized adaptation, appropriation and re-imagination of AI for non-western cultural expression, using the Persian Gulf as a case. Using sociologist Howard Becker’s concept of 'art worlds' as a situated lens to evaluate generative AI, we set up an eight week experimentation and dialogue between artists, art historians and curators. Our project reveals how local art worlds 1) can appropriate AI tools to address contextual and cultural needs; 2) develop \"hacks'' to adapt AI for culturally-specific capabilities; and 3) can be a site for imagining alternative technological trajectories. We thus showcase the importance of expanding the scope of AI evaluations to include the social dynamics AI operates in and its contexts of use. We also reflect on the power that local communities may have to interrupt AI with more culturally-relevant orientations and to offer visions for redesigning AI for non-Western creativity.",
    "title": "AI and Non-Western Art Worlds: Reimagining Critical AI Futures through Artistic Inquiry and Situated Dialogue",
    "id": 189069,
    "sequence": 859,
    "queryCoordinates": {
      "visualization": [
        5.820356850721127,
        -21.216112889270352
      ]
    }
  },
  {
    "session": "Physical and Tangible",
    "abstract": "Norway's long coastline, industrial activities and harsh weather conditions expose it to the global environmental challenge of Marine Plastic Pollution (MPP). Ambitious grassroots coastal cleanup initiatives have been taking place across the country since 2013. The project that is the object of this case study aimed to create a unified visualization tool to enhance data-driven decision-making at local and regional levels. This involved categorizing litter to guide policy making and strengthen environmental protection efforts. However, the research team encountered significant challenge: effectively classifying litter and encouraging the decision-makers to use the tools for decision-making. A visualization tool may not be enough to foster data-driven decision-making but it may bring about the necessary collaboration among various stakeholders by providing a tangible basis and an arena to discuss this poorly-legislated problem. While the field of human-computer interaction (HCI) offers many effective practices for using technology to support environmental protection, we present a case study of an unsuccessful attempt and reflect on the lessons learnt. We focus on designing interactions for often-neglected domains, such as MPP, and reflect on adapting and developing new practices to extend HCI's research, ensuring it can accommodate the unique demands of a diverse stakeholder group and the constraints of real-world projects.",
    "title": "Enhancing Environmental Protection Through HCI: Insights from a Coastal Litter Cleanup Initiative in Norway",
    "id": 189070,
    "sequence": 860,
    "queryCoordinates": {
      "visualization": [
        -10.113147467559688,
        17.25468771955584
      ]
    }
  },
  {
    "session": "Looking Back and Looking Forward",
    "abstract": "This paper reflects on the role of Human-Computer Interaction (HCI) research and practice both in addressing and exacerbating current environmental crises. Observing a discrepancy between the urgency of these crises and the attention they receive in HCI, we generated and analysed twelve fictional narratives that speculate about what it could mean if HCI prioritized environmental sustainability. This exercise helped us identify possible strategies towards this aim through addressing HCI practices such as conferencing, teaching and research. These strategies include building on existing meso-level initiatives in the community, reorienting reviewing processes, practising prefiguration, being mindful of diverse perspectives, and adding a touch of humour. Publishing our set of narratives in the form of a book of fairy tales alongside this paper is one step in that direction. We hope the book and the paper contribute to raising and nuancing the topic of (un)sustainability in HCI.",
    "title": "Once Upon a Time When HCI Prioritised Environmental Sustainability: Reflections on a Collection of Fictions",
    "id": 189071,
    "sequence": 861,
    "queryCoordinates": {
      "visualization": [
        -13.533116534621593,
        -11.86822467180124
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": "1. We are destroying nature. 2. We do not know where to store our radioactive waste. 3. In Chernobyl, wildlife seems to be thriving. We have connected these three considerations in a Found Footage design fiction exploring a near-future of an Austria that has put its hope for an ecologically just and sustainable future into nuclear waste disposal sites turned national parks protected by radiation. This report displays artefacts from the ongoing project and discusses our design process, insights and learnings around Found Footage as a design fiction method to pose critical questions about the emotional factors of technology futures.",
    "title": "Found Footage from the Nuclear Protection National Parks",
    "id": 189072,
    "sequence": 862,
    "queryCoordinates": {
      "visualization": [
        1.953085158797335,
        -10.825223247697277
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "Evaluating UX in the context of AI’s complexity, unpredictability, and generative nature presents unique challenges. How can we support HCI researchers to create comprehensive UX evaluation plans? In this paper, we introduce EvAlignUX, a system powered by large language models and grounded in scientific literature, designed to help HCI researchers explore evaluation metrics and their relationship to research outcomes. A user study with 19 HCI scholars showed that EvAlignUX improved the perceived quality and confidence in UX evaluation plans while prompting deeper consideration of research impact and risks. The system enhanced participants' thought processes, leading to the creation of a “UX Question Bank” to guide UX evaluation development. Findings also highlight how researchers’ backgrounds influence their inspiration and concerns about AI over-reliance, pointing to future research on AI’s role in fostering critical thinking. In a world where experience defines impact, we discuss the importance of shifting UX evaluation from a “method-centric” to a “mindset-centric” approach as the key to meaningful and lasting design evaluation.",
    "title": "EvAlignUX: Advancing UX Evaluation through LLM-Supported Metrics Exploration",
    "id": 189073,
    "sequence": 863,
    "queryCoordinates": {
      "visualization": [
        -14.65654622183926,
        8.61310935998663
      ]
    }
  },
  {
    "session": "More than Human and More",
    "abstract": "While analysing challenges in pilot projects developing AI with marginalized communities, we found it difficult to express them within commonly used paradigms. We therefore constructed an alternative conceptual framework to ground AI development in the social fabric — the Cloud Weaving Model — inspired (amongst others) by indigenous knowledge, motifs from nature, and Eastern traditions. This paper introduces and elaborates on the fundamental elements of the model (clouds, spiders, threads, spiderwebs, and weather) and their interpretation in an AI context. The framework is then applied to comprehend patterns observed in co-creation pilots approaching marginalized communities, highlighting neglected yet relevant dimensions for responsible AI development.\r\n",
    "title": "The Cloud Weaving Model for AI development",
    "id": 189074,
    "sequence": 864,
    "queryCoordinates": {
      "visualization": [
        19.3519818472052,
        -5.049831540303157
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "Great characters are critical to the success of many forms of media, such as comics, games, and films. Designing visually compelling casts of characters requires significant skill and consideration, and there is a lack of specialized tools to support this endeavor. We investigate how AI-driven image-generation techniques can empower creatives to explore a variety of visual design possibilities for individual and groups of characters. Informed by interviews with character designers, Paratrouper is a multi-modal system that enables creating and experimenting with multiple permutations for character casts and visualizing them in various contexts as part of a holistic approach to design. We demonstrate how Paratrouper supports different aspects of the character design process, and share insights from its use by eight creators. Our work highlights the interplay between creative agency and serendipity, as well as the visual interrelationships among character aesthetics.",
    "title": "Paratrouper: Exploratory Creation of Character Cast Visuals Using Generative AI",
    "id": 189075,
    "sequence": 865,
    "queryCoordinates": {
      "visualization": [
        -9.280808951595287,
        -14.24312413777219
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "Prosociality has been well-documented to positively impact mental, social, and physical well-being. However, existing studies of interventions for promoting prosociality have limitations such as small sample sizes or unclear benchmarks. To address this gap, we\r\nconducted a global-scale well-being intervention deployment study, BIGJOY, with more than 18,000 participants from 172 countries and regions. The week-long BIGJOY intervention consists of seven daily micro-acts (i.e., brief actions that require minimal effort), each adapted from validated positive psychology interventions. The analyses of large-scale intervention data reveal unique insights into the impact of well-being micro-acts across diverse populations, patterns of responses, effectiveness of specific micro-acts and their nuanced impacts across different populations, linkages between improvements in prosociality and in well-being, as well as the potential for machine learning to predict changes in prosociality. This study offers valuable insights into a set of design guidelines for future well-being and prosociality interventions. We envision our\r\nwork as a stepping stone towards future large-scale prosociality interventions that foster a more unified and compassionate world.",
    "title": "Promoting Prosociality via Micro-acts of Joy: A Large-Scale Well-Being Intervention Study",
    "id": 189076,
    "sequence": 866,
    "queryCoordinates": {
      "visualization": [
        -15.87967255357936,
        1.9585708031874616
      ]
    }
  },
  {
    "session": "Input and Modeling",
    "abstract": "Light's interaction with object surfaces through anisotropic reflection—where reflected light varies with viewing angles—offers significant potential for enhancing visual capabilities and assisting informed decision-making. Such ubiquitous light transfer phenomenon supports directional information encoding in sensing and dynamic display applications.\r\nWe present LumosX, a set of techniques for encoding and decoding information through light intensity changes using 3D-printed optical anisotropic properties. By optimizing directional reflection and brightness contrasts through off-the-shelf materials and precise control over processing parameters (e.g., extrusion volume, raster angles, layer height, nozzle positioning), we enable cost-effective fabrication of visually enhanced objects. Our method supports modular assembly for highly curved regular surfaces and direct printing on top of relatively flat curved surfaces, enabling flexible information encoding for diverse applications. We showcase LumosX's effectiveness through various indoor and smart urban sensing scenarios, demonstrating significant improvements in both human interaction and autonomous machine perception. ",
    "title": "LumosX: 3D Printed Anisotropic Light-Transfer",
    "id": 189077,
    "sequence": 867,
    "queryCoordinates": {
      "visualization": [
        -4.619397662556434,
        1.9134171618254494
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "Hardware Reverse Engineering (HRE) is a technique for analyzing integrated circuits. Experts employ HRE for security-critical tasks, like detecting Trojans or intellectual property violations, relying not only on their experience and customized tools but also on their cognitive abilities. In this work, we introduce ReverSim, a software environment that models key HRE subprocesses and integrates standardized cognitive tests. ReverSim enables quantitative studies with easier-to-recruit non-experts to uncover cognitive factors relevant to HRE. We empirically evaluated ReverSim in three studies. Semi-structured interviews with 14 HRE professionals confirmed its comparability to real-world HRE processes. Two online user studies with 170 novices and intermediates revealed effective differentiation of participant performance across a spectrum of difficulties, and correlations between participants’ cognitive processing speed and task performance. ReverSim is available as open-source software, providing a robust platform for controlled experiments to assess cognitive processes in HRE, potentially opening new avenues for hardware protection.",
    "title": "ReverSim: An Open-Source Environment for the Controlled Study of Human Aspects in Hardware Reverse Engineering",
    "id": 189078,
    "sequence": 868,
    "queryCoordinates": {
      "visualization": [
        10.83823174995764,
        -17.987015665034882
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "In light of inherent trade-offs regarding fairness, privacy, interpretability and performance, as well as normative questions, the machine learning (ML) pipeline needs to be made accessible for public input, critical reflection and engagement of diverse stakeholders. \r\n\r\nIn this work, we introduce a participatory approach to gather input from the general public on the design of an ML pipeline. We show how people's input can be used to navigate and constrain the multiverse of decisions during both model development and evaluation. We highlight that central design decisions should be democratized rather than \"optimized\" to acknowledge their critical impact on the system's output downstream. We describe the iterative development of our approach and its exemplary implementation on a citizen science platform. Our results demonstrate how public participation can inform critical design decisions along the model-building pipeline and combat widespread lazy data practices.",
    "title": "Preventing Harmful Data Practices by using Participatory Input to Navigate the Machine Learning Multiverse",
    "id": 189079,
    "sequence": 869,
    "queryCoordinates": {
      "visualization": [
        -1.1772563261425726,
        17.96146061829486
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Augmented and virtual reality headsets, collectively referred to as extended reality (XR), can alter, augment, or even replace our reality. While these headsets have made impressive strides in audio-visual immersion over the past half-century, XR interactions remain almost completely absent of appropriately expressive tactile sensations. At present, even mainstream consumer systems rely on vibrotactile haptic actuators in the controllers, which are inherently limited to clicks and buzzes — an exceedingly limited range of expressivity with which to represent the rich tactile world. \r\n\r\nRealizing the holistic promise of XR requires full-body haptic immersion, just as much as it requires full audio-visual immersion. To frame critical design considerations in haptics research, I propose an immersion-practicality tradeoff model. These competing objectives underscore the inherent tension between providing rich sensory feedback (often e.g. costly, bulky), while maintaining consumer feasibility and usability (e.g., low cost, easy to use). Under this framework, I sought to identify and build Pareto-efficient haptic systems where the haptic approach is aligned with humans' sensorimotor system. I present three published projects that embody my design approach with tactile haptics to different regions of the body. My proposed future work extends this framework to the other major dimensions of haptics (kinesthetic/force feedback). These systems serve as probes into my research approach and advance the vision of practical, immersive, full-body haptics.",
    "title": "Sensorimotor-Aligned Design for Pareto-Efficient Haptic Immersion in XR",
    "id": 189080,
    "sequence": 870,
    "queryCoordinates": {
      "visualization": [
        -9.617956964488627,
        -10.173244508476376
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "Walking is among the most common human activities where the feet can gather rich tactile information from the ground. The dynamic contact between the feet and the ground generates vibration signals that can be sensed by the foot skin. While existing research focuses on foot pressure sensing and lower-limb interactions, methods of decoding tactile information from foot vibrations remain underexplored. Here, we propose a foot-equipped wearable system capable of recording wideband vibration signals during walking activities. By enabling location-based recording, our system generates maps of haptic data that encode information on ground materials, lower-limb activities, and road conditions. Its efficacy was demonstrated through studies involving 31 users walking over 18 different ground textures, achieving an overall identification accuracy exceeding 95\\% (cross-user accuracy of 87\\%). Our system allows pedestrians to map haptic information through their daily walking activities, which has potential applications in creating digitalized walking experiences and monitoring road conditions.",
    "title": "VibWalk: Mapping Lower-limb Haptic Experiences of Everyday Walking",
    "id": 189081,
    "sequence": 871,
    "queryCoordinates": {
      "visualization": [
        15.658485462546478,
        13.993278136992085
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "In light of the increasing vulnerability of citizens against cyberattacks, we conducted three representative surveys with German citizens in 2021 (N=1,093), 2023 (N=1,011), and 2024 (N=1,004) to examine their cyber threat awareness, use of protective security measures, and preferred information channels. While our findings attest large proportions of the German population a high level of cyber threat awareness, many citizens feel inadequately informed about coping with cyberattacks and show little confidence in German security authorities to protect citizens and infrastructures. While age correlated with citizens' awareness and behavior, we only saw minor temporal differences between datasets. Finally, we provide design and policy implications for enhancing citizens' awareness of cyber threats and implementing security measures.",
    "title": "Cyber Threat Awareness, Protective Measures and Communication Preferences in Germany: Implications from Three Representative Surveys (2021-2024)",
    "id": 189082,
    "sequence": 872,
    "queryCoordinates": {
      "visualization": [
        14.291588819128245,
        7.193781274473705
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "Engaging with people's lived experiences is foundational for HCI research and design. This paper introduces a novel narrative elicitation method to empower people to easily articulate ‘micro-narratives’ emerging from their lived experiences, irrespective of their writing ability or background. Our approach aims to enable at-scale collection of rich, co-created datasets that highlight target populations' voices with minimal participant burden, while precisely addressing specific research questions. To pilot this idea, and test its feasibility, we: (i) developed an AI-powered prototype, which leverages LLM-chaining to scaffold the cognitive steps necessary for users’ narrative articulation; (ii) deployed it in three mixed-methods studies involving over 380 users; and (iii) consulted with established academics as well as C-level staff at (inter)national non-profits to map out potential applications. Both qualitative and quantitative findings show the acceptability and promise of the micro-narrative method, while also identifying the ethical and safeguarding considerations necessary for any at-scale deployments. ",
    "title": "Micro-narratives: A Scalable Method for Eliciting Stories of People’s Lived Experience",
    "id": 189083,
    "sequence": 873,
    "queryCoordinates": {
      "visualization": [
        -6.386309944090404,
        11.323208259941705
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "Critical thinking plays a crucial role in children's education for fostering cognitive development, cultivating independent thinking habits, and enhancing their ability to problem-solving. However, the current educational model places greater emphasis on children's understanding of factual knowledge, with relatively less focus on developing critical thinking skills. We present CharacterCritique to support children's critical thinking based on the theory of inquiry dialogue. This tool uses an analytical story as the medium, it encourages dialogue between parents, children, and story characters. Through this process, children continuously engage in interpretation, analysis, explanation, evaluation, and regulation, all of which promote critical thinking and decision-making. Such interaction is supported by multiple agents. In our between-subjects study (n=32), we compared CharacterCritique to traditional storybook reading. The results show that CharacterCritique is more effective at sparking children's interest in deeper discussions. It also better fosters critical thinking, problem-solving skills, and creates more opportunities for parent-child dialogue.",
    "title": "CharacterCritique: Supporting Children's Development of Critical Thinking through Multi-Agent Interaction in Story Reading",
    "id": 189084,
    "sequence": 874,
    "queryCoordinates": {
      "visualization": [
        -11.640574572235636,
        7.7779832622744305
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "Sign languages are essential for the Deaf and Hard-of-Hearing (DHH) community. Sign language generation systems have the potential to support communication by translating from written languages, such as English, into signed videos. However, current systems often fail to meet user needs due to poor translation of grammatical structures, the absence of facial cues and body language, and insufficient visual and motion fidelity. \r\nWe address these challenges by building on recent advances in LLMs and video generation models to translate English sentences into natural-looking AI ASL signers. The text component of our model extracts information for manual and non-manual components of ASL, which are used to synthesize skeletal pose sequences and corresponding video frames. Our findings from a user study with 30 DHH participants and thorough technical evaluations demonstrate significant progress and identify critical areas necessary to meet user needs. ",
    "title": "Towards AI-driven Sign Language Generation with Non-manual Markers",
    "id": 189085,
    "sequence": 875,
    "queryCoordinates": {
      "visualization": [
        5.219495154182159,
        4.664426045664028
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "Large Language Model (LLM)-based in-application assistants, or copilots, can automate software tasks, but users often prefer learning by doing, raising questions about the optimal level of automation for an effective user experience. We investigated two automation paradigms by designing and implementing a fully automated copilot (AutoCopilot) and a semi-automated copilot (GuidedCopilot) that automates trivial steps while offering step-by-step visual guidance. In a user study (N=20) across data analysis and visual design tasks, GuidedCopilot outperformed AutoCopilot in user control, software utility, and learnability, especially for exploratory and creative tasks, while AutoCopilot saved time for simpler visual tasks. A follow-up design exploration (N=10) enhanced GuidedCopilot with task-and state-aware features, including in-context preview clips and adaptive instructions. Our findings highlight the critical role of user control and tailored guidance in designing the next generation of copilots that enhance productivity, support diverse skill levels, and foster deeper software engagement.",
    "title": "Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software",
    "id": 189086,
    "sequence": 876,
    "queryCoordinates": {
      "visualization": [
        -16.1175365452339,
        -10.061064342953463
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "Prompt-based music generative artificial intelligence (GenAI) offers an efficient way to engage in music creation through language. However, it faces limitations in conveying artistic intent with language alone, highlighting the need for more research on AI-creator interactions. This study evaluates three different interaction modes (prompt-based, preset-based, and motif-based) of commercialized music AI toots with 17 participants of varying musical expertise to examine how prompt-based GenAI can improve creative intention. Our findings revealed that user groups preferred prompt-based music GenAI for distinct purposes: experts used it to validate musical concepts, novices to generate reference samples, and nonprofessionals to transform abstract ideas into musical compositions. We identified its potential for enhancing compositional efficiency and creativity through intuitive interaction, while also noting limitations in handling temporal and musical nuances solely through prompts. Based on these insights, we present design guidelines to ensure users can effectively engage in the creative process, considering their musical expertise.\r\n",
    "title": "Understanding the Potentials and Limitations of Prompt-based Music Generative AI",
    "id": 189087,
    "sequence": 877,
    "queryCoordinates": {
      "visualization": [
        -5.7182195971039445,
        12.778965710858465
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "In the era of artificial intelligence, AI-assisted decision-making has become a common paradigm. Explainable Artificial Intelligence has been one of the more explored factors in improving transparency of AI tools in AI-assisted decision-making, but sometimes with contradictory results. \r\nFurthermore, while individual AI-assisted decision-making has garnered substantial investigation, the domain of group AI-assisted decision-making remains notably underexplored. This research presents the first look at the impact of explainability and team composition on AI-assisted decision-making. With a controlled experiment on mushroom edibility classification, with 89 participants, we show that the impact of XAI is more pronounced in decision-making with groups (2-person) than in individual decision-making. \r\nGroups rely less on incorrect AI recommendations when explanations are available, but they rely more on incorrect AI recommendations when explanations are absent, compared to individual decision makers.\r\nThis phenomenon underscores the amplified effect of explainability in AI-assisted decision-making in group settings. ",
    "title": "The Amplifying Effect of Explainability in AI-assisted Decision-making in Groups",
    "id": 189088,
    "sequence": 878,
    "queryCoordinates": {
      "visualization": [
        -2.380060020873706,
        -1.8262842870261609
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "Nighttime sidewalk illumination has a significant and unequal influence on where and whether pedestrians walk at night. Despite the importance of pedestrian lighting, there is currently no approach for measuring and communicating how humans experience nighttime sidewalk light levels at scale. We introduce NightLight, a new sensing approach that leverages the ubiquity of smartphones by re-appropriating the built-in light sensor ---traditionally used to adapt screen brightness---to sense pedestrian nighttime lighting conditions. We validated our technique through in-lab and street-based evaluations characterizing performance across phone orientation, phone model, and varying light levels demonstrating the ability to aggregate and map pedestrian-oriented light levels with unaltered smartphones. Additionally, to examine the impact of light level data on pedestrian route choice, we conducted a qualitative user study with 13 participants using a standard map vs. one with pedestrian lighting data from NightLight Our findings demonstrate that people changed their routes in preference of well-light routes during nighttime walking. Our work has implications for expanding  personalized navigation and pedestrian route choice and passive urban sensing.  ",
    "title": "NightLight: Passively Mapping Nighttime Sidewalk Light Data for Improved Pedestrian Routing",
    "id": 189089,
    "sequence": 879,
    "queryCoordinates": {
      "visualization": [
        6.457666452124428,
        13.538779265247907
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "Using smartphone apps during crises is well-established, proving critical for efficient crisis response. However, such apps become futile without an Internet connection, which is a common issue during crises. The ongoing 6G standardization explores the capability to provide local cellular connectivity for areas cut off from the Internet in crises. This paper introduces to the HCI community the concept of cellular island connectivity in isolated areas, promising a seamless transition from normal operation to island operation with local-only cellular connectivity. It presents findings from a survey (N = 857) among adult smartphone users from major German cities regarding their smartphone usage preferences in this model. Results show a shift in app demand, with users favoring general-purpose apps over dedicated crisis apps in specific scenarios. We prioritize smartphone services based on their criticality, distinguishing between apps essential for crisis response and those supporting routines. Our findings provide operators, developers, and authorities insights into making user-centric design decisions for implementing island-ready 6G communication.",
    "title": "The User Perspective on Island-Ready 6G Communication: A Survey of Future Smartphone Usage in Crisis-Struck Areas with Local Cellular Connectivity",
    "id": 189090,
    "sequence": 880,
    "queryCoordinates": {
      "visualization": [
        -9.337918646889381,
        15.38841367211304
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "Decision-making with information displays is a key focus of research in areas like human-AI collaboration and data visualization. However, what constitutes a decision problem, and what is required for an experiment to conclude that decisions are flawed, remain imprecise. We present a widely applicable definition of a decision problem synthesized from statistical decision theory and information economics. We claim that to attribute loss in human performance to bias, an experiment must provide the information that a rational agent would need to identify the normative decision. We evaluate whether recent empirical research on AI-assisted decisions achieves this standard. We find that only 10 (26\\%) of 39 studies that claim to identify biased behavior presented participants with sufficient information to make this claim in at least one treatment condition. We motivate the value of studying well-defined decision problems by describing a characterization of performance losses they allow to be conceived.",
    "title": "Underspecified Human Decision Experiments Considered Harmful",
    "id": 189091,
    "sequence": 881,
    "queryCoordinates": {
      "visualization": [
        12.058376795253729,
        -7.113054833451407
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "This work investigates the integration of generative visual aids in human-robot task communication. We developed GenComUI, a system powered by large language models (LLMs) that dynamically generates contextual visual aids—such as map annotations, path indicators, and animations—to support verbal task communication and facilitate the generation of customized task programs for the robot. This system was informed by a formative study that examined how humans use external visual tools to assist verbal communication in spatial tasks. To evaluate its effectiveness, we conducted a user experiment (n = 20) comparing GenComUI with a voice-only baseline. The results demonstrate that generative visual aids, through both qualitative and quantitative analysis, enhance verbal task communication by providing continuous visual feedback, thus promoting natural and effective human-robot communication. Additionally, the study offers a set of design implications, emphasizing how dynamically generated visual aids can serve as an effective communication medium in human-robot interaction. These findings underscore the potential of generative visual aids to inform the design of more intuitive and effective human-robot communication, particularly for complex communication scenarios in human-robot interaction and LLM-based end-user development.",
    "title": "GenComUI: Exploring Generative Visual Aids as Medium to Support Task-Oriented Human-Robot Communication",
    "id": 189092,
    "sequence": 882,
    "queryCoordinates": {
      "visualization": [
        -12.824335978542786,
        11.159588106621724
      ]
    }
  },
  {
    "session": "Learning and Inspiring, Safety and Security",
    "abstract": "Troubles in speaking, hearing, and understanding occur routinely in any kind of natural conversational setting.\r\nThe natural flow of conversation includes methods for repairing such troubles by repeating or paraphrasing all or parts of prior turns.\r\nIn the case of conversational AI systems, these troubles occur due to failure of different components of the system such as the speech recognition, natural language understanding, and natural language generation. \r\nSuch errors may occur infrequently, but often enough to have a significant impact on key performance indicators (KPIs).\r\nIdentifying the root cause of these errors is a complex task that requires a team to meticulously examine and interpret the interaction between the voice agent and customers.\r\nIn this work, we present an interactive system, DTTool, that surfaces system-generated annotations that hint at anomalous events that lead to candidate errors that impact KPIs and demonstrate how the team could discover unknown errors using DTTool.\r\n",
    "title": "Diagnosing and Prioritizing Issues in Automated Order-Taking Systems: A Machine-Assisted Error Discovery Approach",
    "id": 189093,
    "sequence": 883,
    "queryCoordinates": {
      "visualization": [
        1.1767073490094662,
        -13.95046091764667
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "The uptake of digital technology by older adults and service-providers has been partly driven by the pandemic but more recently by the erosion of in-person services because of increasing austerity and a harsher global economic climate. Against the backdrop of the UK’s cost of living crisis, we examine technology used frequently within five older adults’ households. Through two rounds of in- terviews and participant diaries, we show benefits and struggles of participants’ costly technology use, reflecting on what ‘cost of living’ means when technology designed to simplify older peoples lives, encounters problems. For HCI practitioners, we provide evi- dence of how personal smart devices can be better tailored to help older adults support themselves both economically and practically, during the cost of living crisis. We propose avenues for future re- search and design that better support indirect costs and reflect on how personal devices can be made self-sustaining, integrated and repairable.",
    "title": "Hidden Opportunities for Elder Living: Understanding Shared Technology Troubles and Benefits for Older Adults in the UK Cost of Living Crisis",
    "id": 189094,
    "sequence": 884,
    "queryCoordinates": {
      "visualization": [
        -9.032407769589227,
        -10.696523261502504
      ]
    }
  },
  {
    "session": "Pointing and Selection",
    "abstract": "When using indirect pointing devices in modern operating systems (OS), users' perception of the pointing transfer function is easily influenced by the device's hardware or OS-native transfer function settings. This could hinder users from finding and fully adapting to the transfer function that is optimal for them. We propose a novel hardware-embedded transfer function technique that is expected to allow users to consistently experience the desired function even when device hardware or OS settings change. The technique (1) allows users to define the desired function within the device firmware in physical units and (2) enables the firmware to cancel out the influence of OS-native functions and hardware setting perturbations, so that the uploaded function can persist regardless of the external environment. Through technical evaluation including transfer functions of various shapes, we showed that the proposed technique has comparable robustness and accuracy to the conventional approach.",
    "title": "Hardware-Embedded Pointing Transfer Function Capable of Canceling OS Gains",
    "id": 189095,
    "sequence": 885,
    "queryCoordinates": {
      "visualization": [
        -5.740251485476355,
        -13.858192987669298
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "Context-aware AR instruction enables adaptive and in-situ learning experiences. However, hardware limitations and expertise requirements constrain the creation of such instructions. With recent developments in Generative Artificial Intelligence (Gen-AI), current research tries to tackle these constraints by deploying AI-generated content (AIGC) in AR applications. However, our preliminary study with six AR practitioners revealed that the current AIGC lacks contextual information to adapt to varying application scenarios and is therefore limited in authoring. To utilize the strong generative power of GenAI to ease the authoring of AR instruction while capturing the context, we developed CARING-AI, an AR system to author context-aware humanoid-avatar-based instructions with GenAI. By navigating in the environment, users naturally provide contextual information to generate humanoid-avatar animation as AR instructions that blend in the context spatially and temporally. We showcased three application scenarios of CARING-AI: Asynchronous Instructions, Remote Instructions, and Ad Hoc Instructions based on a design space of AIGC in AR Instructions. With two user studies (N=12), we assessed the system usability of CARING-AI and demonstrated the easiness and effectiveness of authoring with Gen-AI.",
    "title": "CARING-AI: Towards Authoring Context-aware Augmented Reality INstruction through Generative Artificial Intelligence",
    "id": 189096,
    "sequence": 886,
    "queryCoordinates": {
      "visualization": [
        -5.018907846382263,
        -15.192450889488587
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "Semi-transparent visualizations are commonly used to reveal information in overlapped regions by applying colors and opacity. While a few studies made recommendations on how to choose colors and opacity levels to maintain depth perception, they often conflict and overlook the interaction effect between these factors. In this paper, we systematically explore the impact of color and opacity on depth order perception across eight colors, three opacity levels, and various layer orders and arrangements. Our inferential analysis shows that both color hue and opacity significantly influence depth order perception, with the effectiveness depending on their interaction. We also derived 12 features for predictive analysis, achieving the best mean accuracy of 80.72% and mean F1 score of 87.75%, with opacity assigned to the front layer as the top feature for most models. Finally, we provide a small design tool and four guidelines to better align the design rules of colors and opacity in semi-transparent visualizations.",
    "title": "Seeing Through the Overlap: The Impact of Color and Opacity on Depth Order Perception in Visualization",
    "id": 189097,
    "sequence": 887,
    "queryCoordinates": {
      "visualization": [
        4.282572564300316,
        -18.511066210013464
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "A content creator's success depends on understanding their audience, but existing tools fail to provide in-depth insights and actionable feedback necessary for effectively targeting their audience. We present Proxona, an LLM-powered system that transforms static audience comments into interactive, multi-dimensional personas, allowing creators to engage with them to gain insights, gather simulated feedback, and refine content. Proxona distills audience traits from comments, into dimensions (categories) and values (attributes), then clusters them into interactive personas representing audience segments. Technical evaluations show that Proxona generates diverse dimensions and values, enabling the creation of personas that sufficiently reflect the audience and support data grounded conversation. User evaluation with 11 creators confirmed that Proxona helped creators discover hidden audiences, gain persona-informed insights on early-stage content, and allowed them to confidently employ strategies when iteratively creating storylines. Proxona introduces a novel creator-audience interaction framework and fosters a persona-driven, co-creative process.",
    "title": "Proxona: Supporting Creators' Sensemaking and Ideation with LLM-Powered Audience Personas",
    "id": 189098,
    "sequence": 888,
    "queryCoordinates": {
      "visualization": [
        -13.861747250912718,
        -14.417071934058377
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "Traditionally, linters are code analysis tools that help developers by flagging potential issues from syntax and logic errors to enforcing syntactical and stylistic conventions. Recently, linting has been taken as an interface metaphor, allowing it to be extended to more complex inputs, such as visualizations, which demand a broader perspective and alternative approach to evaluation.  We explore a further extended consideration of linting inputs, and modes of evaluation, across the puritanical, neutral, and rebellious dimensions. We specifically investigate the potential for leveraging human computation in linting operations through Community Notes---crowd-sourced contextual text snippets aimed at checking and critiquing potentially accurate or misleading content on social media. We demonstrate that human-powered assessments not only identify misleading or error-prone visualizations but that integrating human computation enhances traditional linting by offering social insights.As is required these days, we consider the implications of building linters powered by Artificial Intelligence. ",
    "title": "Linting is People! Exploring the Potential of Human Computation as a Sociotechnical Linter of Data Visualizations",
    "id": 189099,
    "sequence": 889,
    "queryCoordinates": {
      "visualization": [
        17.987015665034885,
        -10.838231749957629
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "This research explores how interactive technologies can raise awareness, support self-help, and create safe spaces for women affected by forced marriages. Despite legal protections, FMs persist globally, including in Switzerland, where patriarchal family structures contrast with egalitarian societal norms. The study is structured into three stages: (1) supporting awareness and realization of abuse, (2) assisting in help-seeking through self-help and enhanced communication with support organizations, and (3) facilitating life repair to ensure safety and independence post-FM. Collaborating with the Swiss Competence Center against Forced Marriages, this research uses participatory, feminist, and trauma-informed approaches. The expected outcomes include tailored technological solutions for the unique challenges of FMs, offering insights into designing for complex social, cultural, and familial dynamics. This doctoral research aims to contribute to HCI by demonstrating how technology can empower individuals in patriarchal contexts within Western societies.",
    "title": "Designing Technology to Support Awareness, Self-Help, and Create Safe Spaces for Women Affected by Forced Marriages",
    "id": 189100,
    "sequence": 890,
    "queryCoordinates": {
      "visualization": [
        -15.12431017725866,
        14.56898217659937
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Disabled people on social media often experience ableist hate and microaggressions. Prior work has shown that platform moderation often fails to remove ableist hate, leaving disabled users exposed to harmful content. This paper examines how personalized moderation can safeguard users from viewing ableist comments. During interviews and focus groups with 23 disabled social media users, we presented design probes to elicit perceptions on configuring their filters of ableist speech (e.g., intensity of ableism and types of ableism) and customizing the presentation of the ableist speech to mitigate the harm (e.g., AI rephrasing the comment and content warnings). We found that participants preferred configuring their filters through types of ableist speech and favored content warnings. We surface participants’ distrust in AI-based moderation, skepticism in AI’s accuracy, and varied tolerances in viewing ableist hate. Finally, we share design recommendations to support users’ agency, mitigate harm from hate, and promote safety.",
    "title": "“Ignorance is not Bliss”: Designing Personalized Moderation to Address Ableist Hate on Social Media",
    "id": 189101,
    "sequence": 891,
    "queryCoordinates": {
      "visualization": [
        -13.0794851641244,
        -4.992701457272378
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "With psychiatry lagging behind other medical fields in terms of innovation in instruments and methods, AI provides it an opportunity to catch up. Advocates of digital phenotyping promise to provide an objective tool that detects symptoms by analysing data from personal devices. We argue that digital phenotyping requires a more reflexive and critical approach to its design and an alignment of the clinicians' interests in generating relevant evidence with the needs of service users who seek tools to manage their condition. We propose a felt informatics approach, situating digital phenotyping design within the problem space of pragmatist aesthetics. Within this perspective, felt life becomes a central object and a site for digital phenotyping design.  This paper reveals the ways diagnostic data mediates mental ill health experience, emphasises the cultivation of aesthetic sensibility as a fundamental element of digital phenotyping and includes design considerations for practitioners and researchers.",
    "title": "Digital Phenotyping as Felt Informatics: Designing AI-Based Mental Health Diagnostic Tools Through Aesthetics",
    "id": 189102,
    "sequence": 892,
    "queryCoordinates": {
      "visualization": [
        -1.960002402654786,
        -18.898634622151608
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "This paper presents a scoping review on motivational game elements examined in game-based interventions for children’s learning in school context in ACM Digital Library and Scopus, with a total of 119 articles reviewed. The aim of the review is to (1) reveal the current state of the art, (2) identify the types of interventions, the game elements, and investigate the core drives of the interventions, (3) examine the empirical findings on the link between motivation and game elements, and (4) define a future research agenda. The results of the scoping review show that interventions that utilize gamification for children are increasingly gaining attention, mostly involve game elements that address the drive for development and accomplishment, the studies mostly target children between 7 to 13 years and the educational domain. The results further show a wide range of game elements in relation to the core drives, and a need for more diverse studies.",
    "title": "Investigating the Motivational Game Elements in Game-based Interventions in School Context: A Literature Review",
    "id": 189103,
    "sequence": 893,
    "queryCoordinates": {
      "visualization": [
        -18.898634622151608,
        -1.9600024026547802
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "Web3 social media refers to a new generation of platforms built on decentralized technologies, particularly blockchain. Although academia has investigated the newly emerging Web3 social media, it is not clear how users perceive the usability of such platforms and how these perceptions are influenced by the inherent characteristics of Web3. To address this gap, we utilize affordance theory to explore the unique usability of Web3 social media compared with Web2 social media. We conducted interviews with 32 participants who are experienced with Web3 social media and examined the affordances of Web3 social media from the perspectives of content creation, content consumption, and community interaction. We further discuss the correlation between the usability of Web3 social media and the underlying decentralized technology, and provide design implications for enhancing the usability of this new type of social interaction platform.",
    "title": "Using Affordance to Understand Usability of Web3 Social Media",
    "id": 189104,
    "sequence": 894,
    "queryCoordinates": {
      "visualization": [
        1.1758463372162407,
        10.936973319490871
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "Therapeutic virtual reality (VR) can be a tool, platform or experience imaginary in the healthcare setting. Emotions and affective interaction are integral to the care needs and experiences in digital healthcare, yet remain under-investigated in therapeutic VR. We reflect on four cases involving therapeutic VR to critically examine the function and value of affective interaction. Through a synthesis of the cases, we identify how affective interaction can enhance or diminish healthcare outcomes and even cause potential harm. We draw five recommendations for the design and evaluation of therapeutic VR to challenge assumptions about: (1) knowledge holders and knowledge co-production in design, (2) hyper-visiblity of medical gaze and invisibility of affective experiences, (3) diverse utilities of VR, (4) weaving assessment of affective benefits and harms into evaluation of therapeutic VR, and (5) implementation of therapeutic VR in collaboration with caregivers.",
    "title": "Affective Interactions in Therapeutic Virtual Reality: A Critical Perspective",
    "id": 189105,
    "sequence": 895,
    "queryCoordinates": {
      "visualization": [
        -4.289291617583276,
        -20.55728526385062
      ]
    }
  },
  {
    "session": "Education",
    "abstract": "Listening to audio content, such as podcasts and audiobooks, is one way for people to engage with knowledge. Listening affords people more mobility than reading by seeing, thereby broadening their learning opportunities. This study explores the potential applications of large language models (LLMs) to adapt text documents to audio content and addresses the lack of listening-friendly materials for niche content, such as research papers. LLMs can generate scripts of audio content in various styles tailored to specific needs, such as full-content duration or speech types (monologue or dialogue). To explore this potential, we developed PaperWave (https://paperwave.app), a prototype that transforms academic paper PDFs into conversational podcasts. Our two-month investigation, involving 11 participants (including the authors), employed an autobiographical design, a field study, and a design workshop. The findings highlight the importance of considering listener interaction with their environment when designing document-to-audio systems.",
    "title": "PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM",
    "id": 189106,
    "sequence": 896,
    "queryCoordinates": {
      "visualization": [
        -17.790507188419696,
        -2.7382209514184956
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "This study introduces \\textbf{InteractEval}, a framework that integrates the outcomes of Think-Aloud (TA) conducted by humans and LLMs to generate attributes for checklist-based text evaluation. By combining humans' flexibility and high-level reasoning with LLMs' consistency and extensive knowledge, InteractEval outperforms text evaluation baselines on a text summarization benchmark (SummEval) and an essay scoring benchmark (ELLIPSE). Furthermore, an in-depth analysis shows that it promotes divergent thinking in both humans and LLMs, leading to the generation of a wider range of relevant attributes and enhancement of text evaluation performance. A subsequent comparative analysis reveals that humans excel at identifying attributes related to internal quality (Coherence and Fluency), but LLMs perform better at those attributes related to external alignment (Consistency and Relevance). Consequently, leveraging both humans and LLMs together produces the best evaluation outcomes, highlighting the necessity of effectively combining humans and LLMs in an automated checklist-based text evaluation.",
    "title": "Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation",
    "id": 189107,
    "sequence": 897,
    "queryCoordinates": {
      "visualization": [
        17.995716487438365,
        -0.39266793062210015
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "Flow, a state of deep task engagement, is associated with optimal experience and well-being, making its detection a prolific HCI research focus. While physiological sensors show promise for flow detection, most studies are lab-based. Furthermore, brain sensing during natural work remains unexplored due to the intrusive nature of traditional EEG setups. This study addresses this gap by using wearable, around-the-ear EEG sensors to observe flow during natural knowledge work, measuring EEG throughout an entire day. In a semi-controlled field experiment, participants engaged in academic writing or programming, with their natural flow experiences compared to those from a classic lab paradigm. Our results show that natural work tasks elicit more intense flow than artificial tasks, albeit with smaller experience contrasts. EEG results show a well-known quadratic relationship between theta power and flow across tasks, and a novel quadratic relationship between beta asymmetry and flow during complex, real-world tasks.",
    "title": "Exploring Flow in Real-World Knowledge Work Using Discrete cEEGrid Sensors",
    "id": 189108,
    "sequence": 898,
    "queryCoordinates": {
      "visualization": [
        8.314915792601578,
        -3.4441508912858136
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Developing an awareness of internal sensations, or interoceptive awareness (IA), can benefit those with various mental health concerns, including disordered eating. Although IA interventions exist, there is limited research on embedding this skill into daily life through ecological momentary interventions (EMIs). Multidisciplinary research has focused on how and when to deliver EMIs based on users' contexts, but often oversimplifies or relies on proxies to represent their circumstances and environments. Here, we explore context through a user-centered lens, investigating how and when 21 young women are willing to practice IA. During a 2-week experience sampling study, they shared their activities and openness to IA throughout each day. Later, they sketched EMIs to scaffold their activities with IA and shared further qualitative insights across several one-on-one interviews. Our findings identify activities and internal and external qualities conducive to IA and offer broader implications for designing digital EMIs tailored to users' contexts.",
    "title": "Identifying Opportunities and Envisioning Ecological Momentary Interoceptive Awareness Interventions With Young Women",
    "id": 189109,
    "sequence": 899,
    "queryCoordinates": {
      "visualization": [
        18.094189494621475,
        -5.796577139375435
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "In dance performances, choreography, music and lighting are combined to convey meaning to the audience. However, this communication typically relies on visual and auditory stimuli alone. While haptic technologies have been leveraged to enhance the perception of dancers’ movements, less focus has been placed on exploring their potential in enhancing dancers’ somatic expressiveness. Through co-design activities with 5 professional contemporary dancers, we crafted an interdisciplinary combination of choreography and haptics. In total, 128 audience members watched one of three live performances while wearing custom-made haptic wristbands. From an open-ended questionnaire and interviews with audience members, we explore how the introduction of haptics deepens their embodied sensations and helps to create a sense of resonance with the dancers. Based on our findings, we discuss implications for future directions in how haptic technologies could drive innovation in dance performances from the point of view of both dancers’ creativity and audience experiences.",
    "title": "“It’s Like Being On Stage”: Conveying Dancers’ Expressiveness Through A Haptic-Installed Contemporary Dance Performance",
    "id": 189110,
    "sequence": 900,
    "queryCoordinates": {
      "visualization": [
        -12.783990009183134,
        16.66042014611594
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "Visual programming has the potential of providing novice programmers with a low-code experience to build customized processing pipelines. Existing systems typically require users to build pipelines from scratch, implying that novice users are expected to set up and link appropriate nodes from a blank workspace. In this paper, we introduce InstructPipe, an AI assistant for prototyping machine learning (ML) pipelines with text instructions. We contribute two large language model (LLM) modules and a code interpreter as part of our framework. The LLM modules generate pseudocode for a target pipeline, and the interpreter renders the pipeline in the node-graph editor for further human-AI collaboration. Both technical and user evaluation (N=16) shows that InstructPipe empowers users to streamline their ML pipeline workflow, reduce their learning curve, and leverage open-ended commands to spark innovative ideas.",
    "title": "InstructPipe: Generating Visual Blocks Pipelines with Human Instructions and LLMs",
    "id": 189111,
    "sequence": 901,
    "queryCoordinates": {
      "visualization": [
        -3.461170570774929,
        9.381913359224841
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "The death of a young person is particularly tragic, leaving a profound emotional impact on the bereaved. Moreover, their legacies often diverge from traditional ones, incorporating a range of digital artifacts. This design study investigates age-specific approaches to death-related technologies by envisioning digital legacy curation systems tailored for young adults (age 19–34). Using cultural probes, design workbooks, and prototype testing, we examine the values and preferences of young adults in preparing for an untimely death. Our findings highlight relationship-oriented legacies that focus on minimizing the emotional burden of the bereaved and the potential benefits of physical artifacts. Through this study, we: (1) underscore recognizing specific user groups in death-related technologies, (2) explore death as an existential and disorienting grounds within HCI, (3) extend post-userist concepts to consider the notion of ``use'' after death, and (4) identify the liminal space between physical and digital legacies as a meaningful realm to explore.",
    "title": "Digital Legacy Systems for Young Adults: Emphasizing Relationship-Oriented Perspectives and Physical Artifacts in Death Preparation",
    "id": 189112,
    "sequence": 902,
    "queryCoordinates": {
      "visualization": [
        13.799306509009241,
        9.928702829192503
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "How do individuals perceive AI systems as responsible entities in everyday collaborations between humans and AI? Drawing on psychological literature from attribution theory, praise-blame asymmetries and negativity bias, this study investigated the effects of perspective (actor vs observer) and outcome favorability (positive vs negative) on how participants (N=321) attributed responsibility for outcomes resulting from shared human-AI decision-making. Both Bayesian modelling and reflexive thematic analysis of results revealed that, overall, participants were more likely to attribute greater responsibility to the AI systems. When the outcome was positive, participants were more likely to ascribe shared responsibility to both Human and AI systems, rather than either separately. When the outcome was negative, participants were more likely to attribute responsibility to a single entity, but not consistently towards the human or the AI. These results build on the understanding of how individuals cast blame and praise for shared interactions involving AI systems.",
    "title": "Responsibility Attribution in Human Interactions with Everyday AI Systems",
    "id": 189113,
    "sequence": 903,
    "queryCoordinates": {
      "visualization": [
        1.8262842870261617,
        -2.3800600208737057
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "As autonomous AI agents become increasingly integrated into human teams, the level of trust humans place in these agents - both as a piece of technology and increasingly viewed as teammates - significantly impacts the success of human-AI teams (HATs). This work presents a literature review of the HAT research that investigates humans' trust in their AI teammates. In this review, we first identify the ways in which trust was conceptualized and operationalized, which underscores the pressing need for clear definitions and consistent measurements. Then, we categorize and quantify the factors found to influence trust in an AI teammate, highlighting that agent-related factors (such as transparency, reliability) have the strongest impacts on trust in HAT research. We also identify under-explored factors related to humans, teams, and environments, and gaps for future HAT research and design.",
    "title": "Trusting Autonomous Teammates in Human-AI Teams - A Literature Review",
    "id": 189114,
    "sequence": 904,
    "queryCoordinates": {
      "visualization": [
        14.38229602302289,
        -4.260230170558853
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "Occlusion, often caused by the user's body or fingers, can significantly reduce the efficiency and usability of touch interfaces. \r\nAs foot-based interactions in HMDs become more prevalent, self-occlusion becomes a more pronounced issue due to the involvement of the body and legs. \r\nThis work presents SeeThroughBody, a body-rendering approach designed to mitigate occlusion and enhance touch interactions between the foot and interactive floor in virtual environments.\r\nOur user study unveiled twofold results. First, changing VisualizationStyles and BodyPartsVisibility can improve objective performance (e.g., time, movement) by reducing occlusion. \r\nSecond, these modifications also affect the subjective user experience (e.g., embodiment, usability). Different VisualizationStyles and BodyPartsVisibility have varying impacts, presenting trade-offs between performance and experience.\r\nBased on these insights, we recommend Transparent-Foot and Outline-Foot for interactions focused on efficiency, and Transparent-All and Transparent-Thigh for enhancing overall user experience.\r\nFinally, we demonstrate the application of these recommendations in a map browsing scenario using foot touch.",
    "title": "SeeThroughBody: Mitigating Occlusion through Body Transparency to Enhance Touch Interaction between the Foot and Interactive Floor",
    "id": 189115,
    "sequence": 905,
    "queryCoordinates": {
      "visualization": [
        -10.880615565184318,
        -10.325318635406305
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "Problem reframing is a designerly activity wherein alternative perspectives are created to recast what a stated design problem is about. Generating alternative problem frames is challenging because it requires devising novel and useful perspectives that fit the given problem context. Large language models (LLMs) could assist this activity via their generative capability. However, it is not clear whether they can help designers produce high-quality frames. Therefore, we asked if there are benefits to working with LLMs. To this end, we compared three ways of using LLMs (N=280): 1) free-form, 2) direct generation, and 3) a structured approach informed by a theory of reframing. We found that using LLMs does not help improve the quality of problem frames. In fact, it increases the competence gap between experienced and inexperienced designers. Also, inexperienced ones perceived lower agency when working with LLMs. We conclude that there is no benefit to using LLMs in problem reframing and discuss possible factors for this lack of effect.",
    "title": "No Evidence for LLMs Being Useful in Problem Reframing",
    "id": 189116,
    "sequence": 906,
    "queryCoordinates": {
      "visualization": [
        8.99143399423672,
        0.392574486288024
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Equine-Assisted Interventions (EAIs) aim to improve participant health and well-being through the development of a therapeutic relationship with a trained horse. These interventions leverage the horse’s ability to provide emotional feedback, as it responds to negative non-verbal cues with reciprocal negativity, thereby encouraging participants to regulate their emotions and achieve attunement with the horse. Despite their benefits, EAIs face significant challenges, including logistical, financial, and resource constraints, which hinder their widespread adoption and accessibility. To address these issues, we conducted an autoethnographic study of the lead researcher’s engagement in an EAI to investigate the underlying mechanisms and explore potential technological alternatives. Our findings suggest that the reciprocal and responsive non-verbal communication, combined with the horse’s considerable physical presence, supports the potential of an embodied robotic system as a viable alternative. Such a system could offer a scalable and sustainable solution to the current limitations of EAIs.",
    "title": "\"You Can Fool Me, You Can't Fool Her!\": Autoethnographic Insights from Equine-Assisted Interventions to Inform Therapeutic Robot Design",
    "id": 189117,
    "sequence": 907,
    "queryCoordinates": {
      "visualization": [
        12.778965710858465,
        5.718219597103945
      ]
    }
  },
  {
    "session": "Decision-Making and Motivation",
    "abstract": "Understanding engagement with and motivations to contribute to online citizen science projects can improve user experience and aid in attracting and retaining users. This paper proposes that the fundamental grounding of self-determination theory, being the satisfaction of Basic Psychological Needs, is a fruitful lens through which to understand experiences and motivation to take part in online citizen science. Using an online survey, this paper explores how volunteers in online citizen science experience satisfaction and dissatisfaction of needs for autonomy, competence, and relatedness, and how this relates to both their behaviour and motivations to take part. Results suggest that participation in online citizen science on the Zooniverse relates primarily to the satisfaction than dissatisfaction of needs, suggesting that taking part is psychologically beneficial to volunteers. Autonomy is the most supported need and relatedness the least. Whilst results are positive, we observe that measures of need satisfaction must be contextually relevant, especially given the complex nature of autonomy in online citizen science, to aid in further understanding of these relationships. Potential factors related to participation in the Zooniverse that could be enhanced to increase volunteer satisfaction and retention are discussed.",
    "title": "Exploring the Relationship between Basic Psychological Needs and Motivation in Online Citizen Science",
    "id": 189118,
    "sequence": 908,
    "queryCoordinates": {
      "visualization": [
        -10.930365899054108,
        4.9524843576527395
      ]
    }
  },
  {
    "session": "Well-being and Well-dying",
    "abstract": "We explore the intersectional struggles of a non-Western HCI researcher engaging with LGBTQIA+ women's communities. Through self-reflection, the first author explores how her positionalities shaped engagements with the community, academic audience, and the research itself. While her community affiliation facilitated the early stage of research, it conflicted with her effort to balance the insider-outsider boundaries, creating dilemmas and distress. In parallel, she was discouraged by her attempts to bridge queer theory with HCI, the challenge of relying on articles published in Korean, and publication expectations to identify opportunities for ``uniqueness'' in addressing local experiences for global audiences. We triangulate the first author's ``stuckness'' by incorporating the experiences of the research team, connecting contexts and reflecting on the nature of researcher positionality. By articulating the structural challenges of this non-Western Queer HCI researcher, this paper adds specific considerations, analytic lenses, and implications to calls for greater acknowledgment of researcher reflexivity.",
    "title": "Stuck in Translation: Reflexive Practice in Queer HCI Research from Non-Western Perspectives",
    "id": 189119,
    "sequence": 909,
    "queryCoordinates": {
      "visualization": [
        21.716718717951643,
        3.519108995948925
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "Despite the prevalence of autism spectrum disorder (ASD) and other developmental disabilities (DD) worldwide, children with ASD and DD face tremendous difficulties receiving support due to physical, financial, and psychological barriers to onsite health and education clinics. As a result, researchers and practitioners have designed software solutions aimed at providing accessible support to meet users’ needs. However, we have limited knowledge of whether these solutions indeed work in real-world settings. To address this gap, we conducted a case study on a cognitive training program called Dubupang, designed by Dubu Inc. From in-depth interviews with multiple stakeholders and field observations of children with ASD and DD, we identify Dubu Inc.’s internal development processes, the critical design issues that emerged through a series of field trials (e.g., instructional design and feedback), and the key implications (e.g., importance of caregivers’ strategic human interventions) for design that better supports both children with ASD and DD and their caregivers.",
    "title": "Lessons from Real-World Settings: What Makes It Uniquely Difficult to Design Cognitive Training Programs for Children with Autism Spectrum Disorder and Other Developmental Disabilities",
    "id": 189120,
    "sequence": 910,
    "queryCoordinates": {
      "visualization": [
        2.7063521955384577,
        8.583452556734043
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "Advancing technologies enable machine learning applications that replicate the appearance, behavior, and thought patterns of users based on their personal data. Termed as AI self-clones, these digital doppelgangers present introspective opportunities and existential risks, as they might amplify self-awareness or echo problematic self-views. In our participatory design fiction study, we involved 20 diverse individuals to explore the values and risks they associate with creating AI self-clones. Our participants conceptualized AI self-clones by the roles these clones could assume, such as mirror, probe, companion, delegate, and representative. The perceived values and risks tend to correspond to these roles. For example, using self-clones as representatives could enhance relationship maintenance, yet it might also lead to diminished authenticity in personal connections; utilizing self-clones as probes to explore life scenarios could aid decision-making, but it might amplify regrets about unchosen paths. This research lays the groundwork for an ethical design of AI self-clone applications.",
    "title": "Mirror to Companion: Exploring Roles, Values, and Risks of AI Self-Clones through Story Completion",
    "id": 189121,
    "sequence": 911,
    "queryCoordinates": {
      "visualization": [
        17.83918928399116,
        6.539367376890132
      ]
    }
  },
  {
    "session": "XR for Diverse Needs",
    "abstract": "Dark environment challenges low-vision (LV) individuals to engage in running by following sighted guide—a Caller-style guided running—due to insufficient illumination, because it prevents them from using their residual vision to follow the guide and be aware about their environment. We design, develop, and evaluate RunSight, an augmented reality (AR)-based assistive tool to support LV individuals to run at night. RunSight combines see-through HMD and image processing to enhance one's visual awareness of the surrounding environment (e.g., potential hazard) and visualize the guide's position with AR-based visualization. To demonstrate RunSight's efficacy, we conducted a user study with 8 LV runners. The results showed that all participants could run at least 1km (mean = 3.44 km) using RunSight, while none could engage in Caller-style guided running without it. Our participants could run safely because they effectively synthesized RunSight-provided cues and information gained from runner-guide communication.",
    "title": "“I can run at night!\": Using Augmented Reality to Support Nighttime Guided Running for Low-vision Runners",
    "id": 189122,
    "sequence": 912,
    "queryCoordinates": {
      "visualization": [
        12.010433922646728,
        4.974884620746167
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "Teaching literature under interdisciplinary contexts (e.g., science, art) that connect reading materials has become popular in elementary schools. However, constructing such contexts is challenging as it requires teachers to explore substantial amounts of interdisciplinary content and link it to the reading materials. In this paper, we develop LitLinker via an iterative design process involving 13 teachers to facilitate the ideation of interdisciplinary contexts for teaching literature. Powered by a large language model (LLM), LitLinker can recommend interdisciplinary topics and contextualize them with the literary elements (e.g., paragraphs, viewpoints) in the reading materials. A within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker can improve the integration depth of different subjects and reduce workload in this ideation task. Expert interviews (N=9) also demonstrate LitLinker’s usefulness for supporting the ideation of interdisciplinary contexts for teaching literature. We conclude with concerns and design considerations for supporting interdisciplinary teaching with LLMs.",
    "title": "LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools",
    "id": 189123,
    "sequence": 913,
    "queryCoordinates": {
      "visualization": [
        -5.036922252557862,
        -17.280897378946715
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "While existing visualization libraries enable the reuse, extension, and combination of static visualizations, achieving the same for interactions remains nearly impossible.\r\nWe contribute an interaction model and its implementation to achieve this goal. Our model enables the creation of interactions that support direct manipulation, enforce software modularity by clearly separating visualizations from interactions, and ensure compatibility with existing visualization systems.\r\nInteraction management is achieved through an instrument that receives events from the view, dispatches these events to graphical layers containing objects, and then triggers actions.\r\nWe present a JavaScript prototype implementation of our model called Libra.js,  enabling the specification of interactions for visualizations created by different libraries. \r\nWe demonstrate the effectiveness of Libra by describing and generating a wide range of existing interaction techniques. We evaluate Libra.js through diverse examples, a metric-based notation comparison, and a performance benchmark analysis.",
    "title": "Libra: An Interaction Model for Data Visualization",
    "id": 189124,
    "sequence": 914,
    "queryCoordinates": {
      "visualization": [
        -14.382296023022898,
        -4.2602301705588355
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "In the Wizard-of-Oz study paradigm, human \"wizards\" perform not-yet-implemented system behavior, simulating, among others, how autonomous robots could interact in public to see how unwitting bystanders respond. This paper analyzes a 60-minute video recording of two wizards in a public plaza who are operating two trash-collecting robots within their line of sight. We take an ethnomethodology and conversation analysis perspective to scrutinize interactions between the wizards and the people in the plaza, focusing on critical instances where one robot gets stuck and requires collaborative intervention by the wizards. Our analysis unpacks how the wizards deal with emergent problems by pushing one robot into the other, how they manage front and backstage interactions, and how they monitor the location of each other's robots. We discuss how scrutinizing the work of wizards can inform explorative Wizard-of-Oz paradigms, the design of multi-agent robot systems, and the operation of urban robots from a distance.",
    "title": "The People Behind the Robots: How Wizards Wrangle Robots in Public Deployments",
    "id": 189125,
    "sequence": 915,
    "queryCoordinates": {
      "visualization": [
        -7.5323525214641665,
        -2.695118827137761
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "Conversational artificial intelligence (CAI), which replicates human-to-human interaction as human-to-machine, is increasingly developed to address insufficient access to healthcare. In this paper, we use design fiction methods to speculate on ethical consequences of CAI that offers emotional support to complement or replace mental healthcare. Through a near-future news article about a fictional, failed CAI, we explore safety and privacy concerns associated with mismatches between what an emotional support CAI is advertised to do, what it technically can do, and how it is likely to be used. We pose the following questions to researchers, regulators, and developers: How might we jointly and effectively address the anticipatable safety and privacy risks that emotional support CAI pose, including formalizing ethical speculation processes? What streamlined and practically feasible measures can efficiently account for the most dangerous harms? How might differing stakeholder expectations about the CAI be bridged? Finally, in what scenarios is the decision not to design a CAI tool the most ethical or safest option? Content advisement: Contains discussion of disordered eating behaviors and intimate partner violence.",
    "title": "Fictional Failures and Real-World Lessons: Ethical Speculation Through Design Fiction on Emotional Support Conversational AI",
    "id": 189126,
    "sequence": 916,
    "queryCoordinates": {
      "visualization": [
        -7.058336768619223,
        10.916953881956172
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "Tasks in augmented reality (AR), such as 3D interaction and instructional comprehension, are often designed for users with uniform sensory abilities. Such an approach, however, can overlook the more nuanced needs of Deaf and Hard of Hearing (DHH) users who might have reduced auditory perception. To better understand these challenges, our study utilized the single-player AR game Angry Birds AR as a probe to explore how 11 DHH participants and 15 hearing participants experienced AR interactions. Our findings highlight that DHH users prefer interaction based on context, effective haptic cues, audio cue substitutes, and clear instructional design. We, therefore, propose the following design recommendations to enhance the accessibility of AR for DHH users. This includes customizable UI options, modular feedback systems, and virtual avatars for sign language instructions.",
    "title": "Exploring Deaf And Hard of Hearing Peoples’ Perspectives On Tasks In Augmented Reality: Interacting With 3D Objects And Instructional Comprehension",
    "id": 189127,
    "sequence": 917,
    "queryCoordinates": {
      "visualization": [
        0.39257448628802405,
        8.99143399423672
      ]
    }
  },
  {
    "session": "LLM for Health",
    "abstract": "Hospital admission interviews are critical for patient care but strain nurses' capacity due to time constraints and staffing shortages. While LLM-powered conversational agents (CAs) offer automation potential, their rigid sequencing and lack of humanized communication skills risk misunderstandings and incomplete data capture. Through participatory design with clinicians and volunteers, we identified essential communication strategies and developed a novel CA that implements these strategies through: (1) dynamic topic management using graph-based conversation flows, and (2) context-aware scaffolding with few-shot prompt tuning. Technical evaluation on an admission interview dataset showed our system achieving performance comparable to or surpassing human-written ground truth, while outperforming prompt-engineered baselines. A between-subject study (N=44) demonstrated significantly improved user experience and data collection accuracy compared to existing solutions. We contribute a framework for humanizing medical CAs by translating clinician expertise into algorithmic strategies, alongside empirical insights for balancing efficiency and empathy in healthcare interactions, and considerations for generalizability.",
    "title": "Scaffolded Turns and Logical Conversations: Designing Humanized LLM-Powered Conversational Agents for Hospital Admission Interviews",
    "id": 189128,
    "sequence": 918,
    "queryCoordinates": {
      "visualization": [
        4.2919870843548225,
        -21.57727616887107
      ]
    }
  },
  {
    "session": "Pointing and Selection",
    "abstract": "Action pointing involves choosing and executing an action at a specific place in the workspace (e.g., choosing a tool and clicking to start drawing, or selecting an object and copying with a shortcut). The elements of action pointing (choosing an action, specifying a position, and triggering the action) can be carried out in many ways - and our analysis of current techniques identified limitations on performance, particularly for repeated sequences of interactions. To empirically analyse interaction alternatives for action pointing, we developed and evaluated two techniques: ModeKeys removes modifier keys from keyboard shortcuts used to choose actions; AimKeys goes further by using the shortcut (not the mouse) to trigger the action. Three studies over three tasks showed that these reconfigurations were highly effective - in all studies, either AimKeys or ModeKeys were faster, easier, and preferred overall. Our studies show that small variations in the configuration of action pointing can have a large impact, offering opportunities to improve performance with direct-manipulation systems.",
    "title": "Understanding and Improving the Performance of Action Pointing",
    "id": 189129,
    "sequence": 919,
    "queryCoordinates": {
      "visualization": [
        0.3920685613182431,
        3.9807389066887873
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "Infrastructure is a common topic in rural areas around the world. While most existing research attention has been paid to the difficulties with Internet access and the fragile infrastructure of rural areas, our study contributes an empirical understanding of digital platform-as-infrastructure - short video-sharing platforms (SVSPs) in rural China.\r\nThrough semi-structured interviews with 26 rural users including content creators and regular users, we elaborate on their practices, experiences, and perceptions of SVSPs. \r\nWe foreground that SVSPs have reshaped rural people's daily routines and enhanced their self-worth and identity, which in turn led to deeper and more sustained engagement with these platforms. We then situate our findings within the broader context of platform-as-infrastructure, discussing how rural people's adoption and usage intertwine with the infrastructuralization process of SVSPs. We end by discussing how to make future platform-as-infrastructure more engaged and beneficial to rural populations, meeting their practical usage and well-being requirements. ",
    "title": "'Douyin is My Nourishment of the Mind': Exploring the Infrastructuralization Process of Short Video Sharing Platforms From Rural People’s Perspective",
    "id": 189130,
    "sequence": 920,
    "queryCoordinates": {
      "visualization": [
        0.39261567222878546,
        10.992991082226908
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "In online education, innovative tools are crucial for enhancing learning outcomes. SAM (Study with AI Mentor) is an advanced platform that integrates educational videos with a context-aware chat interface powered by large language models. SAM encourages students to ask questions and explore unclear concepts in real time, offering personalized, context-specific assistance, including explanations of formulas, slides, and images. We evaluated SAM in two studies: one with 25 university students and another with 80 crowdsourced participants, using pre- and post-knowledge tests to compare a group using SAM and a control group. The results demonstrated that SAM users achieved greater knowledge gains specifically for younger learners and individuals in flexible working environments, such as students, supported by a 97.6% accuracy rate in the chatbot's responses. Participants also provided positive feedback on SAM’s usability and effectiveness. SAM’s proactive approach to learning not only enhances learning outcomes but also empowers students to take full ownership of their educational experience, representing a promising future direction for online learning tools.",
    "title": "From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant",
    "id": 189131,
    "sequence": 921,
    "queryCoordinates": {
      "visualization": [
        -15.611234080616457,
        -3.5056198425099168
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "As passengers spend more time in vehicles, the demand for non-driving related tasks (NDRTs) increases. In-car Augmented Reality (AR) has the potential to enhance passenger experiences by enabling interaction with the environment through NDRTs using world-fixed Points of Interest (POIs). However, the effectiveness of existing interaction techniques and visualization methods for in-car AR remains unclear. Based on a survey (N=110) and a pre-study (N=10), we developed an interactive in-car AR system using a video see-through head-mounted display to engage with POIs via eye-gaze and pinch. Users could explore passed and upcoming POIs using three visualization techniques: List, Timeline, and Minimap. We evaluated the system's feasibility in a field study (N=21). Our findings indicate general acceptance of the system, with the List visualization being the preferred method for exploring POIs. Additionally, the study highlights limitations of current AR hardware, particularly the impact of vehicle movement on 3D interaction.",
    "title": "Augmented Journeys: Interactive Points of Interest for In-Car Augmented Reality",
    "id": 189132,
    "sequence": 922,
    "queryCoordinates": {
      "visualization": [
        3.501680457838582,
        14.585548805965148
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "As conversational AI systems increasingly engage with people socially and emotionally, they bring notable risks and harms, particularly in human-AI relationships. However, these harms remain underexplored due to the private and sensitive nature of such interactions. This study investigates the harmful behaviors and roles of AI companions through an analysis of 35,390 conversation excerpts between 10,149 users and the AI companion Replika. We develop a taxonomy of AI companion harms encompassing six categories of harmful algorithmic behaviors: relational transgression, harassment, verbal abuse, self-harm, mis/disinformation, and privacy violations. These harmful behaviors stem from four distinct roles that AI plays: perpetrator, instigator, facilitator, and enabler. Our findings highlight relational harm as a critical yet understudied type of AI harm and emphasize the importance of examining AI's roles in harmful interactions to address root causes. We provide actionable insights for designing ethical and responsible AI companions that prioritize user safety and well-being.",
    "title": "The Dark Side of AI Companionship: A Taxonomy of Harmful Algorithmic Behaviors in Human-AI Relationships",
    "id": 189133,
    "sequence": 923,
    "queryCoordinates": {
      "visualization": [
        1.1758463372162355,
        -10.936973319490871
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "With advancements in interactive technologies, research in human-food interaction (HFI) has begun to employ interactive sound to enrich the dining experience. However, chefs' creative use of this sonic interactivity as a new \"ingredient\" in their culinary practices remains underexplored. In response, we conducted an empirical study with six pairs of chefs and diners utilizing SoniCream, an ice cream cone that plays digital sounds while consuming. Through exploration, creation, collaboration, and reflection, we identified four themes concerning culinary creativity, dining experience, interactive sonic gastronomy deployment, and chef-diner interplay. Building on the discussions at the intersection of these themes, we derived four design implications for creating interactive systems that could support chefs' culinary creativity, thereby enriching dining experiences. Ultimately, our work aims to help interaction designers fully incorporate chefs' perspectives into HFI research.",
    "title": "Towards Understanding Interactive Sonic Gastronomy with Chefs and Diners",
    "id": 189134,
    "sequence": 924,
    "queryCoordinates": {
      "visualization": [
        -8.583452556734043,
        -2.7063521955384577
      ]
    }
  },
  {
    "session": "Classroom Technology",
    "abstract": "Students often take digital notes during live lectures, but current methods can be slow when capturing information from lecture slides or the instructor's speech, and require them to focus on their devices, leading to distractions and missing important details. This paper explores supporting live lecture note-taking with mixed reality (MR) to quickly capture lecture information and take notes while staying engaged with the lecture. A survey and interviews with university students revealed common note-taking behaviors and challenges to inform the design. We present MaRginalia to provide digital note-taking with a stylus tablet and MR headset. Students can take notes with an MR representation of the tablet, lecture slides, and audio transcript without looking down at their device. When preferred, students can also perform detailed interactions by looking at the physical tablet. We demonstrate the feasibility and usefulness of MaRginalia and MR-based note-taking in a user study with 12 students.",
    "title": "MaRginalia: Enabling In-person Lecture Capturing and Note-taking Through Mixed Reality",
    "id": 189135,
    "sequence": 925,
    "queryCoordinates": {
      "visualization": [
        -12.288897595450324,
        -4.240636259871297
      ]
    }
  },
  {
    "session": "Inclusive and Participatory",
    "abstract": "PDF documents are usually not born-accessible, and so document authors need to put in additional work (remediation) to make them accessible for people with disabilities. Unfortunately, this step is often overlooked and hard to execute, resulting in a large number of inaccessible PDF documents on the internet. Previously, there have been research efforts to investigate potential solutions for remediating PDF documents for accessibility. However, most of the existing research focuses on accessibility of long or scientific PDF documents meant for passive reading. PDF documents come in different types, and this research project focuses on a distinct type of PDF document—forms—where the user is required to interact with the PDF document and enter data. Through our research work we identified that the PDF form remediation process is non-intuitive, repetitive, and overwhelming due to the high-information density of PDF forms, and existing research and tools do not yet address the challenges. Our research work culminated in the creation of a tool – FormA11y – that addresses these challenges by making the repetitive and painstaking process of form remediation easier. To evaluate the effectiveness and efficiency of FormA11y against the industry standard tool – Adobe Acrobat – for PDF form remediation, we performed a within-subject user study with 20 participants.  With FormA11y, users remediated forms 2.8 times faster while creating more accurately accessible PDF forms.",
    "title": "FormA11y – Research and Development of a Tool for Remediating PDF Forms for Accessibility",
    "id": 189136,
    "sequence": 926,
    "queryCoordinates": {
      "visualization": [
        6.457666452124422,
        -13.53877926524791
      ]
    }
  },
  {
    "session": "Online Media, Robots, Agents",
    "abstract": "Student simulation supports educators to improve teaching by interacting with virtual students. However, most existing approaches ignore the modulation effects of course materials because of two challenges: the lack of datasets with granularly annotated course materials, and the limitation of existing simulation models in processing extremely long textual data. To solve the challenges, we first run a 6-week education workshop from N = 60 students to collect fine-grained data using a custom built online education system, which logs students' learning behaviors as they interact with lecture materials over time. Second, we propose a transferable iterative reflection (TIR) module that augments both prompting-based and finetuning-based large language models (LLMs) for simulating learning behaviors. Our comprehensive experiments show that TIR enables the LLMs to perform more accurate student simulation than classical deep learning models, even with limited demonstration data. Our TIR approach better captures the granular dynamism of learning performance and inter-student correlations in classrooms, paving the way towards a ``digital twin'' for online education.",
    "title": "Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation",
    "id": 189137,
    "sequence": 927,
    "queryCoordinates": {
      "visualization": [
        11.977421706431148,
        14.749283686549392
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Commercial content moderation APIs are marketed as scalable solutions to combat online hate speech. However, the reliance on these APIs risks both silencing legitimate speech, called over-moderation, and failing to protect online platforms from harmful speech, known as under-moderation. To assess such risks, this paper introduces a framework for auditing black-box NLP systems. Using the framework, we systematically evaluate five widely used commercial content moderation APIs. Analyzing five million queries based on four datasets, we find that APIs frequently rely on group identity terms, such as ``black'', to predict hate speech. While OpenAI's and Amazon's services perform slightly better, all providers under-moderate implicit hate speech, which uses codified messages, especially against LGBTQIA+ individuals. Simultaneously, they over-moderate counter-speech, reclaimed slurs and content related to Black, LGBTQIA+, Jewish, and Muslim people. We recommend that API providers offer better guidance on API implementation and threshold setting and more transparency on their APIs' limitations. \r\n\r\n\\noindent \\textit{\\textbf{Warning}: This paper contains offensive and hateful terms and concepts. We have chosen to reproduce these terms for reasons of transparency.}",
    "title": "Lost in Moderation: How Commercial Content Moderation APIs Over- and Under-Moderate Group-Targeted Hate Speech and Linguistic Variations",
    "id": 189138,
    "sequence": 928,
    "queryCoordinates": {
      "visualization": [
        4.664426045664028,
        5.219495154182159
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "The rapid evolution of Extended Reality (XR) technologies---encompassing Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR)---has paved the way for richer and more immersive user experiences. Concurrently, the emergence of Large Language Models (LLMs), such as GPT-4, has unlocked new opportunities to enhance interactions within XR environments. This paper presents the first comprehensive review addressing the underexplored synergy between XR and LLMs, examining how the integration of these technologies can augment various aspects of human awareness: spatial, situational, social, and self-awareness. By systematically analyzing 135 papers, we synthesize and categorize the research field into seven dimensions: 1) diverse application domains, 2) types of human awareness expanded, 3) interaction paradigms between users and systems, 4) effects of LLMs in XR, 5) practices for effectively integrating LLMs into XR environments, and 6) evaluation metrics. We also discuss remaining challenges and propose future research focusing on ethical awareness.",
    "title": "LLM Integration in Extended Reality: A Comprehensive Review of Current Trends, Challenges, and Future Perspectives",
    "id": 189139,
    "sequence": 929,
    "queryCoordinates": {
      "visualization": [
        10.113147467559692,
        17.254687719555836
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "We examine the user experience of distal haptics for touchscreen input through confirmatory vibrations of on-screen touches at various on-body locations. To this end, we introduce the Distal Haptics Continuum, a conceptual framework of haptic feedback delivery across the body, organized along the dimensions of Body Laterality and Proximity to the touch point. Our results, from three experiments involving 45 participants and 16 locations across the hand, arm, and whole body, reveal a strong preference for distal haptics over no haptics at all, despite the spatial decoupling from the touch point, with the index finger yielding the highest user experience. We also identify additional on-body locations, the adjacent fingers, wrist, and abdomen, that unlock distinctive design opportunities. Building on our insights, demonstrating haptics effectiveness even when distant from the touch point, we outline implications for integrating various on-body locations, well beyond the index finger, into the user experience of touchscreen input.",
    "title": "Distal-Haptic Touchscreens: Understanding the User Experience of Vibrotactile Feedback Decoupled from the Touch Point",
    "id": 189140,
    "sequence": 930,
    "queryCoordinates": {
      "visualization": [
        1.9509032201612833,
        9.807852804032304
      ]
    }
  },
  {
    "session": "HCI Methods",
    "abstract": "Qualitative researchers use tools to collect, sort, and analyze their data. Should qualitative researchers use large language models (LLMs) as part of their practice? LLMs could augment qualitative research, but it is unclear if their use is appropriate, ethical, or aligned with qualitative researchers’ goals and values. We interviewed twenty qualitative researchers to investigate these tensions. Many participants see LLMs as promising interlocutors with attractive use cases across the stages of research, but wrestle with their performance and appropriateness. Participants surface concerns regarding the use of LLMs while protecting participant interests, and call attention to an urgent lack of norms and tooling to guide the ethical use of LLMs in research. We document the rapid and broad adoption of LLMs across surfaces, which can interfere with intentional use vital to qualitative research. We use the tensions surfaced by our participants to outline recommendations for researchers considering using LLMs in qualitative research and design principles for LLM-assisted qualitative research tools.",
    "title": "Large Language Models in Qualitative Research: Uses, Tensions, and Intentions",
    "id": 189141,
    "sequence": 931,
    "queryCoordinates": {
      "visualization": [
        4.263200821770462,
        -2.6124928235797436
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "LivingLoom is a design inquiry that proposes a post-anthropocentric approach to fabrication by integrating living plants directly into textiles. Industrial textile fabrication views plants as passive resources. They are grown, harvested, and spun into yarns for textile production, mainly to serve human needs. While efficient, this approach overlooks the intrinsic value of these organisms as living beings. LivingLoom fabrication approach wet-spins biodegradable yarns with seeds that can be further integrated into textiles that can sprout and grow. We present a design space for incorporating microgreen seeds into textiles with a 10-day growth cycle, leveraging care-based fabrication and interaction. We conducted a three-day user study to understand how people wear and care for plant-integrated textiles, revealing new possibilities for living textiles and care-based interactions. LivingLoom examines the intimacy between humans and plants in textile forms, shedding light on the design potential for the care-based fabrication of (e-)textiles.",
    "title": "LivingLoom: Investigating Human-Plant Symbiosis through Integrating Living Plants into (E-)Textiles",
    "id": 189142,
    "sequence": 932,
    "queryCoordinates": {
      "visualization": [
        5.007102888506551,
        -14.139622366382682
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Globally, small and medium-sized businesses (SMBs) have had to adapt to rapid digital changes, a shift accelerated by the COVID-19 pandemic. In Kenya, this transition has involved a significant move towards digital management tools. While many had already experienced marked digitalization over the last few decades, they completed this work differently from their European and North American counterparts. This study explores how Kenyan SMBs continue to navigate these changes and considers the potential of Generative AI in this context. Applying the concept of socio-tecture—which emphasizes social networks, relational business practices, and employees as knowledge producers—we analyze how these elements influence SMB operations in Nairobi. We highlight how socio-tecture affects business performance and growth, and discuss how an Afro-centric strengths-based approach might offer unique opportunities and challenges with the influx of new technologies like Generative AI.",
    "title": "Social by Nature: How Socio-tecture Shapes the Work of SMBs and Considerations for Reimagining Collaborative Human-AI Systems",
    "id": 189143,
    "sequence": 933,
    "queryCoordinates": {
      "visualization": [
        -3.490914277166901,
        -12.52252041361771
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "Recent attention to anthropomorphism---the attribution of human-like qualities to non-human objects or entities---of language technologies like LLMs has sparked renewed discussions about potential negative impacts of anthropomorphism. To productively discuss the impacts of this anthropomorphism and in what contexts it is appropriate, we need a shared vocabulary for the vast variety of ways that language can be anthropomorphic. In this work, we draw on existing literature and analyze empirical cases of user interactions with language technologies to develop a taxonomy of textual expressions that can contribute to anthropomorphism. We highlight challenges and tensions involved in understanding linguistic anthropomorphism, such as how all language is fundamentally human and how efforts to characterize and shift perceptions of humanness in machines can also dehumanize certain humans. We discuss ways that our taxonomy supports more precise and effective discussions of and decisions about anthropomorphism of language technologies.\r\n",
    "title": "A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies",
    "id": 189144,
    "sequence": 934,
    "queryCoordinates": {
      "visualization": [
        -3.517630689399463,
        20.703291388882953
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "Health self-examination, such as checking for changes to skin moles, is key to identifying potential negative changes to one's body. A major barrier to initiating a self-examination is a perceived lack of confidence or knowledge. In this study, we use a 2 x 2 between-subjects design to evaluate the effect of an AI conversational agent (CA) on participant self-efficacy and trust. We manipulated both participants' perceived skill in self-examination (based on prior perceived Success vs. Failure) and the CA's verbal persuasions (Encouraging vs. Neutral), with participants asked to complete a series of skin self-assessment tasks. Our findings show that participants' self-efficacy increased when exposed to encouraging CA persuasion. Additionally, we observed that an encouraging CA significantly increased participants’ trust scores in perceived benevolence compared to a neutral-sounding CA. Our results inform the design of CAs to support users' independent self-examination.",
    "title": "Enhancing Self-Efficacy in Health Self-Examination through Conversational Agent's Encouragement",
    "id": 189145,
    "sequence": 935,
    "queryCoordinates": {
      "visualization": [
        6.5526035912338685,
        -18.89612092933756
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "This paper describes a qualitative study that interrogates the types of technology-facilitated coercive control faced by survivors of human trafficking and uncovers potential interventions to aid survivors’ recovery. Via semi-structured interviews with 21 participants, including trafficking survivors and professional advocates, we show how traffickers use technology as a lever for control, engaging in surveillance, blackmail, impersonation, and harassment as they compel survivors to stay in the trafficking situation. In recovery, digital footprints keep survivors tethered to their trafficking experience, impacting their digital autonomy, economic mobility, and feelings of safety. Nevertheless, technology can also be a valuable tool for survivors’ recovery, connecting them to essential resources and support systems. We discuss the need for interventions and services that account for the specificity of the trafficking context to help survivors attain digital safety and autonomy, including the potential to adapt existing tech safety services designed for other contexts to human trafficking.",
    "title": "Digital Technologies and Human Trafficking: Combating Coercive Control and Navigating Digital Autonomy",
    "id": 189146,
    "sequence": 936,
    "queryCoordinates": {
      "visualization": [
        -14.966453021445819,
        -10.000264194352836
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "Navigation is a crucial part of the VR game experience. However, discrete and continuous optic flow from locomotion techniques (DL and CL) and wayfinding assistance in VR games may impact players' navigation differently. Limited research has explored how DL and CL's influence on navigation changes across different wayfinding assistance conditions. This study employed a 2×3 factorial between-subjects experiment with 78 participants to investigate their joint effects. The study explores explanations for observed differences among conditions from the mixed-method analysis of quantitative data (game performance, spatial learning performance, pressure level, usability, and sickness) and thematic analysis of post-hoc interviews. Therefore, the study identifies three key factors—exploration strategy, attention, and spatial knowledge as explanations. Designers can leverage these insights to improve navigation support in VR games, with broader potential applications in fields such as healthcare and training.",
    "title": "Exploring Joint Effects of Locomotion Continuity and Wayfinding Assistance in Non-Embodied VR Game Navigation",
    "id": 189147,
    "sequence": 937,
    "queryCoordinates": {
      "visualization": [
        -9.212931062685525,
        13.08135701042534
      ]
    }
  },
  {
    "session": "Social Media and Society",
    "abstract": "Smartphone users often regret aspects of their phone use, especially social media use. However, pinpointing specific ways in which the design of an interface contributes to regrettable use can be challenging due to the complexity of social media app features and\r\nuser intentions. We conducted a one-week study with 17 Android users, using a novel method where we passively collected screenshots every five seconds, which we analyzed via a multimodal large language model to understand participants’ usage activity at a fine-grained level. Triangulating this data with data from experience sampling, surveys, and interviews, we found that regret varies based on user intention, with non-intentional and social media use being especially regrettable. Regret also varies by social media activity; participants were most likely to regret viewing algorithmically recommended content and comments. Additionally, participants frequently deviated to browsing social media when their intention was direct communication, which slightly increased their regret. Our findings provide guidance to designers and policy-makers seeking to improve users’ experience and autonomy.",
    "title": "What Social Media Use Do People Regret? An Analysis of 34K Smartphone Screenshots with Multimodal LLM",
    "id": 189148,
    "sequence": 938,
    "queryCoordinates": {
      "visualization": [
        -1.1480502970952684,
        2.7716385975338604
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "Recommender systems treat users inherently differently. Sometimes, however, personalization turns into discrimination. Gender bias occurs when a system treats users differently based on gender. While most research discusses measures and countermeasures for gender bias, one recent study explored whether users enjoy gender de-biased recommendations. However, its methodology has significant shortcomings; It fails to validate its de-biasing method appropriately and compares biased and unbiased models that differ in key properties. We reproduce the study in a 2x2 between-subjects design with n=800 participants. Moreover, we examine the authors' hypothesis that educating users on gender bias improves their attitude towards de-biasing. We find that the genders perceive de-biasing differently. The female users —the majority group — rate biased recommendations significantly higher while the male users —the minority group — indicate no preference. Educating users on gender bias increased acceptance non-significantly. We consider our contribution vital towards understanding how gender de-biasing affects different user groups.",
    "title": "The Effect of Gender De-biased Recommendations – A User Study on Gender-specific Preferences",
    "id": 189149,
    "sequence": 939,
    "queryCoordinates": {
      "visualization": [
        6.7880074553294145,
        -7.343225094356858
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "Social care systems are increasingly adopting personalisation schemes that empower individuals with disabilities and their families to directly purchase services,from assistive technologies to daily living support. Central to this shift are institutions like the National Disability Insurance Scheme, where annual negotiations shape care delivery and social benefits. Drawing on interviews with parents of children with intellectual disabilities, individuals with intellectual disabilities, service managers -- alongside the use of a technology probe -- this paper examines the communication dynamics within these planning processes, identifying critical design opportunities. We explore the issues of communication control, obscured agency, and tokenistic engagement that arise in bureaucratic support planning. As a contribution, we highlight the barriers and facilitators reshaping these interactions, offering key implications for future design interventions.",
    "title": "Beyond the Buckets of Support: Designing for Agency and Interaction in Personalised Disability Systems",
    "id": 189150,
    "sequence": 940,
    "queryCoordinates": {
      "visualization": [
        -9.836477968456824,
        4.9237893106898385
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "Technology profoundly mediates how people feel, think and engage with nature. Here, video games are projected to become one of the most important mediums to facilitate digital human-nature interaction. In this paper, we explore how 16 players make sense of nature-in-games. Drawing from their own lived experiences, we 1) interviewed them, and 2) invited them to show us games that exemplify their conceptualisation of nature-in-games. We thematically analyse these \"show-and-tell\" conversations to construct three inductive themes: We arrive at an understanding that nature-in-games experiences are pluralistic, contested happenings. Participants positioned digital nature 1) as a relational other to respect, 2) as a space to reflect on humankind's current practices towards nature and 3) as a tool to escape from the lack of nature in their everyday lives. Based on our insights, we sketch out design inspirations for people wishing to augment, challenge and expand nature-in-games.",
    "title": "Human-Nature Relationships through Video Games: An Exploration of Players’ Sense-Making",
    "id": 189151,
    "sequence": 941,
    "queryCoordinates": {
      "visualization": [
        3.46117057077493,
        9.381913359224841
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "Index-to-palm interaction plays a crucial role in Mixed Reality(MR) interactions. However, achieving a satisfactory inter-hand interaction experience is challenging with existing vision-based hand tracking technologies, especially in scenarios where only a single camera is available. Therefore, we introduce Palmpad, a novel sensing method utilizing a single RGB camera to detect the touch of an index finger on the opposite palm. Our exploration reveals that the incorporation of optical flow techniques to extract motion information between consecutive frames for the index finger and palm leads to a significant improvement in touch status determination. By doing so, our CNN model achieves 97.0% recognition accuracy and a 96.1% F1 score. In usability evaluation, we compare Palmpad with Quest's inherent hand gesture algorithms. Palmpad not only delivers superior accuracy 95.3% but also reduces operational demands and significantly improves users’ willingness and confidence. Palmpad aims to enhance accurate touch detection for lightweight MR devices.",
    "title": "Palmpad: Enabling Real-Time Index-to-Palm Touch Interaction with a Single RGB Camera",
    "id": 189152,
    "sequence": 942,
    "queryCoordinates": {
      "visualization": [
        4.263200821770462,
        2.612492823579744
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "Password checkup services (PCS) identify compromised, reused, or weak passwords, helping users secure at-risk accounts. However, adoption rates are low. We investigated factors influencing PCS use and password change challenges via an online survey (n=238). Key adoption factors were \"perceived usefulness,\" \"ease of use,\" and \"self efficacy.\" We also identified barriers to changing compromised passwords, including alert fatigue, low perceived urgency, and reliance on other security measures. We then designed interfaces mitigating these issues through clearer messaging and automation (e.g., simultaneous password changes and direct links to change pages). A user study (N=50) showed our designs significantly improved password change success rates, reaching 40% and 74% in runtime alert and PCS checkup reporting scenarios, respectively (compared to 16% and 60% with a baseline).",
    "title": "Understanding and Improving User Adoption and Security Awareness in Password Checkup Services",
    "id": 189153,
    "sequence": 943,
    "queryCoordinates": {
      "visualization": [
        8.613109359986625,
        14.656546221839262
      ]
    }
  },
  {
    "session": "Using AI or Not",
    "abstract": "The rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user's task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.",
    "title": "The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers",
    "id": 189154,
    "sequence": 944,
    "queryCoordinates": {
      "visualization": [
        11.90030010436853,
        9.131421435130807
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "Continuous, everyday ECG monitoring is essential for detecting transient heart conditions and enabling early intervention in cardiovascular diseases. However, current technologies, such as ECG Holter monitors and smartwatches, face challenges in balancing continuous monitoring with long-term wearability due to trade-offs in electrode placement. To address this, we present a novel ECG necklace that leverages its natural placement on the chest to provide continuous, clinically valuable ECG monitoring. Our design positions two electrodes on the left and right sides of the chest, approximating standard Lead I placement for accurate cardiac diagnostics. The necklace features an innovative skin moisture-enhanced electrode design for sustained comfort and integrates a compact 22-mm processing unit as the pendant, offering a 4-day battery life. In our studies, the ECG necklace demonstrated performance comparable to FDA-approved Holter monitors, with key features falling within a timing error range of 3.2–15.7 ms—well within acceptable limits. In our in-the-wild study, participants rated the necklace as highly comfortable and preferred it over traditional ECG monitors. As a widely accepted everyday accessory, the ECG necklace has the potential to seamlessly combine advanced functionality with daily wearability.\r\n",
    "title": "ECG Necklace: Low-power Wireless Necklace for Continuous ECG monitoring",
    "id": 189155,
    "sequence": 945,
    "queryCoordinates": {
      "visualization": [
        7.913412079718248,
        1.173843795642894
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Independent algorithm audits hold the promise of bringing accountability to automated decision-making. However, third-party audits are often hindered by access restrictions, forcing auditors to rely on limited, low-quality data. To study how these limitations impact research integrity, we conduct audit simulations on two realistic case studies for recidivism and healthcare coverage prediction. We examine the accuracy of estimating group parity metrics across three levels of access: (a) aggregated statistics, (b) individual-level data with model outputs, and (c) individual-level data without model outputs. Despite selecting one of the simplest tasks for algorithmic auditing, we find that data minimization and anonymization practices can strongly increase error rates on individual-level data, leading to unreliable assessments. We discuss implications for independent auditors, as well as potential avenues for HCI researchers and regulators to improve data access and enable both reliable and holistic evaluations.",
    "title": "Access Denied: Meaningful Data Access for Quantitative Algorithm Audits",
    "id": 189156,
    "sequence": 946,
    "queryCoordinates": {
      "visualization": [
        -20.96696311537415,
        1.1774793919810207
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "Music videos have traditionally been the domain of experts, but with text-to-video generative AI models, AI artists can now create them more easily. However, accurately reflecting the desired music-visual mise-en-scène remains challenging without specialized knowledge, highlighting the need for supportive tools. To address this, we conducted a design workshop with seven music video experts, identified design goals, and developed MVPrompt—a tool for generating music-visual mise-en-scène prompts. In a user study with 24 AI artists, MVPrompt outperformed the Baseline, effectively supporting the collaborative creative process. Specifically, the Visual Theme stage facilitated the exploration of tone and manner, while the Visual Scene & Grammar stage refined prompts with detailed mise-en-scène elements. By enabling AI artists to specify mise-en-scène creatively, MVPrompt enhances the experience of making music video scenes with text-to-video generative AI.",
    "title": "MVPrompt: Building Music-Visual Prompts for AI Artists to Craft Music Video Mise-en-scène",
    "id": 189157,
    "sequence": 947,
    "queryCoordinates": {
      "visualization": [
        1.1111404660392046,
        1.6629392246050905
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "Unsustainable behaviors are challenging to prevent due to their\r\nlong-term, often unclear consequences. Serious games offer a promising solution by creating artificial environments where players can immediately experience the outcomes of their actions. To explore this potential, we developed EcoEcho, a GenAI-powered game leveraging multimodal agents to raise sustainability awareness. These agents engage players in natural conversations, prompting them to take in-game actions that lead to visible environmental impacts. We evaluated EcoEcho using a mixed-methods approach with 23 participants. Results show a significant increase in intended sustainable\r\nbehaviors post-game, although attitudes towards sustainability had only marginal effects, suggesting that in-game actions likely can motivate intended real world behaviors despite similar opinions on sustainability. This finding highlights multimodal agents and\r\naction-consequence mechanics to effectively raising sustainability awareness and the potential of motivating real-world behavioral change. ",
    "title": "Can AI Prompt Humans? Multimodal Agents Prompt Players’ Game Actions and Show Consequences to Raise Sustainability Awareness",
    "id": 189158,
    "sequence": 948,
    "queryCoordinates": {
      "visualization": [
        -4.05069907325864,
        5.708926082714822
      ]
    }
  },
  {
    "session": "Medical Contexts",
    "abstract": "The action remapping between the user and the avatar creates significant perceptual and behavioral challenges. Recently, in addition to virtual environments, remapping has also given rise to new applications—immersive teleoperated robots. This paper selects immersive telesurgery, a representative scenario, as an opportunity for research, exploring the generalized effects of remapping. In such a scenario, the operator can observe through the robot's camera and use their hands to control the robotic arms, as if they were the robot. However, common remapping of spatial head-hand relations—due to camera adjustments and robotic arm switching—creates significant visual-proprioceptive conflicts and physical limitations. To explore this, we simulated a telesurgery system with 6 head-camera and 12 hand-robotic-arm remapping conditions, assessing non-surgeon participants across four surgical tasks: navigation, location, cutting, and bimanual coordination. The study examines spatial perception bias, interaction deviation, workload, and task completion time. Our findings reveal how different remapping targets, attributes, intensities, and situations affect performance, contributing to the understanding of perception mechanisms and offering insights for optimizing operations or systems.",
    "title": "Exploring the Remapping Impact of Spatial Head-hand Relations in Immersive Telesurgery",
    "id": 189159,
    "sequence": 949,
    "queryCoordinates": {
      "visualization": [
        -14.516002876814685,
        -10.643573670544482
      ]
    }
  },
  {
    "session": "WS06: Envisioning the Future of Interactive Health",
    "abstract": "This workshop will gather the health and well-being (henceforth “Health”) research community to prepare and kickstart an independent conference. While there is substantial research at the intersection of HCI and Health, there is not yet a SIGCHI-sponsored conference dedicated to the HCI and Health community. The workshop will bring together the broad community of academic and industry researchers across Human–Computer Interaction, medical informatics, health informatics, and digital health. This widespread Health community also brings diverse approaches to epistemology and research, requiring that we work towards defining the scope, audience, and methods that will establish a shared language while welcoming areas of growth. This workshop will be an opportunity for the fledgling community to start important discussions around what constitutes a contribution for the Health community",
    "title": "Envisioning the Future of Interactive Health",
    "id": 189160,
    "sequence": 950,
    "queryCoordinates": {
      "visualization": [
        -7.927028958943908,
        -15.038690497648545
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "Patient-provider communication is an important aspect of successful healthcare, as it can directly lead to positive health outcomes. Previous studies examined factors that facilitate communication between healthcare providers and patients in socially marginalized communities, especially developing countries, and applied identified factors to technology development. However, there is limited understanding of how providers work with patients from immigrant populations in a developed country. By conducting semi-structured interviews with 15 providers working with patients from an immigrant community with unique cultural characteristics, we identified providers’ effective communication strategies, including acknowledgment, community involvement, gradual care, and adaptive communication practices (i.e., adjusting the communication style). Based on our findings, we highlight cultural competence and discuss design implications for technologies to support health communication in immigrant communities. Our suggestions propose approaches for HCI researchers to identify practical, contextualized cultural competence for their health technology design.",
    "title": "Designing Health Technologies for Immigrant Communities: Exploring Healthcare Providers’ Communication Strategies with Patients",
    "id": 189161,
    "sequence": 951,
    "queryCoordinates": {
      "visualization": [
        1.1672268192795274,
        4.861849601988383
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "In this systematic review, we analyze the literature on psychological ownership of virtual objects and environments according to the PRISMA statement. Psychological ownership describes the feelings of possession towards an object which are independent of legal possession. The construct stems from organizational management literature, but is gaining in importance in Human-Computer-Interaction as users invest billions to own virtual objects. The analysis of 21 research papers reveals how and why ownership emerges and presents the dimensions and consequences of such feelings. In addition, we relate these variables to the classic psychological ownership motives of self-efficacy, self-identity, and belonging, as well as the routes of control, identity transfer, and intimate knowledge. We outline why designers should pay attention to the phenomenon and how it can be utilized in different contexts. Finally, the paper concludes by outlining why and what research will be needed in the future.",
    "title": "Owning the (Virtual) World: A Systematic Review of Psychological Ownership of Interactive Virtual Objects and Environments",
    "id": 189162,
    "sequence": 952,
    "queryCoordinates": {
      "visualization": [
        -9.386412980437573,
        16.51954149971097
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "Extensive research has focused on community-based moderation involving selected or volunteer moderators. The ``votekick'' system represents a democratized approach allowing all users to participate in moderation. Despite its widespread use in online gaming and social VR platforms, votekicking remains underexplored. This research studies how users use and perceive votekicking in VRChat, a leading social VR platform. Through thematic analysis of discussions from the Reddit community r/VRChat, our findings reveal that votekicking serves to cope with misconduct and enforce group-specific rules, but it also perpetuates toxicity such as materializing community-level biases. While praised for its immediacy and clear messaging against unacceptable behavior, votekicking's effectiveness is hindered by its reactive nature, consensus challenges, and decision-making complexities. This research contributes to broader discussions on the limitations and advantages of direct community involvement in moderation and suggests practical design improvements to address the challenges associated with votekicking.",
    "title": "Democratic Moderation: Exploring the Use and Perception of Votekicking in Social Virtual Reality",
    "id": 189163,
    "sequence": 953,
    "queryCoordinates": {
      "visualization": [
        7.1937812744737055,
        -14.291588819128245
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "How more-than-human gatherings configure and change to support designing is not well understood. In the more-than-human theory of designing-with, these gatherings are called constituencies. This paper aims to shed light on the practices of a constituency, by analyzing the moving of a plant studio from one city to another. The plant studio includes over 250 plants and is where living-with and designing-with plants are conceptualized. The move offered an opportunity to understand the dynamics of the plant studio as a constituency using design events, a vocabulary and analytical tool, for understanding practices and temporality. In our analysis, we surface the role of humans as speaking subjects and five repertoires or considered actions that together articulate the practice of a constituency. We also illustrate the use of design events as an analytical tool for nuance and critical reflections on more-than-human design.",
    "title": "Constituency as a Matter of Practice: Moving a Plant Studio",
    "id": 189164,
    "sequence": 954,
    "queryCoordinates": {
      "visualization": [
        16.99546453789783,
        -0.3926641581010186
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": "Although it is now well recognized that HCI must take a greater account of ethics there is little consensus about which ethical systems are most appropriate or how to incorporate them into the design process. In this paper, we contribute a Design Court workshop method where opposing legal and ethical arguments are set against one another in the form of a mock trial. We describe how we structured and enacted these workshops by combining legal thought experiments and design fiction. The paper reports findings from three Design Courts where a fictional device is the subject of litigation. These court disputations focused on issues of privacy, reciprocity and intent in rich and nuanced debate. We argue that Design Courts may be a useful method for engaging competing ethical standpoints through contested dialogue.",
    "title": "Design Courts: Workshops for Exploring Emerging Technology Ethics",
    "id": 189165,
    "sequence": 955,
    "queryCoordinates": {
      "visualization": [
        4.992701457272388,
        -13.079485164124396
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "Cameras are increasingly augmented with computational processing, producing images that blur the line between documenting reality and creative expression. The rise of text-to-image models has redefined the concept of imagery, sparking ethical and philosophical debates. This paper presents the findings of a qualitative study that employed a provocative prototype `camera’ – the A(I)Cam – to engage creative practitioners directly in these discussions. Developed using a Research-through-Design (RtD) approach, the tangible prototype generates and instantly prints AI-created images. A(I)Cam facilitated reflection among creative practitioners (N=15) on their experiences with AI-driven tools and the broader implications for their future practices. We examine the shifts in perspective that emerged from engaging with this embodied form of generative AI (genAI), challenging traditional text-based interaction paradigms, and inviting new modes of creative exploration and reflection. In addition, we offer insights from the RtD project, highlighting the integration of genAI tools into the industrial design process.",
    "title": "Creative Reflections on Image-Making with Artificial Intelligence: Interactions with a Provocative ‘Camera’",
    "id": 189166,
    "sequence": 956,
    "queryCoordinates": {
      "visualization": [
        1.9578928833007756,
        14.871672920607155
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "AI systems have rapidly advanced, diversified, and proliferated, but our knowledge of people’s perceptions of mind and morality in them is limited, despite its importance for outcomes such as whether people trust AIs and how they assign responsibility for AI-caused harms. In a preregistered online study, 975 participants rated 26 AI and non-AI entities. Overall, AIs were perceived to have low-to-moderate agency (e.g., planning, acting), between inanimate objects and ants, and low experience (e.g., sensing, feeling). For example, ChatGPT was rated only as capable of feeling pleasure and pain as a rock. The analogous moral faculties, moral agency (doing right or wrong) and moral patiency (being treated rightly or wrongly) were higher and more varied, particularly moral agency: The highest-rated AI, a Tesla Full Self-Driving car, was rated as morally responsible for harm as a chimpanzee. We discuss how design choices can help manage perceptions, particularly in high-stakes moral contexts.",
    "title": "Robots, Chatbots, Self-Driving Cars: Perceptions of Mind and Morality Across Artificial Intelligences",
    "id": 189167,
    "sequence": 957,
    "queryCoordinates": {
      "visualization": [
        -18.89612092933756,
        6.552603591233874
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "Researchers commonly rely on contributions from either unpaid contributors or work done by paid crowdworkers. Rarely are the motivations of these workers and the accuracy of their contributions studied simultaneously in the wild over time. We maintain a public system where anyone can edit an evolving tabular dataset of Computer Science faculty profiles useful for the field of CS, and in this work, we analyze both the accuracy of contributions and the motivations of paid crowdworkers and unpaid contributors, combining data from real-world edit histories and a discrete choice experiment. The accuracy of edits made by unpaid contributors was 1.9 times higher than that of paid crowdworkers for difficult-to-find data and 1.5 times greater for data requiring domain-specific expertise. \\actwo{Our discrete choice experiment reveals that while both groups are motivated by common attributes describing a contribution task: pay level, estimated completion time, interest, and the ability to help others, they make different trade-offs between these attributes when choosing crowd contribution tasks.} We provide recommendations to build hybrid data systems that mix extrinsic and intrinsic motivators to motivate highly accurate contributors, whether paid or unpaid.",
    "title": "Towards Fair and Equitable Incentives to Motivate Paid and Unpaid Crowd Contributions",
    "id": 189168,
    "sequence": 958,
    "queryCoordinates": {
      "visualization": [
        14.627356091256488,
        -6.483861024079847
      ]
    }
  },
  {
    "session": "3D Design and Fabrication",
    "abstract": "In this paper, we present Xstrings, a method for designing and fabricating 3D printed objects with integrated cable-driven mechanisms that can be printed in one go without the need for manual assembly. Xstrings supports four types of cable-driven interactions—bend, coil, screw and compress—which are activated by applying an input force to the cables. To facilitate the design of Xstrings objects, we present a design tool that allows users to embed cable-driven mechanisms into object geometries based on their desired interactions by automatically placing joints and cables inside the object. To assess our system, we investigate the effect of printing parameters on the strength of Xstrings objects and the extent to which the interactions are repeatable without cable breakage. We demonstrate the application potential of Xstrings through examples such as manipulable gripping, bionic robot manufacturing, and dynamic prototyping.",
    "title": "Xstrings: 3D Printing Cable-Driven Mechanism for Actuation, Deformation, and Manipulation",
    "id": 189169,
    "sequence": 959,
    "queryCoordinates": {
      "visualization": [
        13.709819760008175,
        -13.15449893185177
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "Filigree art, which represents typical intricate metalwork, has been captivating audiences worldwide with its delicate lace-like patterns and interwoven metal wires' refined aesthetics. Particularly, Chinese Intangible Cultural Heritage filigree craftsmanship has a unique aesthetic value in fine patterns and complex three-dimensional shapes. However, designing and creating filigree artworks is a labor-intensive and technically complex task and often requires extensive training and a deep understanding of the craft, which limits its design aesthetic and cultural continuity. Aiming to overcome these challenges, this study proposes an artificial intelligence (AI)-aided method that uses AI-generated content (AIGC) technology to accelerate the visualization process of this time-consuming and intricate craft by investigating the role of AI in craft design. First, a comprehensive study of filigree art culture is conducted to identify more than ten historic filigree techniques to obtain AI opportunities. Then, an AI-powered framework called AIFiligree is developed by optimizing culture-based labels and training parameters, enabling the generation of highly authentic fine filigree structures. Further, user workflows are introduced to support diverse design scenarios. Through user studies involving 22 filigree experts and 16 designers, we finally gained insights into AI's opportunities and challenges in cultural learning, expression, and design.",
    "title": "AIFiligree: A Generative AI Framework for Designing Exquisite Filigree Artworks",
    "id": 189170,
    "sequence": 960,
    "queryCoordinates": {
      "visualization": [
        19.90369453344394,
        1.960342806591212
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "Overtaking on country roads with possible opposing traffic is a dangerous maneuver and many proposed assistant systems assume car-to-car communication and sensors currently unavailable in cars. To overcome this limitation, we develop an assistant that uses simple in-car sensors to predict the required sight distance for safe overtaking. Our models predict this from vehicle speeds, accelerations, and 3D map data. In a user study with a Virtual Reality driving simulator (N=25), we compare two UI variants (monitoring-focused vs scheduling-focused). The results reveal that both UIs enable more patient driving and thus increase overall driving safety. While the monitoring-focused UI achieves higher System Usability Score and distracts drivers less, the preferred UI depends on personal preference. Driving data shows predictions were off at times. We investigate and discuss this in a comparison of our models to actual driving behavior and identify crucial model parameters and assumptions that significantly improve model predictions.",
    "title": "You Shall Not Pass: Warning Drivers of Unsafe Overtaking Maneuvers on Country Roads by Predicting Safe Sight Distance",
    "id": 189171,
    "sequence": 961,
    "queryCoordinates": {
      "visualization": [
        16.475606624150046,
        7.24944041745727
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "AI shaming is a social phenomenon in which negative judgements are associated with the use of Artificial Intelligence (AI). This includes comparing someone's work with AI-generated work as a means of disparagement, voicing suspicion or alleging that someone has used AI to undermine their reputation, or blaming the poor quality of an artefact on AI use. Common justifications of AI shaming include recourse to AI's societal harms, its technical limitations, and lack of creativity. I argue that, more fundamentally than any of these, AI shaming arises from a class anxiety induced in middle class knowledge workers, and is a form of boundary work to maintain class solidarity and limit mobility into knowledge work. I discuss the role of AI shaming in protecting the privileged class of knowledge work and its attendant harms.",
    "title": "AI Could Have Written This: Birth of a Classist Slur in Knowledge Work",
    "id": 189172,
    "sequence": 962,
    "queryCoordinates": {
      "visualization": [
        6.901097129627651,
        -1.1725435631331595
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "Displaced cultural objects often act as mediators of intercultural understanding due to their connection between the original and host communities. This study explores how immersive embodied VR biography enhances intercultural empathy and understanding of displaced cultural objects. We took the famous Chinese painting, the Admonitions Scroll, housed at the British Museum as an example to design an Immersive Biography in VR. We conducted an empirical study with 24 participants from source and non-source communities. Findings suggested that interacting with biographical narratives of displaced cultural objects in a personified embodied way can effectively promote intercultural empathy and understanding. Additionally, simulated intercultural scenarios and dialogues with personified cultural objects fostered intercultural empathy in both groups, with a stronger effect observed in non-source communities due to differences in cultural identity and personal connections. Our study provided the potential and practical insights of immersive technologies to inspire intercultural communication for displaced cultural objects.",
    "title": "Immersive Biography: Supporting Intercultural Empathy and Understanding for Displaced Cultural Objects in Virtual Reality",
    "id": 189173,
    "sequence": 963,
    "queryCoordinates": {
      "visualization": [
        4.155737519115305,
        7.983097498603995
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "As the use of Head-Mounted Displays in moving vehicles increases, passengers can immerse themselves in visual experiences independent of their physical environment. However, interaction methods are susceptible to physical motion, leading to input errors and reduced task performance. This work investigates the impact of G-forces, vibrations, and unpredictable maneuvers on 3D interaction methods. We conducted a field study with 24 participants in both stationary and moving vehicles to examine the effects of vehicle motion on four interaction methods: (1) Gaze\\&Pinch, (2) DirectTouch, (3) Handray, and (4) HeadGaze. Participants performed selections in a Fitts' Law task. Our findings reveal a significant effect of vehicle motion on interaction accuracy and duration across the tested combinations of Interaction Method $\\times$ Road Type $\\times$ Curve Type. We found a significant impact of movement on throughput, error rate, and perceived workload. Finally, we propose future research considerations and recommendations on interaction methods during vehicle movement.",
    "title": "Bumpy Ride? Understanding the Effects of External Forces on Spatial Interactions in Moving Vehicles",
    "id": 189174,
    "sequence": 964,
    "queryCoordinates": {
      "visualization": [
        2.974334584121431,
        -0.3915785766601547
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "Research ideation involves broad exploring and deep refining ideas. Both require deep engagement with literature. Existing tools focus primarily on broad idea generation, yet offer little support for iterative specification, refinement, and evaluation needed to further develop initial ideas. To bridge this gap, we introduce IdeaSynth, a research idea development system that uses LLMs to provide literature-grounded feedback for articulating research problems, solutions, evaluations, and contributions. IdeaSynth represents these idea facets as nodes on a canvas, and allow researchers to iteratively refine them by creating and exploring variations and combinations. Our lab study (𝑁 = 20) showed that participants, while using IdeaSynth, explored more alternative ideas and expanded initial ideas with more details compared to a strong LLM-based baseline. Our deployment study (𝑁 = 7) demonstrated that participants effectively used IdeaSynth for real-world research projects at various ideation stages from developing initial ideas to revising framings of mature manuscripts, highlighting the possibilities to adopt IdeaSynth in researcher’s workflows.",
    "title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback",
    "id": 189175,
    "sequence": 965,
    "queryCoordinates": {
      "visualization": [
        13.079485164124398,
        4.992701457272382
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "Good writing is a dynamic process of knowledge transformation, where writers refine and evolve ideas through planning, translating, and reviewing. Generative AI-powered writing tools can enhance this process but may also disrupt the natural flow of writing, such as when using LLMs for complex tasks like restructuring content across different sections or creating smooth transitions. We introduce Script&Shift, a layered interface paradigm designed to minimize these disruptions by aligning writing intents with LLM capabilities to support diverse content development and rhetorical strategies. By bridging envisioning, semantic, and articulatory distances, Script&Shift interactions allow writers to leverage LLMs for various content development tasks (scripting) and experiment with diverse organization strategies while tailoring their writing for different audiences (shifting). This approach preserves creative control while encouraging divergent and iterative writing. Our evaluation shows that Script&Shift enables writers to creatively and efficiently incorporate LLMs while preserving a natural flow of composition.",
    "title": "Script&Shift: A Layered Interface Paradigm for Integrating Content Development and Rhetorical Strategy with LLM Writing Assistants",
    "id": 189176,
    "sequence": 966,
    "queryCoordinates": {
      "visualization": [
        5.0287040995216055,
        -16.239215962584357
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "Online debates can enhance critical thinking but may escalate into hostile attacks. As humans are increasingly reliant on Generative AI (GenAI) in writing tasks, we need to understand how people utilize GenAI in online debates. To examine the patterns of writing behavior while making arguments with GenAI, we created an online forum for soccer fans to engage in turn-based and free debates in a post format with the assistance of ChatGPT, arguing on the topic of \"Messi vs Ronaldo\". After 13 sessions of two-part study and semi-structured interviews with 39 participants, we conducted content and thematic analyses to integrate insights from interview transcripts, ChatGPT records, and forum posts. We found that participants prompted ChatGPT for aggressive responses, created posts with similar content and logical fallacies, and sacrificed the use of ChatGPT for better human-human communication. This work uncovers how polarized forum members work with GenAI to engage in debates online.",
    "title": "\"Ronaldo's a poser!\": How the Use of Generative AI Shapes Debates in Online Forums",
    "id": 189177,
    "sequence": 967,
    "queryCoordinates": {
      "visualization": [
        8.314696123025453,
        -5.555702330196022
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "Most research depends to some extent on technologies and computational infrastructures including, and perhaps especially, HCI.  Despite the noted environmental impacts associated with information communication technology (ICT) globally, to date little consideration has been given as to how to limit the impact of research and innovation processes themselves.  Working to understand the technical and cultural drivers of this impact within the specific but resource-intensive domain of High Performance Computing (HPC), we conducted 25 interviews with academic researchers, providers, funders, and commissioners of HPC. We find intersecting socio-cultural and technical dimensions that link to research institutions like conferences, funders, and universities that reinforce and embed, rather than challenge, expectations of growth and waste.  At a time when large scale cloud systems, generative AI and ever larger models are multiplying, we argue to de-escalate demand for computing, aiming for more moderate, responsible and meaningful use of computational infrastructures - including within HCI itself.",
    "title": "The World is Not Enough: Growing Waste in HPC-enabled Academic Practice",
    "id": 189178,
    "sequence": 968,
    "queryCoordinates": {
      "visualization": [
        -14.585548805965146,
        3.501680457838589
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "Exoskeletons open up a unique interaction space that seamlessly integrates users' body movements with robotic actuation. Despite its potential, human-exoskeleton interaction remains an underexplored area in HCI, largely due to the lack of accessible prototyping tools that enable designers to easily develop exoskeleton designs and customized interactive behaviors. We present ExoKit, a do-it-yourself toolkit for rapid prototyping of low-fidelity, functional exoskeletons targeted at novice roboticists. ExoKit includes modular hardware components for sensing and actuating shoulder and elbow joints, which are easy to fabricate and (re)configure for customized functionality and wearability. To simplify the programming of interactive behaviors, we propose functional abstractions that encapsulate high-level human-exoskeleton interactions. These can be readily accessed either through ExoKit's command-line or graphical user interface, a Processing library, or microcontroller firmware, each targeted at different experience levels. Findings from implemented application cases and two usage studies demonstrate the versatility and accessibility of ExoKit for early-stage interaction design.",
    "title": "ExoKit: A Toolkit for Rapid Prototyping of Interactions for Arm-based Exoskeletons",
    "id": 189179,
    "sequence": 969,
    "queryCoordinates": {
      "visualization": [
        -18.89612092933756,
        -6.55260359123387
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "This paper examines how strategies for simulating social presence across distance can evoke a sense of presence and facilitate illusory interactions across time. We conducted a mixed-methods study with 28 participants, exploring their emotional experience of interacting with decade-old recorded piano performances on MirrorFugue—a player piano enhanced with life-sized projections of the pianist’s hands and body, creating the illusion of a virtual reflection playing the instrument. Data were collected via wearable sensors, questionnaires, and interviews.\r\n\r\nResults showed that participants felt a strong presence of past pianists, with some experiencing the illusion of two-way communication and an overall increase in connection. The emotional experience was significantly influenced by the participant’s relationship with the recorded pianist and the pianist's vital status. These findings suggest that telepresence technologies can foster connections with the past, offering spaces for memory recall, self-reflection, and a sense of “time travel.”\r\n",
    "title": "ReMirrorFugue: Examining the Emotional Experience of Presence and (Illusory) Communications Across Time",
    "id": 189180,
    "sequence": 970,
    "queryCoordinates": {
      "visualization": [
        -1.1725435631331542,
        6.901097129627651
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "Contact tracing has shown to be an effective tool in limiting the spread of transmittable diseases in countries where it is widely adopted. During the COVID-19 pandemic, contact tracing app adoption in the United States was low despite having the highest number of recorded cases worldwide. To better understand why, we conducted a survey (N=302, matched to U.S. census demographics) and found that political orientation overwhelmingly predicted attitudes towards COVID-19 and the adoption of contact tracing apps. These attitudes also overwhelmingly shaped people's willingness to participate in contact tracing for diseases in future pandemics. Our findings suggest that the politically charged environment surrounding COVID-19 in the U.S. may have a long-term impact on American's willingness to utilize contact tracing for diseases in future pandemics. We conclude with recommendations for technology designers and policymakers on how to overcome the sharp divide that has been driven by the political discourse in the U.S.",
    "title": "A House Divided: How U.S. Politics Could Shape Contact-Tracing Adoption in Future Pandemics",
    "id": 189181,
    "sequence": 971,
    "queryCoordinates": {
      "visualization": [
        15.388413672113039,
        9.337918646889387
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "Third parties track users' web browsing activities, raising privacy concerns. Tracking protection extensions prevent this, but their influence on privacy protection beliefs shaped by narratives remains uncertain. This paper investigates users' misperception of tracking protection offered by browser plugins. Our study explores how different narratives influence users' perceived privacy protection by examining three tracking protection extension narratives: no protection, functional protection, and a placebo. In a study (N=36), participants evaluated their anticipated protection during a hotel booking process, influenced by the narrative about the plugin's functionality. However, participants viewed the same website without tracking protection adaptations. We show that users feel more protected when informed they use a functional or placebo extension, compared to no protection. Our findings highlight the deceptive nature of misleading privacy tools, emphasizing the need for greater transparency to prevent users from a false sense of protection, as such misleading tools negatively affect user study results.",
    "title": "The Illusion of Privacy: Investigating User Misperceptions in Browser Tracking Protection",
    "id": 189182,
    "sequence": 972,
    "queryCoordinates": {
      "visualization": [
        -5.813545739921832,
        -20.179263760847093
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "Infinite scrolling on social media platforms is designed to encourage prolonged engagement, leading users to spend more time than desired, which can provoke negative emotions. \r\nInterventions to mitigate infinite scrolling have shown initial success, yet users become desensitized due to the lack of contextual relevance. \r\nUnderstanding how contextual factors influence intervention effectiveness remains underexplored.\r\nWe conducted a 7-day user study (N=72) investigating how these contextual factors affect users' reactance and responsiveness to interventions during infinite scrolling. \r\nOur study revealed an interplay, with contextual factors such as being at home, sleepiness, and valence playing significant roles in the intervention's effectiveness. Low valence coupled with being at home slows down the responsiveness to interventions, and sleepiness lowers reactance towards interventions, increasing user acceptance of the intervention.\r\nOverall, our work contributes to a deeper understanding of user responses toward interventions and paves the way for developing more effective interventions during infinite scrolling.",
    "title": "Scrolling in the Deep: Analysing Contextual Influences on Intervention Effectiveness during Infinite Scrolling on Social Media",
    "id": 189183,
    "sequence": 973,
    "queryCoordinates": {
      "visualization": [
        5.049831540303149,
        -19.3519818472052
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "Embedded systems and interactive devices form an essential interface between the physical and digital world and are understandably an important focus for the HCI research community. However, scaling an interactive prototype of a new device concept to enable effective evaluation or to support the transition to a production-ready device is incredibly challenging. To better understand the issues innovators face when scaling up interactive device prototypes we report the results from 22 interviews with practitioners in the interactive device field, including eight academics involved in the HCI and manufacturing research communities. In our two-phase analysis we identify and  validate the following four recurring themes. First and foremost is the observation that ``creating relationships with industry'' is hard. Second, ``effective communication requires a lot of effort'' despite the availability of modern collaboration tools. Thirdly, we observed that ``understanding the manufacturer's perspective'' can be difficult. Finally, ``prototyping is nothing like production''---the vast difference between these two activities still surprises many.\r\nAdditionally, our university-based participants gave us further insights and helped us to identify challenges specific to the academic context, pointing to a number of opportunities relating to hardware device scaling.",
    "title": "Making Hardware Devices at Scale is Still Hard: Challenges and Opportunities for the HCI Community.",
    "id": 189184,
    "sequence": 974,
    "queryCoordinates": {
      "visualization": [
        -6.523884689106628,
        16.776141647090373
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Our study explores the usability and challenges of a Virtual Reality (VR) and Large Language Model (LLM)-based platform designed for soft skills training in vocational programs for autistic individuals, from the perspective of job coaches. The platform features a VR application that integrates an LLM-powered virtual avatar for role-playing scenarios, alongside a web interface system that enables job coaches to develop training scenarios through prompts. We conducted a two-phase longitudinal study with 13 job coaches. Phase 1 involved workshops to introduce the platform and prompt-writing, and assess initial user experiences, while Phase 2 included interviews to gather insights on the system’s usability after 3 months of use. The findings highlight job coaches' perceptions of the system's practicality, the difficulties in integrating the technology into routine coaching, and the challenges faced by non-tech-savvy users. Our study contributes to understanding how VR and LLM tools can be effectively utilized in vocational training.",
    "title": "Generative Role-Play Communication Training in Virtual Reality for Autistic Individuals: A Study on Job Coach Experiences in Vocational Training Programs",
    "id": 189185,
    "sequence": 975,
    "queryCoordinates": {
      "visualization": [
        -11.435759204552243,
        16.408028870510275
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "Location-based recommendation systems are becoming increasingly ubiquitous in the march toward fully tailored user experiences. Applications like Google Maps, Strava, Uber, Hinge, and many others utilize location data as key material for providing contextual recommendations. Rising concerns about usage and misuse of location data have arisen in recent years. We situate this paper within design’s future-oriented nature, critically speculating possible futures with location-based recommenders. We propose a refinement of current approaches and speculative design for engaging domain experts in co-speculation through the use of tailored, high-fidelity, critical design fiction films. In this case study, we lay preliminary insights, including a widespread sense of fatalism, self-described lack of agency, and underlying individualist ideologies driving development and deployment of these systems. We also reflect on the process of creating four critical design fiction videos, their use in 11  guided co-speculation sessions, and implications for their use in gathering rich qualitative data, creating space for reflection, prompting stories and personal connection, and unpacking experts' views on complex wicked problems.",
    "title": "Exploring the use of Speculative Concept Films for Co-Speculation around Data Ethics",
    "id": 189186,
    "sequence": 976,
    "queryCoordinates": {
      "visualization": [
        -19.53531762641745,
        4.286183061301024
      ]
    }
  },
  {
    "session": "3D Design and Fabrication",
    "abstract": "In 3D design, specifying design objectives and visualizing complex shapes through text alone proves to be a significant challenge. Although advancements in 3D GenAI have significantly enhanced part assembly and the creation of high-quality 3D designs, many systems still to dynamically generate and edit design elements based on the shape parameters. To bridge this gap, we propose GenPara, an interactive 3D design editing system that leverages text-conditional shape parameters of part-aware 3D designs and visualizes design space within the Exploration Map and Design Versioning Tree. Additionally, among the various shape parameters generated by LLM, the system extracts and provides design outcomes within the user's regions of interest based on Bayesian inference. A user study (N = 16) revealed that GenPara enhanced the comprehension and management of designers with text-conditional shape parameters, streamlining design exploration and concretization. This improvement boosted efficiency and creativity of the 3D design process.",
    "title": "GenPara: Enhancing the 3D Design Editing Process by Inferring Users' Regions of Interest with Text-Conditional Shape Parameters",
    "id": 189187,
    "sequence": 977,
    "queryCoordinates": {
      "visualization": [
        18.672230487899828,
        3.5139448781596085
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "Internal game balancing is one of the major components that affect player experience, as it is responsible for a large share of development time, the majority of game update patches and long-term player satisfaction. This makes tools and methodologies of assessing and advancing game balance a valuable endeavor for industry and academia. During the past decades, scientific research produced numerous outputs to inform and enhance game balancing, yet most of them only adhere to a single dimension of balance: fixed (end-game) scenarios. However, games are usually experienced throughout a continuous spectrum of ever-changing constellations, which should be reflected. Using simulation, game-playing AI, visual analytics and informative metrics, we introduce a methodology and implementation of Progression Balancing, incorporating multi-dimensional game aspects. For the sake of exposition and ecological validity, we applied it in one of the most successful recent games (Baldur's Gate 3), and evaluated its efficacy with help of its player community.",
    "title": "Progression Balancing × Baldur’s Gate 3: Insights, Terms and Tools for Multi-Dimensional Video Game Balance",
    "id": 189188,
    "sequence": 978,
    "queryCoordinates": {
      "visualization": [
        -11.230871121087912,
        -4.227000575054793
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "In response to the escalating impact of mindless consumption in the fashion and IT industry, we began to think of and with a constraint-based approach to interaction design. This paper describes a research through design investigation into a paradigm of constraint-based design, founded on the practical and perceived constraints of solar-powered internet. Our intention is not to examine individual consumer as a site for sustainable transition, but the industries and industry practitioners at the interface with consumers. We employed strategies that included optimisation as a form of minimisation, visibility as a means to mark existing absence, offloading from automation, and the design of dead-ends. We discuss the challenges in learning to design against the cornucopian paradigm. While the overall vision of an internet powered by the sun seems at once desirable and achievable, the pursuit of a constraints-based interaction design highlights the desire to confirm the dominant paradigm of abundance.",
    "title": "Designing with the Solar Internet: Towards Constraint-Based Design for Sustainable Consumption",
    "id": 189189,
    "sequence": 979,
    "queryCoordinates": {
      "visualization": [
        -14.953760005996921,
        -1.1768864359176656
      ]
    }
  },
  {
    "session": "XR Interaction",
    "abstract": "We know little about the impact of augmented reality (AR) on human cognition, particularly regarding involuntary autobiographical memory (IAM). IAMs are spontaneous recollections of personal events, ubiquitous in daily life but under-researched in both psychology and human-computer interaction. We first discuss the potential opportunities and risks of replacing conventional displays with AR to increase the likelihood of IAMs. We then report on a study investigating whether stimuli displayed on the same mobile device using video-see-through AR are more likely to resurface than those shown with a simple 3D viewer. We found that AR elicits approximately twice as many IAMs in controlled settings with immediate re-exposure to contextual cues, but no measurable effect was found in everyday settings with delayed re-exposure. Therefore, AR can enhance IAMs, but its effects may be modest and short-lived in most cases. Nevertheless, future studies could reveal stronger effects of AR in other settings.",
    "title": "The Effect of Augmented Reality on Involuntary Autobiographical Memory",
    "id": 189190,
    "sequence": 980,
    "queryCoordinates": {
      "visualization": [
        3.9807389066887877,
        0.3920685613182424
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "The increasing emphasis on sustainable practices in HCI requires the development of new materials-based approaches for fabrication, which consider degradation and recycling. In particular, textile products containing rigid elements are usually hard to recycle since they are assembled from different materials, which must be disassembled before recycling.  We introduce a novel method for fabricating knitted textile objects containing both soft and rigid segments using PVA (Polyvinyl Alcohol). PVA is a biodegradable synthetic material that dissolves in water. When exposed to a controlled amount of water and dried, the textile hardens and becomes rigid. We contribute a hardening method and protocol. Additionally, we present methods to achieve selective hardening by using intarsia knitting with two types of PVA. After being subjected to the hardening protocol, one type of PVA hardens while the other remains soft. To illustrate the potential, capabilities, and applications, a series of selectively hardened knitted objects are presented.",
    "title": "Selective Water-Based Hardening of Polyvinyl Alcohol (PVA) Knitted Textiles",
    "id": 189191,
    "sequence": 981,
    "queryCoordinates": {
      "visualization": [
        9.807852804032303,
        -1.9509032201612873
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "Learning drumming is challenging because multiple rhythms must be performed independently and simultaneously using both hands and feet. We conducted two formative studies to understand: 1) professional drumming instructors' teaching methods, and 2) drummers' current self-learning practices and pain points. All instructors deconstructed complex rhythms and limb movements and then used structured progression to teach drumming, which has not been explored by HCI research to date. Based on these findings, we developed a novel micro-progression learning framework for novice drummers that divides and structures comprehension progression (drum sequence and rhythm) and limb coordination progression into 16 stages. We also designed MR-Drum, a mixed-reality system that provides a first-person view of virtual limbs to demonstrate rhythm, limb, and drum surface dynamics, with adjustable tempo and automatic error detection. A summative user study vs. instructional videos showed that MR-Drum significantly improved error rate and timing accuracy, was significantly preferred for comprehension, skill development, and user experience, and was preferred overall by all participants. ",
    "title": "MR.Drum: Designing Mixed Reality Interfaces to Support Structured Learning Micro-Progression in Drumming",
    "id": 189192,
    "sequence": 982,
    "queryCoordinates": {
      "visualization": [
        12.710449912821009,
        2.728454326843018
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "Like humans, today's systems, such as robots and voice assistants, can express curiosity to learn and engage with their surroundings. While curiosity is a well-established human trait that enhances social connections and drives learning, no existing scales assess the perceived curiosity of systems. Thus, we introduce the Perceived System Curiosity (PSC) scale to determine how users perceive curious systems. We followed a standardized process of developing and validating scales, resulting in a validated 12-item scale with 3 individual sub-scales measuring explorative, investigative, and social dimensions of system curiosity. In total, we generated 831 items based on literature and recruited 414 participants for item selection and 320 additional participants for scale validation. Our results show that the PSC scale has inter-item reliability and convergent and construct validity. Thus, this scale provides an instrument to explore how perceived curiosity influences interactions with technical systems systematically.",
    "title": "Developing and Validating the Perceived System Curiosity Scale (PSC): Measuring Users' Perceived Curiosity of Systems",
    "id": 189193,
    "sequence": 983,
    "queryCoordinates": {
      "visualization": [
        8.496093553872488,
        -12.361892829330237
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "In subjective decision-making, where decisions are based on contextual interpretation, Large Language Models (LLMs) can be integrated to present users with additional rationales to consider. The diversity of these rationales is mediated by the ability to consider the perspectives of different social actors; however, it remains unclear whether and how models differ in the distribution of perspectives they provide. We compare the perspectives taken by humans and different LLMs when assessing subtle sexism scenarios. We show that these perspectives can be classified within a finite set (perpetrator, victim, decision-maker), consistently present in argumentations produced by humans and LLMs, but in different distributions and combinations, demonstrating differences and similarities with human responses, and between models. We argue for the need to systematically evaluate LLMs’ perspective-taking to identify the most suitable models for a given decision-making task. We discuss the implications for model evaluation.",
    "title": "A Matter of Perspective(s): Contrasting Human and LLM Argumentation in Subjective Decision-Making on Subtle Sexism",
    "id": 189194,
    "sequence": 984,
    "queryCoordinates": {
      "visualization": [
        0.3901806440322566,
        -1.9615705608064609
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "Augmented reality is projected to be a primary mode of information consumption on the go, seamlessly integrating virtual content into the \\red{physical} world. However, the potential perceptual demands of viewing virtual annotations while \\red{navigating} a physical environment could impact user efficacy and safety, and the implications of these demands are not well understood. Here, we investigate the impact of virtual path guidance and augmentation density visual clutter on search performance and memory. Participants walked along a predefined path, searching for physical or virtual items. They experienced two levels of augmentation density, and either walked freely or with enforced speed and path guidance.} Augmentation density impacted behavior and reduced awareness of uncommon objects in the environment. Analysis of search task performance and post-experiment item recall revealed} differing attention to physical and virtual objects. On the basis of these findings we outline considerations for AR apps designed for use on the go.",
    "title": "On the Go with AR: Attention to Virtual and Physical Targets while Varying Augmentation Density",
    "id": 189195,
    "sequence": 985,
    "queryCoordinates": {
      "visualization": [
        -3.5056198425099216,
        -15.611234080616455
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "In a society where mental health issues are prevalent, engagement with psychotherapy remains low due to stigma and accessibility barriers. Telepsychotherapy offers a potential solution but holds challenges, including difficulties in encouraging open self-disclosure and ease of access. In this paper, we introduce CounselAR, an augmented reality (AR)-mediated therapy service designed to facilitate one-on-one therapy sessions by allowing both client and therapist to use AR filters to maintain varying degrees of anonymity. Through a six-week field deployment involving nine clients and four therapists, we explored how AR-mediated therapy might support psychotherapy from both the clients’ and therapists' perspectives. The results illustrate the potential role of AR filters in enhancing self-disclosure, building rapport, and lowering entry barriers to psychotherapy. Drawing on these findings, we discuss the nuanced role of AR filters and the implications of leveraging AR in psychotherapy.\r\n",
    "title": "CounselAR: Exploring How AR Filters Facilitate Online Psychotherapy In the Wild With South Korean Young Adults",
    "id": 189196,
    "sequence": 986,
    "queryCoordinates": {
      "visualization": [
        4.278346061871099,
        -17.48415725663871
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "Social isolation is a common experience for LGBT+ older adults (OAs) that is often compounded by prejudices of age, sexuality, or gender identity. Little research has explored the specific social needs and barriers that LGBT+ OAs face, particularly in online spaces. To address this gap, we conducted interviews with 10 LGBT+ OAs and an inclusive housing service provider. Our research highlights the importance of LGBT+ community engagement and digitally-supported social networks' role for LGBT+ OAs. We identify challenges such as managing online identity, navigating LGBT+ social media apps and websites, as well as digital disconnectedness challenges among those with lower digital literacy. Recommendations include improving social platforms allowing LGBT+ OAs to manage selective identity characteristics, promoting genuineness and trust in LGBT+ platforms by employing tiered blocking and interest-driven connections, and non-digital outreach strategies for collaborations between LGBT+ organizations and senior centers to engage hidden and isolated LGBT+ OAs.",
    "title": "Challenges and Opportunities for the Design of Inclusive Social Media Experiences with LGBT+ Older Adults",
    "id": 189197,
    "sequence": 987,
    "queryCoordinates": {
      "visualization": [
        1.1770330175946717,
        -15.956647306859043
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "Multimodal interactions are more flexible, efficient, and adaptable than graphical interactions, allowing users to execute commands beyond simply tapping GUI buttons. However, the flexibility of multimodal commands makes it hard for designers to prototype and provide design specifications for developers. It is also hard for developers to anticipate what actions users may want. We present GenieWizard, a tool to aid developers in discovering potential features to implement in multimodal interfaces. GenieWizard supports user-desired command discovery early in the implementation process, streamlining the development process. GenieWizard uses an LLM to generate potential user interactions and parse these interactions into a form that can be used to discover the missing features for developers. Our evaluations showed that GenieWizard can reliably simulate user interactions and identify missing features. Also, in a study (N = 12), we demonstrated that developers using GenieWizard can identify and implement 42% of the missing features of multimodal apps compared to only 10% without GenieWizard.",
    "title": "GenieWizard: Multimodal App Feature Discovery with Large Language Models",
    "id": 189198,
    "sequence": 988,
    "queryCoordinates": {
      "visualization": [
        -0.39157857666015417,
        2.9743345841214315
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "Digital journaling offers a means for older adults to express themselves, document their lives, and engage in self-reflection, contributing to the maintenance of cognitive function and social connectivity. Although previous works have investigated the motivations and benefits of digital journaling for older adults, little technical support has been designed to offer assistance. We conducted a formative study with older adults and uncovered their encountered challenges and preferences for technical support. Informed by the findings, we designed a Large Language Model (LLM) empowered tool, JournalAIde, which provides vicarious experience, idea organization, sample text generation, and visual editing cues to enhance older adults’ confidence, writing ability, and sustained attention during digital journaling. Through a between-subjects study and a field deployment, we demonstrated the JournalAIde’s significant effectiveness compared to a baseline system in empowering older adults in digital journaling. We further investigated older adults' experiences and perceptions of LLM writing assistance.",
    "title": "JournalAIde: Empowering Older Adults in Digital Journal Writing",
    "id": 189199,
    "sequence": 989,
    "queryCoordinates": {
      "visualization": [
        18.89612092933756,
        6.55260359123387
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "Wearable augmented reality (AR) systems have significant potential to enhance surgical outcomes through in-situ visualization of patient-specific data. Yet, efforts to develop AR-based systems for open surgery have been limited, lacking comprehensive interdisciplinary research and actual clinical evaluations in real surgical environments. \r\nOur research addresses this gap by presenting a user-centered design and development process of ARAS, an AR assistance for open pancreatic surgery. ARAS provides in-situ visualization of critical structures, such as the vascular system and the tumor, while offering a robust dual-layer registration method ensuring accurate registration during relevant phases of the surgery.\r\nWe evaluated ARAS in clinical trials of 20 patients with pancreatic tumors. Accuracy validation and postoperative surgeon interviews confirmed its successful deployment, supporting surgeons in vascular localization and critical decision-making.\r\nOur work showcases AR's potential to fundamentally transform procedures for complex surgical operations, advocating a research shift toward ecological validation in open surgery.",
    "title": "From Concept to Clinic: Multidisciplinary Design, Development, and Clinical Validation of Augmented Reality-Assisted Open Pancreatic Surgery",
    "id": 189200,
    "sequence": 990,
    "queryCoordinates": {
      "visualization": [
        5.612970363669895,
        9.460156642284707
      ]
    }
  },
  {
    "session": "Data Interpretation and Storytelling",
    "abstract": "Surveys are a widespread method for collecting data at scale, but their rigid structure often limits the depth of qualitative insights obtained. While interviews naturally yield richer responses, they are challenging to conduct across diverse locations and large participant pools. To partially bridge this gap, we investigate the potential of using LLM-based chatbots to support qualitative data collection through interview probes embedded in surveys. We assess four theory-based interview probes: descriptive, idiographic, clarifying, and explanatory. Through a split-plot study design (N=64), we compare the probes' impact on response quality and user experience across three key stages of HCI research: exploration, requirements gathering, and evaluation. Our results show that probes facilitate the collection of high-quality survey data, with specific probes proving effective at different research stages. We contribute practical and methodological implications for using chatbots as research tools to enrich qualitative data collection.",
    "title": "Chatbots for Data Collection in Surveys: A Comparison of Four Theory-Based Interview Probes",
    "id": 189201,
    "sequence": 991,
    "queryCoordinates": {
      "visualization": [
        -4.2674041195983765,
        -15.420417052727037
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "Virtual YouTubers (VTubers) have recently gained popularity as streamers using computer-generated avatars and real-time motion capture to create distinct virtual identities. While prior research has explored how VTubers construct virtual personas and engage audiences, little attention has been given to viewers’ reactions when virtual and real identities blur—what we refer to as \"seams.\" To address this gap, we conducted a case study on PLAVE, a popular Korean VTuber Kpop idol group, interviewing 24 of their fans. Our findings identified two main sources of seams: technical glitches and identity collapses, where VTubers act inconsistently with their virtual personas, revealing aspects of their real selves. These seams played a pivotal role in shaping diverse fan engagements, with some valuing authenticity linked to real identities, while others prioritized the coherence of virtual personas. Overall, our findings underscore the importance of seams in shaping viewer experiences.\r\n",
    "title": "I Stan Alien Idols and Also the People Behind Them: Understanding How Seams Between Virtual and Real Identities Engage VTuber Fans – A Case Study of PLAVE",
    "id": 189202,
    "sequence": 992,
    "queryCoordinates": {
      "visualization": [
        7.343225094356849,
        -6.788007455329423
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "Recent studies have demonstrated how AI instructors can be used for digital privacy education. However, these studies also highlights the lack of trust that certain individuals–particularly older adults–have in such AI instructors as a major obstacle to their adoption. The current paper introduces \"trust transfer\" as a means to enhance  appropriate trust in AI instructors and improve learning experiences.\r\n\r\nA between-subjects experiment (N = 217) was conducted to test the effect of a human introducing an AI instructor on users' trust and learning experiences. Our findings reveal that this trust transfer positively impacts the perceived trustworthiness of the instructor, as well as users' perception of learning and their enjoyment of the educational material, regardless of age.\r\n\r\nBased on our findings, we discuss how trust transfer can help calibrate users' trust in AI instructors, thereby fostering AI use in digital privacy education, with potential extensions to other domains.",
    "title": "Bridging the Trust Gap: Investigating the Role of Trust Transfer in the Adoption of AI Instructors for Digital Privacy Education",
    "id": 189203,
    "sequence": 993,
    "queryCoordinates": {
      "visualization": [
        4.186597375374282,
        9.081431738250812
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "Despite the importance of viewers' trust in data visualization, there is a lack of research on the viewers’ own perspective on their trust. In addition, much of the research on trust remains relatively theoretical and inaccessible for designers. This work aims to address this gap by conducting a qualitative study to explore how viewers perceive different data visualizations and how their perceptions impact their trust.\r\n    Three dominant themes emerged from the data. First, users appeared to be consistent, listing similar rationale for their trust across different stimuli. Second, there were diverse opinions about what factors were most important to trust perception and about why the factors matter. Third, despite this disagreement, there were important trends to the factors that users reported as impactful. Finally, we leverage these themes to give specific and actionable guidelines for visualization designers to make more trustworthy visualizations.",
    "title": "Trustworthy by Design: The Viewer's Perspective on Trust in Data Visualization",
    "id": 189204,
    "sequence": 994,
    "queryCoordinates": {
      "visualization": [
        15.76444227822306,
        2.7353902201648195
      ]
    }
  },
  {
    "session": "Interactions for Walking and Driving",
    "abstract": "Existing measurements of driver distraction in laboratory settings lack construct and ecological validity, and therefore, cannot provide reliable estimates of in-car tasks’ distraction effects. In this paper, we operationalize driver distraction in a novel way with the help of Drive-In Lab, where any passenger car can be connected to a driving simulation. The operationalization is based on drivers’ headway maintenance during in-car tasks as compared to baseline driving, while accommodating situational and driver-specific variables, such as brake response times. Realistic visual looming cues enable evaluation of distraction effects on cognitive processes crucial for safe driving. Validation studies with two 2024 car models indicate that the method can reliably differentiate distraction effects between cars, in-car tasks, and drivers as large, medium, small, or no effect on crash potential. The method supports design of in-car interactions by providing valid means to reveal the worst and best practices in in-car user interface design.",
    "title": "Evaluating In-Car Tasks’ Distraction Effects with Drive-In Lab",
    "id": 189205,
    "sequence": 995,
    "queryCoordinates": {
      "visualization": [
        2.7417463356180822,
        -21.828486595069407
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "People with energy-limiting conditions, such as chronic fatigue syndrome (ME/CFS) and Long COVID, need to limit their activity levels and balance exertion with rest and restorative activities. This practice is known as “pacing”. There is an opportunity for technology to help people with this process, but conducting research with this population can be difficult given their limited and unpredictable energy levels. This research explores how we can use crip theory to inform the development of co-design methods suitable for this cohort, and as an analytical lens to explore how these tools should be designed outside of normative and abelist assumptions about fatigue and productivity. This is done through a 5 week Asynchronous Remote Community study utilising various co-design techniques. These findings point to future designs of pacing technologies and contribute insights about developing more accessible approaches to conducting research with people with energy-limiting conditions.",
    "title": "Cripping the Co-Design of Pacing Technologies For Energy-Limiting Conditions",
    "id": 189206,
    "sequence": 996,
    "queryCoordinates": {
      "visualization": [
        1.1725435631331567,
        -6.901097129627651
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "ColdGlass is a new material and workflow for accessible, affordable, and full-color glass 3D printing. We present: 1) a recipe for a 3D printable glass paste, 2) software and hardware that enable 3D printing, and 3) a firing schedule for sintering printed parts into solid glass. We evaluate our recipe and firing schedule by comparing the look, feel, shrinkage, porosity, and density of a collection of printed objects. We then present a range of functional and decorative glass artifacts that we 3D printed from ColdGlass including earrings, tiled glass sheets, sculptures, and functional vessels. We also describe methods for reusing and recycling glass in our workflow. We conclude by discussing the unique affordances of ColdGlass and the creative opportunities it provides for digital fabrication, design, and HCI.",
    "title": "ColdGlass: Full-Color Desktop 3D Printing in Glass",
    "id": 189207,
    "sequence": 997,
    "queryCoordinates": {
      "visualization": [
        6.467156727579006,
        -2.6787840265556326
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "It has been increasingly recognized that effective human-AI co-creation requires more than prompts and results, but an environment with empowering structures that facilitate exploration, planning, iteration, as well as control and inspection of AI generation. Yet, a concrete design approach to such an environment has not been established. Our literature analysis highlights that compositional structures—which organize and visualize individual elements into meaningful wholes—are highly effective in granting creators control over the essential aspects of their content. However, efficiently aggregating and connecting these structures to support the full creation process remains challenging. We, therefore, propose a design approach of leveraging compositional structures as the substrates and infusing AI within and across these structures to enable controlled and fluid creation process. We evaluate this approach through a case study of developing a video co-creation environment using this approach. User evaluation shows that such an environment allowed users to stay oriented in their creation activity, remain aware and in control of AI’s generation, and enable flexible human-AI collaborative workflows.\r\n\r\n",
    "title": "Compositional Structures as Substrates for Human-AI Co-creation Environment: A Design Approach and A Case Study",
    "id": 189208,
    "sequence": 998,
    "queryCoordinates": {
      "visualization": [
        -8.758368872374033,
        -8.203107624274448
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "Personal informatics (PI) systems have been utilized to help individuals manage health issues such as stress by leveraging insights from self-tracking data. However, PI users may struggle to develop effective coping strategies because factors influencing stress are often difficult to change in practice, and multiple factors can contribute to stress simultaneously. In this study, we introduce CounterStress, a PI system designed to assist users in identifying contextual changes needed to address high-stress situations. CounterStress employs counterfactual explanations to identify and suggest alternative contextual changes, offering users actionable strategies to achieve a desired state. We conducted both lab-based and field user studies with 12 participants to evaluate the system's usability and applicability, focusing on the benefits of counterfactual-based coping strategies, how users select viable strategies, and their real-world applications. Based on our findings, we discuss design implications for effectively leveraging counterfactuals in PI systems to support users' stress-coping planning.",
    "title": "CounterStress: Enhancing Stress Coping Planning through Counterfactual Explanations in Personal Informatics",
    "id": 189209,
    "sequence": 999,
    "queryCoordinates": {
      "visualization": [
        -15.460209067254741,
        -12.687865683272905
      ]
    }
  },
  {
    "session": "Working with AI",
    "abstract": "AI-assisted decision making becomes increasingly prevalent, yet individuals often fail to utilize AI-based decision aids appropriately especially when the AI explanations are absent, potentially as they do not reflect on AI's decision recommendations critically. Large language models (LLMs), with their exceptional conversational and analytical capabilities, present great opportunities to enhance AI-assisted decision making in the absence of AI explanations by providing natural-language-based analysis of AI's decision recommendation, e.g., how each feature of a decision making task might contribute to the AI recommendation.  In this paper, via a randomized experiment, we first show that presenting LLM-powered analysis of each task feature, either sequentially or concurrently, does not significantly improve people's AI-assisted decision performance. To enable decision makers to better leverage LLM-powered analysis, we then propose an algorithmic framework to characterize the effects of LLM-powered analysis on human decisions and dynamically decide which analysis to present. Our evaluation with human subjects shows that this approach effectively improves decision makers' appropriate reliance on AI in AI-assisted decision making.",
    "title": "From Text to Trust: Empowering AI-assisted Decision Making with Adaptive LLM-powered Analysis",
    "id": 189210,
    "sequence": 1000,
    "queryCoordinates": {
      "visualization": [
        -2.7284543268430257,
        -12.710449912821007
      ]
    }
  },
  {
    "session": "Well-being and Tracking",
    "abstract": "Non-profits such as voluntary and community-based (VC) organisations are facing increasing pressures to engage in data work to sustain themselves. They face challenges with practices, information systems and tools associated with capturing data for supporting service provision. Most recently, researchers working with VC organisations have turned to Feminist and Care discourses to envision alternatives to current socio-technical systems whereby their values and purposes do not match with those of non-profits, consequently pulling the latter away from their socially driven mission. We report on a longitudinal, collaborative study with a UK-based mental health peer support organisation that created innovative tools as a means of navigating current pressures to practice data work for the quantification of mental health service provision. We present findings from interviews conducted with our community partner and share how recovery work has informed careful data practices, offering recommendations for supporting data work in mental health recovery.",
    "title": "Exploring Alternative Socio-Technical Systems for Careful Data Work in Recovery Contexts",
    "id": 189211,
    "sequence": 1001,
    "queryCoordinates": {
      "visualization": [
        -3.5159255986870956,
        -19.688531361797832
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "Recent years have witnessed a growing interest in using robots to support Blind and Low Vision (BLV) people in various tasks and contexts. However, the Human-Computer Interaction (HCI) community still lacks a shared understanding of what, where, and how robots can benefit BLV users in their daily lives. In light of this, we conducted a systematic literature review to help researchers navigate the current landscape of this field through an HCI lens. We followed a systematic multi-stage approach and carefully selected a corpus of 76 papers from premier HCI venues. Our review provides a comprehensive overview of application areas, embodiments, and interaction techniques of the developed robotic systems. Further, we identified opportunities, challenges, and key considerations in this emerging field. Through this systematic review, we aim to inspire researchers, developers, designers, and HCI practitioners, to create a more inclusive environment for the BLV community.",
    "title": "Human Robot Interaction for Blind and Low Vision People: A Systematic Literature Review",
    "id": 189212,
    "sequence": 1002,
    "queryCoordinates": {
      "visualization": [
        21.577276168871066,
        -4.291987084354832
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "Entertainment videogames have been recognized for their potential therapeutic benefits, but there is a need for more in-depth, game-specific explorations of the game features that could contribute to such benefits. This study examines how players of Dark Souls describe the game as helping them cope with depression. We conducted a thematic analysis of Reddit discussions where players narrate their mental health experiences with the game, using AI tools to assist in identifying relevant data for a purposive sample. Our findings suggest that Dark Souls could support players’ mental health, for example, by (1) cultivating resilience and perseverance through its challenging gameplay, (2) triggering existential reflections through symbolic representations of depression, and (3) enabling supportive online communities and interactions. Our findings offer rich, player-centered insights into the perceived mental health benefits of commercial videogames, highlighting their potential to transcend entertainment and inform the design of engaging digital mental health tools.",
    "title": "\"Don't You Dare Go Hollow\": How Dark Souls Helps Players Cope with Depression, a Thematic Analysis of Reddit Discussions",
    "id": 189213,
    "sequence": 1003,
    "queryCoordinates": {
      "visualization": [
        -4.282572564300322,
        -18.51106621001346
      ]
    }
  },
  {
    "session": "Storytelling and Sense-Making",
    "abstract": "Preliminary exploration of vast text corpora for generating and validating hypotheses, typical in academic inquiry, requires flexible navigation and rapid validation of claims. Navigating the corpus by titles, summaries, and abstracts might neglect information, whereas identifying the relevant context-specific claims through in-depth reading is unfeasible with rapidly increasing publication numbers. Our paper identifies three typical user pathways for hypothesis exploration and operationalizes sentence-based retrieval combined with effective contextualization and provenance tracking in a unified workflow. We contribute an interface that augments the previously laborious tasks of claim identification and consistency checking using NLP techniques while balancing user control and serendipity. Use cases, expert interviews, and a user study with 10 participants demonstrate how the proposed workflow enables users to traverse literature corpora in novel and efficient ways. For the evaluation, we instantiate the tool within two independent domains, providing novel insights into the analysis of political discourse and medical contradictions.",
    "title": "Finding Needles in Document Haystacks: Augmenting Serendipitous Claim Retrieval Workflows",
    "id": 189214,
    "sequence": 1004,
    "queryCoordinates": {
      "visualization": [
        -11.159588106621722,
        12.824335978542788
      ]
    }
  },
  {
    "session": "Technology and Society",
    "abstract": "This study aims to investigate the dynamics of young adults' food practices within the interplay between technology and tradition by employing a Value-Sensitive Design (VSD) approach as an analytical lens. We conducted surveys and interviews with young adults. This is complemented by a workshop involving design and gastronomy experts. Grounded in Value-Sensitive Design (VSD) and encompassing 38 core values and resulting in five value conflicts. Our analysis highlights five prominent themes: “Preservation of Culinary Heritage and Relationships”, “Technological Convenience”, “Uniqueness and  Personalisation”, “Globalised Nature of Food”, and “Sustainable Choices and Trustworthiness”.  By bridging between Human-Food Interaction (HFI) and VSD realms, this study provides insights for researchers, designers, and practitioners. The value-laden analytical perspective of the findings sheds light on the food practices of the young generation, for future HFI design studies blending traditional and technological elements.\r\n",
    "title": "Exploring the Nexus of Technology and Food Practices in Young Adults: A Value-Sensitive Design Perspective towards Human-Food Interaction",
    "id": 189215,
    "sequence": 1005,
    "queryCoordinates": {
      "visualization": [
        -17.987015665034882,
        10.838231749957636
      ]
    }
  },
  {
    "session": "Interfaces and Interactions for XR",
    "abstract": "On-body tapping provides a quick way to launch augmented reality (AR) apps using virtual shortcuts placed on the user’s skin, clothes, and jewelry. While prior work has focused on tapping performance, social acceptance, and sensing techniques, users’ behaviour in placing shortcuts on their body has been underexplored. In this work, we propose On-body Icons — a novel interface for launching apps via touching virtual icons placed across the user’s entire body, and use it to investigate locations, reasons for chosen icon placement, and users’ attitudes towards the feature. Results of the qualitative study conducted with 24 participants demonstrated that people employ a wide variety of placement strategies that balance memorability of the locations with accuracy and comfort of reaching the icons. We discuss these findings in regard to current understanding of memorability of icon placement, placement appropriateness, and privacy, and offer design implications for similar features in spatial applications.",
    "title": "On-body Icons: Designing a 3D Interface for Launching Apps in Augmented Reality",
    "id": 189216,
    "sequence": 1006,
    "queryCoordinates": {
      "visualization": [
        -5.0071028885065685,
        -14.139622366382675
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "In this paper, we pay ethnographic attention to the failed attempts at platformization of agricultural trade in one of Asia's largest onion markets, located in rural western Maharashtra. We focus on e-NAM, or the electronic National Agricultural Market, a state-sponsored digital trading platform intended to create a transparent, efficient, and frictionless online national agricultural market by collapsing geographical barriers of traditional marketplaces, commonly known as mandis. We found that despite e-NAM's intended benefits, mandis continue to be the preferred mode of transaction for trading agricultural commodities. We demonstrate that these two agricultural marketplaces foster different meanings of information transparency, efficiency, and participation among stakeholders. In agrarian societies dominated by smallholder farmers, such as India, social collectives and non-economic relationships are crucial for providing safety and risk mitigation when dealing with perishable commodities like onions. We argue that e-NAM fails because its digital intermediation prioritizes an ahistorical and depoliticized free-market approach, which treats farmers (and traders) as independent units driven solely by the economic logic of demand and supply, disconnecting them from their historical and political agrarian social class.",
    "title": "What's in a Place? On Platformization of Traditional Agricultural Marketplaces",
    "id": 189217,
    "sequence": 1007,
    "queryCoordinates": {
      "visualization": [
        -9.465832400385251,
        -8.910556490355516
      ]
    }
  },
  {
    "session": "CS Education and Security",
    "abstract": "Computational thinking (CT) is essential for the 21st century learner. Yet, assessing CT remains challenging. This is particularly challenging in constructionist learning, where individual idiosyncrasies may clash with one-size-fits-all assessments. Tools like Dr. Scratch offer CT metrics that show promise for effective and scalable CT assessments, particularly in constructionist game-based learning (GBL). Prior work has advanced the design of automated CT metrics but hardly included teachers in the process. We extend Dr. Scratch to improve automated CT assessments for GBL and put teachers in the loop to assess its novel features. Specifically, we interviewed seven middle school teachers employing GBL in STEM curricula and asked them to provide feedback on the newly designed CT metrics. Teachers view the new CT metrics positively, underscoring their potential for adaptive CT assessments despite hindrances. We advance automated CT assessments via teacher evaluation toward design-sensitive CT metrics and CT for all.",
    "title": "CT4ALL: Towards Putting Teachers in the Loop to Advance Automated Computational Thinking Metric Assessments in Game-Based Learning",
    "id": 189218,
    "sequence": 1008,
    "queryCoordinates": {
      "visualization": [
        13.99449276936274,
        0.3926475878621654
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "Papermaking is an ancient yet evolving craft, with changes in techniques and materials giving paper contemporary qualities that keep it relevant for everyday use. This adaptability makes papermaking an ideal process for crafting computational composites for tangible interactions. We began by studying ancient Chinese papermaking, replicating it by hand and simplifying the practice into five key steps and tools accessible to novices. We then adapted these steps to imbue the paper with interactive and computational properties, such as integrating conductive materials during pulp preparation, modifying fiber properties through soaking, and customizing sheet texture through watermarking, multi-layering, and coating. We detail our exploration in this paper, as well as demonstrate our findings through four interactive systems focusing on expressive applications made with the computational paper from our adapted process. We also document our exploration in a detailed workbook that captures recipes, failures, and key moments of discovery.",
    "title": "Crafting Interactive Paper Composites through Ancient Papermaking Techniques",
    "id": 189219,
    "sequence": 1009,
    "queryCoordinates": {
      "visualization": [
        2.7284543268430093,
        -12.710449912821012
      ]
    }
  },
  {
    "session": "Well-being and Well-dying",
    "abstract": "We tell a story of a woman getting ready to go for a walk, using a plethora of personal safety technologies designed and reported on by HCI researchers to ensure her own safety against public gendered violence (GV). To reflect on this approach, we elicit the Four Domains of Power, highlighting HCI's over-engagement with interpersonal safety technologies when seeking to intervene in GV. In later parts of the paper, we discuss two main contributions for HCI: (1) The Complexities of Designing for GV as an Interpersonal Problem and (2) Complexities of Designing for Normative Understandings of GV to highlight the potential harm in employing interpersonal technological solutions to socio-political issues. Coming back to the four domains of power, we ultimately argue that HCI-researchers and designers can use the framework to analyze their technological interventions to address GV in more nuanced ways as to not re-produce shortsighted, solutionist, or victim-blaming technologies.",
    "title": "\"The Safest Woman Alive\"",
    "id": 189220,
    "sequence": 1010,
    "queryCoordinates": {
      "visualization": [
        -17.65413504725815,
        -3.5116257962903026
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "Large Language Models (LLMs) like ChatGPT, used by over 200 million people monthly, are increasingly applied in disability contexts, including autism research. However, there has been limited exploration of the potential biases these models hold about autistic people. To explore what biases ChatGPT demonstrates about autistic people, we prompted GPT-3.5 to create three personas, choose one to be autistic, and explain its reasoning for this choice and any suggested changes to the persona description. Our quantitative analysis of the chosen personas indicates that gender and profession influenced GPT's choices. Additionally, our qualitative analysis revealed ChatGPT's tendency to highlight the importance of representation while simultaneously perpetuating mostly negative biases about autistic people, illustrating a \"bias paradox,\" a concept adapted from feminist studies. By applying this concept to LLMs, we provide a lens through which researchers might identify, understand, and address fundamental challenges in the development of responsible and inclusive AI.",
    "title": "\"As an Autistic Person Myself:\" The Bias Paradox Around Autism in LLMs",
    "id": 189221,
    "sequence": 1011,
    "queryCoordinates": {
      "visualization": [
        13.079485164124398,
        -4.992701457272383
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "Recent advances in generative AI music have resulted in new technologies that are being framed as co-creative tools for musicians with early work demonstrating their potential to add to music practice. While the field has seen many valuable contributions, work that involves practising musicians in the design and development of these tools is limited, with the majority of work including them only once a tool has been developed. In this paper, we present a case study that explores the needs of practising musicians through the co-design of a musical variation system, highlighting the importance of involving a diverse range of musicians throughout the design process and uncovering various design insights. This was achieved through two workshops and a two week ecological evaluation, where musicians from different musical backgrounds offered valuable insights not only on a musical system's design but also on how a musical AI could be integrated into their musical practices.",
    "title": "Exploring the Needs of Practising Musicians in Co-Creative AI Through Co-Design",
    "id": 189222,
    "sequence": 1012,
    "queryCoordinates": {
      "visualization": [
        -3.420440747442258,
        7.231914344987546
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "Humans naturally seek to identify causes behind outcomes through causal attribution, yet Human-AI research often overlooks how users perceive causality behind AI decisions. We examine how this perceived locus of causality—internal or external to the AI—influences trust, and how decision stakes and outcome favourability moderate this relationship. Participants (N=192) engaged with AI-based decision-making scenarios operationalising varying loci of causality, stakes, and favourability, evaluating their trust in each AI. We find that internal attributions foster lower trust as participants perceive the AI to have high autonomy and decision-making responsibility. Conversely, external attributions portray the AI as merely \"a tool\" processing data, reducing its perceived agency and distributing responsibility, thereby boosting trust. Moreover, stakes moderate this relationship—external attributions foster even more trust in lower-risk, low-stakes scenarios. Our findings establish causal attribution as a crucial yet underexplored determinant of trust in AI, highlighting the importance of accounting for it when researching trust dynamics.",
    "title": "\"It’s Not the AI’s Fault Because It Relies Purely on Data\": How Causal Attributions of AI Decisions Shape Trust in AI Systems",
    "id": 189223,
    "sequence": 1013,
    "queryCoordinates": {
      "visualization": [
        4.289291617583286,
        -20.557285263850616
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Current AI assistants predominantly use natural language interactions, which can be time-consuming and cognitively demanding, especially for frequent, repetitive tasks in daily life. We propose Persistent Assistant, a framework for seamless and unobtrusive interactions with AI assistants. The framework has three key functionalities: (1) efficient intent specification through grounded interactions, (2) seamless target referencing through embodied input, and (3) intuitive response comprehension through multimodal perceptible feedback. We developed a proof-of-concept system for everyday decision-making tasks, where users can easily repeat queries over multiple objects using eye gaze and pinch gesture, as well as receiving multimodal haptic and speech feedback. Our study shows that multimodal feedback enhances user experience and preference by reducing physical demand, increasing perceived speed, and enabling intuitive and instinctive human-AI assistant interaction. We discuss how our framework can be applied to build seamless and unobtrusive AI assistants for everyday persistent tasks.",
    "title": "Persistent Assistant: Seamless Everyday AI Interactions via Intent Grounding and Multimodal Feedback",
    "id": 189224,
    "sequence": 1014,
    "queryCoordinates": {
      "visualization": [
        -5.805693545089243,
        19.13880671464418
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "Individuals tend to apply preferences and beliefs as heuristics to effectively sift through the sheer amount of information available online. Such tendencies, however, often result in cognitive biases, which can skew judgment and open doors for manipulation. In this work, we investigate how individual and contextual factors lead to instances of confirmation bias when seeking, evaluating, and recalling polarising information. We conducted a lab study, in which we exposed participants to opinions on controversial issues through a Twitter-like news feed. We found that low-effortful thinking, strong political beliefs, and content conveying a strong issue amplify the occurrences of confirmation bias, leading to skewed information processing and recall. We discuss how the adverse effects of confirmation bias can be mitigated by taking bias-susceptibility into account. Specifically, social media platforms could aim to reduce strong expressions and integrate media literacy-building mechanisms, as low-effortful thinking styles and strong political beliefs render individuals especially susceptible to cognitive biases.",
    "title": "Assessing Susceptibility Factors of Confirmation Bias in News Feed Reading",
    "id": 189225,
    "sequence": 1015,
    "queryCoordinates": {
      "visualization": [
        8.78048168486662,
        -20.17184030726304
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Generative AI (GAI) technologies are disrupting professional writing, challenging traditional practices. Recent studies explore GAI adoption experiences of creative practitioners, but we know little about how these experiences evolve into established practices and how GAI resistance alters these practices. To address this gap, we conducted 25 semi-structured interviews with writing professionals who adopted and/or resisted GAI. Using the theoretical lens of Job Crafting, we identify four strategies professionals employ to reshape their roles. Writing professionals employed GAI resisting strategies to maximize human potential, reinforce professional identity, carve out a professional niche, and preserve credibility within their networks. In contrast, GAI-enabled strategies allowed writers who embraced GAI to enhance desirable workflows, minimize mundane tasks, and engage in new AI-managerial labor. These strategies amplified their collaborations with GAI while reducing their reliance on other people. We conclude by discussing implications of GAI practices on writers' identity and practices as well as crafting theory.",
    "title": "AI Rivalry as a Craft: How Resisting and Embracing Generative AI Are Reshaping the Writing Profession",
    "id": 189226,
    "sequence": 1016,
    "queryCoordinates": {
      "visualization": [
        -1.9606357775119523,
        -20.90827365776381
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "Smartwatches offer powerful features, but their small touchscreens limit the expressiveness of the input that can be achieved. To address this issue, we present, and open-source, the first sonar-based around-device input on an unmodified consumer smartwatch. We achieve this using a fine-grained, one-dimensional sonar-based finger-tracking system. In addition, we use this system to investigate the fundamental issue of how to trigger selections during around-device smartwatch input through two studies. The first examines the methods of double-crossing, dwell, and finger tap in a binary task, while the second considers a subset of these designs in a multi-target task and in the presence and absence of haptic feedback. Results showed double-crossing was optimal for binary tasks, while dwell excelled in multi-target scenarios, and haptic feedback enhanced comfort but not performance. These findings offer design insights for future around-device smartwatch interfaces that can be directly deployed on today’s consumer hardware.",
    "title": "Cross, Dwell, or Pinch: Designing and Evaluating Around-Device Selection Methods for Unmodified Smartwatches",
    "id": 189227,
    "sequence": 1017,
    "queryCoordinates": {
      "visualization": [
        -18.511066210013464,
        -4.282572564300317
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "Maintaining engagement in immersive meetings is challenging, particularly when users must catch up on missed content after disruptions. While transcription interfaces can help, table-fixed panels have the potential to distract users from the group, diminishing social presence, while avatar-fixed captions fail to provide past context. We present EngageSync, a context-aware avatar-fixed transcription interface that adapts based on user engagement, offering live transcriptions and LLM-generated summaries to enhance catching up while preserving social presence. We implemented a live VR meeting setup for a 12-participant formative study and elicited design considerations. In two user studies with small (3 avatars) and mid-sized (7 avatars) groups, EngageSync significantly improved social presence (𝑝 < .05) and time spent gazing at others in the group instead of the interface over table-fixed panels. Also, it reduced re-engagement time and increased information recall (𝑝 < .05) over avatar-fixed interfaces, with stronger effects in mid-sized groups (𝑝 < .01).",
    "title": "Since U Been Gone: Augmenting Context-Aware Transcriptions for Re-Engaging in Immersive VR Meetings",
    "id": 189228,
    "sequence": 1018,
    "queryCoordinates": {
      "visualization": [
        7.8863710756765455,
        13.921391857739382
      ]
    }
  },
  {
    "session": "Diversity",
    "abstract": "Cancer treatments often lead to sexual health challenges that greatly impact cancer survivors’ quality of life. Current interventions primarily address physiological aspects, like medication or vaginal care, overlooking psychological, social, and cultural dimensions. This paper explores how HCI can address this gap by supporting post-cancer sexual health with interventions for survivors and their partners, considering their lived experiences. Through reflexive thematic analysis of interviews with (N=6) medical sexologists, we identified five themes: perceiving the body as a medical object, the hot potato problem in oncology, sociotechnical sexploration, reuniting what treatment has divided, and designing interventions with openness in a highly situated context. These themes highlight cancer survivors’ experiences, the (in)effectiveness of current interventions, and provision of care. This research outlines the design space for post-cancer sexual health by providing specific design directions (“what”) and ways for designing them (“how”), while advancing the broader discourse on intimacy and design within HCI.",
    "title": "(Re)discovering Sexual Pleasure after Cancer: Understanding the Design Space",
    "id": 189229,
    "sequence": 1019,
    "queryCoordinates": {
      "visualization": [
        -3.8020298280001548,
        3.247240241650919
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "Companionship is crucial for people's everyday psychological well-being. With growing concerns over harassment against women in embodied social VR spaces, we turn an eye towards AI companions as a potential new approach to protect women in social VR by better fulfilling their under-addressed harassment mitigation needs. Using 20 interviews with women social VR users, we reveal their envisionings for leveraging AI as Accessible Companions, Informational Companions, Emotional Support Companions, and Protective Companions to better protect them in social VR compared to their existing safety mechanisms and strategies. We also reflect upon various sociotechnical complexities for designing and implementing such AI companions in social VR spaces and propose three design principles to inform future efforts to create AI companions to protect women and other marginalized users in social VR. Our work contributes to ongoing discussions on nuanced harassment mitigation approaches that further support marginalized social VR users’ multidimensional needs without harming their self-agency, human relationships, and supportive networks.",
    "title": "\"Comforting and Small Like a House Cat, Big and Intimidating Like a Bodyguard\": How Women Perceive and Envision AI Companions as a New Harassment Mitigation Approach in Social VR",
    "id": 189230,
    "sequence": 1020,
    "queryCoordinates": {
      "visualization": [
        -1.1672268192795268,
        4.861849601988383
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "A persistent challenge in accessible computing is ensuring developers produce web UI code that supports assistive technologies. Despite numerous specialized accessibility tools, novice developers often remain unaware of them, leading to ~96% of web pages that contain accessibility violations. \r\nAI coding assistants, such as GitHub Copilot, could offer potential by generating accessibility-compliant code, but their impact remains uncertain. Our formative study with 16 developers without accessibility training revealed three key issues in AI-assisted coding: failure to prompt AI for accessibility, omitting crucial manual steps like replacing placeholder attributes, and the inability to verify compliance.\r\nTo address these issues, we developed CodeA11y, a GitHub Copilot Extension, that suggests accessibility-compliant code and displays manual validation reminders. We evaluated it through a controlled study with another 20 novice developers. Our findings demonstrate its effectiveness in guiding novice developers by reinforcing accessibility practices throughout interactions, representing a significant step towards integrating accessibility into AI coding assistants.",
    "title": "CodeA11y: Making AI Coding Assistants Useful for Accessible Web Development",
    "id": 189231,
    "sequence": 1021,
    "queryCoordinates": {
      "visualization": [
        -7.704608487732222,
        -10.470864723162293
      ]
    }
  },
  {
    "session": "Make it Visible",
    "abstract": "Multi-class scatterplots are essential for visually comparing data, such as examining class distributions in dimensionality reduction and evaluating classification models. Visual class separation (VCS) measures quantify human perception but are largely derived from and evaluated with datasets reflecting limited types of scatterplot features (e.g., data distribution, similar class densities). Quantitatively identifying which scatterplot features are influential to VCS tasks can enable more robust guidance for future measures. We analyze the alignment between VCS measures and people's perceptions of class separation through a crowdsourced study using 70 scatterplot features relevant to class separation. To cover a wide range of scatterplot features, we generated a set of multi-class scatterplots from 6,947 real-world datasets. Our results highlight that multiple combinations of features are needed to best explain VCS. From our analysis, we develop a composite feature model that identifies key scatterplot features for measuring VCS task performance.",
    "title": "Uncovering How Scatterplot Features Skew Visual Class Separation",
    "id": 189232,
    "sequence": 1022,
    "queryCoordinates": {
      "visualization": [
        13.538779265247904,
        -6.457666452124441
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "Childcare workers, particularly in-home childcare workers and nannies, navigate the unique complexities of a job that is both paid and intimate. As domestic technologies like smart home cameras and voice assistants (VAs) become increasingly prevalent, nannies may interact with and need to navigate these technologies in their care routines. Although prior research has examined the use of VAs in family settings, little attention has been paid to nannies' interactions with these emerging technologies. In this work, we present three scenarios -- speculative yet grounded -- to illustrate underlying tensions and issues that may unfold in nannies' interactions with voice assistant technologies. We found that while VAs could deepen existing tensions around autonomy, responsibilities, and surveillance, they also held potential as tools for reflection and self-advocacy, enabling workers to renegotiate their responsibilities and identities. We conclude by discussing intertwined tensions between in-home childcare work and VAs, offering insights for designing more equitable domestic technologies.",
    "title": "Echoes of Care: Unveiling the Intertwined Tensions between Childcare Work and Voice Assistants",
    "id": 189233,
    "sequence": 1023,
    "queryCoordinates": {
      "visualization": [
        13.533116534621584,
        -11.868224671801249
      ]
    }
  },
  {
    "session": "Design for Diverse Needs",
    "abstract": "In impoverished regions, limited resources, economic constraints, and low psychological health literacy among guardians often prevent timely support for children's mental health. The absence of migrant worker parents further exacerbates these issues, as they remain unaware of their children's psychological states. Existing AI advancements in psychological tools often overlook the specific needs of left-behind children and lack parental involvement. To address this, we developed DiSandbox, a low-cost AI-powered sandbox system that supports children in creating sandbox works for mental health assessments and engages parents in counseling. DiSandbox uses AI to guide children in sandbox play, analyze creations for psychological insights, and help parents understand their children's mental health, enabling timely intervention. By integrating large language models with sandbox play, DiSandbox is a scalable, reliable, and accessible tool for home use. Qualitative and quantitative studies confirm its usability and provide guidance for future AI applications in children's mental health.",
    "title": "\"I Need Your Help!\" : Facilitating Psychological Communication Between Left-Behind Children and Their Parents with an AI-Powered Sandbox",
    "id": 189234,
    "sequence": 1024,
    "queryCoordinates": {
      "visualization": [
        2.6951188271377604,
        7.5323525214641665
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "Software development relies on collaboration and alignment between a variety of roles, including software developers and user experience designers. The increasing focus on artificial intelligence in today's development projects has given rise to new challenges in this collaboration. We extend previous work on the process of designing human-AI systems by analysing collaborative practices between UX designers and AI developers through Mintzberg's theory on coordination mechanisms. We conducted 15 in-depth interviews with UX designers and AI developers currently working on AI projects. We contribute by identifying how coordination mechanisms impact the UX design process when developing AI systems, inter-team (a)symmetries in power relations, and a growing need for tools and cross-disciplinary knowledge to support these collaborative efforts. In particular, we outline the risks of coordinating AI development work through the standardisation of output and skills in separately organised UX and AI development teams.",
    "title": "Coordination Mechanisms in AI Development: Practitioner Experiences on Integrating UX Activities",
    "id": 189235,
    "sequence": 1025,
    "queryCoordinates": {
      "visualization": [
        -13.993278136992089,
        15.658485462546473
      ]
    }
  },
  {
    "session": "CS Education and Security",
    "abstract": "A classic problem in enterprise Wi-Fi is client-side misconfiguration, which enables credential theft via “Evil Twin” (ET) attacks. To mitigate this, we design, develop, and evaluate a new configurator, SeQR, which allows users to effortlessly and securely set up an enterprise Wi-Fi connection. Utilizing existing authenticated channels, SeQR fully automates the client-side enterprise Wi-Fi configuration process with a simple scan, leaving no room for misconfigurations. Specifically, SeQR thwarts ET by making it impossible for users to opt-out from the security-critical certificate validation. We evaluate the efficacy of SeQR on two fronts. First, we implement a prototype of SeQR in Android, and test its functionality and runtime performance. Next, we compare the usability of SeQR against two existing Wi-Fi configuration interfaces of Android in an in-person user study (n=41) with real devices. Our evaluation shows that SeQR achieves noticeable usability improvements over existing designs, and prevents users from misconfiguring.",
    "title": "SeQR: A User-Friendly and Secure-by-Design Configurator for Enterprise Wi-Fi",
    "id": 189236,
    "sequence": 1026,
    "queryCoordinates": {
      "visualization": [
        18.71692722738368,
        -11.561861232726478
      ]
    }
  },
  {
    "session": "Learning and Inspiring, Safety and Security",
    "abstract": "We present BioSpark, a system for analogical innovation designed to act as a creativity partner in reducing the cognitive effort in finding, mapping, and creatively adapting diverse inspirations.\r\nWhile prior approaches have focused on initial stages of finding inspirations, BioSpark uses LLMs embedded in a familiar, visual, Pinterest-like interface to go beyond inspiration to supporting users in identifying the key solution mechanisms, transferring them to the problem domain, considering tradeoffs, and elaborating on details and characteristics. To accomplish this BioSpark introduces several novel contributions, including a tree-of-life enabled approach for generating relevant and diverse inspirations, as well as AI-powered cards including 'Sparks' for analogical transfer; 'Trade-offs' for considering pros and cons; and 'Q&A' for deeper elaboration. We evaluated BioSpark through workshops with professional designers and a controlled user study, finding that using BioSpark led to a greater number of generated ideas; those ideas being rated higher in creative quality; and more diversity in terms of biological inspirations used than a control condition. Our results suggest new avenues for creativity support tools embedding AI in familiar interaction paradigms for designer workflows.",
    "title": "BioSpark: Beyond Analogical Inspiration to LLM-augmented Transfer",
    "id": 189237,
    "sequence": 1027,
    "queryCoordinates": {
      "visualization": [
        9.337918646889388,
        15.388413672113039
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "During care transitions within the hospital, clinical teams align new prescriptions with previous treatment plans through medi- cal reconciliation. Although intended to be a safe process, almost one in three patients is subject to at least one medication error at admission or discharge. Current hospital systems do not ade- quately support collaborative work and instead of integrating into clinical workflows, they oftentimes require additional, potentially disruptive actions. The goal of my thesis is to explore how to build collaborative technologies for care transitions, illustrated by the example of medication management. I have conducted extensive field work in three different hospital environments, and identified how physicians repurpose distributed systems for informal commu- nication or dealing with information overload. Building on these insights, my next step involves conducting participatory design workshops with care providers and evaluate how to successfully design tools that take into account this appropriation. This thesis aims to contribute to the understanding how to design collaborative technologies for safety critical environments.\r\n",
    "title": "Developing Collaborative Technologies for Interdisciplinary Care Teams: What Does This Mean in the Case of Medication Reconciliation?",
    "id": 189238,
    "sequence": 1028,
    "queryCoordinates": {
      "visualization": [
        0.39259815759068667,
        9.992290362407228
      ]
    }
  },
  {
    "session": "Storytelling and Sense-Making",
    "abstract": "Creating promotional posts on social platforms enables everyday users to disseminate their creative outcomes, engage in community exchanges, or generate additional income from micro-businesses. However, crafting eye-catching posts with appealing images and effective captions can be challenging and time-consuming for everyday users since they are mostly design novices. We propose Influencer, an interactive tool that helps novice creators quickly generate ideas and create high-quality promotional post designs through AI. Influencer offers a multi-dimensional recommendation system for ideation through example-based image and caption suggestions. Further, Influencer implements a holistic promotional post-design system supporting context-aware exploration considering brand messages and user-specified design constraints, flexible fusion of content, and a mind-map-like layout for idea tracking. Our user study, comparing the system with industry-standard tools, along with two real-life case studies, indicates that Influencer is effective in assisting design novices to generate ideas as well as creative and diverse promotional posts with user-friendly interaction.",
    "title": "Influencer: Empowering Everyday Users in Creating Promotional Posts via AI-infused Exploration and Customization",
    "id": 189239,
    "sequence": 1029,
    "queryCoordinates": {
      "visualization": [
        4.260230170558842,
        14.382296023022896
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "Creative Problem-Solving (CPS) promotes creative and critical thinking while enhancing real-world problem-solving skills, making it essential for middle school education. However, providing personalized mentorship in CPS projects at scale is challenging due to resource constraints and diverse student needs. To address this, we developed Mentigo, an AI-driven mentor agent designed to guide middle school students through the CPS process. Using a dataset of real classroom interactions, we encoded CPS task stages, adaptive guidance strategies, and personalized feedback mechanisms to inform Mentigo`s dynamic mentoring framework powered by large language models (LLMs). A comparative experiment with 12 students and evaluations from five expert educators demonstrated improved student engagement, creativity, and task performance. Our findings highlight design implications for using LLM-based AI mentors to enhance CPS learning in educational environments.",
    "title": "Mentigo: An Intelligent Agent for Mentoring Students in the Creative Problem Solving Process",
    "id": 189240,
    "sequence": 1030,
    "queryCoordinates": {
      "visualization": [
        -12.852000358697945,
        -1.95603854257218
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "As the global population ages, comprehensively assessing older adults' physical, cognitive, and social capacities is increasingly crucial for guiding care decisions and resource allocation. While technology shows promise in enhancing these assessments, there is limited understanding of how practitioners conduct such assessments and how they perceive and experience assessment technologies in real-world settings. This paper presents an exploratory study of the practices and experiences of practitioners in China’s Ability Assessment of Older Adults (AAOA), based on 28 on-site observations and in-depth interviews with eight assessors in a large southeastern city. Our findings reveal the adaptive workflows, strategies, and diverse challenges faced by assessors, highlighting the complexity, context-specificity, and collaborative nature of these processes. While grounded in China’s evolving healthcare system, these findings also resonate with broader global challenges in aging care, particularly in resource-constrained settings. Based on these insights, we propose implications for designing practical assessment technologies and considerations for better supporting assessors and older adults across care contexts.",
    "title": "\"Watch, Smell, Ask, Touch\": Practices, Challenges, and Technological Support in Ability Assessment of Older Adults from Practitioners' Perspectives in China",
    "id": 189241,
    "sequence": 1031,
    "queryCoordinates": {
      "visualization": [
        -4.992701457272382,
        -13.0794851641244
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "Generative AI has enabled novice designers to quickly create professional-looking visual representations for product concepts. However, novices have limited domain knowledge that could constrain their ability to write prompts that effectively explore a product design space. To understand how experts explore and communicate about design spaces, we conducted a formative study with 12 experienced product designers and found that experts — and their less-versed clients — often use visual references to guide co-design discussions rather than written descriptions. These insights inspired DesignWeaver, an interface that helps novices generate prompts for a text-to-image model by surfacing key product design dimensions from generated images into a palette for quick selection. In a study with 52 novices, DesignWeaver enabled participants to craft longer prompts with more domain-specific vocabularies, resulting in more diverse, innovative product designs. However, the nuanced prompts heightened participants' expectations beyond what current text-to-image models could deliver. We discuss the implications of AI-based product design support tools.",
    "title": "DesignWeaver: Dimensional Scaffolding for Text-to-Image Product Design",
    "id": 189242,
    "sequence": 1032,
    "queryCoordinates": {
      "visualization": [
        -19.3519818472052,
        -5.04983154030315
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "The overview-detail design pattern, characterized by an overview of multiple items and a detailed view of a selected item, is ubiquitously implemented across software interfaces. Designers often try to account for all users, but ultimately these interfaces settle on a single form. For instance, an overview map may display hotel prices but omit other user-desired attributes. This research instead explores the malleable overview-detail interface, one that end-users can customize to address individual needs. Our content analysis of overview-detail interfaces uncovered three dimensions of variation: content, composition, and layout, enabling us to develop customization techniques along these dimensions. For content, we developed Fluid Attributes, a set of techniques enabling users to show and hide attributes between views and leverage AI to manipulate, reformat, and generate new attributes. For composition and layout, we provided solutions to compose multiple overviews and detail views and transform between various overview and overview-detail layouts. A user study on our techniques implemented in two design probes revealed that participants produced diverse customizations and unique usage patterns, highlighting the need and broad applicability for malleable overview-detail interfaces.",
    "title": "Malleable Overview-Detail Interfaces",
    "id": 189243,
    "sequence": 1033,
    "queryCoordinates": {
      "visualization": [
        -18.318276086023058,
        -5.043883547053373
      ]
    }
  },
  {
    "session": "Creative Tools",
    "abstract": "VR is often utilized for organizing virtual events such as meetings, conferences, and concerts; however, support for live production is lacking in most existing VR tools. We present XCam, a toolkit enabling mixed-initiative control over virtual camera systems---from fully manual control by users to increasingly automated, system-driven control with minimal user intervention. XCam's architectural design separates the concerns of object tracking, camera motion, and scene transition, giving more degrees of freedom to operators who can adjust the level of automation along all three dimensions. We used to conduct two studies: (1) interviews with six VR content creators probe into what aspects should and shouldn't be automated based on six applications developed with XCam; (2) three workshops with experts explore XCam's utility in live production of an interactive VR film sequence, a lecture on cinematography, and an alumni meeting in social VR. Expert feedback from our studies suggests how to balance automation and control, and the opportunities and limits of future AI-driven tools.",
    "title": "XCam: Mixed-Initiative Virtual Cinematography for Live Production of Virtual Reality Experiences",
    "id": 189244,
    "sequence": 1034,
    "queryCoordinates": {
      "visualization": [
        -16.633932607670353,
        3.5088867185306785
      ]
    }
  },
  {
    "session": "Ethics and Empowerment",
    "abstract": "Following a review of papers in the ACM DL on ethics and children, this paper shows the growth of interest in this area, summarises the literature found, and then, using detail from 26 papers that offer practical advice, distils a Child Centred Ethics Framework that maps literature onto ethical concerns in relation to the practical application of ethics with children.  The framework offers questions and solutions for researchers from the first inception of a project to the dissemination of the results back to the children. The framework is offered as an adjunct to an ethics / IRB document in that it places the child's experience at the centre of decision-making allowing fuller exploration of aspects like assent, anonymity, inclusion and contribution.  As a practical resource that researchers can use, the framework is presented as a living document waiting to be owned by the community.",
    "title": "Child Centred Ethics (CCE): A Practical Framework for Enhanced Child Participation in HCI",
    "id": 189245,
    "sequence": 1035,
    "queryCoordinates": {
      "visualization": [
        -6.635496031291117,
        -6.080311868540941
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "PDF inaccessibility is an ongoing challenge that hinders individuals with visual impairments from reading and navigating PDFs using screen readers. This paper presents a step-by-step process for both novice and experienced users to create accessible PDF documents, including an approach for creating alternative text for mathematical formulas without expert knowledge. In a study involving nineteen participants, we evaluated our prototype PAVE 2.0 by comparing it against Adobe Acrobat Pro, the existing standard for remediating PDFs. Our study shows that experienced users improved their tagging scores from 42.0% to 80.1%, and novice users from 39.2% to 75.2% with PAVE 2.0. Overall, fifteen participants stated that they would prefer to use PAVE 2.0 in the future, and all participants would recommend it for novice users. Our work demonstrates PAVE 2.0's potential for increasing PDF accessibility for people with visual impairments and highlights remaining challenges.",
    "title": "Towards More Accessible Scientific PDFs for People with Visual Impairments: Step-by-Step PDF Remediation to Improve Tag Accuracy",
    "id": 189246,
    "sequence": 1036,
    "queryCoordinates": {
      "visualization": [
        10.061064342953461,
        -16.117536545233904
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "Access to public spaces is of the utmost importance for social cohesion, inclusion, and civic engagement. Nevertheless, a large majority of public spaces remain incredibly uncomfortable environments for neurodivergent individuals due to, for instance, the unpredictability of such spaces and the sensory stimuli within them. Smart City technologies present an exciting opportunity to improve the accessibility and enjoyment of the spaces where they are deployed by, for instance, offering users the ability to customise a space to their specific sensory needs. However, the research topic of public space technologies for neurodivergent individuals remains scattered and sparsely documented. This critical review analyses the existing domains of inquiry, contributing a theoretical framework based on Spatial Justice and Neuroqueer Technoscience and suggests future research avenues informed by this framework. We advocate for the participatory co-creation of a neurodivergent-affirming landscape of public space technologies that both support neurodivergent needs and promote neurodivergent joy.",
    "title": "Towards Neuroqueer Spatial Justice: A Critical Literature Review of Public Space Technologies for Neurodivergent Populations",
    "id": 189247,
    "sequence": 1037,
    "queryCoordinates": {
      "visualization": [
        7.760250025556352,
        1.943841439226111
      ]
    }
  },
  {
    "session": "Methodology",
    "abstract": "The courtroom methodology is an adaptation of a market research technique that allows for the speed of a focus group with the more depth of understanding that usually comes from in-depth interviews and breadth of understanding that usually comes from surveys and other more wide-reaching methods. The elegance of this methodology is its adaptability, which allows for various configurations, modeled after a courtroom trial with different ‘lawyer groups’ presenting their cases, a neutral ‘jury’ determining a ‘verdict’ based on presented arguments, and a moderator managing and probing questions between and within groups, which is where the true value of this as a methodology is gained. A real example of this method as used by the YouTube Premium user experience team is detailed, as well as best practices and variants that can make this a go-to staple in one’s HCI and UX research toolbox.",
    "title": "The Verdict Is… : A Case Study Detailing the Courtroom Methodology as an Adaptable User Experience Research Method",
    "id": 189248,
    "sequence": 1038,
    "queryCoordinates": {
      "visualization": [
        -8.496093553872504,
        -12.361892829330227
      ]
    }
  },
  {
    "session": "WS24: Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "abstract": "Designing and developing user-friendly interfaces has long been a cornerstone of HCI research. However, we are now at a turning point for how user interfaces can be designed and evaluated with new AI-based models and tools. The latest AI models have shown capabilities to model user behaviors, automate end-user tasks, and even generate user interfaces. We are at a pivotal moment to reflect on current UI design and development practices and discuss the opportunities, challenges, and risks brought by AI. Both incremental improvements and transformative opportunities exist for designers, developers, and the hand-off process in between. In this proposed workshop, we encourage participants to envision AI-enabled UI prototyping tools, workflows, and practices. By bringing together academic researchers and industry practitioners, we aim to identify opportunities to enhance prototyping tools and reshape UI creation workflows for the future as well as discuss potential negative consequences of these tools.",
    "title": "Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "id": 189249,
    "sequence": 1039,
    "queryCoordinates": {
      "visualization": [
        -19.965312203694317,
        1.1774160730237897
      ]
    }
  },
  {
    "session": "Auditory UI",
    "abstract": "Non-speech sounds play an important role in setting the mood of a video and aiding comprehension. However, current non-speech sound captioning practices focus primarily on sound categories, which fails to provide a rich sound experience for d/Deaf and hard-of-hearing (DHH) viewers. Onomatopoeia, which succinctly captures expressive sound information, offers a potential solution but remains underutilized in non-speech sound captioning. This paper investigates how onomatopoeia benefits DHH audiences in non-speech sound captioning. We collected 7,962 sound-onomatopoeia pairs from listeners and developed a sound-onomatopoeia model that automatically transcribes sounds into onomatopoeic descriptions indistinguishable from human-generated ones. A user evaluation of 25 DHH participants using the model-generated onomatopoeia demonstrated that onomatopoeia significantly improved their video viewing experience. Participants most favored captions with onomatopoeia and category, and expressed a desire to see such captions across genres. We discuss the benefits and challenges of using onomatopoeia in non-speech sound captions, offering insights for future practices.",
    "title": "OnomaCap: Making Non-speech Sound Captions Accessible and Enjoyable through Onomatopoeic Sound Representation",
    "id": 189250,
    "sequence": 1040,
    "queryCoordinates": {
      "visualization": [
        4.988817673815268,
        -3.3334213981176175
      ]
    }
  },
  {
    "session": "Social Media and Online Influence",
    "abstract": "Rapid spread of harmful misinformation has led to a dire need for effective media literacy interventions, to which educational games have been suggested as a possible solution. Researchers and educators have created several games that increase media literacy and resilience to misinformation. However, the existing body of misinformation education games rarely focus upon the socio-emotional influences that factor into misinformation belief. Misinformation correction and serious games have both explored narrative as a method to engage with people on an emotional basis. To this end, we investigated how 123 young adults (mean age = 22.98) experienced narrative transportation and identification in two narrative-centered misinformation escape room games developed for library settings. We found that propensity for certain misinformation contexts, such as engagement with fan culture and likelihood to share on social media platforms, significantly affected how participants experienced specific measures of narrative immersion within the games. We discuss design implications for tailoring educational interventions to specific misinformation contexts. ",
    "title": "Does the Story Matter? Applying Narrative Theory to an Educational Misinformation Escape Room Game",
    "id": 189251,
    "sequence": 1041,
    "queryCoordinates": {
      "visualization": [
        20.82034208885002,
        -2.7410500366210853
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "Expressing stressful experiences in words is proven to improve mental and physical health, but individuals often disengage with writing interventions as they struggle to organize their thoughts and emotions. Reflective prompts have been used to provide direction, and large language models (LLMs) have demonstrated the potential to provide tailored guidance. However, current systems often limit users' flexibility to direct their reflections. We thus present ExploreSelf, an LLM-driven application designed to empower users to control their reflective journey, providing adaptive support through dynamically generated questions. Through an exploratory study with 19 participants, we examine how participants explore and reflect on personal challenges using ExploreSelf. Our findings demonstrate that participants valued the flexible navigation of adaptive guidance to control their reflective journey, leading to deeper engagement and insight. Building on our findings, we discuss the implications of designing LLM-driven tools that facilitate user-driven and effective reflection of personal challenges.",
    "title": "ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models",
    "id": 189252,
    "sequence": 1042,
    "queryCoordinates": {
      "visualization": [
        6.902159081189372,
        8.565056918547308
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "Smartphones with large screens provide users with increased display and interaction space but pose challenges in reaching certain areas with the thumb when using the device with one hand. To address this, we introduce GazeSwipe, a multimodal interaction technique that combines eye gaze with finger-swipe gestures, enabling intuitive and low-friction reach on mobile touchscreens. Specifically, we design a gaze estimation method that eliminates the need for explicit gaze calibration. Our approach also avoids the use of additional eye-tracking hardware by leveraging the smartphone's built-in front-facing camera. Considering the potential decrease in gaze accuracy without dedicated eye trackers, we use finger-swipe gestures to compensate for any inaccuracies in gaze estimation. Additionally, we introduce a user-unaware auto-calibration method that improves gaze accuracy during interaction. Through extensive experiments on smartphones and tablets, we compare our technique with various methods for touchscreen reachability and evaluate the performance of our auto-calibration strategy. The results demonstrate that our method achieves high success rates and is preferred by users. The findings also validate the effectiveness of the auto-calibration strategy.",
    "title": "GazeSwipe: Enhancing Mobile Touchscreen Reachability through Seamless Gaze and Finger-Swipe Integration",
    "id": 189253,
    "sequence": 1043,
    "queryCoordinates": {
      "visualization": [
        -16.88673440470715,
        -1.9591327532558562
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "We explore the feasibility of active user-applied locomotion in virtual reality (VR) within in-car environments, diverging from previous in-car VR research that synchronized virtual motion with the car's movement. Through a two-step study, we examined the effects of locomotion methods on user experience in dynamic vehicle environments and evaluated contextual cues designed to mitigate sensory mismatch caused by vehicle motion. The first study evaluated five locomotion methods, identifying joystick-based navigation as the most suitable for in-car use due to its low physical demand and stability. The second study focused on designing and testing contextual cues that translate physical sensations of vehicle motion into virtual effects without limiting the user’s freedom of movement, with results demonstrating their effectiveness in reducing motion sickness and enhancing presence. We conclude with initial insights and design considerations for expanding upon our findings in regards to enabling active locomotion in in-car VR.",
    "title": "I Want to Break Free: Enabling User-Applied Active Locomotion in In-Car VR through Contextual Cues",
    "id": 189254,
    "sequence": 1044,
    "queryCoordinates": {
      "visualization": [
        12.22254512643124,
        -18.292331470656
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "Team closeness provides the foundations of trust and communication, contributing to teams' success and viability. However, newcomers often struggle to be included in a team since incumbents tend to interact more with other existing members. Previous research suggests that online communication technologies can help team inclusion by mitigating members' perceived differences. In this study, we test how virtual reality (VR) can promote team closeness when forming teams. We conducted a between-subject experiment with teams working in-person and VR, where two members interacted first, and then a third member was added later to conduct a hidden-profile task. Participants evaluated how close they felt with their teammates after the task was completed. Our results show that VR newcomers felt closer to the incumbents than in-person newcomers. However, incumbents' closeness to newcomers did not vary across conditions. We discuss the implications of these findings and offer suggestions for how VR can promote inclusion.\r\n",
    "title": "Breaking the Familiarity Bias: Employing Virtual Reality Environments to Enhance Team Formation and Inclusion",
    "id": 189255,
    "sequence": 1045,
    "queryCoordinates": {
      "visualization": [
        5.372471638776147,
        -5.927609002839673
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "This paper presents intermediate-level knowledge in the form of a taxonomy that highlights 12 different ways in which interactive tech might support forest-related experiences that are joyful for humans. It can inspire and provide direction for designs that aim to enrich the experiential texture of forests. The taxonomy stemmed from a reflexive analysis of 104 speculative ideas produced during a year-long co-design process, where we co-experienced and creatively engaged a diverse range forests and forest-related activities with 250+ forest-goers with varied backgrounds and sensitivities. Given that breadth of forests and populations involved, our work foregrounds a rich set of design directions that set an actionable early frame for creating tech that supports joyful human-forest interplays – one that we hope will be extended and consolidated in future research, ours and others'.",
    "title": "How Can Interactive Technology Help Us to Experience Joy With(in) the Forest? Towards a Taxonomy of Tech for Joyful Human-Forest Interactions",
    "id": 189256,
    "sequence": 1046,
    "queryCoordinates": {
      "visualization": [
        16.519541499710964,
        -9.386412980437585
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "Creating custom artifacts with computer numerical control (CNC) milling machines typically requires mastery of complex computer-aided design (CAD) software. To eliminate this user barrier, we introduced Draw2Cut, a novel system that allows users to design and fabricate artifacts by sketching directly on physical materials. Draw2Cut employs a custom-drawing language to convert user-drawn lines, symbols, and colors into toolpaths, thereby enabling users to express their creative intent intuitively. The key features include real-time alignment between material and virtual toolpaths, a preview interface for validation, and an open-source platform for customization. Through technical evaluations and user studies, we demonstrate that Draw2Cut lowers the entry barrier for personal fabrication, enabling novices to create customized artifacts with precision and ease. Our findings highlight the potential of the system to enhance creativity, engagement, and accessibility in CNC-based woodworking.",
    "title": "Draw2Cut: Direct On-Material Annotations for CNC Milling",
    "id": 189257,
    "sequence": 1047,
    "queryCoordinates": {
      "visualization": [
        -4.923789310689837,
        9.836477968456824
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "Desk workers may often experience more negative than positive emotions in office settings, making emotion regulation (ER) crucial for their mental health. Squeezable interfaces have shown the potential to reduce anxiety and stress in digital and non-digital ER. However, few studies have explored how they can be leveraged to provide tangible and embodied support for workplace ER.\r\n\r\nWe interviewed five mental health experts and 16 desk workers and conducted five co-design workshops with 17 desk workers, aiming to understand how validated practices can be integrated into squeezable interfaces and how they should be designed to support ER and accommodate diverse needs in the context of the workplace. This study contributes to digital ER by identifying design opportunities for squeezable interfaces and by outlining design considerations and challenges for tangible and embodied interactions in ER support within the workplace.",
    "title": "Squeeze Away the Worries: Exploring the Potential of Squeezable Interactions for Emotion Regulation for Desk Workers",
    "id": 189258,
    "sequence": 1048,
    "queryCoordinates": {
      "visualization": [
        19.688531361797832,
        3.5159255986870903
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "People frequently exposed to health information on social media tend to overestimate their symptoms during online self-diagnosis due to availability bias. This may lead to incorrect self-medication and place additional burdens on healthcare providers to correct patients' misconceptions. In this work, we conducted two mixed-method studies to identify design goals for mitigating availability bias in online self-diagnosis. We investigated factors that distort self-assessment of symptoms after exposure to social media. We found that availability bias is pronounced when social media content resonated with individuals, making them disregard their own evidences. To address this, we developed and evaluated three chatbot-based symptom checkers designed to foster evidence-based self-reflection for bias mitigation given their potential to encourage thoughtful responses. Results showed that chatbot-based symptom checkers with cognitive intervention strategies mitigated the impact of availability bias in online self-diagnosis.",
    "title": "Mining Evidence about Your Symptoms: Mitigating Availability Bias in Online Self-Diagnosis",
    "id": 189259,
    "sequence": 1049,
    "queryCoordinates": {
      "visualization": [
        7.289409997582997,
        -18.624298695176073
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "We introduce M^2Silent, which enables multi-user silent speech interactions in shared spaces using multi-directional speakers. Ensuring privacy during interactions with voice-controlled systems presents significant challenges, particularly in environments with multiple individuals, such as libraries, offices, or vehicles. M^2Silent addresses this by allowing users to communicate silently, without producing audible speech, using acoustic sensing integrated into directional speakers. We leverage FMCW signals as audio carriers, simultaneously playing audio and sensing the user's silent speech. To handle the challenge of multiple users interacting simultaneously, we propose time-shifted FMCW signals and blind source separation algorithms, which help isolate and accurately recognize the speech features of each user. We also present a deep-learning model for real-time silent speech recognition. M^2Silent achieves Word Error Rate (WER) of 6.5% and Sequence Error Rate (SER) of 12.8% in multi-user silent speech recognition while maintaining high audio quality, offering a novel solution for privacy-preserving, multi-user silent interactions in shared spaces.",
    "title": "M^2Silent: Enabling Multi-user Silent Speech Interactions via Multi-directional Speakers in Shared Spaces",
    "id": 189260,
    "sequence": 1050,
    "queryCoordinates": {
      "visualization": [
        -1.937848579973944,
        -6.7264212536156975
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "Bereavement often places a psychological burden on families and should be addressed appropriately. Although end-of-life care is a collaborative activity with interaction between family caregivers and medical professionals, further research is needed to explore family caregivers’ support needs as collaborative workers and the challenges they face. This study examined the collaboration during the end-of-life process between family caregivers and medical professionals to understand the cooperative activities and factors surrounding them based on unrealized or regrettable experiences during end-of-life care. Semi-structured interviews with bereaved family caregivers who provided end-of-life care and medical professionals who provided support revealed that family caregivers’ aspirations and medical professionals’ support for family caregivers crossed paths, steering end-of-life caregiving in an unintended direction. Characteristic work carried out by each actor in this situation is defined as \"unintended, percolated work\" and considered an overlooked collaboration opportunity, proposing support suggestions for handling family caregivers’ original intentions and needs.",
    "title": "Unintended, Percolated Work: Overlooked Opportunities for Collaboration Between Informal Caregivers and Healthcare Professionals During the End-Of-Life Care Process",
    "id": 189261,
    "sequence": 1051,
    "queryCoordinates": {
      "visualization": [
        -0.39267112332353205,
        -18.99594191897069
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "The contemporary AI development landscape is dominated by big corporations, lacks diversity, and mostly centres the Global North, or applies extractivist logics in the South. This paper showcases a feminist process of AI development from Latin America, where we created an interactive, AI-powered tool that helps criminal court officers open justice data, addressing a data gap on gender-based violence. Through a collaborative autoethnography, drawing from Latin American feminisms, we unpack and visibilize the feminist work that was required, as a crucial step to counter hegemonic narratives. Foregrounding the subjugated knowledges of our experiences, we offer a concrete example of a feminist approach to AI development grounded in practice. With this, we aim to critically inspire those who consider building technology in service of social justice causes, or who choose to build AI systems otherwise.",
    "title": "Doing the Feminist Work in AI: Reflections from an AI Project in Latin America",
    "id": 189262,
    "sequence": 1052,
    "queryCoordinates": {
      "visualization": [
        12.852000358697945,
        1.9560385425721787
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "Recent advances in large language models (LLM) offered human-like capabilities for comprehending emotion and mental states. Prior studies explored diverse prompt engineering techniques for improving classification performance, but there is a lack of analysis of prompt design space and the impact of each component. To bridge this gap, we conduct a qualitative thematic analysis of existing prompts for emotion and mental health classification tasks to define the key components for prompt design space. We then evaluate the impact of major prompt components, such as persona and task instruction, on classification performance by using four LLM models and five datasets. Modular prompt design offers new insights into examining performance variability as well as promoting transparency and reproducibility in LLM-based tasks within health and well-being intervention systems. ",
    "title": "Exploring Modular Prompt Design for Emotion and Mental Health Recognition",
    "id": 189263,
    "sequence": 1053,
    "queryCoordinates": {
      "visualization": [
        -7.249440417457269,
        16.47560662415005
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "Product design is an iterative process involving several kinds of drawing techniques. Analytic drawing, which involves the use of guidelines or scaffolds to draw the object's shape curves, aids in achieving precision and accuracy. Freehand drawing allows designers to add details without guidance. The set of scaffold, shape, and detail curves are heavily interrelated. As a result, once a draft set of curves is completed, modifications are extremely difficult. This impedes iterative exploration.\r\n\r\nWe propose to use scaffold manipulation in virtual reality to assist designers in exploring and modifying their product designs. Our key insight is that the same scaffolds designers create for analytic drawing provide an intuitive set of handles. Given a scaffolded 3D product sketch as input, our VR-based system allows designers to directly manipulate the scaffold lines and add detail strokes in any order. Whenever scaffold lines are edited, our system solves for a scaffold line configuration that preserves inter-scaffold relationships. The shape and detail curves are then deformed to match the new scaffold lines. This allows exploratory product design in which a simple template scaffolded 3D drawing is modified and detailed---and further modified---to create a variety of designs. We validated our approach with professional product designers.",
    "title": "A Scaffold-Based Tool for Product Design Variations in Virtual Reality",
    "id": 189264,
    "sequence": 1054,
    "queryCoordinates": {
      "visualization": [
        -6.425746102545527,
        -12.438238903704212
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "Presence is an important and widely used metric to measure the quality of virtual reality (VR) applications. Given the multifaceted and subjective nature of presence, the most common measures for presence are questionnaires. But there is little research on their validity regarding specific presence dimensions and their responsiveness to differences in perception among users. We investigated four presence questionnaires (SUS, PQ, IPQ, Bouchard) on their responsiveness to intensity variations of known presence dimensions and asked users about their consistency with their experience. Therefore, we created five VR scenarios that were designed to emphasize a specific presence dimension. Our findings showed heterogeneous sensitivity of the questionnaires dependent on the different dimensions of presence. This highlights a context-specific suitability of presence questionnaires. The questionnaires' sensitivity was further stated as lower than actually perceived. Based on our findings, we offer guidance on selecting these questionnaires based on their suitability for particular use cases.",
    "title": "When Do We Feel Present in a Virtual Reality? Towards Sensitivity and User Acceptance of Presence Questionnaires",
    "id": 189265,
    "sequence": 1055,
    "queryCoordinates": {
      "visualization": [
        2.73931367613958,
        -18.801493573216852
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "Modern algorithmic recommendation systems seek to engage users through behavioral content-interest matching. While many platforms recommend content\r\nbased on engagement metrics, others like TikTok deliver interest-based content, resulting in recommendations perceived to be hyper-personalized compared to other platforms. TikTok's robust recommendation engine has led some users\r\nto suspect that the algorithm knows users “better than they know themselves,\" but this is not always true. In this paper, we explore TikTok users’ perceptions of recommended content on their For You Page (FYP), specifically\r\ncalling attention to unwanted recommendations. Through qualitative interviews of 14 current and former TikTok users, we find themes of frustration with recommended content, attempts to rid themselves of unwanted content, and various degrees of success in eschewing such content. We discuss implications in the larger context of folk theorization and contribute concrete tactical and behavioral examples of \\textit{algorithmic persistence}.",
    "title": "“They’ve Over-Emphasized That One Search”: Controlling Unwanted Content on TikTok's For You Page",
    "id": 189266,
    "sequence": 1056,
    "queryCoordinates": {
      "visualization": [
        1.9547456807350525,
        -11.83971998501855
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "Empirical evidence shows that typing on touchscreen devices is prone to errors and that correcting them poses a major detriment to users’ performance. Design of text entry systems that better serve users, across their broad capability range, necessitates understanding the cognitive mechanisms that underpin these errors. However, prior models of typing cover only motor slips. The paper reports on extending the scope of computational modeling of typing to cover the cognitive mechanisms behind the three main types of error: slips (inaccurate execution), lapses (forgetting), and mistakes (incorrect knowledge). Given a phrase, a keyboard, and user parameters, Typoist simulates eye and finger movements while making human-like insertion, omission, substitution, and transposition errors. Its main technical contribution is the formulation of a supervisory control problem wherein the controller allocates cognitive resources to detect and fix errors generated by the various mechanisms. The model generates predictions of typing performance that can inform design, for better text entry systems.",
    "title": "Simulating Errors in Touchscreen Typing",
    "id": 189267,
    "sequence": 1057,
    "queryCoordinates": {
      "visualization": [
        10.197152635012317,
        -19.49405237856566
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Emotions, shaped by past experiences, significantly influence decision-making and goal pursuit. Traditional cognitive-behavioral techniques for personal development rely on mental imagery to envision ideal selves, but may be less effective for individuals who struggle with visualization. This paper introduces Emotional Self-Voice (ESV), a novel system combining emotionally expressive language models and voice cloning technologies to render customized responses in the user's own voice. We investigate the potential of ESV to nudge individuals towards their ideal selves in a study with 60 participants. Across all three conditions (ESV, text-only, and mental imagination), we observed an increase in resilience, confidence, motivation, and goal commitment, and the ESV condition was perceived as uniquely engaging and personalized. We discuss the implications of designing generated self-voice systems as a personalized behavioral intervention for different scenarios.",
    "title": "Leveraging AI-Generated Emotional Self-Voice to Nudge People towards their Ideal Selves",
    "id": 189268,
    "sequence": 1058,
    "queryCoordinates": {
      "visualization": [
        3.4909142771668997,
        12.52252041361771
      ]
    }
  },
  {
    "session": "Personal Data and Decision-Making",
    "abstract": "Data Humanism has gained prominence in personal visualization and Personal Informatics, advocating for a subjective and slow approach to engage with personal data. Collaborative sensemaking has great potential for understanding personal data, yet little is known about addressing requirements of structure and coordination when integrating Data Humanism into collaborative visualization. In this paper, we propose a set of design principles for collaborative visualizations to be both subjective and effective, while coordinating the slow sensemaking process and promoting data awareness and communication. We operationalize these principles into a personal visualization toolkit, which we evaluate with an observational study involving 16 university students (8 pairs) analyzing each other's screen-time data. Our findings reveal that implementing the proposed design principles: (1) facilitated data comparison from shared subjective perspectives, (2) helped coordinate sensemaking while allowing time for understanding personal data, and (3) helped the contextualization of data patterns, in turn aiding self-reflection.",
    "title": "Reciportrait: a Data Humanism Approach for Collaborative Sensemaking of Personal Data",
    "id": 189269,
    "sequence": 1059,
    "queryCoordinates": {
      "visualization": [
        15.65848546254648,
        -13.99327813699208
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Advanced AI models allow users to perform diverse tasks by simply expressing their high-level intents, without performing low-level operations.However, users can struggle to fully form and effectively express their intents, and inspecting and evaluating model outputs to verify whether their intents have been satisfied incurs significant cognitive load. My PhD research introduces the concept of intent manipulation, where user intents are externalized as interactive objects, allowing for direct exploration and iteration on both intents and model outputs. I explore three forms of intent manipulation: intent curation, disentangle intents into palettes users can curate their intent with; intent assembly, creating intent blocks that users can combine and experiment with; and intent framing, helping users inspect outputs through the lens of their intents. This work contributes to human-AI interaction by suggesting how interfaces can be designed to support iterative exploration and sensemaking of one's own intents and the AI models in parallel.",
    "title": "Interacting with AI by Manipulating Intents",
    "id": 189270,
    "sequence": 1060,
    "queryCoordinates": {
      "visualization": [
        -5.708926082714822,
        -4.050699073258639
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Research in human-agent interaction highlights the significance of agents’ politeness in enhancing social engagement and interaction satisfaction. It remains unclear, however, if agents should maintain politeness even in time-constraint situations. This study explores how a voice agent should deliver instructions for emergency evacuation using a between-subjects experiment in which we manipulated agent speech style (politeness: positive vs. negative vs. direct) and voice tone (urgency: high vs. low) and measured the effects on users’ perceptions of the agent and their cognitive workload. We found that the urgency of the agent's tone had a positive effect on the perceived anthropomorphism, likability, and intelligence of the agent while reducing the required effort and frustration to complete the tasks. Urgent voices increased the cognitive trust and likeability of the agent when the agent used negative politeness for instructions. Our findings provide guidelines for designing voice agents for emergencies.",
    "title": "Should Voice Agents Be Polite in an Emergency? Investigating Effects of Speech Style and Voice Tone in Emergency Simulation",
    "id": 189271,
    "sequence": 1061,
    "queryCoordinates": {
      "visualization": [
        18.898634622151608,
        1.960002402654781
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "Many design researchers have been exploring what it means to take a more-than-human design approach in their practice. In particular, the technique of “noticing” has been explored as a way of intentionally opening a designer’s awareness to more-than-human worlds. In this paper we present autoethnographic accounts of our own efforts to notice solar energy. Through two studies we reflect on the transformative potential of noticing the more-than-human, and the difficulties in trying to sustain this change in oneself and one’s practice. We propose that noticing can lead to activating exiled capacities within the noticer, relational abilities that lie dormant in each of us. We also propose that emphasising sense-fullness in and through design can be helpful in the face of broader psychological or societal boundaries that block paths towards more relational ways of living with non-humans.  ",
    "title": "What Comes After Noticing?: Reflections on Noticing Solar Energy and What Came Next",
    "id": 189272,
    "sequence": 1062,
    "queryCoordinates": {
      "visualization": [
        6.190939493098339,
        7.853169308807449
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "When several individuals collaborate on a shared task, their brain activities often synchronize. This phenomenon, known as Inter-brain Synchronization (IBS), is notable for inducing prosocial outcomes such as enhanced interpersonal feelings, including closeness, trust, empathy, and more. Further strengthening the IBS with the aid of external feedback would be beneficial for scenarios where those prosocial feelings play a vital role in interpersonal communication, such as rehabilitation between a therapist and a patient, motor skill learning between a teacher and a student, and group performance art. This paper investigates whether visual, auditory, and haptic feedback of the IBS level can further enhance its intensity, offering design recommendations for feedback systems in IBS. We report findings when three different types of feedback were provided: IBS level feedback by means of on-body projection mapping, sonification using chords, and vibration bands attached to the wrist.",
    "title": "NeuResonance: Exploring Feedback Experiences for Fostering the Inter-brain Synchronization",
    "id": 189273,
    "sequence": 1063,
    "queryCoordinates": {
      "visualization": [
        -1.1773424979433096,
        -18.963487670851492
      ]
    }
  },
  {
    "session": "XR Interaction",
    "abstract": "Flights in general aviation require pilots to navigate using 2D maps, which splits their attention between the cockpit and the outside environment, reducing situation awareness.\r\nAugmented reality (AR) can bridge the gap between the inside and outside world, and thus can resolve the issue of attention switches. In a mixed methods simulator study with 19 pilots, we tested an AR application that integrated invisible and hard-to-see aeronautical data and navigation features with the visible world. Results show that the AR tool enhances and accelerates orientation, and can result in flight trajectories being more accurate with AR than without AR. Situation awareness, measured with a subjective self-rating, was not increased with AR support. Participants voiced concerns about AR content occluding outside features, while positive feedback included use cases in unfamiliar areas and in low visibility, as well as highlighting of hazards.",
    "title": "Next-Generation Navigation: Evaluating the Impact of Augmented Reality on Situation Awareness in General Aviation Cockpits",
    "id": 189274,
    "sequence": 1064,
    "queryCoordinates": {
      "visualization": [
        -4.240636259871298,
        12.288897595450324
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "Prosocial behaviors, such as helping others, are well-known to enhance human well-being. While there is a growing trend of humans helping AI agents, it remains unclear whether the well-being benefits of helping others extend to interactions with non-human entities. To address this, we conducted an experiment (N = 295) to explore how helping AI agents impacts human well-being, especially when the agents fulfill human basic psychological needs—relatedness, competence, and autonomy—during the interaction. Our findings showed that helping AI agents reduced participants' feelings of loneliness. When AI met participants’ needs for competence and autonomy during the helping process, there was a further decrease in loneliness and an increase in positive affect. However, when AI did not meet participants' need for relatedness, participants experienced an increase in positive affect. We discuss the implications of these findings for understanding how AI can support human well-being.",
    "title": "The Benefits of Prosociality towards AI Agents: Examining the Effects of Helping AI Agents on Human Well-Being",
    "id": 189275,
    "sequence": 1065,
    "queryCoordinates": {
      "visualization": [
        -1.8855869473039915,
        -3.5276850573934198
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "Navigating is essential in many video games. However, previous work suggests that many games still suffer from navigational problems that decrease enjoyment. In this paper, we focus on \"Desire Paths\", informal trails collectively created by pedestrians representing the most convenient route. While they are known to be useful wayfinding aids, it is unclear how they affect navigation and experience in games. We therefore investigated diegetically visualized player trajectory data in a 2D game through virtual footprints that were persistently visible for all subsequent players. Through a mixed-methods study involving 50 participants, we found that virtual footprints improved navigation by guiding players to points of interest and reducing disorientation for early players. However, visual clutter from excessive footprints reduced their effectiveness in later stages. They also fostered a sense of community, especially for late-stage players and prompted exploration of yet undiscovered areas. We further discuss design implications and future research directions.",
    "title": "Pathways of Desire: Enhancing Navigation and Sense of Community Through Player-Generated Desire Paths",
    "id": 189276,
    "sequence": 1066,
    "queryCoordinates": {
      "visualization": [
        8.014976662062809,
        -18.323759142342723
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "While interest in blending sound with culinary experiences has grown in Human-Food Interaction (HFI), the significance of food’s material properties in shaping sound-related interactions has largely been overlooked. This paper explores the opportunity to enrich the HFI experience by treating food not merely as passive nourishment but as an integral material in computational architecture with input/output capabilities. We introduce “Sonic Delights,” where food is a comestible auditory-gustatory interface to enable users to interact with and consume digital sound. This concept redefines food as a conduit for interactive auditory engagement, shedding light on the untapped multisensory possibilities of merging taste with digital sound. An associated study allowed us to articulate design insights for forthcoming HFI endeavors that seek to weave food into multisensory design, aiming to further the integration of digital interactivity with the culinary arts.",
    "title": "Sonic Delights: Exploring the Design of Food as An Auditory-Gustatory Interface",
    "id": 189277,
    "sequence": 1067,
    "queryCoordinates": {
      "visualization": [
        -3.496870694341175,
        -13.55624930971166
      ]
    }
  },
  {
    "session": "Diversity",
    "abstract": "Spectating sports matches or concerts is a popular activity, but these public live events have yet to become more accessible to people with disabilities. Inspecting the corresponding interactive seat plan before purchasing tickets online can be necessary to avoid or prepare for barriers at these venues. Unfortunately, these representations often lack valuable accessibility information. To explore how this can affect the disabled community, we leverage autoethnography to provide an in-depth introspective account through the lens of a person with a mobility disability. We apply Thematic Analysis to synthesise field notes from his research diary. The crafted themes showcase the lacking accessibility support in seat plans and illustrate the first author’s adaptation strategies to facilitate accessible experiences. We further contextualise his social relationships as a key factor throughout this process. Grounded in these results, we reflect on the provision of accessibility information, the categorisation of seats, and interdependent relationships within and through these systems.",
    "title": "\"Is This Seat Accessible for Me?\": An Autoethnography of a Person With a Mobility Disability Using Interactive Seat Plans for Public Events",
    "id": 189278,
    "sequence": 1068,
    "queryCoordinates": {
      "visualization": [
        -6.861828880002177,
        -4.112821953545772
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "This research examines the tactics employed by digital archive projects focused on Himalayan histories and cultures to navigate knowledge conflicts. While digital archives offer the means to provide visibility and increase the accessibility and recognition to marginalized communities, they inevitably give rise to knowledge conflicts, which may lead to epistemic injustices. Through interviews with contributors to Himalayan digital archives, we find that these projects attempt to navigate knowledge conflicts and address epistemic injustices by drawing on inclusive, participatory, and activist-oriented practices. We discuss the importance of surfacing conflicts when designing tools and practices for collaboration and cooperation within digital archives. Doing so, we argue, can help contextualize historical issues in the present and strengthen advocacy efforts against ongoing socio-environmental injustices. Finally, we highlight the opportunity for reconfiguring digital archives as digital commons to foster commoning practices and enable post-custodial, co-created, and self-governed archival infrastructures.",
    "title": "Digital Archives, Knowledge Conflicts, and Epistemic Injustices in the Himalayas",
    "id": 189279,
    "sequence": 1069,
    "queryCoordinates": {
      "visualization": [
        -10.555408354592712,
        13.32604046473649
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "Alcohol consumption poses a significant public health challenge, presenting serious risks to individual health and contributing to over 700 daily road fatalities worldwide. Digital interventions can play a crucial role in reducing these risks. However, reliable drunk driving detection systems are vital to effectively deliver these interventions. To develop and evaluate such a system, we conducted an interventional study on a test track to collect real vehicle data from 54 participants. Our system reliably identifies non-sober driving with an area under the receiver operating characteristic curve (AUROC) of 0.84 ± 0.11 and driving above the WHO-recommended blood alcohol concentration limit of 0.05 g/dL with an AUROC of 0.80 ± 0.10. Our models rely on well-known physiological drunk driving patterns. To the best of our knowledge, we are the first to (1) rigorously evaluate the potential of (2) driver monitoring cameras and real-time vehicle data for detecting drunk driving in a (3) real vehicle.",
    "title": "Moving Beyond the Simulator: Interaction-Based Drunk Driving Detection in a Real Vehicle Using Driver Monitoring Cameras and Real-Time Vehicle Data",
    "id": 189280,
    "sequence": 1070,
    "queryCoordinates": {
      "visualization": [
        11.640574572235634,
        -7.7779832622744305
      ]
    }
  },
  {
    "session": "XR for Diverse Needs",
    "abstract": "Prior research has highlighted numerous accessibility barriers within virtual reality software, with guidelines emerging to address the requirements of diverse audiences. However, an empirical understanding of industry practitioner implementation of accessible guidelines within mainstream commercial applications is currently lacking. This review addresses this gap by categorising all accessibility features presented at a software-level in 330 of the most used virtual reality applications released between 2016 to 2023 on the Steam, Meta, Oculus, Viveport, and SideQuest platforms. Results suggest a growing lack of interaction customisation, with the number of applications allowing for alternative inputs and physical posture flexibility decreasing. Meanwhile, display output settings, such as text font resizing and colourblind alterations, are almost completely absent. Our findings highlight the evolution in the implementation of accessible features in virtual reality software, contributing to a representative overview of practitioner decisions, and acting as a catalyst towards the establishment of industry-wide guidelines.",
    "title": "Asleep at the Virtual Wheel: The Increasing Inaccessibility of Virtual Reality Applications",
    "id": 189281,
    "sequence": 1071,
    "queryCoordinates": {
      "visualization": [
        -5.0189078463822625,
        15.192450889488587
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "The proliferation of LLM-based conversational agents has resulted in excessive disclosure of identifiable or sensitive information. However, existing technologies fail to offer perceptible control or account for users’ personal preferences about privacy-utility tradeoffs due to the lack of user involvement. To bridge this gap, we designed, built, and evaluated Rescriber, a browser extension that supports user-led data minimization in LLM-based conversational agents by helping users detect and sanitize personal information in their prompts. Our studies (N=12) showed that Rescriber helped users reduce unnecessary disclosure and addressed their privacy concerns. Users’ subjective perceptions of the system powered by Llama3-8B were on par with that by GPT-4o. The comprehensiveness and consistency of the detection and sanitization emerge as essential factors that affect users’ trust and perceived protection. Our findings confirm the viability of smaller-LLM-powered, user-facing, on-device privacy controls, presenting a promising approach to address the privacy and trust challenges of AI.",
    "title": "Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots",
    "id": 189282,
    "sequence": 1072,
    "queryCoordinates": {
      "visualization": [
        -5.98715353943162,
        0.3924187753808587
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "Video editors often record multiple versions of a performance with minor differences. When they add graphics atop one video, they may wish to transfer those assets to another recording, but differences in performance, wordings, and timings can cause assets to no longer be aligned with the video content. Fixing this is a time consuming, manual task. We present a technique which preserves the temporal and spatial alignment of the original composition when automatically retargeting speech-driven video compositions. It can transfer graphics between both similar and dissimilar performances, including those varying in speech and gesture. We use a large language model for transcript-based temporal alignment and integer programming for spatial alignment. Results from retargeting between 51 pairs of performances show that we achieve a temporal alignment success rate of 90% compared to hand-generated ground truth compositions. We demonstrate challenging scenarios, retargeting video compositions across different people, aspect ratios, and languages.",
    "title": "VidSTR: Automatic Spatiotemporal Retargeting of Speech-Driven Video Compositions",
    "id": 189283,
    "sequence": 1073,
    "queryCoordinates": {
      "visualization": [
        5.927609002839671,
        -5.372471638776149
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "Navigating emotional conflicts within relationships can be challenging. People often struggle to express their emotions during a conflict, which can lead to misunderstandings and unresolved feelings. To facilitate deeper emotional expression, we developed TogetherReflect, a multi-user Virtual Reality (VR) experience designed for couples. Partners first draw their emotions related to a shared conflict in VR, allowing for individual expression and self-reflection. They then invite each other into their drawings to discuss their feelings, before drawing together on a shared canvas to reaffirm their love and commitment. Throughout this process, TogetherReflect provides prompts and guidance, aiming to foster self-reflection and communication skills. We exploratory evaluated the experience with 10 couples (n=20). Our findings indicate that TogetherReflect deepens personal emotional insights, fosters mutual understanding, and strengthens relational bonds. We highlight the potential of guided VR experiences to transform conflict resolution in intimate relationships and offer design considerations for future development.",
    "title": "TogetherReflect: Supporting Emotional Expression in Couples Through a Collaborative Virtual Reality Experience",
    "id": 189284,
    "sequence": 1074,
    "queryCoordinates": {
      "visualization": [
        10.782766458219994,
        -16.844344674325736
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "With the recent advancements in Large Language Models (LLMs), web developers increasingly apply their code-generation capabilities to website design. However, since these models are trained on existing designerly knowledge, they may inadvertently replicate bad or even illegal practices, especially deceptive designs (DD). This paper examines whether users can accidentally create DD for a fictitious webshop using GPT-4. We recruited 20 participants, asking them to use ChatGPT to generate functionalities (product overview or checkout) and then modify these using neutral prompts to meet a business goal (e.g., \"increase the likelihood of us selling our product\"). We found that all 20 generated websites contained at least one DD pattern (mean: 5, max: 9), with GPT-4 providing no warnings. When reflecting on the designs, only 4 participants expressed concerns, while most considered the outcomes satisfactory and not morally problematic, despite the potential ethical and legal implications for end-users and those adopting ChatGPT's recommendations.",
    "title": "\"Create a Fear of Missing Out\" – ChatGPT Implements Unsolicited Deceptive Designs in Generated Websites Without Warning",
    "id": 189285,
    "sequence": 1075,
    "queryCoordinates": {
      "visualization": [
        -20.557285263850616,
        4.289291617583284
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "As a marginalised group at increased risk of violence, trans people's perspectives on social media aid us in a nuanced understanding of current issues and consideration of more just futures. We conducted in-depth design interviews along participatory speculative activities around a utopian social media application with seven young trans participants to explore desirable and meaningful social media. Participants reported experiences of algorithmic and other forms of violence, and discussed frictions between safety and freedom as they described their embodied experiences of shifting spaces. We identify scale, commercialisation and automation as core issues, and challenge the potential of large-public, profile-centric social media spaces to support human flourishing. Drawing from aspects of social media participants consider desirable and meaningful, we discuss the idea of a shift towards interest-centric, community-oriented spaces that prioritise interactions based on solidarity over those based on identity.",
    "title": "Social Media as Marginalisation Machine: The Trans Desire for Solidarity Spaces",
    "id": 189286,
    "sequence": 1076,
    "queryCoordinates": {
      "visualization": [
        14.701407435386669,
        -16.366692378692697
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "Youth are particularly likely to encounter hateful internet content, which can severely impact their well-being. While most social media provide reporting mechanisms, in several countries, severe hateful content can alternatively be reported to law enforcement or dedicated reporting centers. However, in Germany, many youth never resort to reporting. While research in human-computer interaction has investigated adults' views on platform-based reporting, youth perspectives and platform-independent alternatives have received little attention. By involving a diverse group of 47 German adolescents and young adults in eight focus group interviews, we investigate how youth-sensitive reporting systems for hateful content can be designed. We explore German youth’s reporting barriers, finding that on platforms, they feel particularly discouraged by deficient rule enforcement and feedback, while platform-independent alternatives are rather unknown and perceived as time-consuming and disruptive. We further elicit their requirements for platform-independent reporting tools and contribute with heuristics for designing youth-sensitive and inclusive reporting systems.",
    "title": "Towards Youth-Sensitive Hateful Content Reporting: An Inclusive Focus Group Study in Germany",
    "id": 189287,
    "sequence": 1077,
    "queryCoordinates": {
      "visualization": [
        4.267404119598371,
        -15.42041705272704
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "Smart home technologies embed values such as sustainability, comfort, privacy, and security, which can sometimes conflict with one another, considering the complexities of domestic environments. This paper investigates the potential implications of these value conflicts and the corresponding design challenges. Through an enactment session and co-speculations with professional actors, we explored what it means to navigate multiple values simultaneously, live with products that impose their own values, and manage value conflicts both with and among smart products. The findings challenge the seamless and harmonious vision of smart homes conceived by technologists, proposing shifts in the common narrative: from value alignment to value transparency, from service provision to mutual care, and from autonomy to responsiveness. We discuss that acknowledging value conflicts, rather than eliminating them, is an opportunity to gain a deeper understanding of users and home environments and guide the design of smart home technologies. ",
    "title": "Dramatic Things: Investigating Value Conflicts in Smart Home through Enactment and Co-speculation",
    "id": 189288,
    "sequence": 1078,
    "queryCoordinates": {
      "visualization": [
        -9.807852804032304,
        1.9509032201612861
      ]
    }
  },
  {
    "session": "Decision Making",
    "abstract": "Quadratic voting (QV) is a means of making collective decisions that include and reflect the intensity of individual voter preferences. While QV has mainly been applied to legislative case studies, it is our conjecture that QV also holds potential for decision-making processes taking place in cohousing communities. To explore this conjecture, we conducted a situated design case study in which we introduced QV into the decision-making process of the Community Land Trust H-buurt, Amsterdam (NL). Our case study includes four situated actions taken from an embedded position in the community, and yielded data ranging from screenshots, sketch notes and photos, to a QV tool, ballot issues and voting data. In this paper, we describe our case study in more detail, report and discuss our results, and present our conclusion that cohousing is ripe for QV as well as recommendations to operationalize QV in this domain.",
    "title": "The Potential of Quadratic Voting for Cohousing Communities: A Situated Design Case Study",
    "id": 189289,
    "sequence": 1079,
    "queryCoordinates": {
      "visualization": [
        6.50561835020653,
        -15.705952052691872
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "Advancements in large language models (LLMs) enable the development of interactive systems that enhance user engagement with cinematic content. We introduce \\textit{Cinema Multiverse Lounge}, a multi-agent conversational system where users interact with LLM-based agents embodying diverse film-related personas. We investigate how user interactions with these agents influence their film appreciation. Thirty participants engaged in three discussion sessions, freely selecting persona agents such as film characters, filmmakers, or anonymous audiences. We explored how users composed different combinations of personas, the factors affecting their engagement and interpretation, and how diverse perspectives influenced film appreciation. Results indicate that interactions with varied agents enhanced participants’ appreciation by enabling the exploration of multiple viewpoints and fostering deeper narrative engagement. Moreover, the unexpected clashes between different worldviews added a fresh and enjoyable layer to the interactions. Our findings provide empirical insights and design implications for developing multi-agent systems that support enriched media consumption experiences.",
    "title": "Cinema Multiverse Lounge: Enhancing Film Appreciation via Multi-Agent Conversations",
    "id": 189290,
    "sequence": 1080,
    "queryCoordinates": {
      "visualization": [
        -14.241717591081393,
        12.576703862931765
      ]
    }
  },
  {
    "session": "Designing, Making, Exploring",
    "abstract": "We report on the use case of an instrumented self-service lunch line of a research restaurant that gathers data about dining and diners, using scales, screens, and other collection instruments. The data collection is automated, but requires some participation or compliance from the diners. We developed and tested a non-intrusive LED cue system to guide diner behavior, evaluating its effectiveness through telemetry data, user observations and focus groups. Contrary to expectations, the system did not increase user compliance. To better understand user behavior, we applied context analysis, cognitive load, and affordance theories. The reflections of this research delivers a toolkit to support researchers in the human-computer interaction (HCI) field to analyze the factors for success/failure of guidance systems and/or guide the design of new such systems with high probability of success.",
    "title": "Designing a Toolkit for Evaluating HCI Guidance Systems in Physical Spaces: Case of Flavoria Research Lunch Line",
    "id": 189291,
    "sequence": 1081,
    "queryCoordinates": {
      "visualization": [
        -12.994069198363935,
        0.3926393614115548
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "Creating games together is both a playful and effective way to develop skills in computational thinking, collaboration, and more. However, game development can be challenging for younger developers who lack formal training. While teenage developers frequently turn to online communities for peer support, their experiences may vary. To better understand the benefits and challenges teens face within online developer communities, we conducted interviews with 18 teenagers who created games or elements in Roblox and received peer support from one or more online Roblox developer communities. Our findings show that developer communities provide teens with valuable resources for technical, social, and career growth. However, teenagers also struggle with inter-user conflicts and a lack of community structure, leading to difficulties in handling complex issues that may arise, such as financial scams. Based on these insights, we propose takeaways for creating positive and safe online spaces for teenage game creators. ",
    "title": "Leveling Up Together: Fostering Positive Growth and Safe Online Spaces for Teen Roblox Developers",
    "id": 189292,
    "sequence": 1082,
    "queryCoordinates": {
      "visualization": [
        19.11767109249287,
        -10.886443496351896
      ]
    }
  },
  {
    "session": "Vulnerable Populations",
    "abstract": "Child Sexual Abuse (CSA) remains a critical global issue, with the rise of online grooming posing new threats to young people’s safety. This paper presents the Cesagram platform, a gamified digital platform designed to prevent CSA by raising awareness of online grooming among children aged 11-14. The platform integrates interactive learning activities within a narrative-driven environment, featuring customizable avatars and four thematic districts. The effectiveness of the Cesagram platform combined with theoretical content was evaluated through 11 workshops involving 195 students from Lithuania and Greece, utilizing pre- and post-workshop questionnaires. Findings indicate that the workshops effectively improved participants' knowledge of CSA and grooming, while also promoting user engagement. This study underscores the potential of gamification in sensitive educational contexts, contributing to digital well-being and safety education.",
    "title": "Leveraging Gamification to Address Child Sexual Abuse: A Preliminary Evaluation of the Cesagram Platform",
    "id": 189293,
    "sequence": 1083,
    "queryCoordinates": {
      "visualization": [
        15.46020906725474,
        12.68786568327291
      ]
    }
  },
  {
    "session": "With AI",
    "abstract": "This case study explores the experiences of Microsoft employees, who are early adopters of multi-agent generative AI systems, as they experiment with these technologies to design, test, and deploy new tools attempting to bridge the gap between existing Microsoft products and emerging AI capabilities. Thirteen developers and creators participated in 60-minute semi-structured interviews to elicit their challenges, use cases, and lessons learned from their experimentation with multi-agent AI frameworks. A thematic qualitative analysis process was conducted to analyze the interview data. Participants reported building multi-agent AI tools to address tasks in team collaboration, productivity, customer support, creative processes, and security. Strategies for managing complexity, enhancing transparency, and balancing agent autonomy with human oversight were found to be important human-agent interaction design considerations. Findings from this study highlight the capabilities and limitations of specialized multi-agents within the contexts of participants' use cases and provide insights to inform the human-agent interaction design of future multi-agent generative AI systems.",
    "title": "Exploring Early Adopters' Use of AI Driven Multi-Agent Systems to Inform Human-Agent Interaction Design: Insights from Industry Practice",
    "id": 189294,
    "sequence": 1084,
    "queryCoordinates": {
      "visualization": [
        -1.1774160730237773,
        19.965312203694317
      ]
    }
  },
  {
    "session": "Well-being and Well-dying",
    "abstract": "In this paper, we share a case study of using critical disability studies to design for chronic illness. Specifically, we draw from the Political/Relational model of disability to explore designs for rest. Through a 6-week design collaboration, we brought together different design perspectives and worked through tensions between utility-oriented product design approaches and critical disability approaches for access. Our process yielded three design strategies: 1) moving from designing a product to designing a provocation; 2) using mapping as a process of building collective understanding of the built and social environment; and 3) re-imagining institutional practices around access as a starting point for design. We end by unpacking tensions in our design process and sharing some reflections on how to critically design for access in HCI.",
    "title": "Designing for Rest: Rethinking Access for / from Chronic Illness",
    "id": 189295,
    "sequence": 1085,
    "queryCoordinates": {
      "visualization": [
        -1.9547456807350778,
        -11.839719985018547
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "Sketch mapping is an effective technique to externalize and communicate spatial information. However, it has been limited to 2D mediums, making it difficult to represent 3D information, particularly for terrains with elevation changes. We present Sketch2Terrain, an intuitive generative-3D-sketch-mapping system combining freehand sketching with generative Artificial Intelligence that radically changes sketch map creation and representation using Augmented Reality. Sketch2Terrain empowers non-experts to create unambiguous sketch maps of natural environments and provides a homogeneous interface for researchers to collect data and conduct experiments. A between-subject study (N=36) revealed that generative-3D-sketch-mapping improved efficiency by 38.4%, terrain-topology accuracy by 12.5%, and landmark accuracy by up to 12.1%, with only a 4.7% trade-off in terrain-elevation accuracy compared to freehand 3D-sketch-mapping. Additionally, generative-3D-sketch-mapping reduced perceived strain by 60.5% and stress by 39.5% over 2D-sketch-mapping. These findings underscore potential applications of generative-3D-sketch-mapping for in-depth understanding and accurate representation of vertically complex environments. The implementation is publicly available.",
    "title": "Sketch2Terrain: AI-Driven Real-Time Terrain Sketch Mapping in Augmented Reality",
    "id": 189296,
    "sequence": 1086,
    "queryCoordinates": {
      "visualization": [
        9.386412980437578,
        -16.519541499710968
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "Woodworkers have to navigate multiple considerations when planning a project, including available resources, skill-level, and intended effort. Do it yourself (DIY) woodworkers face these challenges most acutely because of tight material constraints and a desire for custom designs tailored to specific spaces. To address these needs, we present XR-penter, an extended reality (XR) application that supports in situ, material-aware woodworking for casual makers. Our system enables users to design virtual scrap wood assemblies directly in their workspace, encouraging sustainable practices through the use of discarded materials. Users register physical material as virtual twins, manipulate these twins into an assembly in XR (while receiving feedback on material usage and alignment with their surroundings), and preview cuts needed for fabrication. We conducted a case study and feedback sessions demonstrating that XR-penter supports improvisational workflows in practice, and found that woodworkers who prioritize material-driven and adaptive workflows would benefit most from our system.\r\n",
    "title": "XR-penter: Material-Aware and In Situ Design of Scrap Wood Assemblies",
    "id": 189297,
    "sequence": 1087,
    "queryCoordinates": {
      "visualization": [
        20.703291388882953,
        3.517630689399465
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "AI literacy research has had great success in offering competencies that capture the knowledge and skills users and developers of AI need to have for a world full of AI, helping them maximize its benefits and minimize its harms. However, recent years have witnessed other roles beyond users and developers whose responsibilities have been complicated by AI. In this work, we apply a service design approach to identify such roles and their responsibilities across various AI applications. By mapping the responsibilities to current AI literacy competencies, we exposed gaps suggesting unmet learning needs in current AI literacy research: identifying and assessing AI benefits, strategizing about AI’s benefits and risks, and monitoring and refining deployed AI to understand their changing impact. We discuss implications for future AI literacy research and its connection to Responsible AI research.",
    "title": "Exploring What People Need to Know to be AI Literate: Tailoring for a Diversity of AI Roles and Responsibilities",
    "id": 189298,
    "sequence": 1088,
    "queryCoordinates": {
      "visualization": [
        3.3334213981176144,
        4.988817673815271
      ]
    }
  },
  {
    "session": "Biosensing for Interactions",
    "abstract": "Understanding user input preferences is crucial in immersive environments, where input methods such as gestures and controllers are common. Traditional evaluation methods rely on post experience questionnaires, which don't capture real-time preferences. This study used brain signals to classify input preferences during Augmented Reality (AR) interactions. Thirty participants performed three interaction tasks (pointing, manipulation, and rotation) using hands or controllers. Their electroencephalogram (EEG) data were collected at varying task difficulties (low, medium, high) and phases (preparation, task, and completion). Machine learning was used to classify preferred and non-preferred input methods. Results showed that EEG signals effectively classify preferences with accuracies up to 86%, with the completion phase being the best indicator of preference. In addition, different input methods exhibited distinct EEG patterns. These findings highlight the potential of EEG signals for decoding real-time input preference in AR, offering insights for enhancing user experiences.",
    "title": "The Brain Knows What You Prefer: Using EEG to Decode AR Input Preferences",
    "id": 189299,
    "sequence": 1089,
    "queryCoordinates": {
      "visualization": [
        3.52768505739342,
        1.8855869473039906
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "Avatar is a critical medium for identity representation in social virtual reality (VR). However, options for disability expression are highly limited on current avatar interfaces. Improperly designed disability features may even perpetuate misconceptions about people with disabilities (PWD). As more PWD use social VR, there is an emerging need for comprehensive design standards that guide developers and designers to create inclusive avatars. Our work aim to advance the avatar design practices by delivering a set of centralized, comprehensive, and validated design guidelines that are easy to adopt, disseminate, and update. Through a systematic literature review and interview with 60 participants with various disabilities, we derived 20 initial design guidelines that cover diverse disability expression methods through five aspects, including avatar appearance, body dynamics, assistive technology design, peripherals around avatars, and customization control. We further evaluated the guidelines via a heuristic evaluation study with 10 VR practitioners, validating the guideline coverage, applicability, and actionability. Our evaluation resulted in a final set of 17 design guidelines with recommendation levels.",
    "title": "Inclusive Avatar Guidelines for People with Disabilities: Supporting Disability Representation in Social Virtual Reality",
    "id": 189300,
    "sequence": 1090,
    "queryCoordinates": {
      "visualization": [
        -1.9560385425721898,
        -12.852000358697943
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "Interpersonal motor synchronization (IMS) occurs when people move together, in temporal alignment. Being in IMS can result in prosocial effects: increased liking, similarity and trust. We address the possibility of remote IMS (rIMS) between people who are not co-located, through mobile phone interactions. A threat to rIMS is the temporal noise inherent to communication networks. We created a mobile phone application in which a human participant tries to tap in synchrony with a remote participant, that is in fact a responsive computer algorithm. We introduced three levels of synthetic network noise to the joint tapping. We show that pro-sociality can be created in rIMS, but that as network noise increases the prosocial effects decrease. Participants' textual answers are analyzed thematically to learn about the effects of remote synchronization. Our findings motivate the creation of remote interactions with elements of IMS as well as inform the network requirements for successful rIMS.",
    "title": "Interpersonal Synchrony Over a Distance –  the Effect of Network Noise on Synchronization and its Prosocial Consequences",
    "id": 189301,
    "sequence": 1091,
    "queryCoordinates": {
      "visualization": [
        6.7264212536156975,
        1.9378485799739456
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Surgical procedures demand exceptional spatial and temporal coordination, precision, and advanced motor skills, challenging surgeons' cognitive abilities. Although numerous augmented reality (AR) systems have been developed to assist with the precise localization of target regions through anatomical visualizations, they often add visual complexity and increase the information burden during high-intensity tasks. In these situations of information overload, multisensory feedback can help to disambiguate uni-sensory representations, resulting in more robust interpretations and enhancing task performance. In my thesis, I aim to design and evaluate multimodal interactions in AR that enhance user performance and reduce cognitive load during surgical procedures, focusing primarily on audiovisual interactions. Preliminary findings from my Ph.D. indicate that audiovisual interactions improve accuracy and reduce cognitive load during surgical alignment and localization tasks. Moving forward, I plan to explore whether cognitive load-adaptive audiovisual augmentations can further enhance surgeon performance and user experience.",
    "title": "Designing Multimodal Interactions in Medical Augmented Reality",
    "id": 189302,
    "sequence": 1092,
    "queryCoordinates": {
      "visualization": [
        -13.18225668992948,
        7.15738140389413
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "Visualization literacy is the ability to both interpret and construct visualizations. Yet existing assessments focus solely on visualization interpretation. A lack of construction-related measurements hinders efforts in understanding and improving literacy in visualizations. We design and develop AVEC, an assessment of a person's visual encoding ability—a core component of the larger process of visualization construction—by: (1) creating an initial item bank using a design space of visualization tasks and chart types, (2) designing an assessment tool to support the combinatorial nature of selecting appropriate visual encodings, (3) building an autograder from expert scores of answers to our items, and (4) refining and validating the item bank and autograder through an analysis of test tryout data with 95 participants and feedback from the expert panel. We discuss recommendations for using AVEC, potential alternative scoring strategies, and the challenges in assessing higher-level visualization skills using constructed-response tests. Supplemental materials are available at: https://osf.io/hg7kx/.",
    "title": "AVEC: An Assessment of Visual Encoding Ability in Visualization Construction",
    "id": 189303,
    "sequence": 1093,
    "queryCoordinates": {
      "visualization": [
        -6.552603591233871,
        18.89612092933756
      ]
    }
  },
  {
    "session": "Game Experience",
    "abstract": "This paper explores the design of interpersonal bodily intertwinement in social body games. We present ``Light Up Fireflies'', a two-player VR game where players embody a single avatar, with each player responsible for controlling one half of the avatar’s body. Players must coordinate closely to navigate the virtual environment and engage with the game’s tasks, where any misalignment might cause the avatar to fall. Unlike previous research, which often focused on partial or segmented bodily interactions, our game encourages a fully integrated form of bodily coordination. Players do not merely react to each other’s movements but co-experience the avatar's body, fostering a richer and more immersive connection between them. Through a study with 16 participants, we identified three key player experiences: bodily strangeness, intertwined bodily movements, and interpersonal bodily understanding. We also provide design implications for future social body games that aim to facilitate deeper, more intertwined embodied experiences.",
    "title": "Light Up Fireflies: Exploring the Design of Interpersonal Bodily Intertwinement in Social Body Games",
    "id": 189304,
    "sequence": 1094,
    "queryCoordinates": {
      "visualization": [
        1.9615705608064609,
        0.3901806440322565
      ]
    }
  },
  {
    "session": "Vulnerable Populations",
    "abstract": "Older adults often experience psychological stress and physical discomfort during medical visits, as they must simultaneously manage various tasks such as wayfinding, making payments, and understanding medical results. Traditional tools like signage, mobile apps, and asking for help often fall short due to unclear information and complex interfaces, increasing cognitive load and potentially diminishing their overall healthcare experience.\r\n\r\nTo address these challenges, we developed Mediguide, a virtual assistant that provides personalized navigation support through multimodal interactions and dynamic adjustments. Mediguide aims to help older adults receive clear, accurate information, supporting them in navigation and decision-making processes. A comparative study using a virtual reality (VR) hospital simulation demonstrated reduction in cognitive load, and a decrease in decision errors, and significant improvements in both autonomy and overall healthcare experience.\r\n\r\nMediguide supports older adults in managing complex tasks during medical visits and offers practical insights for designing age-inclusive healthcare systems.",
    "title": "Mediguide: Reducing Cognitive Load and Improving Elderly Patients' Healthcare Experience",
    "id": 189305,
    "sequence": 1095,
    "queryCoordinates": {
      "visualization": [
        -8.758368872374025,
        8.203107624274459
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "The recent excitement around generative models has sparked a wave of proposals suggesting the replacement of human participation and labor in research and development–e.g., through surveys, experiments, and interviews—with synthetic research data generated by large language models (LLMs). We conducted interviews with 19 qualitative researchers to understand their perspectives on this paradigm shift. Initially skeptical, researchers were surprised to see similar narratives emerge in the LLM-generated data when using the interview probe. However, over several conversational turns, they went on to identify fundamental limitations, such as how LLMs foreclose participants’ consent and agency, produce responses lacking in palpability and contextual depth, and risk delegitimizing qualitative research methods. We argue that the use of LLMs as proxies for participants enacts the surrogate effect, raising ethical and epistemological concerns that extend beyond the technical limitations of current models to the core of whether LLMs fit within qualitative ways of knowing.",
    "title": "Simulacrum of stories: Examining Large Language Models as Qualitative Research Participants",
    "id": 189306,
    "sequence": 1096,
    "queryCoordinates": {
      "visualization": [
        16.844344674325733,
        -10.782766458220003
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Human-centered AI and robots can augment the capacity of teachers and parents in educating children through collaboration, empowering them to overcome limitations such as skill levels, energy and time to deliver higher quality of interaction with children. My current research focuses on understanding and designing technologies enabled by AI-assisted social robots to support parenting practices to enhance informal in-home learning of young children. In addition, I developed comprehensive framework and concrete prototypes to demonstrate and evaluate novel interaction paradigms that enable seamless collaboration between parents and robots to support children's learning at home. My next step involves expanding my research to encompass both formal and informal learning settings, using a human-centered approach to iteratively design, implement, and evaluate novel human-AI collaboration mechanisms for educational robots. The goal is to empower teachers and parents, ultimately improving children's learning outcomes and experiences in a way that is ethical, responsible, and developmentally-appropriate.",
    "title": "Empowering Parents and Teachers to Support Children's Learning through AI-based and Robotic Learning Companions",
    "id": 189307,
    "sequence": 1097,
    "queryCoordinates": {
      "visualization": [
        12.783990009183134,
        16.66042014611594
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "Many technologists who work in robotics and AI bristle at the idea that human worker displacement is problematic. Others wish to account for workers' needs, but face pervasive myths about the impacts of these technologies. This paper aims to clear the air by refuting five common arguments for automation: 1) the jobs being automated are undesirable, 2) labor shortages necessitate automation, 3) by \"augmenting rather than automating'\" labor displacement will be prevented, 4) there will be new and better job creation, and 5) automation will give us all more leisure time. The advent of foundational models has led to an industrial gold rush, accelerating deployment without careful consideration of responsible and sustaiable design and deployment of these technologies. Despite technologists' best intentions, this path of pervasive automation we are on is not a good one, and we offer suggestions for how technologists, designers, and decision makers can push for worker-centered technological change moving forward. ",
    "title": "The Future Is Rosie?: Disempowering Arguments About Automation and What to Do About It",
    "id": 189308,
    "sequence": 1098,
    "queryCoordinates": {
      "visualization": [
        2.7410500366210946,
        -20.82034208885002
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "AI tools are often promoted as revolutionary for streamlining labor- and cost-intensive UX workflows. Although their actual adoption and usage are more complex and nuanced than often portrayed, instances, where AI may be unnecessary or even undesirable, are frequently overlooked. Therefore, we aim to gain deeper insights into technology non-use—viewed not merely as a binary opposite to use but as a spectrum of practices. Through semi-structured interviews with 15 UX practitioners, we identified factors influencing non-use across individual, professional, organizational, and societal dimensions. We use a sociotechnical assemblage lens to explore how multiple layers of an individual’s context interact within professional settings, how diverse politics intersect within individuals or organizations, and how these interactions evolve over time. We propose implications for rethinking AI application design and evaluation, for considering policy frameworks and AI design together, and deliberating about where AI should and should not be used.",
    "title": "Understanding Socio-technical Factors Configuring AI Non-Use in UX Work Practices",
    "id": 189309,
    "sequence": 1099,
    "queryCoordinates": {
      "visualization": [
        -17.12677824814447,
        12.152097219775916
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "Parental emotion coaching approaches that advocate for noticing and validating child emotions can greatly impact children's regulatory abilities. However, in daily life, parents often struggle to apply emotion coaching strategies that they access through parenting programmes or online help, suggesting a need for in situ support. This paper explores a potential new avenue for providing such support. We undertook conceptual work to develop a set of emotion-focused reflective questions that could increase parents’ attention to child emotions and delivered these as daily ecological momentary assessments (EMAs). We investigated the perceived impact of the approach through a 2-week online trial (n=33) and then co-designed child-facing component with parents through a 4-week asynchronous remote community study (n=15). Our paper contributes (1) conceptual insights on designing a potential novel intervention approach, (2) empirical insights on its acceptability and perceived impacts for parents, and (3) design implications for applying the approach to wider psychological constructs.",
    "title": "Designing Daily Supports for Parent-Child Conversations about Emotion: Ecological Momentary Assessment as Intervention",
    "id": 189310,
    "sequence": 1100,
    "queryCoordinates": {
      "visualization": [
        -7.224031878618172,
        -15.388741450057195
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "Chronic liver disease can lead to neurological conditions that result in coma or death. Although early detection can allow for intervention, testing is infrequent and unstandardized. Beacon is a device for at-home patient self-measurement of cognitive function via critical flicker frequency, which is the frequency at which a flickering light appears steady to an observer. This paper presents our efforts in iterating on Beacon’s hardware and software to enable at-home use, then reports on an at-home deployment with 21 patients taking measurements over 6 weeks. We found that measurements were stable despite being taken at different times and in different environments. Finally, through interviews with 15 patients and 5 hepatologists, we report on participant experiences with Beacon, preferences around how CFF data should be presented, and the role of caregivers in helping patients manage their condition. Informed by our experiences with Beacon, we further discuss design implications for home health devices.",
    "title": "Deploying and Examining Beacon for At-Home Patient Self-Monitoring with Critical Flicker Frequency",
    "id": 189311,
    "sequence": 1101,
    "queryCoordinates": {
      "visualization": [
        10.437085085210516,
        -3.4737954637652773
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "Menstrual discomfort is a prevalent, diverse, and cyclical lived experience, impacting everyday lives. However, in HCI, it has been mostly approached as a data point, leaving much unknown on how technologies can care for these experiences. In response, we designed Touchware, a collection of on-body touch probes with pneumatic shape-change and weight components, which invite wearers to engage with and care for their menstrual discomfort. We report on the participatory soma design process of making Touchware and its two-week-long deployment study with 6 participants in a workplace setting. Our data analysis highlights diffuse and lingering qualities of menstrual discomfort, shedding light on how technologies may touch bodies in vulnerable states. We discuss the importance and challenges of designing touch technologies for and with bodies in the moments of menstrual discomfort. We conclude with a reflection on the agency of touch and its potential to support the self-care labour and nurturing the radical normalization of rest.",
    "title": "Designing Touch Technologies for and with Bodies in Menstrual Discomfort",
    "id": 189312,
    "sequence": 1102,
    "queryCoordinates": {
      "visualization": [
        -1.1770330175946777,
        -15.956647306859043
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "Research in HCI and autism has become more focused on involving autistic adults in technological design. In this paper, we present the results of a scoping review analysis of 11 projects across 18 papers that focused on including autistic adults in the design of technology that impacts their lives. This paper contributes a deeper understanding of how autistic adults were involved in participatory design processes. Our findings reveal mixed positions on how the lived autistic perspective was harnessed to direct the application of topics and technologies chosen. Most projects employed infrastructures to enhance participation (e.g., providing multiple modes to participate or employing a tailored methodology). We pose future opportunities for autistic involvement, for example, in topics and technologies where autistic research is employed (e.g., autism diagnosis and machine learning), reviewing the importance of formal diagnosis for inclusion, and harnessing the multiple expertise of autistic adults.\r\n",
    "title": "Involvement of Autistic Adults in the Participatory Design of Technology: A Scoping Review",
    "id": 189313,
    "sequence": 1103,
    "queryCoordinates": {
      "visualization": [
        -5.049831540303156,
        -19.3519818472052
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "In Spring 2020, digital review-based platform Yelp added the searchable ``Black-owned'' attribute to support Black-owned businesses. Based on the literature, the impacts of this design intervention were mixed. As such, we sourced an original dataset of 250,000+ Yelp reviews from Black and non-Black-owned restaurants in Detroit and Los Angeles. Performing statistical and trend analyses, we compared the reputation metrics of Black-owned restaurants to their non-Black-owned counterparts before and after the intervention. Although Yelp reported positive impacts, our results contribute to the growing evidence of the harms and unintended costs of platform interventions. Specifically, while awareness of Black ownership and the number of Black-owned restaurant reviews increased, assumedly among and by Yelp’s predominately non-Black users, Black-owned restaurants saw a decline in average star ratings. Altogether, the findings highlight the need to interrogate underlying assumptions in the design process, integrating critical race concepts to better contextualize and evaluate interventions targeting marginalized users.",
    "title": "The Unintended Costs of Platform Interventions: Black-Owned Restaurants and Yelp Reputation",
    "id": 189314,
    "sequence": 1104,
    "queryCoordinates": {
      "visualization": [
        1.9603428065912019,
        -19.90369453344394
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "Existing tools for laypeople to create personal classifiers often assume a motivated user working uninterrupted in a single, lengthy session. However, users tend to engage with social media casually, with many short sessions on an ongoing, daily basis. To make creating personal classifiers for content curation easier for such users, tools should support rapid initialization and iterative refinement. In this work, we compare three strategies---(1) example labeling, (2) rule writing, and (3) large language model (LLM) prompting---for end users to build personal content classifiers. From an experiment with 37 non-programmers tasked with creating personalized moderation filters, we found that participants preferred different initializing strategies in different contexts, despite LLM prompting's better performance. However, all strategies faced challenges with iterative refinement. To overcome challenges in iterating on their prompts, participants even adopted hybrid approaches such as providing examples as in-context examples or writing rule-like prompts.",
    "title": "End User Authoring of Personalized Content Classifiers: Comparing Example Labeling, Rule Writing, and LLM Prompting",
    "id": 189315,
    "sequence": 1105,
    "queryCoordinates": {
      "visualization": [
        -17.280897378946715,
        5.036922252557861
      ]
    }
  },
  {
    "session": "Emotion and Behavior Change",
    "abstract": "Personalized support is essential to fulfill individuals’ emotional needs and sustain their mental well-being. Large language models (LLMs), with great customization flexibility, hold promises to enable individuals to create their own emotional support agents. In this work, we developed ChatLab, where users could construct LLM-powered chatbots with additional interaction features including voices and avatars. Using a Research through Design approach, we conducted a week-long field study followed by interviews and design activities (N = 22), which uncovered how participants created diverse chatbot personas for emotional reliance, confronting stressors, connecting to intellectual discourse, reflecting mirrored selves, etc. We found that participants actively enriched the personas they constructed, shaping the dynamics between themselves and the chatbot to foster open and honest conversations. They also suggested other customizable features, such as integrating online activities and adjustable memory settings. Based on these findings, we discuss opportunities for enhancing personalized emotional support through emerging AI technologies.",
    "title": "Customizing Emotional Support: How Do Individuals Construct and Interact With LLM-Powered Chatbots",
    "id": 189316,
    "sequence": 1106,
    "queryCoordinates": {
      "visualization": [
        -8.56505691854731,
        -6.902159081189369
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "Humans now interact with a variety of digital minds, systems that appear to have mental faculties such as reasoning, emotion, and agency, and public figures are discussing the possibility of sentient AI. We present initial results from 2021 and 2023 for the nationally representative AI, Morality, and Sentience (AIMS) survey (N = 3,500). Mind perception and moral concern for AI welfare were surprisingly high and significantly increased: in 2023, one in five U.S. adults believed some AI systems are currently sentient, and 38% supported legal rights for sentient AI. People became more opposed to building digital minds: in 2023, 63% supported banning smarter-than-human AI, and 69% supported banning on sentient AI. The median 2023 forecast was that sentient AI would arrive in just five years. The development of safe and beneficial AI requires not just technical study but understanding the complex ways in which humans perceive and coexist with digital minds.",
    "title": "Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey",
    "id": 189317,
    "sequence": 1107,
    "queryCoordinates": {
      "visualization": [
        10.992991082226908,
        0.392615672228785
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "Fertility trackers are popular for self-monitoring menstrual cycles and managing other aspects of reproductive or sexual health. However, the intimate nature of fertility tracking raises particular concerns about potential data (mis)use. Our study deepens understandings of fertility tracker data sharing and presents co-created mechanisms to enhance user agency over their data in intimate contexts. To achieve this, we first analysed the network transmissions from eight fertility tracker products, observing that many data transmissions appear to be tied to particular uses of the tracker and that the products communicate with endpoints associated with various organisations across different countries. This raises concerns about how intimate data is governed, used, and shared. To understand user attitudes towards data sharing in intimate contexts, we then conducted a survey exploring factors influencing user data sharing preferences. Our findings reveal that users desire transparency and control mechanisms and that their willingness to share data is influenced by contextual factors, including the third parties involved, the purposes of data collection, and the sensitivity of the data. Building on these findings, we worked with users to co-design ten concrete mechanisms for enhancing data transparency and control throughout fertility tracker product usage lifecycles. In all, our mixed-method study provides an in-depth understanding of fertility tracker data flows and preferences and proposes actionable mechanisms designers can utilise to support and protect data rights in intimate data ecosystems.",
    "title": "Intimate Data Sharing: Enhancing Transparency and Control in Fertility Tracking",
    "id": 189318,
    "sequence": 1108,
    "queryCoordinates": {
      "visualization": [
        15.946413075454142,
        12.071118839071428
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "Telepresence robots have the potential to change our experiences in galleries and museums, allowing for a range of hybrid interactions for visitors and museum professionals, improving accessibility, offering activities or information, and providing a range of practical use cases (e.g. the robots augmenting museum exhibits). We present the results of 3 qualitative studies conducted in the UK exploring the acceptability (1 - interviews with museum professionals with no previous exposure to telepresence), acceptance (2 – focus groups for initial exposure to telepresence robots), and adoption (3 – interviews with museum professionals with long-term exposure to robots) of telepresence robots in museums. Our results identified opportunities and barriers focusing on the unique perspective of museum professionals and showed how priorities of museums shift and change according to their exposure to different technologies. We proposed a set of practical guidelines for future telepresence robots in museums, including design implications, potential applications, and integration strategies.",
    "title": "Acceptability, Acceptance and Adoption of Telepresence Robots in Museums: The Museum Professionals' Perspectives",
    "id": 189319,
    "sequence": 1109,
    "queryCoordinates": {
      "visualization": [
        -2.73539022016482,
        15.76444227822306
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Embodied agents are increasingly accessible to users and deployed in critical domains, which creates an urgent need for intuitive, human-centred risk communication to ensure users understand potential risks and infer appropriate action. My research explores embodied agents as novel interfaces for risk communication, investigating how these agents can intuitively convey risk information and facilitate risk alignment as an integral part of risk communication. I examine how using embodied agents to communicate risk impacts users’ risk perception, decision-making, and understandability. Building on this work, my proposed research focuses on how agents can further support risk alignment by allowing users to specify and adjust their risk preferences through risk alignment interfaces. My dissertation contributes empirical insights, implications, and design considerations for human-centred risk communication in human-agent interaction and contributes to HCI by offering important insights for designing agents that prioritise risk comprehension and appropriate risk responses in complex environments.",
    "title": "Designing Embodied Agents for Impactful Human-Centred Risk Communication",
    "id": 189320,
    "sequence": 1110,
    "queryCoordinates": {
      "visualization": [
        -10.65831031959658,
        2.7203715060963725
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "The growing popularity of interactive time series exploration platforms has made data visualization more accessible to the public. However, the ease of creating polished charts with preloaded data also enables selective information presentation, often resulting in biased or misleading visualizations. Research shows that these tools have been used to spread misinformation, particularly in areas such as public health and economic policies during the COVID-19 pandemic. Post hoc fact-checking may be ineffective because it typically addresses only a portion of misleading posts and comes too late to curb the spread. In this work, we explore using visualization design to counteract cherry-picking, a common tactic in deceptive visualizations. We propose a design space of guardrails—interventions to expose cherry-picking in time-series explorers. Through three crowd-sourced experiments, we demonstrate that guardrails, particularly those superimposing data, can encourage skepticism, though with some limitations. We provide recommendations for developing more effective visualization guardrails.",
    "title": "Visualization Guardrails: Designing Interventions Against Cherry-Picking in Interactive Data Explorers",
    "id": 189321,
    "sequence": 1111,
    "queryCoordinates": {
      "visualization": [
        4.619397662556434,
        1.913417161825449
      ]
    }
  },
  {
    "session": "Earable and Hearable",
    "abstract": "The provision of audio augmented reality (AAR) experiences is becoming more widespread. In this study, to investigate the influence of device design on AAR experience from the perspective of acoustic transparency, physical and subjective evaluations were conducted using five devices with different shapes and transparency modes. In the subjective evaluation, perceived transparency, impressions of real-world sound, and subjective impressions of AAR experience when wearing each device were evaluated for two distinct content types. We found that device design can potentially influence impressions of real-world sound, such as auditory source width, listener envelopment and punch, and subjective impressions during AAR experience. Devices with high transparency were more likely to draw attention to real-world sounds when users were experiencing AAR, and the experience was evaluated as enjoyable and natural. Two demonstration experiments showed that adding virtual sounds by open-ear earphones to real contents can provide acoustic effects such as distance enhancement.",
    "title": "Effects of Acoustic Transparency of Wearable Audio Devices on Audio AR",
    "id": 189322,
    "sequence": 1112,
    "queryCoordinates": {
      "visualization": [
        -20.996328379167675,
        -0.39267619504895124
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "Text in dashboards plays multiple critical roles, including providing context, offering insights, guiding interactions, and summarizing key information. Despite its importance, most dashboarding tools focus on visualizations and offer limited support for text authoring. To address this gap, we developed Plume, a system to help authors craft effective dashboard text. Through a formative review of exemplar dashboards, we created a typology of text parameters and articulated the relationship between visual placement and semantic connections, which informed Plume’s design. Plume employs large language models (LLMs) to generate contextually appropriate content and provides guidelines for writing clear, readable text. A preliminary evaluation with 12 dashboard authors explored how assisted text authoring integrates into workflows, revealing strengths and limitations of LLM-generated text and the value of our human-in-the-loop approach. Our findings suggest opportunities to improve dashboard authoring tools by better supporting the diverse roles that text plays in conveying insights.",
    "title": "Plume: Scaffolding Text Composition in Dashboards",
    "id": 189323,
    "sequence": 1113,
    "queryCoordinates": {
      "visualization": [
        -7.990363649641379,
        -0.39254139461934534
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "Human intervention is claimed to safeguard decision-subjects' rights in algorithmic decision-making and contribute to their fairness perceptions. However, how decision subjects perceive hybrid decision-maker configurations (i.e., combining humans and algorithms) is unclear. We address this gap through a mixed-methods study in an algorithmic policy enforcement context. Through qualitative interviews (Study 1; N_1=21), we identify three characteristics (i.e., decision-maker's profile, model type, input data provenance) that affect how decision-subjects perceive decision-makers' ability, benevolence, and integrity (ABI). Through a quantitative study (Study 2; N_2=223), we then systematically evaluate the individual and combined effects of these characteristics on decision-subjects' perceptions towards decision-makers, and fairness perceptions. We found that only decision-maker’s profile contributes to perceived ability, benevolence, and integrity. Interestingly, the effect of decision-maker's profile on fairness perceptions was mediated by perceived ability and integrity. Our findings have design implications for ensuring effective human intervention as a protection against harmful algorithmic decisions.",
    "title": "Towards Effective Human Intervention in Algorithmic Decision-Making: Understanding the Effect of Decision-Makers' Configuration on Decision-Subjects' Fairness Perceptions",
    "id": 189324,
    "sequence": 1114,
    "queryCoordinates": {
      "visualization": [
        -7.140180062621116,
        -5.478852861078486
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "Integrating AI in healthcare requires effective interdisciplinary collaboration, yet challenges like methodological differences, terminology barriers, and divergent objectives persist. To address the issues, we introduce MedAI-SciTS, a structured approach combining a theoretical framework and a toolkit to improve collaboration across disciplines. The framework builds on a formative study (N=12) and literature review, identifying the key challenges and potential solutions in medical-AI projects. We further develop an innovative toolkit with twelve tools, featuring an AI-enhanced research glossary with personalized analogies, an agile co-design platform, and an integrated resource management system. A three-month case study involving AI and medical professionals (N=16 total) applying a segmentation algorithm for adrenal CT images confirmed the toolkit’s effectiveness in enhancing team engagement, communication, trust, and collaboration outcomes. \r\nWe envision MedAI-SciTS could potentially be applied to a wide range of medical applications and facilitate broader medical-AI collaboration.",
    "title": "MedAI-SciTS: Enhancing Interdisciplinary Collaboration between AI Researchers and Medical Experts",
    "id": 189325,
    "sequence": 1115,
    "queryCoordinates": {
      "visualization": [
        -9.276125440352839,
        7.61271940996375
      ]
    }
  },
  {
    "session": "Decision Making",
    "abstract": "This paper investigates the potential of using large language models (LLMs) for personalized movie recommendations in an online field experiment. We assess the performance of LLM recommenders using a combination of between-subject prompts, historical consumption patterns, and within-subject recommendation scenarios. Analyzing conversation and survey data from 160 active users, we find that while LLMs excel in providing explainable recommendations, they lack in personalization, diversity, and user trust. Interestingly, personalized prompting techniques do not significantly affect user-perceived recommendation quality, while the number of movies a user has watched plays a more significant role. Furthermore, LLMs demonstrate a stronger ability to recommend lesser-known or niche movies. Through qualitative analysis, we identify key conversational patterns linked to positive and negative user interaction experiences and conclude that providing personal context and examples is crucial for obtaining high-quality recommendations from LLMs. These insights offer practical implications for improving LLM-based RecSys in real-world applications.",
    "title": "Multi-Prompting Scenario-based Movie Recommendation with Large Language Models: Real User Case Study",
    "id": 189326,
    "sequence": 1116,
    "queryCoordinates": {
      "visualization": [
        5.813545739921838,
        20.17926376084709
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "Many mobile apps are inaccessible, thereby excluding people from their potential benefits. Existing rule-based accessibility checkers aim to mitigate these failures by identifying errors early during development but are constrained in the types of errors they can detect. We present ScreenAudit, an LLM-powered system designed to traverse mobile app screens, extract metadata and transcripts, and identify screen reader accessibility errors overlooked by existing checkers. We recruited six accessibility experts including one screen reader user to evaluate ScreenAudit's reports across 14 unique app screens. Our findings indicate that ScreenAudit achieves an average coverage of 69.2%, compared to only 31.3% with a widely-used accessibility checker. Expert feedback indicated that ScreenAudit delivered higher-quality feedback and addressed more aspects of screen reader accessibility compared to existing checkers, and that ScreenAudit would benefit app developers in real-world settings.",
    "title": "ScreenAudit: Detecting Screen Reader Accessibility Errors in Mobile Apps Using Large Language Models",
    "id": 189327,
    "sequence": 1117,
    "queryCoordinates": {
      "visualization": [
        15.956647306859043,
        -1.1770330175946786
      ]
    }
  },
  {
    "session": "HCI Methods",
    "abstract": "Although the literature on Human-Computer Interaction (HCI) catalogues many theories, it offers surprisingly few tools for theorising. This paper critiques dominant approaches to engaging with theory and proposes a working model for theorising in HCI. We then present graphical causal modelling as an effective theorising tool. This includes a step-by-step guide to building causal models and examples of their use in different stages of the research process. We explain how causal models help develop method-agnostic representations of research problems using directed acyclic graphs, identify potential confounders, and construct alternative interpretations of data. Finally, we discuss their limitations and challenges for adoption by the HCI community.",
    "title": "Theorising in HCI using Causal Models",
    "id": 189328,
    "sequence": 1118,
    "queryCoordinates": {
      "visualization": [
        -4.861849601988383,
        1.1672268192795276
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "In client-AI expert collaborations, the planning stage of AI application development begins from the client; a client outlines their needs and expectations while assessing available resources (pre-collaboration planning). Despite the importance of pre-collaboration plans for discussions with AI experts for iteration and development, the client often fails to reflect their needs and expectations into a concrete actionable plan. To facilitate pre-collaboration planning, we introduce PlanTogether, a system that generates tailored client support using large language models and a Planning Information Graph, whose nodes and edges represent information in the plan and the information dependencies. Using the graph, the system links and presents information that guides client's reasoning; it provides tips and suggestions based on relevant information and displays an overview to help understand the progression through the plan. A user study validates the effectiveness of PlanTogether in helping clients navigate information dependencies and write actionable plans reflecting their domain expertise.",
    "title": "PlanTogether: Facilitating AI Application Planning Using Information Graphs and Large Language Models",
    "id": 189329,
    "sequence": 1119,
    "queryCoordinates": {
      "visualization": [
        -7.983097498603995,
        4.155737519115306
      ]
    }
  },
  {
    "session": "Engaging with Data",
    "abstract": "Dimensionality reduction (DR) techniques are essential for visually analyzing high-dimensional data. However, visual analytics using DR often face unreliability, stemming from factors such as inherent distortions in DR projections. This unreliability can lead to analytic insights that misrepresent the underlying data, potentially resulting in misguided decisions. To tackle these reliability challenges, we review 133 papers that address the unreliability of visual analytics using DR. Through this review, we contribute (1) a workflow model that describes the interaction between analysts and machines in visual analytics using DR, and (2) a taxonomy that identifies where and why reliability issues arise within the workflow, along with existing solutions for addressing them. Our review reveals ongoing challenges in the field, whose significance and urgency are validated by five expert researchers. This review also finds that the current research landscape is skewed toward developing new DR techniques rather than their interpretation or evaluation, where we discuss how the HCI community can contribute to broadening this focus.",
    "title": "Unveiling High-dimensional Backstage: A Survey for Reliable Visual Analytics with Dimensionality Reduction",
    "id": 189330,
    "sequence": 1120,
    "queryCoordinates": {
      "visualization": [
        13.99449276936274,
        -0.3926475878621654
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "Precise editing of text-to-image model outputs remains challenging. Slider-based editing is a recent approach wherein the image’s semantic attributes are manipulated via sliders. However, it has significant user-centric issues. First, slider variations are often inconsistent across the sliding range. Second, the optimal slider range is unpredictable, with default values often being too large or small depending on the prompt and attribute. Third, manipulating one attribute can unintentionally alter others due to the complex entanglement of latent spaces.\r\nWe introduce AdaptiveSliders, a tool that addresses these challenges by adapting to the specific attributes and prompts, generating consistent slider variations and optimal bounds while minimizing unintended changes. AdaptiveSliders also suggests initial attributes and generates initial images more aligned with prompt semantics. Through three validation studies and one end-to-end user study, we demonstrate that AdaptiveSliders significantly improves user control and experience, enabling semantic slider-based editing aligned with user needs and expectations. ",
    "title": "AdaptiveSliders: User-aligned Semantic Slider-based Editing of Text-to-Image Model Output",
    "id": 189331,
    "sequence": 1121,
    "queryCoordinates": {
      "visualization": [
        11.839719985018547,
        1.9547456807350647
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "Note-taking is critical during speeches and discussions, serving for later summarization and organization and for real-time question and opinion reminding in question-and-answer sessions or timely contributions in discussions. Manually typing on smartphones for note-taking could be distracting and increase cognitive load. While LLMs are used to automatically generate summaries and highlights, the content generated by AI may not match users’ intentions without user input. Therefore, we propose an AI-copiloted AR system, GazeNoter, to allow users to swiftly select diverse LLM-generated suggestions via gaze on an AR headset for real-time note-taking. GazeNoter leverages an AR headset as a medium for users to swiftly adjust the LLM output to match their intentions, forming a user-in-the-loop AI system for both within-context and beyond-context notes. We conducted two studies to verify the usability of GazeNoter in attending speeches in a static sitting condition and walking meetings and discussions in a mobile walking condition, respectively.",
    "title": "GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions",
    "id": 189332,
    "sequence": 1122,
    "queryCoordinates": {
      "visualization": [
        -1.1753739745783758,
        9.930684569549262
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "Older adults (65+) increasingly use voice assistants for information-seeking, but experience challenges and uncertainty in assessing information quality due to limited visual cues. HCI researchers have primarily used nudging, subtle approaches to guide users towards better decision-making, in visual interfaces to mitigate online misinformation and facilitate critical thinking. Thus, we extend nudging to voice-based systems to help older adults alleviate uncertainty in voice-based searches. We evaluate four audio nudge prototypes (i.e., non-speech and speech-based) with older adults (n = 34). Findings show that speech nudges more effectively prompt critical reflection than non-speech nudges because they are more disruptive. We discuss the significance of these findings for designing accessible audio nudges, highlighting the tension between disruption and accessibility best practices. Further, we propose that effective audio nudges should be explanatory and interactive to help older adults mitigate information uncertainty and raise open questions for the community about designing reflective nudges.",
    "title": "Designing Accessible Audio Nudges for Voice Interfaces",
    "id": 189333,
    "sequence": 1123,
    "queryCoordinates": {
      "visualization": [
        8.03635207966689,
        -19.401470182737018
      ]
    }
  },
  {
    "session": "Personal Data and Decision-Making",
    "abstract": "Temporal predictive models have the potential to improve decisions in health care, public services, and other domains, yet they often fail to effectively support decision-makers. Prior literature shows that many misalignments between model behavior and decision-makers' expectations stem from issues of model specification, namely how, when, and for whom predictions are made. However, model specifications for predictive tasks are highly technical and difficult for non-data-scientist stakeholders to interpret and critique. To address this challenge we developed Tempo, an interactive system that helps data scientists and domain experts collaboratively iterate on model specifications. Using Tempo's simple yet precise temporal query language, data scientists can quickly prototype specifications with greater transparency about pre-processing choices. Moreover, domain experts can assess performance within data subgroups to validate that models behave as expected. Through three case studies, we demonstrate how Tempo helps multidisciplinary teams quickly prune infeasible specifications and identify more promising directions to explore.",
    "title": "Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks",
    "id": 189334,
    "sequence": 1124,
    "queryCoordinates": {
      "visualization": [
        -1.9585708031874554,
        -15.879672553579361
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "GPTs are customized LLM apps built on OpenAI's large language model. Any individual or organization can use and create GPTs without needing programming skills. However, the rapid proliferation of over three million GPTs has raised significant privacy concerns. To explore the privacy perspectives of users and creators, we interviewed 23 GPT users with varying levels of creation experience. Our findings reveal blurred lines between user and creator roles and their understanding of GPT data flows. Participants raised concerns about data handling during collection, processing, and dissemination, alongside the lack of privacy regulations. Creators also worried about loss of their proprietary knowledge. In response, participants adopted practices like self-censoring input, evaluating GPT actions, and minimizing usage traces. Focusing on the dual role of user-creators, we find that expertise and responsibility shape privacy perceptions. Based on these insights, we propose practical recommendations to improve data transparency and platform regulations. ",
    "title": "Privacy Perceptions of Custom GPTs by Users and Creators",
    "id": 189335,
    "sequence": 1125,
    "queryCoordinates": {
      "visualization": [
        -1.959132753255861,
        16.88673440470715
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "Sensing touch on arbitrary surfaces has long been a goal of ubiquitous computing, but often requires instrumenting the surface. Depth camera-based systems have emerged as a promising solution for minimizing instrumentation, but at the cost of high touch-down detection error rates, high touch latency, and high minimum hover distance, limiting them to basic tasks. We developed HaloTouch, a vision-based system which exploits a multipath interference effect from an off-the-shelf time-of-flight depth camera to enable fast, accurate touch interactions on general surfaces. HaloTouch achieves a 99.2% touch-down detection accuracy across various materials, with a motion-to-photon latency of 150 ms. With a brief (20s) user-specific calibration, HaloTouch supports millimeter-accurate hover sensing as well as continuous pressure sensing. We conducted a user study with 12 participants, including a typing task demonstrating text input at 26.3 AWPM. HaloTouch shows promise for more robust, dynamic touch interactions without instrumenting surfaces or adding hardware to users.",
    "title": "HaloTouch: Using IR Multi-Path Interference to Support Touch Interactions with General Surfaces",
    "id": 189336,
    "sequence": 1126,
    "queryCoordinates": {
      "visualization": [
        19.087414025656432,
        -8.756176437987879
      ]
    }
  },
  {
    "session": "Technologies for Sustainable Development",
    "abstract": "It is pivotal for patients to receive accurate health information, diagnoses, and timely treatments. However, in China, the significant imbalanced doctor-to-patient ratio intensifies the information and power asymmetries in doctor-patient relationships. Health information-seeking, which enables patients to collect information from sources beyond doctors, is a potential approach to mitigate these asymmetries. While HCI research predominantly focuses on common chronic conditions, our study focuses on specialized disorders, which are often familiar to specialists but not to general practitioners and the public. With Hemifacial Spasm (HFS) as an example, we aim to understand patients' health information and top-tier medical resource seeking journeys in China. Through interviews with three neurosurgeons and 12 HFS patients from rural and urban areas, and applying Actor-Network Theory, we provide empirical insights into the roles, interactions, and workflows of various actors in the health information-seeking network. We also identified five strategies patients adopted to mitigate asymmetries and access top-tier medical resources, illustrating these strategies as subnetworks within the broader health information-seeking network and outlining their advantages and challenges.",
    "title": "The Odyssey Journey: Top-Tier Medical Resource Seeking for Specialized Disorder in China",
    "id": 189337,
    "sequence": 1127,
    "queryCoordinates": {
      "visualization": [
        -2.735390220164827,
        -15.764442278223058
      ]
    }
  },
  {
    "session": "Storytelling and Sense-Making",
    "abstract": "Personalized interaction is highly valued by parents in their story-reading activities with children. While AI-empowered story-reading tools have been increasingly used, their abilities to support personalized interaction with children are still limited. Recent advances in large language models (LLMs) show promise in facilitating personalized interactions, but little is known about how to effectively and appropriately use LLMs to enhance children's personalized story-reading experiences. This work explores this question through a design-based study. Drawing on a formative study, we designed and developed StoryMate, an LLM-empowered personalized interactive story-reading tool for children, following an empirical study with children, parents, and education experts. Our participants valued the personalized features in StoryMate, and also highlighted the need to support personalized content, guiding mechanisms, reading context variations, and interactive interfaces. Based on these findings, we propose a series of design recommendations for better using LLMs to empower children's personalized story reading and interaction.",
    "title": "Characterizing LLM-Empowered Personalized Story Reading and Interaction for Children: Insights From Multi-Stakeholders' Perspective",
    "id": 189338,
    "sequence": 1128,
    "queryCoordinates": {
      "visualization": [
        -10.061064342953463,
        16.1175365452339
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "How creative is HCI research? Although creativity has been a notable theme in HCI, the landscape of the creativity of HCI research itself remains unclear. In this paper, we address this by measuring the disruptiveness of HCI research, one important dimension distinguishing the level of creativity, through a large-scale data-driven bibliometric analysis. By quantitatively tracing its evolution over the past 40 years, we find that the disruptiveness of HCI is decreasing sharply, even at a faster speed than the global average across all fields. We characterize the patterns shown by the themes, knowledge use, and authorship of disruptive papers in HCI, and identify how they associate with disruptiveness, e.g., the positive relationship between author freshness and disruptiveness. Based on our results, we discuss practical implications to improve and secure disruptiveness and creativity in HCI.",
    "title": "The Sharply Decreasing Disruptiveness of HCI",
    "id": 189339,
    "sequence": 1129,
    "queryCoordinates": {
      "visualization": [
        7.990180696711442,
        -17.238242730449638
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Queer users of Douyin, the Chinese version of TikTok, suspect that the platform removes and suppresses queer content, thus reducing queer visibility. In this study, we examined how Chinese queer users recognize and react to Douyin's moderation of queer content by conducting interviews with 21 queer China-based Douyin content creators and viewers. \r\nFindings indicate that queer users actively explore and adapt to the platform's underlying moderation logic. They employ creative content and posting strategies to reduce the likelihood of their expressions of queer topics and identities being removed or suppressed. \r\nLike Western platforms, Douyin's moderation approaches are often ambiguous; but unlike Western platforms, queer users sometimes receive clarity on moderation reasons via direct communication with moderators. Participants suggested that Douyin's repressive moderation practices are influenced by more than just platform policies and procedures - they also reflect state-led homophobia and societal discipline. This study underscores the challenges Chinese queer communities face in maintaining online visibility and suggests that meaningful change in their experiences is unlikely without broader societal shifts towards queer acceptance.",
    "title": "The Virtual Jail: Content Moderation Challenges Faced by Chinese Queer Content Creators on Douyin",
    "id": 189340,
    "sequence": 1130,
    "queryCoordinates": {
      "visualization": [
        14.24312413777219,
        -9.280808951595287
      ]
    }
  },
  {
    "session": "Understanding and Working with Algorithms",
    "abstract": "Previous research pays attention to how users strategically understand and consciously interact with algorithms but mainly focuses on an individual level, making it difficult to explore how users within communities could develop a collective understanding of algorithms and organize collective algorithmic actions. Through a two-year ethnography of online fan activities, this study investigates 43 core fans who always organize large-scale fans collective actions and their corresponding general fan groups. This study aims to reveal how these core fans mobilize millions of general fans through collective algorithmic actions. These core fans reported the rhetorical strategies used to persuade general fans, the steps taken to build a collective understanding of algorithms, and the collaborative processes that adapt collective actions across platforms and cultures. Our findings highlight the key factors that enable computer-supported collective algorithmic actions and extend collective action research into the large-scale domain targeting algorithms.",
    "title": "Let's Influence Algorithms Together: How Millions of Fans Build Collective Understanding of Algorithms and Organize Coordinated Algorithmic Actions",
    "id": 189341,
    "sequence": 1131,
    "queryCoordinates": {
      "visualization": [
        0.392541394619345,
        7.990363649641379
      ]
    }
  },
  {
    "session": "Mobile Robots",
    "abstract": "Soft robots, constructed from compliant materials, offer unique flexibility and adaptability. However, most research has focused on small-scale interactions, leaving the potential of large-scale soft robots largely unexplored.  This research explores how humans engage with inflatable soft robots that are large in size and created for fun and artistic expression.  We conducted 22 hours of video analysis (N=30) and thematic interviews (N=20) to understand user engagement and explore their motivations. Our findings revealed a range of interactions, from delicate touches to immersive full-body engagement, driven by trust, safety, and emotional connection. Participants frequently compared the robots to peaceful creatures like plants and sea animals, fostering playful and therapeutic interactions. These insights highlight the potential of giant soft robots in enhancing emotional well-being, therapeutic applications, and immersive experiences. This paper aims to inspire future designs that leverage the unique attributes of large-scale soft robots for trust-centered, interactive human-robot relationships.",
    "title": "Encounter with the Giants: Understanding Interaction with Large-scale Inflatable Soft Robots",
    "id": 189342,
    "sequence": 1132,
    "queryCoordinates": {
      "visualization": [
        21.828486595069407,
        -2.7417463356180916
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "Technology has become deeply woven into the practices of faith communities who engage in shared prayer, online worship, or meditation. Despite a growing body of research on religious/spiritual practices, the Human-Computer Interaction (HCI) community has yet to fully investigate Techno-Spirituality, especially through a first-person approach. We explored prayer experiences to understand which elements evoke such experiences from a Christian perspective. We present results from an eight-month autoethnographic study of private prayer by the first author, also a community member, while incorporating both technological (e.g., a Muse 2 electroencephalogram headband) and non-technological (e.g., religious iconography) media. We reflect on emerging practices and limitations of integrating technology during Christian prayer. This paper provides empirical insights on spiritual practices with technologies, and contributes to discourses on Techno-Spirituality in HCI.",
    "title": "Walking in My Shoes: An Autoethnography of Techno-Spiritual Practices",
    "id": 189343,
    "sequence": 1133,
    "queryCoordinates": {
      "visualization": [
        -16.239215962584357,
        5.028704099521603
      ]
    }
  },
  {
    "session": "Content Moderation",
    "abstract": "Nascent research on human-computer interaction concerns itself with fairness of content moderation systems. Designing globally applicable content moderation systems requires considering historical, cultural, and socio-technical factors. Inspired by this line of work, we investigate Arab users' perception of Facebook's moderation practices. We collect a set of 448 deleted Arabic posts, and we ask Arab annotators to evaluate these posts based on (a) Facebook Community Standards (FBCS) and (b) their personal opinion. Each post was judged by 10 annotators to account for subjectivity. Our analysis shows a clear gap between the Arabs' understanding of the FBCS and how Facebook implements these standards. The study highlights a need for discussion on the moderation guidelines on social media platforms about who decides the moderation guidelines, how these guidelines are interpreted, and how well they represent the views of marginalised user communities.",
    "title": "Who should set the Standards? Analysing Censored Arabic Content on Facebook during the Palestine-Israel Conflict",
    "id": 189344,
    "sequence": 1134,
    "queryCoordinates": {
      "visualization": [
        5.028704099521595,
        16.23921596258436
      ]
    }
  },
  {
    "session": "Critics on AI",
    "abstract": "Despite the importance of AI literacy for both children and adults, adults have been understudied. We developed short videos for adults that provided training on the basics of AI understanding, use, and evaluation. In an online experiment, 94 adults aged 30-49 were randomly assigned in a 1:2 ratio to view either short videos on AI history (control group) or AI literacy training videos (treatment group). The results showed that the intervention significantly improved people’s self-efficacy of AI use but not in AI understanding or evaluation. Interestingly, participants’ fears of AI bias, privacy violations, and job replacement increased after the training, although they remained below the midpoints. We argue that the heightened fear in the treatment group reflects a foundation for critical thinking skills, as it moves them closer to a more calibrated, moderate level of fear. Therefore, this study uniquely contributes by utilizing short-form experiential content to both educate and foster a more informed, critical interaction with AI technologies. The implications of designing AI literacy educational materials for adults were discussed.  ",
    "title": "Empowering Adults with AI Literacy: Using Short Videos to Transform Understanding and Harness Fear for Critical Thinking",
    "id": 189345,
    "sequence": 1135,
    "queryCoordinates": {
      "visualization": [
        17.654135047258144,
        -3.511625796290317
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "Olfactory stimuli have demonstrated the potential to evoke emotional depth and enhance user experiences in HCI. Yet, their role in shaping perceptions of social robots remains largely untapped. This study investigates how olfactory (scent) and auditory (voice) stimuli influence user perceptions of social robots. Using a 2x2 between-subjects design, participants interacted with a social robot under conditions with pleasant/unpleasant scents and friendly/unfriendly voices. The study measured perceived trust, friendliness, competence, and engagement. Our findings show that pleasant scents can enhance the perceptions of friendliness and engagement, while friendly voices can improve trust, friendliness, and engagement. The congruent combination of scents and voices affects friendliness and engagement but does not influence trust and competence. This study contributes to the growing work on multi-sensory Human-Robot Interaction (HRI) design, offering implications for creating more socially interactive robots.",
    "title": "Crossmodal Interactions in Human-Robot Communication: Exploring the Influences of Scent and Voice Congruence on User Perceptions of Social Robots",
    "id": 189346,
    "sequence": 1136,
    "queryCoordinates": {
      "visualization": [
        -9.836477968456826,
        -4.923789310689836
      ]
    }
  },
  {
    "session": "Privacy and Security",
    "abstract": "Malware analysis provides useful information for defending organizations against the growing number of cyberattacks. To leverage such information to enhance security, malware analysts are expected to collaborate with members of their own and other teams. However, there has been insufficient research into their actual collaboration and communication. Furthermore, given that challenges in their communication can lead to critical errors, it is imperative to understand and mitigate these challenges. We interviewed 15 malware analysts to explore their roles, collaborators, and communication means and challenges. We found that the roles within malware analysis teams are diverse and identified the roles and collaborations in which analysts leverage malware analysis knowledge effectively. We also identified several key communication challenges, including difficulties in aligning understanding in collaborative analysis and low motivation for information sharing. On the basis of our findings, we provide recommendations to address each communication challenge.",
    "title": "Collaborative Work in Malware Analysis: Understanding the Roles and Challenges of Malware Analysts",
    "id": 189347,
    "sequence": 1137,
    "queryCoordinates": {
      "visualization": [
        -2.7410500366210835,
        20.82034208885002
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": "Friction -- disagreement and breakdown -- is an omnipresent aspect of conducting interdisciplinary research yet is rarely presented in formal research reporting. We analyse a performance-led research process where professional dancers with different disabilities explored how to improvise with an industrial robot, with the support of an interdisciplinary team of human-computer and human-robot interaction researchers. We focus on one site of friction in our research process; how to dance -- safely -- with robots? By presenting our research process, we exemplify the different ways in which we encountered this friction and how we reconfigured the research process around it. We contribute five ways in which we arrived at a generative ethical outcome, which may be helpful in productively engaging with friction in interdisciplinary collaboration. ",
    "title": "Friction in Processual Ethics: Reconfiguring Ethical Relations in Interdisciplinary Research",
    "id": 189348,
    "sequence": 1138,
    "queryCoordinates": {
      "visualization": [
        9.08143173825081,
        -4.186597375374289
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": "We present QuiltDesigner, a programming language for designing quilt patterns packaged in a web interface with a cozy aesthetic. Two user studies with quantitative and qualitative surveys are performed to characterize how QuiltDesigner can support the creativity needs of its programmers. We argue for refeminization of creative computing, i.e., to supplant existing narratives of its femininity with one where language creation and design creation have equal feminine status.",
    "title": "Refeminizing Creative Computing through a Programming Language for Quilts",
    "id": 189349,
    "sequence": 1139,
    "queryCoordinates": {
      "visualization": [
        15.420417052727037,
        4.267404119598374
      ]
    }
  },
  {
    "session": "Make it Visible",
    "abstract": "Transcripts are central to qualitative research in HCI, particularly for researchers using methods of Conversation Analysis (CA) and Interaction Analysis (IA) who study the socially situated nature of human-computer interaction. However, CA and IA researchers continue to highlight the significant need for more dynamic ways to visualize transcripts to support interaction analysis. This need is particularly evident in HCI, where transcripts as a form of data have received little attention. In this article, we make three contributions to HCI research. First, we present Transcript Explorer, an open-source visualization system that integrates three visualization techniques we have developed to interactively visualize transcripts linked to videos: Distribution Diagrams, Turn Charts and Contribution Clouds. Second, we present findings from a qualitative analysis of focus group interviews with three different qualitative research groups who engaged with this system to analyze common transcript data. Finally, we expand upon transcripts as a unique form of data for HCI research and propose directions for future research.",
    "title": "Exploratory Visual Analysis of Transcripts for Interaction Analysis in Human-Computer Interaction",
    "id": 189350,
    "sequence": 1140,
    "queryCoordinates": {
      "visualization": [
        5.740251485476337,
        -13.858192987669305
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "Creating new fonts requires a lot of human effort and professional typographic knowledge. Despite the rapid advancements of automatic font generation models, existing methods require users to prepare pre-designed characters with target styles using font-editing software, which poses a problem for non-expert users. To address this limitation, we propose FontCraft, a system that enables font generation without relying on pre-designed characters. Our approach integrates the exploration of a font-style latent space with human-in-the-loop preferential Bayesian optimization and multimodal references, facilitating efficient exploration and enhancing user control. Moreover, FontCraft allows users to revisit previous designs, retracting their earlier choices in the preferential Bayesian optimization process. Once users finish editing the style of a selected character, they can propagate it to the remaining characters and further refine them as needed. The system then generates a complete outline font in OpenType format. We evaluated the effectiveness of FontCraft through a user study comparing it to a baseline interface. Results from both quantitative and qualitative evaluations demonstrate that FontCraft enables non-expert users to design fonts efficiently.",
    "title": "FontCraft: Multimodal Font Design Using Interactive Bayesian Optimization",
    "id": 189351,
    "sequence": 1141,
    "queryCoordinates": {
      "visualization": [
        -11.032648715793071,
        11.58795332722347
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "Touchscreens and touchpads offer intuitive interfaces but provide limited tactile feedback, usually just mechanical vibrations. These devices lack continuous feedback to guide users’ fingers toward specific directions. Recent innovations in surface haptic devices, however, leverage ultrasonic traveling waves to create active lateral forces on a bare fingertip. This paper \\revised{investigates the effects and design possibilities of active forces feedback in touch interactions by rendering artificial potential fields on a touchpad.Three user studies revealed that: (1) users perceived attractive and repulsive fields as bumps and holes with similar detection thresholds; (2) step-wise force fields improved targeting by 22.9% compared to friction-only methods; and (3) active force fields effectively communicated directional cues to the users. Several applications were tested, with user feedback favoring this approach for its enhanced tactile experience, added enjoyment, realism, and ease of use.",
    "title": "Attracting Fingers with Waves: Potential Fields Using Active Lateral Forces Enhance Touch Interactions",
    "id": 189352,
    "sequence": 1142,
    "queryCoordinates": {
      "visualization": [
        17.373778320622144,
        -13.496363468204317
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "In times of crisis, communities rise to fill the void of faltering institutions, self-organising to provide essential resources to marginalised populations. From providing relief to survivors of natural disasters, to addressing crises caused by societal failings like poverty, homelessness and unemployment, mutual aid is an important tool for community care and the development of new systems of survival. With mutual aid efforts increasingly entering the digital sphere, some work has investigated how the internet has transformed mutual aid, especially via social media. While such work describes mutual aid across a variety of contexts, we lack a broad understanding of how mutual aid principles translate online and the challenges organisers face in this digital landscape. To address this, we review 19 papers, identifying key characteristics, strategies, and challenges in online mutual aid. In doing so, we aim to enhance our understanding of how technology might foster sustainable community support and solidarity. \r\n",
    "title": "Virtual Solidarity, Concrete Care: A Review of Mutual Aid Online",
    "id": 189353,
    "sequence": 1143,
    "queryCoordinates": {
      "visualization": [
        -5.478852861078488,
        -7.1401800626211145
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "In this paper we describe how we designed the performance Human-Computer Counter-Choreographies (HCCC) using a methodology that borrows from artistic research, critical design, choreography, and embodied sense-making. HCCC is a live-coding performance in which I (the first author) manipulate JavaScript code and use a modified version of the open-source DuckDuckGo privacy extension to unveil online tracking algorithms on stage. Throughout the performance, the audience is encouraged to participate in a sequence of choreographic prompts where they embody aspects of online tracking such as fingerprinting and profiling. We analysed audience responses to questionnaires after three performances of HCCC and found that it allows audience members to gain awareness and engage their bodies to critically reflect on online tracking. We contribute a new approach to live-coding that bridges choreography with online tracking, and present empirical findings on the efficacy of this approach to engage audiences in reflecting on data tracking.",
    "title": "Human-Computer Counter-Choreographies: raising awareness of data tracking through live coding",
    "id": 189354,
    "sequence": 1144,
    "queryCoordinates": {
      "visualization": [
        -0.39254139461934406,
        7.990363649641379
      ]
    }
  },
  {
    "session": "Dark Patterns and Content Moderation",
    "abstract": "Social media platforms played a significant role in spreading genocidal content in the 2020-2022 Tigray war, where the deadliest genocide of the 21st century was committed. While linguistic expertise is clearly needed to adequately moderate such content, we ask: What additional expertise is needed? Why and to what extent do experts disagree on what constitutes harmful content, and what is the best way to resolve these disagreements? What do social media platforms do instead? We examine these questions through a 4 month study with 7 experts labeling 340 X (formerly Twitter) posts, and by interviewing 15 commercial content moderators. We find in-depth cultural knowledge and dialects to be most important for accurate hate speech annotation – knowledge which social media platforms do not prioritize. Even amongst experts, disagreements are high (71%), dropping to 40% after deliberation meetings. Based on these results, we present 7 recommendations to improve hate speech annotation and moderation practices.",
    "title": "The Role of Expertise in Effectively Moderating Harmful Social Media Content",
    "id": 189355,
    "sequence": 1145,
    "queryCoordinates": {
      "visualization": [
        8.695725088797944,
        -16.893323094644522
      ]
    }
  },
  {
    "session": "Workplace Interactions and Wellbeing",
    "abstract": "Bossware, software that monitors worker activity, is a common feature of workplaces. What do workers know about these tools and how they relate to their rights at work? We explored this question through two studies. Study 1 surveyed 100 workers to assess their understanding of work monitoring terminology. Participants were confident in their knowledge of key terms but struggled to accurately define them. Study 2 explored awareness of legal protection in relation to work monitoring through 19 semi-structured online interviews. We found that awareness varied with industry and work role, but was generally low and lacked certainty. Participants were largely skeptical of the use of bossware, questioning its necessity. Limited knowledge of monitoring terminology and legal protection at work further weakens workers' ability to notice and challenge the use of monitoring tools in their workplaces. We finish by speculating on whether educating workers about bossware and workplace rights would help.",
    "title": "Boss is aWare—Are you? Employee Comprehension and Legal Awareness of Workplace Monitoring",
    "id": 189356,
    "sequence": 1146,
    "queryCoordinates": {
      "visualization": [
        2.733532882382198,
        -14.74882361345932
      ]
    }
  },
  {
    "session": "Trust Uncertainty and Security",
    "abstract": "Email is ubiquitous, and in the context of phishing, it becomes critical, as risky behaviours like clicking on phishing links or downloading malicious files can lead to severe consequences. While much research exists on phishing susceptibility, there is still a gap in understanding factors that influence user micro-behaviour when interacting with phishing emails. To address this, we offer a tool, the Precision Email Simulator, to support phishing researchers, as well as considerations in conceptualising controlled `experimental simulation' studies, which are currently underutilised in phishing research. The Precision Email Simulator simulates real-world email inboxes and tracks precision user data, such as time spent on messages and eye-tracking for key areas like URLs and sender addresses. We discuss the practical uses of our simulator, and provide recommendations and guidelines of using our email simulator.",
    "title": "Precision Email Simulator for Research on Safety-Critical Phishing Behaviour",
    "id": 189357,
    "sequence": 1147,
    "queryCoordinates": {
      "visualization": [
        -7.140180062621115,
        5.478852861078488
      ]
    }
  },
  {
    "session": "XR for Diverse Needs",
    "abstract": "Accessibility is a crucial concept in Virtual Reality (VR), pivotal for meeting the needs of users, including those with disabilities. In recent years, there is an increasing focus of VR products on enhancing the accessibility of a diverse range of digital content. Despite this growing attention from the VR community, there is a serious lack of empirical research on  how VR practitioners consider VR accessibility. This includes their understanding of and insights into VR accessibility challenges and practices in the VR software development life cycle. In this paper, we aim to address these gaps using a mixed-methods approach. Specifically, we conducted interviews with 21 VR practitioners (incl. 3D modelers, developers, technical directors, and product managers), and surveyed 202 VR practitioner respondents from VR related industries. Our findings outline their insights and challenges they face concerning VR accessibility practices in the software development life cycle. Furthermore, our findings shed light on the challenges faced by practitioners concerning VR accessibility and the reasons why it often goes unconsidered. As far as we know, this is the first comprehensive report about the understanding of accessibility for VR software from the practitioner's perspective. We hope this paper will help VR professionals to better understand the issues and challenges in VR accessibility, and the potential solutions.",
    "title": "Understanding VR Accessibility Practices of VR Professionals ",
    "id": 189358,
    "sequence": 1148,
    "queryCoordinates": {
      "visualization": [
        -9.992290362407228,
        0.3925981575906895
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "Recent advances in generative AI have precipitated a proliferation of novel writing assistants. These systems typically rely on multilingual large language models (LLMs), providing globalized workers the ability to revise or create diverse forms of content in different languages. However, there is substantial evidence indicating that the performance of multilingual LLMs varies between languages. Users who employ writing assistance for multiple languages are therefore susceptible to disparate output quality. Importantly, recent research has shown that people tend to generalize algorithmic errors across independent tasks, violating the behavioral axiom of choice independence. In this paper, we analyze whether user utilization of novel writing assistants in a charity advertisement writing task is affected by the AI's performance in a second language. Furthermore, we quantify the extent to which these patterns translate into the persuasiveness of generated charity advertisements, as well as the role of peoples’ beliefs about LLM utilization for their donation choices. Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM. While these patterns do not affect the aggregate persuasiveness of the generated advertisements, people's beliefs about the source of an advertisement (human versus AI) do. In particular, Spanish-speaking female participants who believed that they read an AI-generated advertisement strongly adjusted their donation behavior downwards. Furthermore, people are generally not able to adequately differentiate between human-generated and LLM-generated ads. Our work has important implications on the design, development, integration, and adoption of multilingual LLMs as assistive agents—particularly in writing tasks.",
    "title": "Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages",
    "id": 189359,
    "sequence": 1149,
    "queryCoordinates": {
      "visualization": [
        4.050699073258642,
        -5.708926082714821
      ]
    }
  },
  {
    "session": "Robot and Agent",
    "abstract": "Temporary teams are important in modern work but often struggle with interpersonal factors that hinder consensus-driven tasks, especially in design teams where effective discussion and execution are critical. Integrating AI into these teams provides a promising solution. While some studies have explored AI’s role in enhancing teamwork, they often ignore the bidirectional impact of team dynamics: teams need to maintain a moderate level of disagreement, which must be effectively managed. To explore the mechanisms regulating conflict escalation and de-escalation in online collaboration of temporary design teams, we conducted exploratory research and an expert workshop (N=6) to propose proactive intervention strategies for AI voice agents. A controlled experiment (N=36) showed that teams with AI voice agent intervention performed better in improving interpersonal relationships, communication-related collaboration quality, and collaboration experience. This work suggests that AI voice agents can support team conflict dynamics by fostering constructive discussions and managing disagreements arising positively.",
    "title": "Maintaining \"Balanced\" Conflict: Proactive Intervention Strategies of AI Voice Agents in Online Collaboration of Temporary Design Teams",
    "id": 189360,
    "sequence": 1150,
    "queryCoordinates": {
      "visualization": [
        8.657797840548973,
        -15.781081602735142
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "Image-generative AI provides new opportunities to transform personal data into alternative visual forms. In this paper, we illustrate the potential of AI-generated images in facilitating meaningful engagement with personal data. In a formative autobiographical design study, we explored the design and use of AI-generated images derived from personal data. Informed by this study, we designed a web-based application as a probe that represents personal data through generative images utilizing Open AI’s GPT-4 model and DALL-E 3. We then conducted a 21-day diary study and interviews using the probe with 16 participants to investigate users’ in-depth experiences with images generated by AI in everyday lives. Our findings reveal new qualities of experiences in users’ engagement with data, highlighting how participants constructed personal meaning from their data through imagination and speculation on AI-generated images. We conclude by discussing the potential and concerns of leveraging image-generative AI for personal data meaning-making. ",
    "title": "Reimagining Personal Data: Unlocking the Potential of AI-Generated Images in Personal Data Meaning-Making",
    "id": 189361,
    "sequence": 1151,
    "queryCoordinates": {
      "visualization": [
        1.957892883300769,
        -14.871672920607157
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "Consumer virtual private network (VPN) providers promise online security and privacy by tunneling user traffic through their servers. However, there is a growing disparity between the users' perceptions of achievable security and privacy and the actual limitations of such services. In a large-scale, multi-step mixed methods study, we holistically investigated the degree to which 78 consumer VPN providers support or undermine proper mental models for their products and services. We collected search queries from 300 participants - coming from five countries across four continents - to identify suitable VPN providers and, subsequently their security and privacy promises. Among VPN providers’ statements, a large share contains misleading or false information, and more than half do not mention any threat agent at all. Our results extend the current research on consumer VPNs and provide a more realistic, holistic, and accurate overview of information on VPN provider websites.",
    "title": "Security Knight in Shining Armor: What and Who VPN Providers Claim to Shield Consumers Against",
    "id": 189362,
    "sequence": 1152,
    "queryCoordinates": {
      "visualization": [
        8.910556490355518,
        9.46583240038525
      ]
    }
  },
  {
    "session": "WS09: GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "abstract": "This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways.  Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together.\r\n\r\nFollowing successful workshops in 2022--2024, we convene the interdisciplinary research domain of generative AI and HCI. Participation is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",
    "title": "GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "id": 189363,
    "sequence": 1153,
    "queryCoordinates": {
      "visualization": [
        -1.885586947303989,
        3.527685057393421
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "Choreographers face increasing pressure to create content rapidly, driven by growing demand in social media, entertainment, and commercial sectors, often compromising creativity. This study introduces ChoreoCraft, a novel in-situ virtual reality (VR) choreographic system designed to enhance the creation process of choreography. Through contextual inquiries with professional choreographers, we identified key challenges such as memory dependency, creative plateaus, and abstract feedback to formulate design implications. Then, we propose a VR choreography creation system embedded with a context-aware choreography suggestion system and a choreography analysis system, all grounded in choreographers' creative processes and mental models. Our study results demonstrated that ChoreoCraft fosters creativity, reduces memory dependency, and improves efficiency in choreography creation. Participants reported high satisfaction with the system's ability to overcome creative plateaus and provide objective feedback. Our work advances creativity support tools by providing digital assistance in dance composition that values artistic autonomy while fostering innovation and efficiency.",
    "title": "ChoreoCraft: In-situ Crafting of Choreography in Virtual Reality through Creativity Support Tool",
    "id": 189364,
    "sequence": 1154,
    "queryCoordinates": {
      "visualization": [
        15.124310177258657,
        14.568982176599372
      ]
    }
  },
  {
    "session": "UI/UX Design",
    "abstract": "We present Persona-L, a novel approach for creating personas using Large Language Models (LLMs) and an ability-based framework, specifically designed to improve the representation of people with complex needs. Traditional methods of persona creation often fall short of accurately depicting the dynamic and diverse nature of complex needs, resulting in oversimplified or stereotypical profiles. Persona-L enables users to create and interact with personas through a chat interface. Persona-L was evaluated through interviews with UX designers (N=6), where we examined its effectiveness in reflecting the complexities of lived experiences of people with complex needs. We report our findings that indicate the potential of Persona-L to increase empathy and understanding of complex needs while also revealing the need for transparency of data used in persona creation, the role of the language and tone, and the need to provide a more balanced presentation of abilities with constraints.\r\n\r\n",
    "title": "Persona-L has Entered the Chat: Leveraging LLMs and Ability-based Framework for Personas of People with Complex Needs",
    "id": 189365,
    "sequence": 1155,
    "queryCoordinates": {
      "visualization": [
        3.5159255986870885,
        -19.688531361797835
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "Generative AI models are increasingly being integrated into human task workflows, enabling the production of expressive content across a wide range of contexts. Unlike traditional human-AI design methods, the new approach to designing generative capabilities focuses heavily on prompt engineering strategies. This shift requires a deeper understanding of how collaborative software teams establish and apply design guidelines, iteratively prototype prompts, and evaluate them to achieve specific outcomes. To explore these dynamics, we conducted design studies with 39 industry professionals, including UX designers, AI engineers, and product managers. Our findings highlight emerging practices and role shifts in AI system prototyping among multistakeholder teams. We observe various prompting and prototyping strategies, highlighting the pivotal role of to-be-generated content characteristics in enabling rapid, iterative prototyping with generative AI. By identifying associated challenges, such as the limited model interpretability and overfitting the design to specific example content, we outline considerations for generative AI prototyping. ",
    "title": "Prototyping with Prompts: Emerging Approaches and Challenges in Generative AI Design for Collaborative Software Teams",
    "id": 189366,
    "sequence": 1156,
    "queryCoordinates": {
      "visualization": [
        -8.613109359986627,
        14.656546221839262
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "People's decision-making abilities often fail to improve or may even erode when they rely on AI for decision support, even when the AI provides informative explanations. We argue this is partly because people intuitively seek contrastive explanations, which clarify the difference between the AI's decision and their own reasoning, while most AI systems offer \"unilateral\" explanations that justify the AI’s decision but do not account for users' knowledge and thinking. To address potential human knowledge gaps, we introduce a framework for generating human-centered contrastive explanations that explain the difference between AI's choice and a predicted, likely human choice about the same task.\r\nResults from a large-scale experiment (N = 628) demonstrate that contrastive explanations significantly enhance users' independent decision-making skills compared to unilateral explanations, without sacrificing decision accuracy. As concerns about deskilling in AI-supported tasks grow, our research demonstrates that integrating human reasoning into AI design can promote human skill development.",
    "title": "Contrastive Explanations That Anticipate Human Misconceptions Can Improve Human Decision-Making Skills",
    "id": 189367,
    "sequence": 1157,
    "queryCoordinates": {
      "visualization": [
        19.688391629423982,
        7.305288156289772
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "Improving decision-making capabilities in Autonomous Intelligent Vehicles (AIVs) has been a heated topic in recent years. Despite advancements, training machine to capture regions of interest for comprehensive scene understanding, like human perception and reasoning, remains a significant challenge. This study introduces a novel framework, Human Attention-based Explainable Guidance for Intelligent Vehicle Systems (AEGIS). \r\nAEGIS utilizes human attention, converted from eye-tracking, to guide reinforcement learning (RL) models to identify critical regions of interest for decision-making. AEGIS uses a pre-trained human attention model to guide reinforcement learning (RL) models to identify critical regions of interest for decision-making. By collecting 1.2 million frames from 20 participants across six scenarios, AEGIS pre-trains a model to predict human attention patterns. The learned human attention guides the RL agent’s focus on task-relevant objects, prioritizes critical instances, enhances robustness in unseen environments, and leads to faster learning convergence. This approach enhances interpretability by making machine attention more comparable to human attention and thus enhancing the RL agent’s performance in diverse driving scenarios. The code is available in https://github.com/ALEX95GOGO/AEGIS.",
    "title": "AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems",
    "id": 189368,
    "sequence": 1158,
    "queryCoordinates": {
      "visualization": [
        13.154498931851764,
        -13.709819760008182
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "Understanding the intentions of robots is essential for natural and seamless human-robot collaboration. Ensuring that robots have means for non-verbal communication is a basis for intuitive and implicit interaction. For this, we describe an approach to elicit and design human-understandable robot expressions. We outline the approach in the context of non-humanoid robots. We paired human mimicking and enactment with research from gesture elicitation in two phases: first, to elicit expressions, and second, to ensure they are understandable. We present an example application through two studies (N=16 \\& N=260) of our approach to elicit expressions for a simple 6-DoF robotic arm. We show that the approach enabled us to design robot expressions that signal curiosity and interest in getting attention. Our main contribution is an approach to generate and validate understandable expressions for robots, enabling more natural human-robot interaction.",
    "title": "An Approach to Elicit Human-Understandable Robot Expressions to Support Human-Robot Interaction",
    "id": 189369,
    "sequence": 1159,
    "queryCoordinates": {
      "visualization": [
        -2.714404498650742,
        -9.624552364536473
      ]
    }
  },
  {
    "session": "Systems, Power, and Digital Realities",
    "abstract": "Email is a horrible thing. The following goofy but thoughtful rant describes the four Axioms of Email, analyzes our inbox using Yoblanski’s Laws of UX, and describes exactly how and why email is so brutal. In particular, this work: identifies email as an unending background hum in the soundtrack of our lives; reveals how our inbox constantly lies to us; and explores how our brains are both awesome and terrible. Potential design solutions are suggested, and three new Laws of UX are proposed: Schrodinger’s Email; the Sisyphus Effect; and Caro’s Law. Readers who hate email will benefit from a better understanding of why it sucks so much; and readers who find email simple and straightforward will learn why they should stop judging the rest of us. Feel free to give a copy of this anonymously to your boss, so they’re less rude next time you miss an important email (that could have just been a meeting!).",
    "title": "Musings on the Brutality of Email",
    "id": 189370,
    "sequence": 1160,
    "queryCoordinates": {
      "visualization": [
        12.295263713085193,
        -11.739952735240909
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "California’s agricultural workers are a vulnerable population due to their undocumented status and poor working conditions. This paper describes community engagement with NGO workers, farm laborers, and farm owners to identify and address the effects of climate change, namely heat stress, on, strawberry field workers. We deployed personal informatics devices in a longitudinal study with three field workers for a month and a half and presented the collected statistics back to them, asking them to reflect on their personal health (e.g., exposure to heat stress) and work data. We found that field workers normalized grit - the irregularity, adversity, competitiveness, and helplessness of their labor - thereby limiting the promise of personal informatics to help users lead healthier lives. Implicitly, personal informatics supports white collar workers such as information workers; overall, however, our study suggests a mismatch between current designs and front-line work which involve intensive physical work requirements.",
    "title": "Normalizing Grit: The Futility of Personal Informatics for Farm Workers and Climate Change",
    "id": 189371,
    "sequence": 1161,
    "queryCoordinates": {
      "visualization": [
        -0.39266415810101685,
        -16.99546453789783
      ]
    }
  },
  {
    "session": "Methodology",
    "abstract": "HCI researchers have explored ways to improve HCI and design education. We designed and conducted an experiential learning internship to teach principles of design research to first-year undergraduate students. We describe the framework we used for the design of the internship and the lessons we learned in a self-reflective case study. We provide the following recommendations to other educators who want to incorporate similar programs: 1) prepare for clients having differences in opinion, 2) use multiple educational methods to supplement the experience, 3) allow interns to navigate a project space on their own, but identify areas that may create major delays, and 4) prepare educational material on the latest trends and tools that may be of interest to the interns.",
    "title": "Experiential Learning Internship for Teaching Design Research",
    "id": 189372,
    "sequence": 1162,
    "queryCoordinates": {
      "visualization": [
        7.319067412721325,
        -20.746837161554065
      ]
    }
  },
  {
    "session": "Technologies for Decision Making",
    "abstract": "Adolescent girls and young women (AGYW) in sub-Saharan Africa face unique barriers to contraceptive access and lack AGYW-centered contraceptive decision-support resources. To empower AGYW to make informed choices and improve reproductive health outcomes, we developed a tablet-based application to provide contraceptive education and decision-making support in the pharmacy setting - a key source of contraceptive services for AGYW - in Kenya. We conducted workshops with AGYW and pharmacy providers in Kenya to gather app feedback and understand how to integrate the intervention into the pharmacy setting. Our analysis highlights how intermediated interactions - a multiuser, cooperative effort to enable technology use and information access - could inform a successful contraceptive intervention in Kenya. The potential strengths of intermediation in our setting inform implications for technological health interventions in intermediated scenarios in low- and middle-income countries, including challenges and opportunities for extending impact to different populations and integrating technology into resource-constrained healthcare settings.",
    "title": "Supporting Contraceptive Decision-Making in the Intermediated Pharmacy Setting in Kenya",
    "id": 189373,
    "sequence": 1163,
    "queryCoordinates": {
      "visualization": [
        -16.95919536008319,
        -1.1771545092012563
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "We present BioTube, a sustainable and highly accessible DIY fabrication approach for creating hollow tubular alginate, and demonstrate its potential for making biodegradable transient devices. This technique involves extruding alginate into a calcium solution, initiating a progressive crosslinking process that starts from the outer shell and progresses inward. This controlled process removes the uncrosslinked core before complete gelation, yielding hollow alginate fibers. To further enhance the capabilities of BioTube, we explored three further crosslinking strategies to customize the fiber shape, local cross-sectional geometry, and stiffness. The versatility of this method is demonstrated through three key functional primitives: shape, morphing, and sensing. These capabilities are further illustrated through five application examples, including transient wearables, edible shape-changing interfaces, experimental gastronomy, underwater grippers, and sacrificial casting molds. We believe that BioTube will expand the design possibilities for alginate, enabling the creation of innovative biodegradable devices.",
    "title": "BioTube: Designing and Fabricating Biodegradable Hollow Tubular Devices Through Progressive Crosslinking Alginate",
    "id": 189374,
    "sequence": 1164,
    "queryCoordinates": {
      "visualization": [
        10.696523261502504,
        -9.032407769589227
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "Large language models (LLMs) have been positioned to revolutionize HCI, by reshaping not only the interfaces, design patterns, and sociotechnical systems that we study, but also the research practices we use. To-date, however, there has been little understanding of LLMs' uptake in HCI. We address this gap via a systematic literature review of 153 CHI papers from 2020-24 that engage with LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in HCI projects; (3) contribution types; and (4) acknowledged limitations and risks. We find LLM work in 10 diverse domains, primarily via empirical and artifact contributions. Authors use LLMs in five distinct roles, including as research tools or simulated users. Still, authors often raise validity and reproducibility concerns, and overwhelmingly study closed models. We outline opportunities to improve HCI research with and on LLMs, and provide guiding questions for researchers to consider the validity and appropriateness of LLM-related work.",
    "title": "Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review",
    "id": 189375,
    "sequence": 1165,
    "queryCoordinates": {
      "visualization": [
        11.942216720066362,
        -1.1762056839547368
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "The global environmental crises continue to get worse, fast approaching various irreversible thresholds. While a vast array of approaches to solving sustainability problems are found under the umbrella of Sustainable HCI, their contributions are sometimes hard to compare. In this essay, we describe a set of assumptions that influence what is considered meaningful and important areas of sustainability research, along four dimensions of sustainability: 1) the depth and nature of the sustainability challenges; 2) the role of technological innovation in sustainability; 3) what gets defined as \"externalities\" to a design or system; and 4) the time perspective used to consider sustainability. We argue that what one assumes within each of these dimensions directly influences what one means by the term \"sustainability\", which is then reflected in the questions that are asked, the methods chosen, the proposed solutions and the developed systems. By describing these assumptions and some of their commensurate actions, we offer a framework that may enable members of the SHCI community to reflect on and better position their own work and that of others in the field. Our intention is for the framework to lead to better transparency and more constructive conversations about where we might collectively direct our efforts moving forward.",
    "title": "Exploring Assumptions about Sustainability: Towards a Constructive Framework for Action in Sustainable HCI",
    "id": 189376,
    "sequence": 1166,
    "queryCoordinates": {
      "visualization": [
        -14.291588819128247,
        7.193781274473704
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "With the growing number of immigrants globally, language barriers have become a significant challenge, particularly for those entering English-speaking countries. Traditional language learning methods often fail to provide sufficient practical opportunities, especially for diverse accents. To address this, we introduce Language Urban Odyssey (LUO), a serious game that leverages large language models (LLMs) and game-based learning to offer a low-cost, accessible virtual environment for English learners. Built on the Minecraft platform, LUO offers real-time speech interaction with NPCs of various accents, supported by multi-modal feedback. A controlled study (N=30) showed improvements in speaking abilities, accent comprehension, and emotional confidence. Our findings suggest that LUO provides a scalable, immersive platform that bridges gaps in language learning for immigrants facing cultural and social challenges.",
    "title": "Unlocking the Power of Speech: Game-Based Accent and Oral Communication Training for Immigrant English Language Learners via Large Language Models",
    "id": 189377,
    "sequence": 1167,
    "queryCoordinates": {
      "visualization": [
        -5.884711682419383,
        1.1705419320967716
      ]
    }
  },
  {
    "session": "Games",
    "abstract": "User-generated game (UGG) platforms like Roblox are enormously popular among children but are increasingly scrutinized for safety risks, such as gambling-like gameplay features and disturbing game themes such as slavery and Nazi roleplay. Researchers have started to examine harms in UGGs, but little attention has been paid to how game creators themselves consider child safety in their game making practices. To answer this question, we conducted an interview study with 20 Roblox creators with varied degrees of success. We found that our interviewees observed several types of risks to child players’ safety in their games, such as child-specific deceptive design, gambling-like gameplay, sexual abuse, and scamming. They further reasoned about major causes of these safety risks, such as Roblox’s profit-driven monetization model, and leaving the burden of moderation to individual game creators. We discuss implications for platform governance on UGG platforms as well as policymaking.",
    "title": "\"The System is Made to Inherently Push Child Gambling in my Opinion\": Child Safety, Monetization, and Moderation on Roblox",
    "id": 189378,
    "sequence": 1168,
    "queryCoordinates": {
      "visualization": [
        -3.9807389066887877,
        -0.39206856131824236
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "As the global aging population grows and technology advances rapidly, integrating technology into community-based initiatives for older adults has become an increasingly important topic among HCI researchers. This research explores the role of Information and Communication Technology (ICT) tools in the co-creation and maintenance of a community gardening program involving researchers, older adult residents, and supporting organizations. A follow-up study, conducted eight months after the program’s initiation assessed its sustainability, revealing how stakeholders navigated diverse ICT preferences and challenges by employing a hybrid communication system that integrated both digital and face-to-face methods to foster collaboration and sustain the initiative. This research contributes to the understanding of community preferences and needs, and the importance of contextualizing technology use within Japanese local community for collaborative community development.",
    "title": "The Role of ICT Tools through a Community Program Co-creation in a Japanese Aging Community",
    "id": 189379,
    "sequence": 1169,
    "queryCoordinates": {
      "visualization": [
        5.773321504383243,
        15.98964536214065
      ]
    }
  },
  {
    "session": "WS29: Everyday AR through AI-in-the-Loop",
    "abstract": "This workshop brings together experts and practitioners from augmented reality (AR) and artificial intelligence (AI) to shape the future of AI-in-the-loop everyday AR experiences. With recent advancements in both AR hardware and AI capabilities, we envision that everyday AR---always-available and seamlessly integrated into users' daily environments---is becoming increasingly feasible. This workshop will explore how AI can drive such everyday AR experiences. We discuss a range of topics, including adaptive and context-aware AR, generative AR content creation, always-on AI assistants, AI-driven accessible design, and real-world-oriented AI agents. Our goal is to identify the opportunities and challenges in AI-enabled AR, focusing on creating novel AR experiences that seamlessly blend the digital and physical worlds. Through the workshop, we aim to foster collaboration, inspire future research, and build a community to advance the research field of AI-enhanced AR.",
    "title": "Everyday AR through AI-in-the-Loop",
    "id": 189380,
    "sequence": 1170,
    "queryCoordinates": {
      "visualization": [
        -14.99485987463336,
        0.39265422461810134
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "This study investigates how interaction scenarios of human caregiving for robots affect humans’ perceived bond with robots. In a between-subjects lab experiment (n = 88), participants played a game with a social robot during which they provided either 1) emotional care (comforting the robot); 2) instrumental care (helping with battery charging); or 3) no care for the robot. Results indicated that caregiving did not significantly affect human-robot bonding according to explicit relationship measures including closeness, social attraction, or desire for future interaction. However, caregiving mattered when bonding was measured implicitly. Those in the emotional caregiving scenario were more hesitant to replace the robot and invested more effort in a voluntary task requested by the robot than those who provided no care. These findings provide empirical evidence that emotional caregiving interactions can effectively foster initial human-robot bonding, highlighting a promising design scenario for human-robot interaction.",
    "title": "Does Care Lead to Bonds? Exploring the Relationship Between Human Caregiving for Robots and Human-Robot Bonding",
    "id": 189381,
    "sequence": 1171,
    "queryCoordinates": {
      "visualization": [
        6.190939493098339,
        -7.853169308807449
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "Digital artists use creativity support tools guided by their ideas of “intended use” and therefore \"misuse''—but what does misuse mean in creative practice? To discover what constitutes misuse and what creative contexts call for misuse, we interviewed 20 expert creative practitioners across 8 visual art disciplines. We identify five sources of normativity which form conventions of misuse: traditional practices, educational institutions, industry norms, online communities, and tools themselves. We surface why artists defy norms and misuse creative software by exploring how software apathy affects tool engagement, how tool genealogies and personal histories impact artists’ practices, and how artists prioritize practical and professional needs during the creative process. Alongside traditional definitions, we offer artists’ individual perspectives on what misuse means and its relevance to their creative practice. By understanding artists as \"mis-users\", we present an opportunity to revise how we design for using and misusing creativity support tools.",
    "title": "Reimagining Misuse as Creative Practice: Impressions and Implications of Usage Norms on Digital Artists",
    "id": 189382,
    "sequence": 1172,
    "queryCoordinates": {
      "visualization": [
        -7.193781274473707,
        14.291588819128243
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "Children are playing games from a young age and, despite their best efforts, parents often lack the support to fully understand what their children are playing.  Ratings systems like PEGI are designed to allow informed parental decisions, but it is currently largely unknown if they capture what parents care about.  In this study, we analysed 821 1-star reviews of 40 top-grossing mobile games on the Google Play store focused on parental concerns. We used content analysis to identify the key concerns that parents were expressing with regards to the games their children were playing.  The reviews found that parents often reported technical issues, issues surrounding in-game purchases and concerns around player-to-player interaction.  This research has implications for the way games are sold to parents and the way children play games, as well as presenting some suggestions for future research and innovation in this area.  ",
    "title": "\"Leave our kids alone!\": Exploring Concerns Reported by Parents in 1-star Reviews",
    "id": 189383,
    "sequence": 1173,
    "queryCoordinates": {
      "visualization": [
        0.39265422461808347,
        -14.99485987463336
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "This paper presents the design process, outcomes, and installation of ShamAIn, a multi-modal embodiment of conversational AI inspired by the beliefs and symbols of Korean shamanism. Adopting a research-through-design approach, we offer an alternative perspective on conversational AI design, emphasizing perceived superiority. ShamAIn was developed based on strategies derived from investigating people's experiences with shamanistic counseling and rituals. We deployed the system in an exhibition room for six weeks, during which 20 participants made multiple visits to engage with ShamAIn. Through subsequent in-depth interviews, we found that participants felt a sense of awe toward ShamAIn and engaged in interactions with humility and respect. Our participants disclosed personal and profound concerns, reflecting deeply on the responses they received. Consequently, they relied on ShamAIn and formed relationships in which they received support. In the discussion, we present the design implications of conversational AI perceived as superior to humans, along with the ethical considerations involved in designing such AI.",
    "title": "ShamAIn: Designing Superior Conversational AI Inspired by Shamanism",
    "id": 189384,
    "sequence": 1174,
    "queryCoordinates": {
      "visualization": [
        1.1747357299804615,
        -8.923003752364295
      ]
    }
  },
  {
    "session": "HCI Methods",
    "abstract": "We examine how micro-phenomenology, a qualitative research method developed to attend to, articulate, and analyse lived experience in fine detail, can be employed to study the experience of using digital systems. Micro-phenomenological interviews unpack the specific experiences of interviewees in fine-grained detail and have previously been acknowledged as a potent tool for Human-Computer Interaction Research. More recently, the method has been extended to comprise a structured analysis method to systematically analyse the temporal unfolding and qualitative dimensions of experiences captured by the interviews. This is the first paper demonstrating the combined use of interviews and analysis via a case in which they were employed to examine the experience of using WeUsedTo, a website for sharing experiences related to the COVID-19 pandemic. On this basis, we discuss the potentials of the method for eliciting and understanding experiential aspects of interactive systems, particularly pertaining to embodiment, temporality, attention, agency, and the systemic nature of experience.",
    "title": "Micro-Phenomenology as a Method for Studying User Experience in Human-Computer Interaction",
    "id": 189385,
    "sequence": 1175,
    "queryCoordinates": {
      "visualization": [
        3.473795463765275,
        10.437085085210516
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "Research and technological advancements have driven the development of wearable technology for stress management. Previous reviews primarily focused on its performance and effectiveness in health contexts. In contrast, this review takes a human-centric approach and reviews studies on users’ attitudes and experiences. We conducted a narrative review to identify (1) the facilitators and barriers of wearable stress management technology (WSMT) and (2) design considerations for human-centered WSMT. We identified 28 articles reporting user perspectives on stress management technology, primarily based on evaluation studies in which user perspectives were gathered through qualitative methods. We found five facilitators and barriers of WSMT (i.e., usefulness, functionality/interactivity, seamlessness, user privacy, and technology’s image). Additionally, we synthesized 18 design considerations, highlighted two main design challenges, and proposed a value-sensitive approach for future research. This review adds to the HCI literature by demonstrating the complexity of designing human-centered WSMT and the need for actionable recommendations.",
    "title": "Facilitators and Barriers of Wearable Stress Management Technology: A Narrative Review of User Perspectives",
    "id": 189386,
    "sequence": 1176,
    "queryCoordinates": {
      "visualization": [
        6.505618350206527,
        15.705952052691874
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "Automated vehicle (AV) acceptance relies on their understanding via feedback. While visualizations aim to enhance user understanding of AV's detection, prediction, and planning functionalities, establishing an optimal design is challenging. Traditional \"one-size-fits-all\" designs might be unsuitable, stemming from resource-intensive empirical evaluations. This paper introduces OptiCarVis, a set of Human-in-the-Loop (HITL) approaches using Multi-Objective Bayesian Optimization (MOBO) to optimize AV feedback visualizations. We compare conditions using eight expert and user-customized designs for a Warm-Start HITL MOBO. An online study (N=117) demonstrates OptiCarVis efficacy in significantly improving trust, acceptance, perceived safety, and predictability without increasing cognitive load. OptiCarVis facilitates a comprehensive design space exploration, enhancing in-vehicle interfaces for optimal passenger experiences and broader applicability.",
    "title": "OptiCarVis: Improving Automated Vehicle Functionality Visualizations Using Bayesian Optimization to Enhance User Experience",
    "id": 189387,
    "sequence": 1177,
    "queryCoordinates": {
      "visualization": [
        -6.901097129627651,
        1.1725435631331558
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "Music notation programs force composers to follow the many rules of the staff notation when writing music and constantly seek to optimize symbol placement, making numerous adjustments automatically. Even though this impedes their creative process, many composers still use them throughout their workflow, for lack of a better option. We introduce EuterPen, a music notation program prototype that selectively relaxes both syntactic and structural constraints while editing a score. Composers can input and manipulate music symbols with increased flexibility, leveraging the affordances of pen and touch. They can make space on, between and around staves to insert additional content such as digital ink, pictures and audio samples. We describe the iterative design process that led to EuterPen: prototyping phases, a participatory design workshop, and a series of interviews. Feedback from the participating professional composers indicates that EuterPen offers a compelling and promising approach to music writing.",
    "title": "EuterPen: Unleashing Creative Expression in Music Score Writing",
    "id": 189388,
    "sequence": 1178,
    "queryCoordinates": {
      "visualization": [
        15.124310177258666,
        -14.568982176599366
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "Virtual reality (VR) is often used in small physical environments, requiring users to remain aware of their environment to avoid injury or damage. However, this can reduce their spatial presence in VR. Previous work and theory lack an account of how the physical environment (PE) affects spatial presence. To address this gap, we investigated the effect on spatial presence of (1) the degree of spatial knowledge of the PE and (2) knowledge of and (3) collisions with obstacles in the PE. Estimates from Bayesian regression models suggest that limiting spatial knowledge of the PE increases spatial presence initially but amplifies the detrimental effect of obstacle collisions. Repeatedly avoiding obstacles further decreases spatial presence, but removing them from the user's path yields a partial recovery. Our work contributes empirical evidence to theories of spatial presence formation and highlights the need to consider the physical environment when designing for presence in VR.",
    "title": "How your Physical Environment Affects Spatial Presence in Virtual Reality",
    "id": 189389,
    "sequence": 1179,
    "queryCoordinates": {
      "visualization": [
        5.758320584559815,
        -14.92788478135582
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "Haptic Experience (HX) encompasses distinct quality criteria specific to haptic interactions, yet no standardized instrument exists to measure it. This makes understanding and evaluating HX challenging. This paper reports on the development and validation of the Haptic Experience Inventory (HXI), a questionnaire measuring HX. An item pool of 50 items is developed through theoretical construction, expert reviews (N=10), and cognitive interviews (N=9). These items are then subjected to exploratory and confirmatory factor analysis using data from 591 participants across in-person and online studies, covering vibrotactile, force-feedback, and mid-air devices. Eventually, a 20-item HXI with five dimensions is established: Autotelics, Realism, Involvement, Harmony, and Discord. The HXI converges with theory and shows strong reliability, validity, and measurement invariance, suggesting it is effective across deployed modalities and contexts. The HXI provides empirical evidence about the structure of HX and offers a robust, standardized tool for assessing haptic feedback in research and practice.",
    "title": "Development and Initial Validation of the Haptic Experience Inventory (HXI)",
    "id": 189390,
    "sequence": 1180,
    "queryCoordinates": {
      "visualization": [
        1.9286367918189637,
        -5.681580776970636
      ]
    }
  },
  {
    "session": "WS40: Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "abstract": "Local and federal agencies are rapidly adopting AI systems to augment or automate critical decisions, efficiently use resources, and improve public service delivery. AI systems are being used to support tasks associated with urban planning, security, surveillance, energy and critical infrastructure, and support decisions that directly affect citizens and their ability to access essential services. Local governments act as the governance tier closest to citizens and must play a critical role in upholding democratic values and building community trust especially as it relates to smart city initiatives that seek to transform public services through the adoption of AI. Community-centered and participatory approaches have been central for ensuring the appropriate adoption of technology; however, AI innovation introduces new challenges in this context because participatory AI design methods require more robust formulation and face higher standards for implementation in the public sector compared to the private sector. This requires us to reassess traditional methods used in this space as well as develop new resources and methods. This workshop will explore emerging practices in participatory algorithm design – or the use of public participation and community engagement - in the scoping, design, adoption, and implementation of public sector algorithms.",
    "title": " Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "id": 189391,
    "sequence": 1181,
    "queryCoordinates": {
      "visualization": [
        -3.5139448781596045,
        18.672230487899828
      ]
    }
  },
  {
    "session": "WS27: Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "abstract": "Education, healthcare, poverty, and equity are just some of the social problems in which XR researchers leverage augmented reality, virtual reality, and mixed reality to create novel solutions. In this workshop proposal, we intend on gathering XR researchers who are interested in making a positive impact with their research, and to use this opportunity to discuss leveraging unique affordances of XR technology and common challenges. In our motivation, we refer to recent human computer interaction gatherings that discuss applications of XR to social benefit. Then, we present a background of research across XR technologies and diverse social problems to illustrate example affordances and challenges. To attend the workshop, attendees will submit a position paper on a particular XR affordances and how it can help address a social problem, and optionally submit a demo artifact as a sample for group discussion. The workshop will include a keynote, discussion based activities and demos, and conclude with a speculative exercise, where attendees will work together to describe XR technology in the context of an ethical future.",
    "title": "Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "id": 189392,
    "sequence": 1182,
    "queryCoordinates": {
      "visualization": [
        7.961196423942022,
        16.14370934758839
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "While voice input offers a convenient alternative to traditional text editing on mobile devices, practical implementations face two key challenges: 1) reliably distinguishing between editing commands and content dictation, and 2) effortlessly pinpointing the intended edit location. We propose Tap&Say, a novel multimodal system that combines touch interactions with Large Language Models (LLMs) for accurate text correction. By tapping near an error, users signal their edit intent and location, addressing both challenges. Then, the user speaks the correction text. Tap&Say utilizes the touch location, voice input, and existing text to generate contextually relevant correction suggestions. We propose a novel touch location-informed attention layer that integrates the tap location into the LLM's attention mechanism, enabling it to utilize the tap location for text correction. We fine-tuned the touch location-informed LLM on synthetic touch locations and correction commands, achieving significantly higher correction accuracy than the state-of-the-art method VT. A 16-person user study demonstrated that Tap&Say outperforms VT with 16.4% shorter task completion time and 47.5% fewer keyboard clicks and is preferred by users.",
    "title": "Tap&Say: Touch Location-Informed Large Language Model for Multimodal Text Correction on Smartphones",
    "id": 189393,
    "sequence": 1183,
    "queryCoordinates": {
      "visualization": [
        6.080311868540942,
        6.635496031291117
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "What drives employees to ensure security when handling information assets in organizations? There is growing interest from the security behavior community in how autonomous motivators shape employees’ security-related behaviors. To reconcile the scattered viewpoints on autonomous motivation and synthesize findings from studies utilizing various theoretical frameworks, we systematically reviewed relevant publications. We present a preregistered literature review that investigated (a) what forms of autonomous motivation have been examined in organizational security contexts, (b) which behaviors/behavioral intentions are related to autonomous motivators, and (c) how autonomous motivation affects employees’ security behaviors. Based on an initial set of 432 papers, filtered down to 45 studies, we identified 17 unique autonomous motivators and three types of related security behaviors. This review not only develops a refined taxonomy of autonomous motivation related to security behaviors but also charts a path forward for future research on autonomous motivation in human-centered security.",
    "title": "Beyond Deterrence: A Systematic Review of the Role of Autonomous Motivation in Organizational Security Behavior Studies",
    "id": 189394,
    "sequence": 1184,
    "queryCoordinates": {
      "visualization": [
        1.9286367918189702,
        5.681580776970634
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "Chief Information Security Officers (CISOs) are responsible for setting and executing organizations' information security strategies. This role has only grown in importance as a result of today's increasingly high-stakes threat landscape. To understand these key decision-makers, we interviewed 16 current and former CISOs to understand how they build a security strategy and the day-to-day obstacles that they face. Throughout, we find that the CISO role is strongly shaped by a business enablement perspective, driven by broad organizational goals beyond solely technical protection. Within that framing, we describe the most salient concerns for CISOs, isolate key decision-making factors they use when prioritizing security investments, and surface practical complexities and pain points that they face in executing their strategy. Our results surface opportunities to help CISOs better navigate the complex task of managing organizational risk, as well as lessons for how security tools can be made more deployable in practice.",
    "title": "\"Perfect is the Enemy of Good\": The CISO's Role in Enterprise Security as a Business Enabler",
    "id": 189395,
    "sequence": 1185,
    "queryCoordinates": {
      "visualization": [
        -12.946655249022182,
        1.1764853857852937
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "Cryptocurrency adoption has surged dramatically, with over 500 million global users. Despite the appeal of self-custodial wallets, which grant users control over their assets, these users often struggle with the complexities of securing seed phrases, leading to substantial financial losses. This paper investigates the behaviors, challenges, and security practices of cryptocurrency users regarding seed phrase management. We conducted a mixed-methods study comprising semi-structured interviews with 20 participants and a comprehensive survey of 643 respondents. Our findings reveal significant gaps in users' understanding and practices around seed phrase security \r\nand the circumstances under which users share their seed phrases. We also explore users' mental models of shared accounts and strategies for handling cryptocurrency assets in the event of death. We found that the majority of our participants harbored significant misconceptions about seed phrases that could expose them to significant security risks --- e.g., only 43% could correctly identify an image of a seed phrase, many believed they could reset their seed phrase if they lost them. Moreover, only a minority have engaged in any estate planning for their crypto assets.  By identifying these challenges and behaviors, we provide actionable insights for the design of more secure and user-friendly cryptocurrency wallets, ultimately aiming to enhance user confidence in managing their crypto assets reduce their exposure to scams and accidental loss of assets, and simplify the creation of bequeathment plans.",
    "title": "Of Secrets and Seedphrases: Conceptual misunderstandings and security challenges for seed phrase management among cryptocurrency users",
    "id": 189396,
    "sequence": 1186,
    "queryCoordinates": {
      "visualization": [
        -7.5323525214641665,
        2.695118827137759
      ]
    }
  },
  {
    "session": "Knowledge Work",
    "abstract": "Knowledge gaps often arise during communication due to diverse backgrounds, knowledge bases, and vocabularies. With recent LLM developments, providing real-time knowledge support is increasingly viable, but is challenging due to shared and individual cognitive limitations (e.g., attention, memory, and comprehension) and the difficulty in understanding the user's context and internal knowledge. To address these challenges, we explore the key question of understanding how people want to receive real-time knowledge support. We built StopGap---a prototype that provides real-time knowledge support for explaining jargon words in videos---to conduct a design probe study (N=24) that explored multiple visual knowledge representation formats. Our study revealed individual differences in preferred representations and highlighted the importance of user agency, personalization, and mixed-initiative assistance. Based on our findings, we map out six key design dimensions for real-time LLM knowledge support systems and offer insights for future research in this space.",
    "title": "Exploring the Design Space of Real-time LLM Knowledge Support Systems: A Case Study of Jargon Explanations",
    "id": 189397,
    "sequence": 1187,
    "queryCoordinates": {
      "visualization": [
        -15.78108160273514,
        -8.657797840548973
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "With the increasing spread of AR head-mounted displays suitable for everyday use, interaction with information becomes ubiquitous, even while walking. However, this requires constant shifts of our attention between walking and interacting with virtual information to fulfill both tasks adequately. Accordingly, we as a community need a thorough understanding of the mutual influences of walking and interacting with digital information to design safe yet effective interactions. Thus, we systematically investigate the effects of different AR anchors (hand, head, torso) and task difficulties on user experience and performance. We engage participants (n=26) in a dual-task paradigm involving a visual working memory task while walking. We assess the impact of dual-tasking on both virtual and walking performance, and subjective evaluations of mental and physical load. Our results show that head-anchored AR content least affected walking while allowing for fast and accurate virtual task interaction, while hand-anchored content increased reaction times and workload.",
    "title": "AR You on Track? Investigating Effects of Augmented Reality Anchoring on Dual-Task Performance While Walking",
    "id": 189398,
    "sequence": 1188,
    "queryCoordinates": {
      "visualization": [
        11.86822467180124,
        13.533116534621593
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "Parkinson's Disease (PD) significantly impacts driving abilities, often leading to early driving cessation or accidents due to reduced motor control and increasing reaction times. To diminish the impact of these symptoms, we developed PANDA (Parkinson's Assistance and Notification Driving Aid), a multi-modality real-time alert system designed to monitor driving patterns continuously and provide immediate alerts for irregular driving behaviors, enhancing driver safety of individuals with PD. The system was developed through a participatory design process with 9 people with PD and 13 non-PD individuals using a driving simulator, which allowed us to identify critical design characteristics and collect detailed data on driving behavior. A user study involving individuals with PD evaluated the effectiveness of PANDA, exploring optimal strategies for delivering alerts and ensuring they are timely and helpful. Our findings demonstrate that PANDA has the potential to enhance the driving safety of individuals with PD, offering a valuable tool for maintaining independence and confidence behind the wheel.",
    "title": "PANDA: Parkinson's Assistance and Notification Driving Aid",
    "id": 189399,
    "sequence": 1189,
    "queryCoordinates": {
      "visualization": [
        2.974334584121431,
        0.3915785766601547
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "While digital play installations for outdoor use are becoming more common, little work has been done on how such technology shapes play in nature-rich environments. We performed a study of children’s self-directed play with access to nature as well as digital installations. Our findings show that play with nature materials and digital installations emerged in different ways. Most notably, imaginative play was observed emerging in close interaction with nature, while the digital installations mostly inspired rule-based play. Furthermore, engagement with digital installations typically involved an active exploration phase which was not observed with nature materials. Nature materials instead engaged the children’s senses more immediately, and often offered opportunities for collection and consumption, paving way for fluent play activities roaming large areas. We argue that these differences motivate rethinking the design of digital installations for play in nature and suggest guidelines to this purpose.\r\n",
    "title": "Digital Play in Nature: A Study of Digital Play Installations from a Nature Play Perspective",
    "id": 189400,
    "sequence": 1190,
    "queryCoordinates": {
      "visualization": [
        12.994069198363935,
        0.392639361411555
      ]
    }
  },
  {
    "session": "Virtual Presence and Awareness",
    "abstract": "Within the virtual reality (VR) research community, there have been several efforts to develop questionnaires with the aim of better understanding the sense of presence. Despite having numerous surveys, the community does not have a questionnaire that informs which components of a VR application contributed to the sense of presence. Furthermore, previous literature notes the absence of consensus on which questionnaire or questions should be used. Therefore, we conducted a Delphi study, engaging presence experts to establish a consensus on the most important presence questions and their respective verbiage. We then conducted a validation study with an exploratory factor analysis (EFA). The efforts between our two studies led to the creation of the Fidelity-based Presence Scale (FPS). With our consensus-driven approach and fidelity-based factoring, we hope the FPS will enable better communication within the research community and yield important future results regarding the relationship between VR system fidelity and presence.",
    "title": "The Fidelity-based Presence Scale (FPS): Modeling the Effects of Fidelity on Sense of Presence",
    "id": 189401,
    "sequence": 1191,
    "queryCoordinates": {
      "visualization": [
        1.1774160730237835,
        -19.965312203694317
      ]
    }
  },
  {
    "session": "Decision Making and Analysis",
    "abstract": "Users often have access to multiple forecasts regarding an event. Different forecasts incorporate different assumptions and epistemic information. A growing body of work argues against decision-making solely based on expected utility maximisation strategies in multiple forecasts scenarios, in favour of other strategies such as the maximin expected utility. In this work, we compare two different approaches for depicting epistemic uncertainty—ensembles (a direct representation of multiple forecasts) and p-boxes (a representation which only communicates the bounds of epistemic uncertainty)—in plots where individual distributions are represented as cumulative distribution plots (CDFs). We conduct three experiments to investigate the impact of the visual representation on the decision-making strategies that people adopt. Our results suggest that participants adopt conservative decision-making strategies (i.e. place greater weight on the worst-case forecast than the best-case forecast) for both p-boxes and ensembles if the set of forecasts are uniformly distributed. However, if a majority of the forecasts are clustered near one of the bounds, participants may discount the forecast which appears as a visual outlier.",
    "title": "More Forecasts, More (Decision) Problems: How Uncertainty Representations for Multiple Forecasts Impact Decision Making",
    "id": 189402,
    "sequence": 1192,
    "queryCoordinates": {
      "visualization": [
        14.95376000599692,
        1.176886435917674
      ]
    }
  },
  {
    "session": "Education",
    "abstract": "Collecting African American Vernacular English (AAVE) voice data presents challenges in balancing trust, community interests, and technological advancements. This study uses an autoethnographic approach to examine a collaboration between researchers at Howard University, a Historically Black College/University (HBCU), and an industry partner. We explore the challenges and opportunities that arise when HBCU researchers conduct large-scale data collection within their communities. Our findings highlight the key role HBCUs play in ethically collecting data from communities of color, emphasizing community-centered methods and the complexities of managing partnerships. We provide recommendations for future collaborations that prioritize community needs and advance technological equity, focusing on four key factors including managing trust and data ethics, managing community engagement, resource management, and managing power dynamics. This work contributes to ongoing discussions on ethical AI development, cultural preservation, and the role of HBCUs in shaping the future of voice recognition technology.",
    "title": "Centering Black Voices: Lessons Learned and Reflections from a Large-Scale AAVE Data Collection at a Historically Black University",
    "id": 189403,
    "sequence": 1193,
    "queryCoordinates": {
      "visualization": [
        19.138806714644176,
        -5.80569354508925
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "The growing use of smart home devices poses considerable privacy and security challenges, especially for individuals like migrant domestic workers (MDWs) who may be surveilled by their employers. This paper explores the privacy and security challenges experienced by MDWs in multi-user smart homes through in-depth semi-structured interviews with 26 MDWs and 5 staff members of agencies that recruit and/or train domestic workers in China. Our findings reveal power imbalances in the relationships between MDWs and their employers and agencies, influenced by Chinese cultural and social factors (such as Confucianism and collectivism) as well as legal ones. Furthermore, the widespread and normalized use of surveillance technologies in China, particularly in public spaces, exacerbates these power imbalances, reinforcing a sense of constant monitoring and control. Drawing on our findings, we provide recommendations for domestic worker agencies and policymakers to address the privacy and security challenges faced by MDWs in Chinese smart homes.",
    "title": "Exploring the Privacy and Security Challenges Faced by Migrant Domestic Workers in Chinese Smart Homes",
    "id": 189404,
    "sequence": 1194,
    "queryCoordinates": {
      "visualization": [
        1.9560385425721827,
        12.852000358697945
      ]
    }
  },
  {
    "session": "Image and AI",
    "abstract": "Visual blends combine elements from two distinct visual concepts into a single, integrated image, with the goal of conveying ideas through imaginative and often thought-provoking visuals. Communicating abstract concepts through visual blends poses a series of conceptual and technical challenges. To address these challenges, we introduce Creative Blends, an AI-assisted design system that leverages metaphors to visually symbolize abstract concepts by blending disparate objects. Our method harnesses commonsense knowledge bases and large language models to align designers’ conceptual intent with expressive concrete objects. Additionally, we employ generative text-to-image techniques to blend visual elements through their overlapping attributes. A user study (N=24) demonstrated that our approach reduces participants’ cognitive load, fosters creativity, and enhances the metaphorical richness of visual blend ideation. We explore the potential of our method to expand visual blends to include multiple object blending and discuss the insights gained from designing with generative AI.",
    "title": "Creative Blends of Visual Concepts",
    "id": 189405,
    "sequence": 1195,
    "queryCoordinates": {
      "visualization": [
        -5.21949515418216,
        -4.664426045664027
      ]
    }
  },
  {
    "session": "WS07: Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "abstract": "  Recent developments in XR-related technologies enable us to extend the use of XR beyond laboratory settings and, therefore, beyond the common paradigm of head-mounted displays (HMD) or AR glasses. As the industry is pushing XR glasses to become the next-generation computer interface and mobile phone replacement, we see an opportunity to reconsider the future of XR interfaces beyond just this form factor and explore whether new affordances can be leveraged. In fact, while glasses represent the most convenient and practical wearable interface, users remain limited to a specific set of displays, raising concerns about privacy, social acceptability, and overreliance on the visual channel. Conversely, we believe that there is an opportunity to leverage the physicality of the world, including the human body and the surrounding space, to create more engaging XR experiences. In this workshop, our goal is to gather fresh insights and perspectives from HCI researchers, practitioners, and professionals on strategies and techniques to enhance interactions in XR beyond the conventional glasses framework. We will bring together experienced academics and emerging researchers within the interdisciplinary field of HCI. We anticipate developing research pathways to leverage physicality to investigate possibilities and obstacles beyond XR glasses, ultimately shaping a new approach to engaging with XR.\r\n",
    "title": "Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "id": 189406,
    "sequence": 1196,
    "queryCoordinates": {
      "visualization": [
        -8.7866640640794,
        -1.9479565254429263
      ]
    }
  },
  {
    "session": "Product Design",
    "abstract": "A design method card deck helps designers understand and provoke thinking by presenting each method in a simple format and allow designers to switch between methods seamlessly by maintaining the same simple format across the deck. However, recent observations have shown designers hesitate to use a card deck due to the lack of support, while other tools have provided identified support with generative AI. Through a formative study, we identified the specific support designers need when applying the design method cards and intentions in integrating generative AI. Accordingly, we developed the intelligent design method card deck, I-Card, which integrates generative AI to provide applicable design methods, design knowledge and data support, and interactive and dynamic support. A user study demonstrates that I-Card improved the design efficiency and applicability by offering personalized guidance, enhanced decision-making with comprehensive data generation and provided more design inspiration via interactive support.",
    "title": "I-Card: A Generative AI-Supported Intelligent Design Method Card Deck",
    "id": 189407,
    "sequence": 1197,
    "queryCoordinates": {
      "visualization": [
        -2.714404498650742,
        9.624552364536473
      ]
    }
  },
  {
    "session": "Haptic Technology",
    "abstract": "We present a qualitative study with five healthcare experts specialised in different types of touch practice to gain insight in how caring touch can be enacted. Through our analysis we focus on how to transfer this learning into design considerations towards enacting caring touch from technologies. Despite the rapidly growing expectation for and design interest in touch from technologies intending to enhance care and well-being, the knowledge on how to design caring touch is still fragmented. How caring touch is enacted in inter-personal touch is under-explored and such expertise from healthcare practitioners has not been engaged from the perspective of HCI design research. We propose designers to consider caring as an experiential quality instead of a division between instrumental types of touch and caring types. We recommend when designing for a caring quality in technology-initiated touch that designers create a progression of touch with dynamic sensitivity and adapt the materiality of actuating devices to the plural dimensions of the body's textures. ",
    "title": "Towards Caring Touch From Technologies: Knowledge From Healthcare Practitioners",
    "id": 189408,
    "sequence": 1198,
    "queryCoordinates": {
      "visualization": [
        -8.613109359986625,
        -14.656546221839264
      ]
    }
  },
  {
    "session": "Technology in Education",
    "abstract": "Education technologies (edtech) are increasingly incorporating new features built on large language models (LLMs), with the goals of enriching the processes of teaching and learning and ultimately improving learning outcomes. However, the potential downstream impacts of LLM-based edtech remain understudied. Prior attempts to map the risks of LLMs have not been tailored to education specifically, even though it is a unique domain in many respects: from its population (students are often children, who can be especially impacted by technology) to its goals (providing the correct answer may be less important for learners than understanding how to arrive at an answer) to its implications for higher-order skills that generalize across contexts (e.g., critical thinking and collaboration). We conducted semi-structured interviews with six edtech providers representing leaders in the K-12 space, as well as a diverse group of 23 educators with varying levels of experience with LLM-based edtech. Through a thematic analysis, we explored how each group is anticipating, observing, and accounting for potential harms from LLMs in education. We find that, while edtech providers focus primarily on mitigating technical harms, i.e., those that can be measured based solely on LLM outputs themselves, educators are more concerned about harms that result from the broader impacts of LLMs, i.e., those that require observation of interactions between students, educators, school systems, and edtech to measure. Overall, we (1) develop an education-specific overview of potential harms from LLMs, (2) highlight gaps between conceptions of harm by edtech providers and those by educators, and (3) make recommendations to facilitate the centering of educators in the design and development of edtech tools.",
    "title": "\"Don't Forget the Teachers\": Towards an Educator-Centered Understanding of Harms from Large Language Models in Education",
    "id": 189409,
    "sequence": 1199,
    "queryCoordinates": {
      "visualization": [
        -6.902159081189375,
        -8.565056918547304
      ]
    }
  },
  {
    "session": "Input and Modeling",
    "abstract": "3D artists (professionals and novices alike) often take inspiration from sketches or photos to guide their designs. Yet, existing modeling systems are not tailored to fully make use of such input. Consequently, significant effort and expertise are needed when creating model prototypes or exploring design options. In this work, we introduce a system to support the exploratory modeling process by enabling the transformation of 2D image elements into geometric 3D objects. Our solution relies on a novel d2 distance function, supporting a region-based lofting process, and delivers easily-editable 3D geometric \"spine-rib\" representations. The user draws a spine, and the system generates and modifies a generalized cylinder around it, considering image edges. The proposed approach, driven by simple user-defined scribble definitions, can robustly handle various image sources, ranging from photos to hand-drawn content.",
    "title": "SpineLoft: Interactive Spine-based 2D-to-3D Modeling",
    "id": 189410,
    "sequence": 1200,
    "queryCoordinates": {
      "visualization": [
        2.7716385975338595,
        -1.148050297095271
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "Neurodiversity perspectives have in recent years made headway in HCI, broadening the role of autistic people. Outside HCI, an essential tool of the neurodiversity movement is the use of first person methods such as autoethnography. This paper explores how interaction design may contribute to ease the burden of conducting Autistic autoethnography (aut-ethnography), and how aut-ethnography may contribute to HCI. \r\nTaking an autoethnographic approach in the design of a set of recording devices, we identify three design sensitivities when designing for aut-ethnography: Inertial, sensory, and social fit. We further nuance these in an exploratory trial with other autistic people. \r\nWe conclude that designing for the context of aut-ethnography requires significant adaptability of the designed artifacts in order to facilitate maintenance of existing rhythms in practice and adhere to fine-grained idiosyncratic preferences and ideals of practicing care and fairness. ",
    "title": "De-centering Inclusivity: Fitting Design for Aut-Ethnography",
    "id": 189411,
    "sequence": 1201,
    "queryCoordinates": {
      "visualization": [
        1.1764853857852784,
        -12.946655249022184
      ]
    }
  },
  {
    "session": "Innovations in Interaction Design",
    "abstract": "Authors of typeset formulas augment those formulas to make them easier to understand. When they do so, they trade off between using markup tools like LaTeX and formula-unaware graphical editors. In this paper, we explore how editing tools could combine the best affordances of both kinds of tools. We develop FreeForm, a projectional editor wherein authors can augment formulas---with color, labels, spacing, and more---across multiple synchronized representations. Augmentations are created graphically using direct selections and compact menus. Those augmentations propagate to LaTeX markup, which can itself be edited and easily exported. In two lab studies, we observe the value of our editor versus baselines of a widely-used LaTeX document editor and a state-of-the-art formula augmentation tool. Finally, we make recommendations for the design of projectional markup augmentation editors.",
    "title": "FreeForm: Flexibly Augmenting Formulas with Synchronized Markup and Graphical Edits",
    "id": 189412,
    "sequence": 1202,
    "queryCoordinates": {
      "visualization": [
        6.635496031291117,
        6.080311868540942
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "Home routers serve as a gateway to the Internet and configuration issues such as weak passwords can simply be introduced by users that configured them, potentially leading to severe consequences. The most critical phase in the lifecycle of a home router is perhaps the initial setup intended for users to complete. Yet, the mindset and behavior of users during this process remain under-explored. In a comprehensive online survey of 392 participants across several regions, we find that router settings and user behavior vary significantly between China and English-speaking countries, influenced by factors like IT background, age, gender, and education. A majority of participants go through the configuration of their own routers, but many also admit keeping the default settings and are not actively maintaining their router firmware up-to-date, leaving security vulnerabilities unfixed. We estimate that 91% of participant routers run with default settings, which should push router manufacturers to focus on safe defaults. Moreover, while default passwords are often changed, some participants report coping strategies. With noteworthy differences that we have observed across user backgrounds, we believe that our takeaways can shed some light on advancing the area of home network security.",
    "title": "Understanding Home Router Configuration Habits & Attitudes",
    "id": 189413,
    "sequence": 1203,
    "queryCoordinates": {
      "visualization": [
        10.696523261502504,
        9.032407769589227
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "Assistive technologies, such as smartphone-based object-recognition (OR) apps, provide visual assistance to people who are blind or low-vision to enable increased independent participation in society. While previous research has explored the functional accessibility of object-recognition technologies, little attention has been given to their social accessibility, particularly in interdependent socio-cultural contexts of the Global South. Through a mixed-methods approach, employing a seven-day diary study followed by one-on-one interviews with seven OR app users in India, we explore their experiences in depth. Our findings highlight the nuances of what interdependence looks like in a multicultural, Indian society, as people navigate public and private spheres with a camera-based assistive technology designed for independent, western contexts. We argue for the necessity to design assistive technologies following the interdependence framework that accommodates the social and cultural context of the Global South. Additionally, we propose design guidelines for assistive technologies in community-oriented societies, emphasizing community-centered approaches, cultural alignment, and locally adaptable designs.",
    "title": "Exploring the Experiences of Individuals Who are Blind or Low-Vision Using Object-Recognition Technologies in India ",
    "id": 189414,
    "sequence": 1204,
    "queryCoordinates": {
      "visualization": [
        -17.987015665034875,
        -10.838231749957648
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "Generative AI is increasingly used to create images from text, but its role in documentary photography remains under-explored. This paper investigates how generative AI can be integrated into documentary practice while maintaining ethical standards. Through interviews with six documentary photographers, we explored their views on AI’s potential to support community-driven storytelling. While AI presents opportunities for creative expression and community involvement, concerns about trust, authenticity, and decontextualization of images persist. Photographers expressed doubts about AI’s ability to accurately represent lived experiences, fearing it could compromise narrative integrity. Our findings suggest that AI tools should be designed to enhance collaboration and transparency in storytelling, complementing rather than replacing traditional documentary methods. This study contributes to the ongoing discourse on AI in photography, advocating for the development of tools that preserve the ethical foundations of documentary storytelling while empowering communities.",
    "title": "Generative AI in Documentary Photography: Exploring Opportunities and Challenges for Visual Storytelling",
    "id": 189415,
    "sequence": 1205,
    "queryCoordinates": {
      "visualization": [
        18.292331470655995,
        -12.222545126431248
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "In networked applications, latency can disrupt the sense of synchrony by causing offsets e.g. between local speech and remote visual response. We investigate the influence of frequency and Stimulus Onset Asynchrony (SOA) on synchrony perception during rhythmic audiovisual experiences. Our results show that the Point of Subjective Synchrony (PSS) is influenced by frequency, whereas the Window of Subjective Synchrony (WSS) is not. Variations in SOA induce adaptive gaze behavior in response to audiovisual latencies, while pupil diameter increases with increasing SOA, suggesting a higher cognitive load for successive unisensory rather than integrated events. This has practical implications for the design of computer-mediated applications that promote a sense of community through rhythmic interaction. Eye tracking data may indicate perceived (a)synchrony in audiovisual integration. In addition, the choice of frequencies may help to mask latencies, enhance the experience of synchrony and thus support feelings of closeness and intimacy in virtual interaction.",
    "title": "Perceived Asynchrony of Rhythmic Stimuli Affects Pupil Diameter and Smooth Pursuit Eye Movements",
    "id": 189416,
    "sequence": 1206,
    "queryCoordinates": {
      "visualization": [
        13.326040464736492,
        10.55540835459271
      ]
    }
  },
  {
    "session": "Social Media",
    "abstract": "Social media is central to activists, who use it internally for coordination and externally to reach supporters and the public. To date, the HCI community has not explored activists' perspectives on future social media platforms. In interviews with 14 activists from an environmental and a queer-feminist movement in Germany, we identify activists' needs and feature requests for future social media platforms. The key finding is that on- and offline safety is their main need. Based on this, we make concrete proposals to improve safety measures. Increased control over content presentation and tools to streamline activist workflows are also central to activists. We make concrete design and research recommendations on how social media platforms and the HCI community can contribute to improved safety and content presentation, and how activists themselves can reduce their workload. ",
    "title": "Social Media for Activists: Reimagining Safety, Content Presentation, and Workflows",
    "id": 189417,
    "sequence": 1207,
    "queryCoordinates": {
      "visualization": [
        -12.78960246531138,
        7.83747847073924
      ]
    }
  },
  {
    "session": "Design Thinking",
    "abstract": "Generative AI (GenAI) has been widely applied in UX design, yet its potential in the Journey Map (JM) creation process remains under-explored. We conducted a formative study (N = 24) to identify designers' needs for GenAI in JM creation, resulting in six design goals implemented (e.g., Acting as Different Stakeholders) in our tool, GeneyMAP. GeneyMAP streamlines the JM creation process, allowing designers to map interview data efficiently with flexibility, uncovering design opportunities through visual inspiration. A subsequent user study (N = 20) demonstrated that GeneyMAP, compared with the common tool, accelerated JM creation and fostered creativity mainly by providing diverse inspirations and facilitating progressive discussions. Our findings proved GeneyMAP‘s utility and effectiveness while challenges in maintaining control and trust in GenAI outputs were noted. Our research highlights the promising role of GenAI in refining JM creation practices and suggests implications for incorporating GenAI in JM and design workflows.",
    "title": "GeneyMAP: Exploring the Potential of GenAI to Facilitate Mapping User Journeys for UX Design",
    "id": 189418,
    "sequence": 1208,
    "queryCoordinates": {
      "visualization": [
        0.39262899386130307,
        -11.993575049716387
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Recent advancements in large language models (LLMs) have led to the creation of intelligent agents capable of performing complex tasks. This paper introduces a novel LLM-based multimodal agent framework designed to operate smartphone applications. Our framework allows the agent to mimic human-like interactions such as tapping and swiping through a simplified action space, eliminating the need for system back-end access and enhancing its versatility across various apps.  Central to the agent's functionality is an innovative in-context learning method, where it either autonomously explores or learns from human demonstrations, creating a knowledge base used to execute complex tasks across diverse applications. We conducted extensive testing with our agent on over 50 tasks spanning 10 applications, ranging from social media to sophisticated image editing tools. Additionally, a user study confirmed the agent's superior performance and practicality in handling a diverse array of high-level tasks, demonstrating its effectiveness in real-world settings. Our project page is available at \\url{https://appagent-official.github.io/}.\r\n",
    "title": "AppAgent: Multimodal Agents as Smartphone Users",
    "id": 189419,
    "sequence": 1209,
    "queryCoordinates": {
      "visualization": [
        13.398003232593183,
        16.17076094002452
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "Existing defense strategies against cyberattacks on automated vehicles (AVs) often overlook the great potential of humans in detecting such attacks. To address this, we identified three types of human-detectable attacks targeting transportation infrastructure, AV perception modules, and AV execution modules. We proposed two types of displays: Alert and Alert plus Explanations (AlertExp), and conducted an online video survey study involving 260 participants to systematically evaluate the effectiveness of these displays across cyberattack types.\r\nResults showed that AV execution module attacks were the hardest to detect and understand, but AlertExp displays mitigated this difficulty. In contrast, AV perception module attacks were the easiest to detect, while infrastructure attacks resulted in the highest post-attack trust in the AV system. Although participants were prone to false alarms, AlertExp displays mitigated their negative impacts, whereas Alert displays performed worse than having no display. Overall, AlertExp displays are recommended to enhance human detection of cyberattacks.",
    "title": "Explanations Help: Leveraging Human Capabilities to Detect Cyberattacks on Automated Vehicles",
    "id": 189420,
    "sequence": 1210,
    "queryCoordinates": {
      "visualization": [
        -2.736930109284018,
        -16.778236307100176
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "Young adults often encounter challenges in career exploration. Self-guided interventions, such as the letter-exchange exercise, where participants envision and adopt the perspective of their future selves by exchanging letters with their envisioned future selves, can support career development. However, the broader adoption of such interventions may be limited without structured guidance. To address this, we integrated Large Language Model (LLM)-based agents that simulate participants’ future selves into the letter-exchange exercise and evaluated their effectiveness. A one-week experiment (N=36) compared three conditions: (1) participants manually writing replies to themselves from the perspective of their future selves (baseline), (2) future-self agents generating letters to participants, and (3) future-self agents engaging in chat conversations with participants. Results indicated that exchanging letters with future-self agents enhanced participants' engagement during the exercise, while overall benefits of the intervention on future orientation, career self-concept, and psychological support remained comparable across conditions. We discuss design implications for AI-augmented interventions for supporting young adults' career exploration.",
    "title": "Letters from Future Self: Augmenting the Letter-Exchange Exercise with LLM-based Agents to Enhance Young Adults' Career Exploration",
    "id": 189421,
    "sequence": 1211,
    "queryCoordinates": {
      "visualization": [
        -13.285048758225628,
        14.950166537251942
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "Effects of embodying virtual avatars are routinely validated experimentally by comparing synchronous and asynchronous movements between virtual and real bodies. This experimental paradigm, however, lacks justification, validation, and standardization. Asynchrony is currently implemented in numerous ways, such as through delayed, dislocated, or prerecorded movements, and these may impact embodiment and user experience distinctively.  An online study (N = 202) revealed that variations of asynchrony cause disparate responses to embodiment and user experience, with prerecorded movements distorting embodiment the most. A think-aloud study (N = 16) revealed that asynchronous conditions lead to peculiar and oftentimes negative experiences. Furthermore, asynchronous conditions in some cases maintain, rather than break the body ownership illusion, as participants imitate the virtual body. Our results show that asynchrony in experiments on embodiment entails profound validity issues and should therefore be used with caution.",
    "title": "Does Random Movements mean Random Results? Why Asynchrony in Experiments on Body Ownership does not Work as Intended",
    "id": 189422,
    "sequence": 1212,
    "queryCoordinates": {
      "visualization": [
        5.884711682419381,
        -1.1705419320967776
      ]
    }
  },
  {
    "session": "Eating and Digital Health",
    "abstract": "Healthy eating is essential to overall well-being. Deciding what and how to eat often requires collaboration and coordination with others to develop routines and create enjoyable experiences. However, life changes like moving or unemployment can disrupt food routines and social dining. Current technologies often overlook these evolving changes and do not adequately support individuals in collaborating with others to adapt to these impacts. In this paper, we interviewed 18 participants who experienced various routine changes during life events. Findings highlight the need for tools to support individuals in adapting to food practices, facilitating social coordination, and mediating conflicts during transitions. We explore design opportunities that facilitate technology reconfiguration, value clarification and mediation, and social coordination, aiming to better support individuals in times of change, both for those who undergo life events and others who offer help with food practices. Our work offers design considerations for technologies that enhance healthy eating and food service, ensuring sustained support during life changes.",
    "title": "Preparing and Experiencing Food During Life Events: Implications for Technology Supporting Social and Value Changes",
    "id": 189423,
    "sequence": 1213,
    "queryCoordinates": {
      "visualization": [
        -8.49609355387249,
        12.361892829330237
      ]
    }
  },
  {
    "session": "Virtual and Mixed Reality Interaction",
    "abstract": "Virtual and mixed reality headsets, such as the Apple Vision Pro and Meta Quest, began supporting use in reclined postures in 2024, accommodating users who prefer or require this position. However, the surfaces on which users rest restrict shoulder and head rotation, reducing viewing range and comfort. A formative study (n=16) comparing usage while standing vs. lying down showed that head rotation range decreased from 261º to 130º horizontally and from 172º to 94.9º vertically. To improve viewing range and comfort, we present HeadTurner, a novel approach that assists user-initiated head rotations by actuating the resting surface to yield in pitch and yaw axes. In a user study (n=16), HeadTurner significantly expanded the field of view and improved comfort compared to a fixed surface. Although VR sickness was slightly reduced with HeadTurner, the difference was not statistically significant. Overall, HeadTurner was preferred by 75% of participants. Although our proof-of-concept device was prototyped as a bed, the approach can be extended to more compact and affordable device form factors, such as motorized reclining chairs, offering the potential for comfortable use of VR and MR headsets over extended periods, and was shown to inspire users with interested applications in back-rested scenarios.",
    "title": "HeadTurner: Enhancing Viewing Range and Comfort of using Virtual and Mixed-Reality Headsets while Lying Down via Assisted Shoulder and Head Actuation",
    "id": 189424,
    "sequence": 1214,
    "queryCoordinates": {
      "visualization": [
        1.14805029709527,
        2.77163859753386
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "Efforts to integrate living organisms in the design of new technologies are often motivated by prospects of greater sustainability and increased connection with more-than-human worlds. In this paper, we critically discuss these motivations by analysing the vast and mostly hidden ecologies of more-than-human organisms implicated in a biodesign lab experiment. Through the lenses of labour theory, we investigate the extent to which organisms’ bodily functions and relationships can be subsumed into capitalist modes of production. In order to help reveal and map out the network of more-than-human contributors to biodesign, we develop a workshop method and a labour provenance analytical framework that identifies five types of more-than-human labourers, stretching from the centre to the periphery of biodesign. We conclude by discussing how sustainable approaches should account for wider more-than-human ecologies, and how the labour lens could help stress conflicting goals, implicit anthropocentric agendas and ways of improving organismal welfare in biological design and HCI.",
    "title": "Labour Provenance as a Lens to Reveal More-Than-Human Ecologies in Biological Design and HCI",
    "id": 189425,
    "sequence": 1215,
    "queryCoordinates": {
      "visualization": [
        3.8020298280001548,
        3.2472402416509185
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "Gender-affirming voice training is critical for the transition process for many transgender individuals, enabling their voice to align with their gender identity. Individualized voice goals guide and motivate the voice training journey, but existing voice training technologies fail to define clear goals. We interviewed six voice experts and ten transgender individuals with voice training experience (voice trainees), focusing on how they defined, triangulated, and used voice goals. We found that goal voice exploration involves navigation between descriptive and technical goals, and continuous reevaluation throughout the voice training journey. Our study reveals how goal descriptions, subjective satisfaction, voice examples, and voice modification and training technologies inform goal exploration, and identifies risks of overemphasizing goals. We identified technological implications informed by existing expert and trainee strategies, and provide guidelines for supporting individualized goals throughout the voice training journey based on brainstorming with trainees and experts.",
    "title": "Beyond the \"Industry Standard\": Focusing Gender-Affirming Voice Training Technologies on Individualized Goal Exploration",
    "id": 189426,
    "sequence": 1216,
    "queryCoordinates": {
      "visualization": [
        -3.0920418134509484,
        -2.537573136654581
      ]
    }
  },
  {
    "session": "Accessibility",
    "abstract": "Our team of culturally Deaf ASL-signing and hearing non-signing HCI researchers conduct research with the Deaf community to create ASL resources. This case study summarizes reflections, learning, and challenges with HCI user study protocols based on our experience conducting five user studies with deaf ASL-signing participants. The case study offers considerations for researchers in this space related to conducting think-aloud protocols, interviews and surveys, getting informed consent, interpreter services and data analysis and storage. Our goal is to share the lessons we learned, and offer recommendations for future research in this area. Going beyond accommodations and accessibility, we hope these reflections contribute to a shift toward ASL-centric HCI research methodologies for working with the Deaf Community.",
    "title": "Conducting HCI Research with the Deaf Community in American Sign Language: Practices and Experiences",
    "id": 189427,
    "sequence": 1217,
    "queryCoordinates": {
      "visualization": [
        -4.286183061301025,
        -19.535317626417445
      ]
    }
  },
  {
    "session": "Lessons Learned from Real Experience",
    "abstract": "In our effort to implement an interactive customer segmentation tool for a global manufacturing company, we identified user experience (UX) challenges with technical implications. The main challenge relates to domain users’ effort, in our case sales experts, to interpret the clusters produced by an unsupervised Machine Learning (ML) algorithm, for creating a customer segmentation. An additional challenge is what sort of interactions should such a tool support to enable meaningful interpretations of the output of clustering models. In this case study, we describe what we learned from implementing an Interactive Machine Learning (IML) prototype to address such UX challenges. We leverage a multi-year real-world dataset and domain experts’ feedback from a global manufacturing company to evaluate our tool. We report what we found to be effective and wish to inform designers of IML systems in the context of customer segmentation and other related unsupervised ML tools.",
    "title": "UX Challenges in Implementing an Interactive B2B Customer Segmentation Tool",
    "id": 189428,
    "sequence": 1218,
    "queryCoordinates": {
      "visualization": [
        -18.801493573216852,
        2.7393136761395858
      ]
    }
  },
  {
    "session": "Cultures and Languages",
    "abstract": "Young children increasingly interact with Artificial Intelligence (AI) in their everyday lives, often without being made aware of the ethical issues in the design and use of such technologies. This prompts the need for AI literacy that also implores them to adopt critical perspectives towards technology design and use. We conducted critical AI literacy workshops with 96 schoolchildren (ages 11-12 years) in Japan, inviting participants to imagine and design future classrooms and schools. While participants' imagined future technologies incorporated elements of anthropomorphised AI as well as magical thinking; these future imaginaries revealed diverse perspectives on ethical AI design and use, including concerns about empathy, inclusion and fairness, and accountability and sustainability. Their future designs also underscored the everyday problems that matter to them the most. With our work, we highlight the need for exploring children's perspectives towards ethical AI to envision inclusive ethical AI futures with and by children.",
    "title": "A robot teacher \"is very good for learning, but not for human relationships\": Japanese Children’s Critical Perspectives Towards Ethical AI Futures",
    "id": 189429,
    "sequence": 1219,
    "queryCoordinates": {
      "visualization": [
        -18.379691860083824,
        -10.158096629210041
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "Tactile charts are essential for conveying data to blind and low vision (BLV) readers but are difficult for designers to construct. Non-expert designers face barriers to entry due to complex guidelines, while experts struggle with fragmented and time-consuming workflows that involve extensive customization. Inspired by formative interviews with expert tactile graphics designers, we created Tactile Vega-Lite (TVL): an extension of Vega-Lite that offers tactile-specific abstractions and synthesizes existing guidelines into a series of smart defaults. Predefined stylistic choices enable non-experts to produce guideline-compliant tactile charts quickly. Expert users can override defaults to tailor customizations for their intended audience. In a user study with 12 tactile graphics creators, we show that Tactile Vega-Lite enhances flexibility and consistency by automating tasks like adjusting spacing and translating braille while accelerating iterations through pre-defined textures and line styles. Through expert critique, we also learn more about tactile chart design best practices and design decisions. ",
    "title": "Tactile Vega-Lite: Rapidly Prototyping Tactile Charts with Smart Defaults",
    "id": 189430,
    "sequence": 1220,
    "queryCoordinates": {
      "visualization": [
        2.7402468336393597,
        19.811386808871546
      ]
    }
  },
  {
    "session": "AR Interaction",
    "abstract": "We present PerspectAR, a novel system addressing perspective distortion on displays caused by large size and wide viewing angles. PerspectAR has three components: a virtual AR screen that curves dynamically according to a user's position relative to the display, a sliding transparent window giving unobstructed access to the physical display in front of the user, and gaze indicators to assist collaborators when they are looking at different renderings. In a within-subjects study in a semi-controlled public environment with 12 pairs, we compared physical display-only and PerspectAR configurations for data analysis tasks. Participants reported less physical workload with PerspectAR and spent more time near the physical display without compromising task performance. Feedback indicates that PerspectAR addressed perspective distortion and provided a contextual view that was useful as a memory aid. Due to the virtual screen curvature, PerspectAR was seen as less effective for tasks involving distance estimates between objects.",
    "title": "PerspectAR: Addressing Perspective Distortion on Very Large Displays with Adaptive Augmented Reality Overlays",
    "id": 189431,
    "sequence": 1221,
    "queryCoordinates": {
      "visualization": [
        12.438238903704212,
        -6.425746102545528
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "Despite the significant increase in popularity of Virtual YouTubers (VTubers), research on the unique dynamics of viewer-VTuber parasocial relationships is  nascent. This work investigates how English-speaking viewers grieved VTubers whose identities are no longer used, an interesting context as the \\textit{nakanohito} (i.e., the person behind the VTuber identity) is usually alive post-retirement and might ``reincarnate'' as another VTuber. We propose a typology for VTuber retirements and analyzed 13,655 Reddit posts and comments spanning nearly three years using mixed-methods. Findings include how viewers coped using methods similar to when losing loved ones, alongside novel coping methods reflecting different attachment styles. Although emotions like sadness, shock, concern, disapproval, confusion, and love decreased with time, regret and loyalty showed opposite trends. Furthermore, viewers' reactions situated a VTuber identity within a community of content creators and viewers. We also discuss design implications alongside implications on the VTuber ecosystem and future research directions.\r\n",
    "title": "\"Can't believe I'm crying over an anime girl\": Public Parasocial Grieving and Coping Towards VTuber Graduation and Termination",
    "id": 189432,
    "sequence": 1222,
    "queryCoordinates": {
      "visualization": [
        17.790507188419692,
        -2.7382209514185094
      ]
    }
  },
  {
    "session": "AI in the Classroom",
    "abstract": "Students struggle with accurately assessing their own performance, especially given little training to do so. We propose an AI-powered training tool to help students improve “metacognitive calibration,” or the ability to accurately predict their own learning, potentially enhancing learning outcomes by enabling students’ use of metacognition-informed learning behaviors. We present results from a randomized controlled trial (N = 133) assessing the effectiveness of the tool in a college-level computer-based learning environment. The AI-driven tool significantly improved learning gains compared to the control group by 8.9% (t = -2.384, p = .019), and this effect was significantly mediated by learning behaviors. Overconfident students who received the intervention showed significantly greater metacognitive calibration improvement than the control group by 4.1% (t = 2.001, p = .049). These insights highlight the value of AI-powered metacognitive calibration training and the importance of promoting specific metacognition-informed learning behaviors in computer-based learning.",
    "title": "Learning Behaviors Mediate the Effect of AI-powered Support for Metacognitive Calibration on Learning Outcomes",
    "id": 189433,
    "sequence": 1223,
    "queryCoordinates": {
      "visualization": [
        14.037920695671874,
        11.266622499313064
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "We design \"D-Twins\" (Digital Twins), an LLM-based affective AI agent that embodies each user's emotional reactions and personality traits, presenting a real-time, authentic reflection of the user. D-Twins addresses the current lack of personalized boredom interventions in automated environments by utilizing real-time physiological data to provide interventions aligned with users' emotional responses. Initially, we collected users' natural language expressions to capture their unique characteristics. These patterns were used to create LLM-based AI agents that highly resemble the users. Then, we developed a boredom classification model by collecting electroencephalogram (EEG) data in an automated environment and integrated it into D-Twins. This integration enables D-Twins to rapidly recognize boredom and initiate personalized interventions, which users perceive as highly empathetic, turning boring environments into engaging experiences. Our study highlights that AI agents with user-similar emotional resonance offer a novel, real-time personalized intervention solution in boredom situations.",
    "title": "D-Twins: Your Digital Twin Designed for Real-Time Boredom Intervention",
    "id": 189434,
    "sequence": 1224,
    "queryCoordinates": {
      "visualization": [
        18.801493573216852,
        2.7393136761395884
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "Household collaboration among cohabiting couples presents unique challenges due to the intimate nature of the relationships and the lack of external rewards. Current efficiency-oriented technologies neglect these distinct dynamics. Our study aims to examine the real-world context and underlying needs of couples in their collaborative homemaking. We conducted a 10-day empirical investigation involving six Korean couples, supplemented by a probe approach to facilitate reflection on their current homemaking practices. We identified the requirement for ideal household collaboration as a 'shared ritual for celebratory interaction' and pinpointed the challenges in achieving this goal. We propose three design opportunities for domestic technology to address this gap: strengthening the meaning of housework around family values, supporting recognition of the partner's efforts through visualization, and initiating negotiation through defamiliarization. These insights extend the design considerations for domestic technologies, advocating for a broader understanding of the values contributing to satisfactory homemaking activities within the household.",
    "title": "Exploring Design Spaces to Facilitate Household Collaboration for Cohabiting Couples",
    "id": 189435,
    "sequence": 1225,
    "queryCoordinates": {
      "visualization": [
        -10.71852654580977,
        15.68799504993456
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Virtual reality (VR) applications achieve their high immersive potential by detaching the user from the real world, replacing it through a virtual environment. This detachment also blocks real-world orientation cues, which might cause fear of colliding with the real environment and negatively impact the player experience. However, since collision anxiety (CA) is a relatively young concept, it is unclear how factors like users’ VR expertise or specific game design choices may affect it. We defined expected CA profiles for five commercial VR games and conducted a longitudinal study examining how growing VR expertise and VR game design influence the users’ CA. After six weeks and a total of 154 VR sessions, results indicate that CA differs between applications and generally decreases as VR expertise increases. Based on our results, we propose design implications, providing researchers and designers with guidelines on when to expect and how to avoid fear of colliding.",
    "title": "Long-Term Effects of User Expertise and Application Design on Collision Anxiety in VR Games",
    "id": 189436,
    "sequence": 1226,
    "queryCoordinates": {
      "visualization": [
        2.740246833639355,
        -19.811386808871546
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "In light of machine learning's increasing computational needs, developers created energy and carbon-reporting tools to calculate and communicate their models' environmental impact. These tools use modeling parameters as inputs and respond with expected or incurred energy requirements or carbon emissions. This work critically and systematically analyses them regarding their content, form, and design process. Besides their noble intentions, many of the shortcomings of early sustainable HCI eco-feedback tools are still being propagated in these tools. Moreover, their design and development have limited inclusion of potential stakeholders. We argue the need for a next generation of approaches to ML eco-feedback that (a) further support rematerialization, (b) use participatory approaches in their design and development to support collaborative team environments and go beyond individual persuasion, (c) consider complexities of ML models and processes, and more broadly, (d) re-center around sufficiency rather than only efficiency.",
    "title": "A Critical Analysis of Machine Learning Eco-feedback Tools through the Lens of Sustainable HCI",
    "id": 189437,
    "sequence": 1227,
    "queryCoordinates": {
      "visualization": [
        -14.139622366382678,
        -5.007102888506558
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "Recovery from adverse incidents, such as accidents or cyber attacks, is a cornerstone of cyber resilience. Backups are essential in facilitating systems recovery. We have limited understanding of how devices for personal use are backed up, and of how data loss and recovery occur, including which factors might be helpful to afford resilience. To gain insights, we surveyed almost representative (in age and gender) samples of German, UK and USA populations, 1423 in total. Almost half of the participants (656, 46%) experienced at least one data loss incident. Whereas 42%  of 656 participants recovered using  backups, over half of them had outdated or incomplete backups. High levels of stress were reported, especially by those recovering without backups or with problematic backups. In the full sample, 86% of participants created full or partial backups of at least one of their devices, the most important trigger being prior data loss experiences.",
    "title": "Achieving Resilience: Data Loss and Recovery on Devices for Personal Use in Three Countries",
    "id": 189438,
    "sequence": 1228,
    "queryCoordinates": {
      "visualization": [
        4.923789310689836,
        -9.836477968456826
      ]
    }
  },
  {
    "session": "Accessibility",
    "abstract": "Despite the rise of affordable XR technologies, accessibility still remains a key concern,  often excluding people with disabilities from accessing immersive XR platforms. This work highlights these issues through a case study centered on an XR artwork: Crip Sensorama, co-created by two disabled artists and an HCI researcher. First, we present the accessibility challenges encountered by the artists to navigate and interact in XR. Secondly, we introduce the methodology of Criptastic Hacking, which led to the creation of two sets of mouth gestures for the artists as an interaction modality in XR. Finally, we share insights on how integrating this unconventional but accessible input modality into the artwork allowed us to incorporate the lived experiences of disability within HCI-based frameworks, that encourages inclusive XR design. Through this work, we aim to share new approaches to accessible XR design through inter-able collaborations, potentially reshaping future HCI research and practice.",
    "title": "\"Can I use my mouth to navigate in VR?\": Integrating Mouth Gestures in XR with (and for) Disabled Artists Through Criptastic Hacking",
    "id": 189439,
    "sequence": 1229,
    "queryCoordinates": {
      "visualization": [
        8.203107624274455,
        8.758368872374028
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "Transgender people often use face filters to try and see different possible futures: versions of what they might look like during or post transition, or how they might appear in an ideal future or alternate world. However, there are effectively no face filters made for trans people to feel good using. As a result, people often end up feeling bad or dysphoric instead of supported in their pursuit to envision the future. We asked 44 trans people about augmented reality and face filters, and to speculate on future technologies that would support their wellbeing and desires for transition. We found that trans-affirming face filters would be designed to support data privacy, agency, intersectionality, and consideration for expansive identity categories. Meeting these design goals would enable trans people to explore many different radically possible futures, facilitating expansive, transformative, self-perceptions that honor the multiplicity inherent in trans identity.",
    "title": "\"That Moment of Curiosity\": Augmented Reality Face Filters for Transgender Identity Exploration, Gender Affirmation, and Radical Possibility",
    "id": 189440,
    "sequence": 1230,
    "queryCoordinates": {
      "visualization": [
        13.862535754710239,
        1.9570647534969925
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "To make an engaging video, people sequence interesting moments and add visuals such as B-rolls or text. While video editing requires time and effort, AI has recently shown strong potential to make editing easier through suggestions and automation. A key strength of generative models is their ability to quickly generate multiple variations, but when provided with many alternatives, creators struggle to compare them to find the best fit. We propose VideoDiff, an AI video editing tool designed for editing with alternatives. With VideoDiff, creators can generate and review multiple AI recommendations for each editing process: creating a rough cut, inserting B-rolls, and adding text effects. VideoDiff simplifies comparisons by aligning videos and highlighting differences through timelines, transcripts, and video previews. Creators have the flexibility to regenerate and refine AI suggestions as they compare alternatives. Our study participants (N=12) could easily compare and customize alternatives, creating more satisfying results.",
    "title": "VideoDiff: Human-AI Video Co-Creation with Alternatives",
    "id": 189441,
    "sequence": 1231,
    "queryCoordinates": {
      "visualization": [
        0.39266793062208843,
        -17.995716487438365
      ]
    }
  },
  {
    "session": "Auditory UI",
    "abstract": "We introduce SPECTRA, a novel pipeline for personalizable sound recognition designed to understand DHH users' needs when collecting audio data, creating a training dataset, and reasoning about the quality of a model. To evaluate the prototype, we recruited 12 DHH participants who trained personalized models for their homes. We investigated waveforms, spectrograms, interactive clustering, and data annotating to support DHH users throughout this workflow, and we explored the impact of a hands-on training session on their experience and attitudes toward sound recognition tools. Our findings reveal the potential for clustering visualizations and waveforms to enrich users' understanding of audio data and refinement of training datasets, along with data annotations to promote varied data collection. We provide insights into DHH users' experiences and perspectives on personalizing a sound recognition pipeline. Finally, we share design considerations for future interactive systems to support this population.",
    "title": "SPECTRA: Personalizable Sound Recognition for Deaf and Hard of Hearing Users through Interactive Machine Learning",
    "id": 189442,
    "sequence": 1232,
    "queryCoordinates": {
      "visualization": [
        -9.212931062685524,
        -13.081357010425341
      ]
    }
  },
  {
    "session": "Interfaces and Interactions for XR",
    "abstract": "Inspired by the concepts of diminishing reality and ad-blocking in browsers, this study investigates the perceived benefits and concerns of blocking physical, real-world content, particularly ads, through Extended Reality (XR). To understand how users perceive this concept, we first conducted a user study (N=18) with an ad-blocking prototype to gather initial insights. The results revealed a mixed willingness to adopt XR blockers, with participants appreciating aspects such as customizability, convenience, and privacy. Expected benefits included enhanced focus and reduced stress, while concerns centered on missing important information and increased feelings of isolation. Hence, we investigated the user acceptance of different ad-blocking visualizations through a follow-up online survey (N=120), comparing six concepts based on related work. The results indicated that the XR ad-blocker visualizations play a significant role in how and for what kinds of advertisements such a concept might be used, paving the path for future feedback-driven prototyping.",
    "title": "Ad-Blocked Reality: Evaluating User Perceptions of Content Blocking Concepts Using Extended Reality",
    "id": 189443,
    "sequence": 1233,
    "queryCoordinates": {
      "visualization": [
        -0.3926475878621645,
        13.99449276936274
      ]
    }
  },
  {
    "session": "WS25: Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "abstract": "Interconnectedness and relationality have become integral to technology development and innovation, which has led to indigenous and cultural philosophies and approaches becoming important in developing effective and inclusive design practices. This workshop challenges the dominant paradigms in Human-Computer Interaction (HCI) by exploring the potential of indigeneity and culture to inform design methodologies. We invite participants to reflect on how such approaches can move HCI research toward more inclusive, culturally diverse, and mutually beneficial synergies. Through constructive conflict and co-creation, we aim to illuminate the potential of indigenous and cultural approaches in HCI practice, inspiring vital shifts towards decolonial and pluralistic design. We welcome HCI researchers and practitioners and indigenous scholars and experts interested in disrupting traditional methods and embracing indigenous and cultural lenses to join this critical conversation.",
    "title": "Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "id": 189444,
    "sequence": 1234,
    "queryCoordinates": {
      "visualization": [
        9.13142143513081,
        11.900300104368528
      ]
    }
  },
  {
    "session": "Creativity Support",
    "abstract": "Animated virtual reality (VR) stories, combining the presence of VR and the artistry of computer animation, offer a compelling way to deliver messages and evoke emotions. Motivated by the growing demand for immersive narrative experiences, more creators are creating animated VR stories. However, a holistic understanding of their creation processes and challenges involved in crafting these stories is still limited. Based on semi-structured interviews with 21 animated VR story creators, we identify ten common stages in their end-to-end creation processes, ranging from idea generation to evaluation, which form diverse workflows that are story-driven or visual-driven. Additionally, we highlight nine unique issues that arise during the creation process, such as a lack of reference material for multi-element plots, the absence of specific functionalities for story integration, and inadequate support for audience evaluation. We compare the creation of animated VR stories to general XR applications and distill several future research opportunities.",
    "title": "\"You'll Be Alice Adventuring in Wonderland!\" Processes, Challenges, and Opportunities of Creating Animated Virtual Reality Stories",
    "id": 189445,
    "sequence": 1235,
    "queryCoordinates": {
      "visualization": [
        1.1771545092012556,
        16.95919536008319
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "Recent research within the HCI community has illuminated the challenges faced by marginalized groups on algorithm-driven livestreaming platforms. However, there is a notable gap in understanding how elderly livestreamers interact with the platform content moderation and algorithmic (in)visibility. This study investigates the perceptions of the algorithm-moderated (in)visibility and the coping strategies of 16 elderly streamers on Douyin. We find that, contrary to stereotypes of elderly users as digitally uninformed, these streamers actively engage with the platform to facilitate their understanding about platform algorithm. This engagement involves official guidance, peer learning, and personal experimentation. The streamers adopt various strategies to align with the perceived algorithmic preferences. Despite their rich knowledge about the platform's visibility moderation, many elderly streamers face significant challenges, such as physical and psychological strain and low viewer traffic. We conclude with design implications for livestreaming platforms to foster fairness and promote engagement among elderly streamers.",
    "title": "'Even When Success Seems Impossible, I Keep Streaming': How Do Chinese Elderly Streamers Interact with Platform Algorithmic (In)visibility",
    "id": 189446,
    "sequence": 1236,
    "queryCoordinates": {
      "visualization": [
        13.533116534621593,
        11.86822467180124
      ]
    }
  },
  {
    "session": "WS30: Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "abstract": "Over the past decade, a noticeable increase in literature can be seen in wearable foot interfaces, which have evolved from activity tracking to enhancing human capabilities. Our legs, being the largest body limbs, play an essential role in various functions such as locomotion, maintaining balance, supporting proper posture and providing ground-contact using our feet. Hence, foot augmentations offer the opportunity to augment our entire body. However, most prior research focuses on specific application areas, thus affording a research agenda to further understand the full potential of feet in designing augmentations and to contextualize it in the broader human augmentation space. To achieve this, in this workshop, we invite researchers, designers, and practitioners, novice and expert, interested in designing human and foot augmentations. We will discuss how early foot interfaces helped in augmenting humans, and based on current work and trends in foot augmentation, we will formulate strategies for the next steps and discuss the applicability of such strategies in the broader space of human augmentation. ",
    "title": "Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "id": 189447,
    "sequence": 1237,
    "queryCoordinates": {
      "visualization": [
        -8.923003752364293,
        1.1747357299804642
      ]
    }
  },
  {
    "session": "Non-Verbal Communications",
    "abstract": "Videoconferencing is integral to modern work and living. Recently, technologists have sought to leverage data captured -- e.g. from cameras and microphones -- to augment communication. This might mean capturing communication information about verbal (e.g. speech, chat messages), or non-verbal exchanges (e.g. body language, gestures, tone of voice) and using this to mediate -- and potentially improve -- communication. However, such tracking has implications for user experience and raises wider concerns (e.g. privacy). To design tools which account for user needs and preferences, this study investigates perspectives on communication tracking through a global survey and interviews, exploring how daily behaviours and the impact of specific features influence user perspectives. We examine user preferences on non-verbal communication tracking, preferred methods of how this information is conveyed and to whom this should be communicated. Our findings aim to guide the development of non-verbal communication tools which augment videoconferencing that prioritise user needs.",
    "title": "Trusting Tracking: Perceptions of Non-Verbal Communication Tracking in Videoconferencing",
    "id": 189448,
    "sequence": 1238,
    "queryCoordinates": {
      "visualization": [
        -9.843705449290027,
        12.613542842025701
      ]
    }
  },
  {
    "session": "Autonomus Vehicle",
    "abstract": "Low trust remains a significant barrier to Autonomous Vehicle (AV) adoption. To design trustworthy AVs, we need to better understand the individual traits, attitudes, and experiences that impact people's trust judgements. We use machine learning to understand the most important factors that contribute to young adult trust based on a comprehensive set of personal factors gathered via survey (n = 1457). Factors ranged from psychosocial and cognitive attributes to driving style, experiences, and perceived AV risks and benefits. Using the explainable AI technique SHAP, we found that perceptions of AV risks and benefits, attitudes toward feasibility and usability, institutional trust, prior experience, and a person's mental model are the most important predictors. Surprisingly, psychosocial and many technology- and driving-specific factors were not strong predictors. Results highlight the importance of individual differences for designing trustworthy AVs for diverse groups and lead to key implications for future design and research.",
    "title": "Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning",
    "id": 189449,
    "sequence": 1239,
    "queryCoordinates": {
      "visualization": [
        -0.39265422461809524,
        14.99485987463336
      ]
    }
  },
  {
    "session": "Earable and Hearable",
    "abstract": "Imagine being in a crowded space where people speak a different language and having hearables that transform the auditory space into your native language, while preserving the spatial cues for all speakers. We introduce spatial speech translation, a novel concept for hearables that translate  speakers in the  wearer's environment,  while maintaining the direction and unique voice characteristics of each speaker in the binaural output. To achieve this, we tackle several technical challenges  spanning blind source separation, localization, real-time expressive translation, and binaural rendering to preserve the speaker directions in the translated audio, while achieving real-time inference on the Apple M2 silicon. Our proof-of-concept evaluation with a prototype binaural headset shows that, unlike existing models, which fail in the presence of interference, we achieve a BLEU score of upto 22.01 when translating between languages, despite strong interference from other speakers in the environment. User studies further confirm the system’s effectiveness in spatially rendering the translated speech in previously unseen real-world reverberant environments. Taking a step back, this work marks the first step towards integrating spatial perception into speech translation.",
    "title": "Spatial Speech Translation: Translating Across Space With Binaural Hearables",
    "id": 189450,
    "sequence": 1240,
    "queryCoordinates": {
      "visualization": [
        0.3925744862880219,
        -8.99143399423672
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "Mixed-Reality physical task guidance systems have the benefit of providing virtual instructions while enabling learners to interact with the tangible world. However, they are mostly built around single-path tasks and often employ visual cues for motion guidance without explanations on why an action was recommended. In this paper, we introduce eXplainMR, a mixed-reality tutoring system that teaches medical trainees to perform cardiac ultrasound. eXplainMR automatically generates subgoals for obtaining an ultrasound image that contains clinically relevant information, and textual and visual explanations for each recommended move based on the visual difference between the two consecutive subgoals. We performed a between-subject experiment (N=16) in one US teaching hospital comparing eXplainMR with a baseline MR system that offers commonly used arrow and shadow guidance. We found that after using eXplainMR, medical trainees demonstrated a better understanding of anatomy and showed more systematic reasoning when deciding on the next moves, which was facilitated by the real-time explanations provided in eXplainMR.",
    "title": "eXplainMR: Generating Real-time Textual and Visual eXplanations to Facilitate UltraSonography Learning in MR",
    "id": 189451,
    "sequence": 1241,
    "queryCoordinates": {
      "visualization": [
        2.7203715060963645,
        -10.658310319596582
      ]
    }
  },
  {
    "session": "Expressive Machines",
    "abstract": "Urban gardening is widely recognized for its numerous health and environmental benefits. However, the lack of suitable garden spaces, demanding daily schedules and limited gardening expertise present major roadblocks for citizens looking to engage in urban gardening. While prior research has explored smart home solutions to support urban gardeners, these approaches currently do not fully address these practical barriers. In this paper, we present PlantPal, a system that enables the cultivation of garden spaces irrespective of one's location, expertise level, or time constraints. PlantPal enables the shared operation of a precision agriculture robot (PAR) that is equipped with garden tools and a multi-camera system. Insights from a 3-week deployment (N=18) indicate that PlantPal facilitated the integration of gardening tasks into daily routines, fostered a sense of connection with one's field, and provided an engaging experience despite the remote setting. We contribute design considerations for future robot-assisted urban gardening concepts.",
    "title": "PlantPal: Leveraging Precision Agriculture Robots to Facilitate Remote Engagement in Urban Gardening",
    "id": 189452,
    "sequence": 1242,
    "queryCoordinates": {
      "visualization": [
        10.555408354592712,
        13.32604046473649
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "Can Multimodal Large Language Models (MLLMs), with capabilities in perception, recognition, understanding, and reasoning, act as independent assistants in art evaluation dialogues? Current MLLM evaluation methods, reliant on subjective human scoring or costly interviews, lack comprehensive scenario coverage. This paper proposes a process-oriented Human-Computer Interaction (HCI) space design for more accurate MLLM assessment and development. This approach aids teachers in efficient art evaluation and records interactions for MLLM capability assessment. We introduce ArtMentor, a comprehensive space integrating a dataset and three systems for optimized MLLM evaluation. It includes 380 sessions from five art teachers across nine critical dimensions. The modular system features entity recognition, review generation, and suggestion generation agents, enabling iterative upgrades. Machine learning and natural language processing ensure reliable evaluations. Results confirm GPT-4o’s effectiveness in assisting teachers in art evaluation dialogues. Our contributions are available at https://artmentor.github.io/.",
    "title": "ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities",
    "id": 189453,
    "sequence": 1243,
    "queryCoordinates": {
      "visualization": [
        -14.382296023022894,
        4.260230170558845
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "d/Deaf and hearing song-signers have become prevalent across video-sharing platforms, but translating songs into sign language remains cumbersome and inaccessible. Our formative study revealed the challenges song-signers face, including semantic, syntactic, expressive, and rhythmic considerations in translations. We present ELMI, an accessible song-signing tool that assists in translating lyrics into sign language. ELMI enables users to edit glosses line-by-line, with real-time synced lyric and music video snippets.  Users can also chat with a large language model-driven AI to discuss meaning, glossing, emoting, and timing. Through an exploratory study with 13 song-signers, we examined how ELMI facilitates their workflows and how song-signers leverage and receive an LLM-driven chat for translation. Participants successfully adopted ELMI to song-signing, with active discussions throughout. They also reported improved confidence and independence in their translations, finding ELMI  encouraging, constructive, and informative. We discuss research and design implications for accessible and culturally sensitive song-signing translation tools.",
    "title": "ELMI: Interactive and Intelligent Sign Language Translation of Lyrics for Song Signing",
    "id": 189454,
    "sequence": 1244,
    "queryCoordinates": {
      "visualization": [
        20.38252791652121,
        -5.054953583588435
      ]
    }
  },
  {
    "session": "HCI Method Considerations",
    "abstract": "People have different levels of affinity for technology, which impacts their attitudes and behavior when using novel technologies. Capturing this difference requires a validated multi-language instrument. Hence, we translated and validated English, Japanese, and Spanish versions of the Affinity for Technology questionnaire (TAEG), which has so far only been available in German. The TAEG consists of four scales assessing enthusiasm, perceived competence, and positive and negative consequences of technology. After systematic translation, we collected and analyzed age and gender-stratified samples from Germany, Mexico, Japan, and the US, with a total sample N=1206. All TAEG versions showed an excellent fit with the four-factor model and good criterion validity. We also introduced a short-scale (TAEG-S) that captures the global construct. We found significant cross-country variations, with Mexico reporting the highest TAEG scores on all scales. The validated versions of TAEG provide a robust tool to assess individuals’ affinity for technology internationally.",
    "title": "The TAEG Questionnaire: Assessing Individual Affinity for Technology Across Different Countries",
    "id": 189455,
    "sequence": 1245,
    "queryCoordinates": {
      "visualization": [
        12.613542842025703,
        -9.843705449290026
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "Art appreciation serves as a crucial medium for emotional communication and sociocultural dialogue. In the digital era, fostering deep user engagement on online art appreciation platforms remains a challenge. Leveraging large language models (LLMs), we present EyeSee, a system designed to engage users through anthropomorphic characters. We implemented and evaluated three modes--Narrator, Artist, and In-Situ--acting as a third-person narrator, a first-person creator, and first-person created objects, respectively, across two sessions: Narrative and Recommendation. We conducted a within-subject study with 24 participants. In the Narrative session, we found that the In-Situ and Artist modes had higher aesthetic appeal than the Narrator mode, although the Artist mode showed lower perceived usability. Additionally, from the Narrative to the Recommendation session, we found that the user-perceived relatability and believability were sustained, but the user-perceived consistency and stereotypicality changed. Our findings suggest novel implications for anthropomorphic character design in enhancing user engagement.",
    "title": "EyeSee: Enhancing Art Appreciation through Anthropomorphic Interpretations from Multiple Perspectives",
    "id": 189456,
    "sequence": 1246,
    "queryCoordinates": {
      "visualization": [
        1.1774793919810287,
        20.96696311537415
      ]
    }
  },
  {
    "session": "Embodiment and Immersion",
    "abstract": "As vehicles become more advanced, in-car agents must manage increasingly complex interactions, heightening the need for effective information delivery. This paper investigates how different embodiments of in-car agents affect the delivery of various information types. We developed the ‘Drop-lit’ prototype to explore three embodiment features: physicality, characterization, and movement. In a user study with 20 participants, we compared three representative agent designs: abstraction, digital character, and mixed-media, across six categories of in-car information. Additionally, a co-design session allowed participants to self-customize and combine embodiment features for six specific driving scenarios. Results indicated that mixed-media agents were most effective for urgent warnings, digital characters for recommendations, and abstracted agents for simple reference information. The study also revealed how embodiment influenced experiential factors such as attention-grabbing, urgency, friendliness, trustworthiness, and playfulness, offering insights for optimizing agent design to enhance user engagement and information delivery in automotive contexts.",
    "title": "The Effect of In-Car Agent Embodiment on Different Types of Information Delivery",
    "id": 189457,
    "sequence": 1247,
    "queryCoordinates": {
      "visualization": [
        -10.825223247697279,
        -1.953085158797331
      ]
    }
  },
  {
    "session": "Mediated Social Interactions",
    "abstract": "Charts are used to communicate data visually, but often, we do not know whether a chart's intended message aligns with the message readers perceive. In this mixed-methods study, we investigate how data journalists encode data and how members of a broad audience engage with, experience, and understand these visualizations. We conducted workshops and interviews with school and university students, job seekers, designers, and senior citizens to collect perceived messages and feedback on eight real-world charts. We analyzed these messages and compared them to the intended message. Our results help to understand the gulf that can exist between messages (that producers encode) and viewer interpretations. In particular, we find that consumers are often overwhelmed with the amount of data provided and are easily confused with terms that are not well known. Chart producers tend to follow strong conventions on how to visually encode particular information that might not always benefit consumers.",
    "title": "The Gulf of Interpretation: From Chart to Message and Back Again",
    "id": 189458,
    "sequence": 1248,
    "queryCoordinates": {
      "visualization": [
        -2.653732141314013,
        -5.381236449196128
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "Intermittent Interaction is a turn-taking approach used to interact with fabrication devices to do something that otherwise would be impractical or impossible for the machine. We investigate how people perceive intermittent interactions in a controlled study.\r\nA LEGO assembly task with timed lock boxes simulates human involvement with a semi-automated machine process, similar to a 3D printer. This is used in an in situ study with 12 participants over 4-hour sessions with experimental controls for number of interactions and step complexity. \r\nResults suggest complex interactions during assembly can amplify the perceived value of the assembled object and increase enjoyment. \r\nParticipants used either a clustered or evenly distributed strategy to schedule interactions, which can be modelled with simple heuristics.\r\nWe contribute evidence that intermittent interaction is generally acceptable for creation tasks and practical guidelines for integrating intermittent interactions into semi-automated fabrication systems.",
    "title": "Intermittent Interaction in Digital Fabrication: User Perception of Periodic Intervention in Semi-Automated Creation Tasks",
    "id": 189459,
    "sequence": 1249,
    "queryCoordinates": {
      "visualization": [
        16.40802887051027,
        11.435759204552244
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "Designing haptic effects is a complex, time-consuming process requiring specialized skills and tools. To support haptic design, we introduce HapticGen, a generative model designed to create vibrotactile signals from text inputs. We conducted a formative workshop to identify requirements for an AI-driven haptic model. Given the limited size of existing haptic datasets, we trained HapticGen on a large, labeled dataset of 335k audio samples using an automated audio-to-haptic conversion method. Expert haptic designers then used HapticGen's integrated interface to prompt and rate signals, creating a haptic-specific preference dataset for fine-tuning. We evaluated the fine-tuned HapticGen with 32 users, qualitatively and quantitatively, in an A/B comparison against a baseline text-to-audio model with audio-to-haptic conversion. Results show significant improvements in five haptic experience (e.g., realism) and system usability factors (e.g., future use). Qualitative feedback indicates HapticGen streamlines the ideation process for designers and helps generate diverse, nuanced vibrations.",
    "title": "HapticGen: Generative Text-to-Vibration Model for Streamlining Haptic Design",
    "id": 189460,
    "sequence": 1250,
    "queryCoordinates": {
      "visualization": [
        -9.930684569549262,
        1.1753739745783756
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "Creating animation takes time, effort, and technical expertise. To help novices with animation, we present LogoMotion, an AI code generation approach that helps users create semantically meaningful animation for logos. LogoMotion automatically generates animation code with a method called visually-grounded code synthesis and program repair. This method performs visual analysis, instantiates a design concept, and conducts visual checking to generate animation code. LogoMotion provides novices with code-connected AI editing widgets that help them edit the motion, grouping, and timing of their animation. In a comparison study on 276 animations, LogoMotion was found to produce more content-aware animation than an industry-leading tool. In a user evaluation (n=16) comparing against a prompt-only baseline, these code-connected widgets helped users edit animations with control, iteration, and creative expression.",
    "title": "LogoMotion: Visually-Grounded Code Synthesis for Creating and Editing Animation",
    "id": 189461,
    "sequence": 1251,
    "queryCoordinates": {
      "visualization": [
        -11.86822467180124,
        13.533116534621593
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "Dwell-based text entry seems to peak at 20 words per minute (WPM). Yet, little is known about the factors contributing to this limit, except that it requires extensive training. Thus, we conducted a longitudinal study, broke the overall dwell-based selection time into six different components, and identified several design challenges and opportunities. Subsequently, we designed two novel dwell keyboards that use multiple yet much shorter dwell thresholds: Dual-Threshold Dwell (DTD) and Multi-Threshold Dwell (MTD). The performance analysis showed that MTD (18.3 WPM) outperformed both DTD (15.3 WPM) and the conventional Constant-Threshold Dwell (12.9 WPM). Notably, absolute novices achieved these speeds within just 30 phrases. Moreover, MTD’s performance is also the fastest-ever reported average text entry speed for gaze-based keyboards. Finally, we discuss how our chosen parameters can be further optimized to pave the way toward more efficient dwell-based text entry.",
    "title": "There Is More to Dwell Than Meets the Eye: Toward Better Gaze-Based Text Entry Systems With Multi-Threshold Dwell",
    "id": 189462,
    "sequence": 1252,
    "queryCoordinates": {
      "visualization": [
        5.6129703636698896,
        -9.46015664228471
      ]
    }
  },
  {
    "session": "Working with AI",
    "abstract": "Documentation plays a crucial role in both external accountability and internal governance of AI systems. Although there are many proposals for documenting AI data, models, systems, and methods, the ways these practices enhance governance as well as the challenges practitioners and organizations face with documentation remain underexplored. In this paper, we analyze 37 proposed documentation frameworks and 22 empirical studies evaluating their use. We identify several pathways or \"theories of change\" through which documentation can enhance governance, including informing stakeholders about AI risks and applications, facilitating collaboration, encouraging ethical deliberation, and supporting best practices. However, empirical findings reveal significant challenges for practitioners, such as insufficient incentives and resources, structural and organizational communication barriers, interpersonal and organizational constraints to ethical action, and poor integration with existing workflows. These challenges often hinder the realization of the possible benefits of documentation. We also highlight key considerations for organizations when designing documentation, such as determining the appropriate level of detail and balancing automation in the process. We conclude by discussing how future research can expand on our findings such as by exploring documentation approaches that support governance of general-purpose models and how multiple transparency and documentation methods can collectively improve governance outcomes. ",
    "title": "Improving Governance Outcomes Through AI Documentation: Bridging Theory and Practice",
    "id": 189463,
    "sequence": 1253,
    "queryCoordinates": {
      "visualization": [
        -8.657797840548975,
        15.78108160273514
      ]
    }
  },
  {
    "session": "Smart Home and Buildings",
    "abstract": "Hubs are at the core of most smart homes. Modern cross-ecosystem protocols and standards enable smart home hubs to achieve interoperability across devices, offering the unique opportunity to integrate universally available smart home privacy awareness and control features. To date, such privacy features mainly focus on individual products or prototypical research artifacts. We developed a cross-ecosystem hub featuring a tangible dashboard and a digital web application to deepen our understanding of how smart home users interact with functional privacy features. The ecosystem allows users to control the connectivity states of their devices and raises awareness by visualizing device positions, states, and data flows. We deployed the ecosystem in six households for one week and found that it increased participants' perceived control, awareness, and understanding of smart home privacy. We further found distinct differences between tangible and digital mechanisms. Our findings highlight the value of cross-ecosystem hubs for effective privacy management.",
    "title": "PrivacyHub: A Functional Tangible and Digital Ecosystem for Interoperable Smart Home Privacy Awareness and Control",
    "id": 189464,
    "sequence": 1254,
    "queryCoordinates": {
      "visualization": [
        -3.5159255986870908,
        19.688531361797832
      ]
    }
  },
  {
    "session": "Technologies for Parental Engagement",
    "abstract": "As children progress through developmental stages, they undergo substantial biological, cognitive, and social changes, creating unique needs for online safety across different age groups (e.g., young children, tweens, teens). The existing parental control tools fail to account for these differences, leaving a notable gap in the literature on parental mediation. To this end, we conducted 10 focus group sessions with a total of 20 parents to understand their preferences for age-appropriate design components that promote self-regulation and open communication, followed by an ideation workshop with four UX design experts to translate these preferences into customized features. We then evaluated these designs (presented as storyboards) through semi-structured interviews with 25 parents. Our study joins the body of work on parental mediation, providing valuable insights into customizing parental control settings as children transition through the developmental stages. Based on our findings, we offer guidelines for future research in these directions.",
    "title": "One Size Doesn’t Fit All: Towards Design and Evaluation of Developmentally Appropriate Parental Control Tool",
    "id": 189465,
    "sequence": 1255,
    "queryCoordinates": {
      "visualization": [
        1.9547456807350658,
        11.839719985018547
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "Amid the recent uptake of Generative AI, sociotechnical scholars and critics have traced a multitude of resulting harms, with analyses largely focused on values and axiology (e.g., bias). While value-based analyses are crucial, we argue that ontologies—concerning what we allow ourselves to think or talk about—is a vital but under-recognized dimension in analyzing these systems. Proposing a need for a practice-based engagement with ontologies, we offer four orientations for considering ontologies in design: pluralism, groundedness, liveliness, and enactment. We share examples of potentialities that are opened up through these orientations across the entire LLM development pipeline by conducting two ontological analyses: examining the responses of four LLM-based chatbots in a prompting exercise, and analyzing the architecture of an LLM-based agent simulation. We conclude by sharing opportunities and limitations of working with ontologies in the design and development of sociotechnical systems.\r\n",
    "title": "Ontologies in Design: How Imagining a Tree Reveals Possibilities and Assumptions in Large Language Models",
    "id": 189466,
    "sequence": 1256,
    "queryCoordinates": {
      "visualization": [
        11.032648715793071,
        11.58795332722347
      ]
    }
  },
  {
    "session": "Learning and Inspiring, Safety and Security",
    "abstract": "This paper investigates museum educators' perceptions of play, games, and learning, as well as their approaches to designing and implementing interactive experiences. Through a thematic analysis, we found that museum educators tend to favor games and hands-on learning due to the strong association between learning, play, and curiosity. This connection often drives educators to integrate games and interactive elements into museum experiences. Key challenges in the design process included limited resources, time, and skills, as well as more contextual tensions. These included balancing 'fun' versus serious learning objectives and addressing discomfort that may arise from certain learning experiences, with the recognition that not all games need to be designed solely for fun. Our paper contributes to a deeper understanding of how educators incorporate game-like and playful learning in museums. We also offer a design considerations in the form of a checklist to guide other museum educators in developing effective play-based learning experiences.",
    "title": "Learning Curiosity through Play: Exploring the Role of Games and Interactive Design in Museums",
    "id": 189467,
    "sequence": 1257,
    "queryCoordinates": {
      "visualization": [
        -13.858192987669298,
        5.740251485476354
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "Long-distance running is introduced as an example of a sport-specific somatic and embodied data practice that may expand the repertoire of techniques and methods of embodied interaction design and provide insights into the design of technologies for running specifically and sports technology more broadly. Through an autobiographic study of everyday experiences of running and the use of a basic sports watch, a number of themes revolving around the multi-sensoriality of running are introduced. Reflections on the intimate coupling of digital data, running skills, and somatic sensing in the practice of 'doing endurance running' are provided in order to conceptualise the specific sensitivities, perceptions and experiences of body-data-environment entanglements that emerge during long-distance running. By unpacking a number of such sports-specific skills and data practices involved in long-distance running, six themes for novel perspectives on the design of sports technology are discussed.",
    "title": "The Body as Its Own Best Sensor - An Autoethnographic Study of the Sensitivities of the Body in Long-Distance Running",
    "id": 189468,
    "sequence": 1258,
    "queryCoordinates": {
      "visualization": [
        -5.681580776970635,
        -1.9286367918189664
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "Scientists across disciplines write code for critical activities like data collection and generation, statistical modeling, and visualization. As large language models that can generate code have become widely available, scientists may increasingly use these models during research software development. We investigate the characteristics of scientists who are early-adopters of code generating models and conduct interviews with scientists at a public, research-focused university. Through interviews and reviews of user interaction logs, we see that scientists often use code generating models as an information retrieval tool for navigating unfamiliar programming languages and libraries. We present findings about their verification strategies and discuss potential vulnerabilities that may emerge from code generation practices unknowingly influencing the parameters of scientific analyses.",
    "title": "How Scientists Use Large Language Models to Program",
    "id": 189469,
    "sequence": 1259,
    "queryCoordinates": {
      "visualization": [
        4.112821953545775,
        6.861828880002176
      ]
    }
  },
  {
    "session": "Being Inclusive",
    "abstract": "Previous work on Social Comparison Theory shows that comparing oneself to others can lead to negative self-perceptions and rumination, reducing self-confidence. Despite these harmful effects, social comparisons are frequently used as engagement strategies in personal informatics systems, such as health and wellness apps. There is limited understanding of how users perceive these comparisons and their impact on wellbeing. To address this, we reviewed the Top 50 Health & Wellness smartphone applications to analyse implemented comparison strategies and the metrics such comparisons are used for. We conducted an online vignette study (n=192) and an interview study (n=12) to further explore the impact of social comparisons on users. Our study shows that comparisons in personal informatics motivate users but simultaneously lead to negative emotions (e.g., inferiority, disappointment), potentially leading to obsessive thoughts and overtraining. Based on our findings, we propose design guidelines for implementing social comparison features that prioritise users’ wellbeing.",
    "title": "Unhealthy Comparisons to Promote Healthy Behavior? Exploring the Impact of Social Comparison Strategies in Personal Informatics.",
    "id": 189470,
    "sequence": 1260,
    "queryCoordinates": {
      "visualization": [
        -20.966963115374146,
        -1.1774793919810342
      ]
    }
  },
  {
    "session": "Malleable and Adaptive Interface",
    "abstract": "Traditional Programming by Demonstration (PBD) systems primarily automate tasks by recording and replaying operations on Graphical User Interfaces (GUIs), without fully considering the cognitive processes behind operations. This limits their ability to generalize tasks with interdependent operations to new contexts (e.g. collecting and summarizing introductions depending on different search keywords from varied websites). We propose TaskMind, a system that automatically identifies the semantics of operations, and the cognitive dependencies between operations from demonstrations, building a user-interpretable task graph. Users modify this graph to define new task goals, and TaskMind executes the graph to dynamically generalize new parameters for operations, with the integration of Large Language Models (LLMs). We compared TaskMind with a baseline end-to-end LLM which automates tasks from demonstrations and natural language commands, without task graph. In studies with 20 participants on both predefined and customized tasks, TaskMind significantly outperforms the baseline in both success rate and controllability.",
    "title": "From Operation to Cognition: Automatic Modeling Cognitive Dependencies from User Demonstrations for GUI Task Automation",
    "id": 189471,
    "sequence": 1261,
    "queryCoordinates": {
      "visualization": [
        -11.435759204552248,
        -16.40802887051027
      ]
    }
  },
  {
    "session": "Social Good",
    "abstract": "In this paper, we extend the Digital Border Assemblages framework (DBA) by locating the role of ICTs in enabling means of racialized control at geographical boundaries or borders. Applying a critical-interpretive approach, we identify key features of DBA that contribute to such racial formations. We analyze three case studies of border technologies deployed at and beyond physical sites of border control: electronic device inspections, electronic location monitoring, and restricted transactions in financial technologies. Although a framework of DBA exists in the current paradigm of border studies, we argue that a close examination of the entanglements between borders and ICTs offers us key insights into how migrant bodies are subjected to racialized control at/by the border.  Implications for HCI researchers include studying the experiences of those impacted by this assemblage and developing methods inspired by the legal field for studying these obscure systems.",
    "title": "The Role of ICTs in the Maintenance and Reproduction of Digital Border Assemblages",
    "id": 189472,
    "sequence": 1262,
    "queryCoordinates": {
      "visualization": [
        2.7369301092840272,
        -16.778236307100176
      ]
    }
  },
  {
    "session": "Interacting with Robots",
    "abstract": "In this work, we introduce a formal design approach derived from the performing arts to design robot group movement. In our first experiment, we worked with trained actors and professional performers in a participatory design approach to identify common group movement patterns. In a follow-up studio work, we identified twelve common group movement patterns, transposed them into a performance script, built a scale model to support the performance process, and evaluated the patterns with a senior actor under studio conditions. We evaluated our refined models with 20 volunteers in a user study in the third experiment. Results from our affective circumplex modelling suggest that the patterns elicit positive emotional responses from the users. Also, participants performed better than chance in identifying the motion patterns without prior training. Based on our results, we propose design guidelines for social robots’ behaviour and movement design to improve their overall comprehensibility in interaction.",
    "title": "Playing with Robots: Performing Arts Techniques for Designing and Understanding Robot Group Movement",
    "id": 189473,
    "sequence": 1263,
    "queryCoordinates": {
      "visualization": [
        1.9560385425721736,
        -12.852000358697945
      ]
    }
  },
  {
    "session": "Methodology",
    "abstract": "In today’s fast-paced conference environment, traditional networking methods often fall short of fostering genuine connections. This case study explores innovative strategies for enhancing attendee engagement through the F.I.S.H. framework: Fun, Interactive, Sketching, and Humour. By integrating these elements, attendees can break down barriers, promote creativity, and cultivate a more relaxed atmosphere conducive to meaningful interactions. I discuss the role of sketching as a visual communication medium that encourages collaboration and idea sharing, while humour acts as the chum, attracting participants to the conversation and preventing the social waters from becoming stagnant and keeping awkwardness from hooking anyone. Through two case studies, I highlight the effectiveness of this medium in transforming the conference experience, ultimately leading to richer connections and enhanced networking outcomes. This research encourages the practical application of creative engagement techniques, such as sketching, at conferences. The findings suggest that this approach can significantly improve networking outcomes and foster a more vibrant and innovative community.",
    "title": "Visualizing Engagement: The Power of Fun, Interactive, Sketching and Humour in Conference Networking (F.I.S.H.)",
    "id": 189474,
    "sequence": 1264,
    "queryCoordinates": {
      "visualization": [
        -11.406089484000459,
        9.741720724952762
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "Participatory Design (PD) has become increasingly prevalent in Human-Computer Interaction (HCI) research. However, there remains a lack of comprehensive understanding of how PD has been used by HCI scholars. To bridge this gap, we sampled PD application cases (N = 185) from the SIGCHI conferences {over the past decade} and examined these cases through the dimensions of application features (e.g., contexts and functions of PD) and PD principles (e.g., its political commitment and mutual learning principle). Our analysis reveals the various ways PD has been applied in HCI and how its core features have been or have not been manifested in these cases. Based on these findings, we reflect on the conceptual understanding of PD within the HCI community and discuss potential misconceptions. Ultimately, we hope this work can serve as a useful reference for HCI researchers and beyond who are interested in incorporating PD into their design and research practices. ",
    "title": "Participatory Design in Human-Computer Interaction: Cases, Characteristics, and Lessons",
    "id": 189475,
    "sequence": 1265,
    "queryCoordinates": {
      "visualization": [
        15.995181099139268,
        0.3926596563665966
      ]
    }
  },
  {
    "session": "Communication and Socialization",
    "abstract": "Accelerated globalization has made migration commonplace, creating significant cultural adaptation challenges, particularly for young migrants. While HCI research has explored the role of technology in migrants' cultural adaptation, there is a need to address the diverse cultural backgrounds and needs of young migrants specifically. Recognizing the potential of conversational AI to adapt to diverse cultural contexts, we investigate how young migrants could use this technology in their adaptation journey and explore its societal implementation. Through individual workshops with young migrants and stakeholder interviews—including AI practitioners, public sector workers, policy experts, and social scientist—we found that both groups of participants expect conversational AI to support young migrants in connecting with the host culture before migration, exploring the home culture, and aligning identities across home and host cultures. However, challenges such as expectation gaps and cultural bias may hinder cultural adaptation. We discuss design considerations for culturally sensitive AI that empower young migrants and propose strategies to enhance societal readiness for AI-driven cultural adaptation.",
    "title": "Into the Unknown: Leveraging Conversational AI in Supporting Young Migrants' Journeys Towards Cultural Adaptation ",
    "id": 189476,
    "sequence": 1266,
    "queryCoordinates": {
      "visualization": [
        -1.177479391981022,
        -20.96696311537415
      ]
    }
  },
  {
    "session": "WS31: Affective interaction and affective computing - past, present and future",
    "abstract": "HCI researchers recognize affect and emotion as fundamental parts of human experience however conceptualizing emotions as ineffable, embodied, situated, or culturally bound does not fit within some of the dominant paradigm of Affective computing and emotion AI research focused mostly on recognition and classification of basic emotions. An alternative term, \\textit{Affective Interaction}, has emerged to bring together a growing body of research which treats emotion and affect within HCI in similar ways. This workshop brings the research community together to examine various perspectives on affect, and specifically contrast Affective Interaction with Affective Computing. The aim is to discuss opportunities and limitations associated with each perspective, reconcile with advances in the science of emotion, and to speculate on future research directions. We believe that bringing together HCI researchers around Affective Interaction is vitally important because the broad reach of Affective Computing techniques may be obscuring advances in emotion research that show evidence that emotion defies easy categories and is culturally situated. ",
    "title": "Affective interaction and affective computing - past, present and future",
    "id": 189477,
    "sequence": 1267,
    "queryCoordinates": {
      "visualization": [
        11.159588106621731,
        -12.824335978542779
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Learning therapeutic counseling involves significant role-play experience with mock patients, with current manual training methods providing only intermittent granular feedback. We seek to accelerate and optimize counselor training by providing frequent, detailed feedback to trainees as they interact with a simulated patient. Our first application domain involves training motivational interviewing skills for counselors. Motivational interviewing is a collaborative counseling style in which patients are guided to talk about changing their behavior, with empathetic counseling an essential ingredient. We developed and evaluated an LLM-powered training system that features a simulated patient and visualizations of turn-by-turn performance feedback tailored to the needs of counselors learning motivational interviewing. We conducted an evaluation study with professional and student counselors, demonstrating high usability and satisfaction with the system. We present design implications for the development of automated systems that train users in counseling skills and their generalizability to other types of social skills training.",
    "title": "Scaffolding Empathy: Training Counselors with Simulated Patients and Utterance-level Performance Visualizations",
    "id": 189478,
    "sequence": 1268,
    "queryCoordinates": {
      "visualization": [
        -6.273549006284605,
        -9.035628526325407
      ]
    }
  },
  {
    "session": "Conversations with AI",
    "abstract": "Recent advances in conversational AI and the ubiquity of related devices and applications---from robots to smart speakers to chatbots---has led to extensive research on designing and studying conversational systems with older adults. Despite a growing literature on this topic, many studies examine small groups of older adults and specific devices, neglecting a holistic understanding of how diverse groups of older adults perceive conversational interaction more broadly. We present a systematic review that synthesizes older adults’ perceptions of the challenges and opportunities for interacting with these systems. We highlight their vision for future AI-based conversational systems, emphasizing a desire for more human-like interactions, personalization, and greater control over their information. We discuss the implications for future research and design of conversational AI systems for older adults.",
    "title": "Designing Conversational AI for Aging: A Systematic Review of Older Adults’ Perceptions and Needs",
    "id": 189479,
    "sequence": 1269,
    "queryCoordinates": {
      "visualization": [
        -1.957064753496992,
        -13.862535754710239
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "Fine-tuning Large Language Models (LLMs) is one response to the critique of LLMs being biased, erasing diversity, and raising ethical concerns. The Artificial Intimacy project employs artistic methods, taking personalization of chatbots to an extreme by fine-tuning LLMs on individual social media data. We find that regular GPT-3 chatbots attempt to circumvent value-laden content through flagging prompts and producing generic non-answers with variable success. While the transactional nature of such output allowed participants to make sense of responses with less personification, fine-tuned models presented value-laden, normative, and familiar personalities, resulting in strong personification as a way of making sense of the interactions. This mimicry of emotional connection resulted in a sense of artificial intimacy creating expectations for reciprocity and consideration that the models cannot express by design. As the commercialization of interactions with chatbots continues, we discuss the ethics of such emotional manipulation and its implications for personalization of LLMs.",
    "title": "Artificial Intimacy: Exploring Normativity and Personalization through Fine-tuning LLM Chatbots",
    "id": 189480,
    "sequence": 1270,
    "queryCoordinates": {
      "visualization": [
        13.002551317075602,
        12.447235004080849
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "Despite the growth of video as a medium, videos remain inaccessible to many people. Prior video accessibility research has focused primarily on blind and low vision or d/Deaf and hard of hearing audiences. However, the video watching experiences of people with ADHD are largely unexplored. Through semi-structured interviews with 20 participants self-identifying with ADHD, we uncovered video watching frustrations, current strategies for access, and desired accessibility features. Participants faced both overstimulation and understimulation from visuals and audio (e.g., flashing lights, slower speech), which impacted their attention, engagement, and information retention. Common strategies included altering video speed, using captions, and leveraging timestamps for skipping through videos. Participants desired adjustable sound channels for aiding focus, video summaries for retaining information, and warnings for preempting sensory discomfort. We close by discussing (1) design recommendations for platforms and creators to support users in achieving their viewing goals and (2) ADHD-inclusive design principles.",
    "title": "Shifting the Focus: Exploring Video Accessibility Strategies and Challenges for People with ADHD",
    "id": 189481,
    "sequence": 1271,
    "queryCoordinates": {
      "visualization": [
        -6.539367376890133,
        -17.83918928399116
      ]
    }
  },
  {
    "session": "Nature",
    "abstract": "Animals living alongside humans are navigating a world increasingly filled with technology, yet little is known about how they interface with these systems, whether designed for, with, or around them. Anchored in HCI and ranging across diverse fields, this scoping review analyzes nearly 800 research works to explore the diverse realities of animal-technology research, examining the who, what, why, and how of animal-technology entanglements. Our analysis revealed 11 research objectives and eight types of technologies across six animal contexts. By categorizing the literature based on authors' aims and intended beneficiaries, we highlight trends, gaps, and ethical considerations. We find that most systems involve animals with limited potential for direct engagement or sense-making. We propose a framework to understand animals as users versus subjects of interactive systems, focusing on feedback, empirical testing, and projected animal benefits. Our findings offer a foundation to understand current and future animal technology research and the diversity of animal user experience.",
    "title": "Animals' Entanglement with Technology: a Scoping Review",
    "id": 189482,
    "sequence": 1272,
    "queryCoordinates": {
      "visualization": [
        2.77163859753386,
        1.1480502970952693
      ]
    }
  },
  {
    "session": "Multimodal Interaction",
    "abstract": "Novice content creators often invest significant time recording expressive speech for social media videos. While recent advancements in text-to-speech (TTS) technology can generate highly realistic speech in various languages and accents, many struggle with unintuitive or overly granular TTS interfaces. We propose simplifying TTS generation by allowing users to specify high-level context alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages user-provided context to inform and influence TTS output, enabling iterative refinement with high-level feedback.  This approach was informed by two 8-subject formative studies: one examining content creators' experiences with TTS, and the other drawing on effective strategies from voice actors. Our evaluation shows that participants using SpeakEasy were more successful in generating performances matching their personal standards, without requiring significantly more effort than leading industry interfaces.\r\n",
    "title": "SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content Creation",
    "id": 189483,
    "sequence": 1273,
    "queryCoordinates": {
      "visualization": [
        11.186146795015487,
        8.418439278177681
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Current voice agents wait for a user to complete their verbal instruction before responding; yet, this is misaligned with how humans engage in everyday conversational interaction, where interlocutors use multimodal signaling (e.g. nodding, grunting, or looking at referred to objects) to ensure conversational grounding. \r\nWe designed an embodied VR agent that exhibits multimodal signaling behaviors in response to situated prompts, by turning its head, or by visually highlighting objects being discussed or referred to. \r\nWe explore how people prompt this agent to design and manipulate the objects in a VR scene.\r\nThrough a Wizard of Oz study, we found that participants interacting with an agent that indicated its understanding of spatial and action references were able to prevent errors 30% of the time, and were more satisfied and confident in the agent's abilities.\r\nThese findings underscore the importance of designing multimodal signalling communication techniques for future embodied agents.",
    "title": "Prompting an Embodied AI Agent: How Embodiment and Multimodal Signaling Affects Prompting Behaviour",
    "id": 189484,
    "sequence": 1274,
    "queryCoordinates": {
      "visualization": [
        7.990363649641379,
        -0.3925413946193441
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "AI is increasingly used to enhance images and videos, both intentionally and unintentionally. As AI editing tools become more integrated into smartphones, users can modify or animate photos into realistic videos. This study examines the impact of AI-altered visuals on false memories—recollections of events that didn’t occur or deviate from reality. In a pre-registered study, 200 participants were divided into four conditions of 50 each. Participants viewed original images, completed a filler task, then saw stimuli corresponding to their assigned condition: unedited images, AI-edited images, AI-generated videos, or AI-generated videos of AI-edited images. AI-edited visuals significantly increased false recollections, with AI-generated videos of AI-edited images having the strongest effect (2.05x compared to control). Confidence in false memories was also highest for this condition (1.19x compared to control). We discuss potential applications in HCI, such as therapeutic memory reframing, and challenges in ethical, legal, political, and societal domains.",
    "title": "Synthetic Human Memories: AI-Edited Images and Videos Can Implant False Memories and Distort Recollection",
    "id": 189485,
    "sequence": 1275,
    "queryCoordinates": {
      "visualization": [
        1.91341716182545,
        -4.619397662556433
      ]
    }
  },
  {
    "session": "Accessibility",
    "abstract": "The Deaf and Hard of Hearing (D/HH) community faces significant communication gaps, limiting their full participation in everyday settings such as education and healthcare. This study designed an Artificial Intelligence (AI)-driven bi-directional communication system and demonstrated its efficiency via two usability tests of D/HH individuals to narrow those gaps. The bi-directional communication system comprised two major components: Sign Language Recognition (SLR) and Sign Language Production (SLP). Usability tests were conducted to survey D/HH individuals' communication preferences on 1) bi-directional system versus one-way system (only provided SLP) versus zero-way system (typing back and forth); 2) cartoon avatars versus human-like avatars. Results collected from 66 D/HH individuals showed that: 1) AI-driven communication systems should provide bi-directional support; 2) AI-generated avatars should be human-like. This work offered valuable insights for future bi-directional communication system design and SLP development for D/HH community.",
    "title": "Evaluating an AI Bi-Directional System for Communication Between Deaf and Hard of Hearing Individuals and Hearing Persons: A Pilot Case Study",
    "id": 189486,
    "sequence": 1276,
    "queryCoordinates": {
      "visualization": [
        17.55371111771445,
        7.270985214936706
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "Autistic adults are among the groups most likely to experience financial hardship, yet little is known about their money management practices or their use of financial technologies. Incorporating the perspectives from the Neurodiversity Movement and Crip Technoscience, my research aims to uncover how financial technologies are meeting the needs and preferences of autistic people and identify factors that may exacerbate financial exclusion. In this process, I aim to learn from the autistic community. The goal of my research is to facilitate a participatory design process in which autistic adults share and develop alternative approaches to financial technology that centre on the diverse voices, experiences and expertise of autistic people.",
    "title": "Reinventing the Future of Financial Technologies with Autistic Adults",
    "id": 189487,
    "sequence": 1277,
    "queryCoordinates": {
      "visualization": [
        14.99485987463336,
        0.39265422461809724
      ]
    }
  },
  {
    "session": "Technology-Facilitated Family Interaction",
    "abstract": "Intergenerational co-creation using technology between grandparents and grandchildren can be challenging due to differences in technological familiarity. AI has emerged as a promising tool to support co-creative activities, offering flexibility and creative assistance, but its role in facilitating intergenerational connection remains underexplored. In this study, we conducted a user study with 29 grandparent-grandchild groups engaged in AI-supported story creation to examine how AI-assisted co-creation can foster meaningful intergenerational bonds. Our findings show that grandchildren managed the technical aspects, while grandparents contributed creative ideas and guided the storytelling. AI played a key role in structuring the activity, facilitating brainstorming, enhancing storytelling, and balancing the contributions of both generations. The process fostered mutual appreciation, with each generation recognizing the strengths of the other, leading to an engaging and cohesive co-creation process. We offer design implications for integrating AI into intergenerational co-creative activities, emphasizing how AI can enhance connection across skill levels and technological familiarity.",
    "title": "Bridging Generations using AI-Supported Co-Creative Activities",
    "id": 189488,
    "sequence": 1278,
    "queryCoordinates": {
      "visualization": [
        -3.5139448781596174,
        -18.672230487899828
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "In this paper, we introduce the concept of asocial technologies (e.g., online purchases), which digitize activities that traditionally would have been carried out in person (e.g., in-person shopping). We argue that using asocial technologies limits users' opportunities for face-to-face interactions, which can be particularly detrimental to older adults (65+) who are more prone to social isolation and loneliness. Analyzing longitudinal survey data from the U.S. National Health and Aging Trends Study (N = 1925), we identified the adverse effects of asocial technologies on older adults' well-being. Using a within-between-level analytical framework, we found that an increased use of asocial technologies in a given year is associated with higher levels of anxiety and depression, and lower levels of overall health experienced by older adults in the following year. This work highlights the negative consequences of asocial technology use, emphasizing the need for more systematic designs in digital innovations that target seniors.",
    "title": "Increased Use of Asocial Technologies Is Associated with Reduced Well-being Among Older Adults",
    "id": 189489,
    "sequence": 1279,
    "queryCoordinates": {
      "visualization": [
        4.765594435939468,
        6.425660251845159
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "This research explores whether the rapid digital transformation due to COVID-19 managed to close or exacerbate the digital divide concerning users’ digital skills. We conducted a pre-registered survey with N = 1,143 German Internet users. Our findings suggest the latter: younger, male, and higher educated users were more likely to improve their digital skills than older, female, and less educated ones. According to their accounts, the pandemic helped Internet users improve their skills in communicating with others by using video conference software and reflecting critically upon information they found online. These improved digital skills exacerbated not only positive (e.g., feeling informed and safe) but also negative (e.g., feeling lonely) effects of digital media use during the pandemic. We discuss this research's theoretical and practical implications regarding the impact of challenges, such as technological disruption and health crises, on humans’ digital skills, capabilities, and future potential, focusing on the second-level digital divide.",
    "title": "A Pandemic for the Good of Digital Literacy? An Empirical Investigation of Newly Improved Digital Skills during COVID-19 Lockdowns",
    "id": 189490,
    "sequence": 1280,
    "queryCoordinates": {
      "visualization": [
        -13.730993925645226,
        -2.731264508225797
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "Daytime urinary frequency syndrome (DUFS) is a prevalent pediatric voiding dysfunction. Managing DUFS involves sufficient water intake and monitoring voiding and defecation behaviors, which can be challenging for preschool-aged patients to perform throughout the day for prolonged periods. To address this problem, we created FluidTrack, a semi-automated tracking system enabling child and parents to collaboratively track child's fluid intake, voiding, and defecation, while encouraging adequate water consumption. To examine preschoolers’ engagement in behavior tracking with their parents, we conducted a 4-week deployment study with 14 DUFS patients (4--6 years) and their parents as part of DUFS management. The majority of patient participants enthusiastically engaged in semi-automated data capture, driven by their initial interest in FluidTrack. Sustaining the children’s enthusiasm and behind-the-scenes parental assistance were critical for continuing semi-automated tracking. Our findings demonstrated the feasibility of children’s semi-automated self-tracking in collaboration with their parents, and identified design suggestions for future work.",
    "title": "FluidTrack: Investigating Child-Parent Collaborative Tracking for Pediatric Voiding Dysfunction Management",
    "id": 189491,
    "sequence": 1281,
    "queryCoordinates": {
      "visualization": [
        -0.3926156722287893,
        -10.992991082226908
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "The rapid adoption of generative AI in software development has impacted the industry, yet its effects on developers with visual impairments remain largely unexplored. To address this gap, we used an Activity Theory framework to examine how developers with visual impairments interact with AI coding assistants. For this purpose, we conducted a study where developers who are visually impaired completed a series of programming tasks using a generative AI coding assistant. We uncovered that, while participants found the AI assistant beneficial and reported significant advantages, they also highlighted accessibility challenges. Specifically, the AI coding assistant often exacerbated existing accessibility barriers and introduced new challenges. For example, it overwhelmed users with an excessive number of suggestions, leading developers who are visually impaired to express a desire for \"AI timeouts.'' Additionally, the generative AI coding assistant made it more difficult for developers to switch contexts between the AI-generated content and their own code. Despite these challenges, participants were optimistic about the potential of AI coding assistants to transform the coding experience for developers with visual impairments. Our findings emphasize the need to apply activity-centered design principles to generative AI assistants, ensuring they better align with user behaviors and address specific accessibility needs. This approach can enable the assistants to provide more intuitive, inclusive, and effective experiences, while also contributing to the broader goal of enhancing accessibility in software development.",
    "title": "The Impact of Generative AI Coding Assistants on Developers Who Are Visually Impaired",
    "id": 189492,
    "sequence": 1282,
    "queryCoordinates": {
      "visualization": [
        -19.138806714644176,
        5.805693545089248
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "Amateurism (e.g., hobbyist and do-it-yourself making) has long helped human-computer interaction (HCI) scholars map alternatives to status quo technology developments, cultures, and practices. Following the 2023 Hollywood film worker strikes, many scholars, artists, and activists alike have called for alternative approaches to AI that reclaim the apparatus for co-creative and resistant means. Towards this end, we conduct an 11-week diary study with 20 amateur filmmakers of 15 AI-infused films, investigating the emerging space of generative cinema as a critical technical practice. Our close reading of the films and filmmakers’ reflections on their processes reveal four critical approaches to negotiating AI use in filmmaking: minimization, maximization, compartmentalization, and revitalization. We discuss how these approaches suggest the potential for underground filmmaking cultures to form around AI with critical amateurs reclaiming social control over the creative possibilities.",
    "title": "Underground AI? Critical Approaches to Generative Cinema through Amateur Filmmaking",
    "id": 189493,
    "sequence": 1283,
    "queryCoordinates": {
      "visualization": [
        -3.5276850573934198,
        1.8855869473039912
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "Soundscapes are widely used for relaxation, but their potential for personalized, navigable experiences remains under-explored. To address this, we developed Sonora, an AI tool that enables real-time generation of synthetic, spatialized soundscapes, allowing users to navigate immersive auditory environments and customize soundscapes using voice commands. Sonora's architecture integrates audio diffusion models and LLMs within Unity. A between-subjects study with 32 participants investigated its effects on anxiety and user experience, compared to a control condition involving passive listening to a soundscape. Participants who interacted with Sonora reported higher entertainment than the control group. A positive correlation was found between state anxiety and user requests for Sonora, suggesting anxious users engaged more. Participants with moderate to high trait anxiety experienced significant reductions in state anxiety across both conditions, with no significant difference in cognitive load. Our findings highlight Sonora's potential to promote relaxation, emphasizing the value of personalized experiences for mental health.",
    "title": "Sonora: Human-AI Co-Creation of 3D Audio Worlds and its Impact on Anxiety and Cognitive Load",
    "id": 189494,
    "sequence": 1284,
    "queryCoordinates": {
      "visualization": [
        18.323759142342713,
        -8.014976662062834
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "Understanding the motivations of volunteer developers is crucial for the HCI community as it seeks to design sustainable, community-driven digital platforms. This study explores the dynamics of motivation among volunteer developers in the Foodsharing.de platform, a grassroots movement focused on reducing food waste through community engagement. By investigating the evolving motivations and challenges faced by these developers, our research highlights the unique blend of personal passion, technical skill, and social commitment that sustains their long-term involvement. Through interviews, observations, and participatory research, we uncover how developers balance their commitment to Free and Open Source Software (FOSS) with the platform’s socio-ecological mission. Our findings emphasize the importance of fostering a supportive community, clear governance, and effective infrastructuring to manage motivation, frustration, and expectations. We discuss strategies to enhance volunteer retention, such as improving feedback mechanisms and recognizing contributions, which are critical for the sustainability of volunteer-driven platforms.",
    "title": "Blending Code and Cause: Understanding the Dynamic Motivations of Volunteer Developers in community-driven FOSS projects",
    "id": 189495,
    "sequence": 1285,
    "queryCoordinates": {
      "visualization": [
        -6.861828880002176,
        4.112821953545774
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "Stress is an inevitable part of day-to-day life yet many find themselves unable to manage it themselves, particularly when professional or peer support are not always readily available. As self-care becomes increasingly vital for mental well-being, this paper explores the potential of social simulation as a safe, virtual environment for practicing in-the-moment stress relief for everyday social situations. Leveraging the immersive capabilities of VR, AR, and LLMs to create realistic interactions and environments, we developed eight interactive prototypes for various stress related scenarios (e.g. public speaking, interpersonal conflict) across design dimensions of modality, interactivity, and mental health guidance in order to conduct prototype-driven semi-structured interviews with 19 participants. Our qualitative findings reveal that people currently lack effective means to support themselves through everyday stress and perceive social simulation -- even at low immersion and interaction levels -- to fill a gap for practical, controlled training of} mental health practices. We outline key design needs for developing social simulation for self-care needs, and identify important considerations including risks of trauma from hyper-realism, distrust of LLM-recommended timing for mental health recommendations, and the value of accessibility for self-care interventions.\r\n",
    "title": "Social Simulation for Everyday Self-Care: Design Insights from Leveraging VR, AR, and LLMs for Practicing Stress Relief",
    "id": 189496,
    "sequence": 1286,
    "queryCoordinates": {
      "visualization": [
        -16.88673440470715,
        1.9591327532558602
      ]
    }
  },
  {
    "session": "Lifetime Digital Health",
    "abstract": "Making activities have been shown to offer potential for inclusive access to digital literacy amongst marginalized groups, but research exploring such approaches with older adults is still scarce. Our study introduces an electronic-card-making workshop, co-developed with Japanese older women to foster engagement aligning with their purpose, physical and cognitive skills. The workshop was initially delivered to 14 women. Following initial success, 4 participants decided to deliver a second workshop, with the support of our team, for 15 local children. We present findings from both these workshops unpacking how women's motivation for engaging in eMaking revolved around the idea of sharing, both through displaying created artefacts and the transmission of knowledge, how their learning consolidated around implicit actions and was supported by the creation of escalation strategies when they felt that demands exceeded their level of proficiency. Based on our results, we propose guidelines for inclusive eMaking involving novice older women.",
    "title": "Sticking With Electronics for Crafting Practices: An Inclusive Approach to Promote Making Literacy Among Older Adults",
    "id": 189497,
    "sequence": 1287,
    "queryCoordinates": {
      "visualization": [
        -5.681580776970634,
        1.9286367918189704
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "Process-based learning is crucial for the transmission of intangible cultural heritage, especially in complex arts like Chinese calligraphy, where mastering techniques cannot be achieved by merely observing the final work. To explore the challenges faced in calligraphy heritage transmission, we conducted semi-structured interviews (N=8) as a formative study. Our findings indicate that the lack of calligraphy instructors and tools makes it difficult for students to master brush techniques, and teachers struggle to convey the intricate details and rhythm of brushwork. To address this, we collaborated with calligraphy instructors to develop an educational tool that integrates writing process capture and visualization, showcasing the writing rhythm, hand force, and brush posture. Through empirical studies conducted in multiple teaching workshops, we evaluated the system's effectiveness with teachers (N=4) and students (N=12). The results show that the tool significantly enhances teaching efficiency and aids learners in better understanding brush techniques.",
    "title": "CalliSence: An Interactive Educational Tool for Process-based learning in Chinese Calligraphy",
    "id": 189498,
    "sequence": 1288,
    "queryCoordinates": {
      "visualization": [
        -0.39229547863922437,
        4.9845866686656395
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "People often apply gender stereotypes to Artificial Intelligence (AI), and AI design frequently reinforces these stereotypes, perpetuating traditional gender ideologies in state-of-the-art technology. Despite growing interests in investigating this phenomenon, there is little conceptual clarity or consistency regarding what actually constitutes a \"gender stereotype\" in AI. Therefore, it is critical to provide a more comprehensive image of existing understandings and ongoing discussions of gender stereotypes of AI to guide AI design that reduces the harmful effects of these stereotypes. In doing so, this paper presents a scoping review of over 20 years of research across HCI, HRI and various social science disciplines on how gender stereotypes are applied to AI. We outline the methods and contexts of this growing body of work, develop a typology to clarify these stereotypes, highlight under-explored approaches for future research, and offer guidelines to improve rigor and consistency in this field that may inform responsible AI design in the future. ",
    "title": "A Scoping Review of Gender Stereotypes in Artificial Intelligence",
    "id": 189499,
    "sequence": 1289,
    "queryCoordinates": {
      "visualization": [
        7.983097498603995,
        4.155737519115305
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "Financial technology (fintech), including online banking and digital payments, can facilitate or hinder participation in financial activities. Current fintech support for older adults, notably delegation to close others, inadequately accommodates their cognitive strengths and life transitions. To envision fintech support for age-related cognitive diversity in a rapidly changing fintech landscape, we engaged 17 older adults, five family members, and five professionals in co-creating and critiquing personas, scenarios, and design concepts through interviews and group discussions. Our thematic analysis uncovers interrelated social factors and financial management collaborations across inner and outer circles, highlighting the importance of preparedness for transitions, long-term safeguarding, and short-term fail-safes. From these insights, we propose design avenues for layered fintech support networks across close and distant others, situated meta-design for mutual fintech support, and personalized fintech \"first aid.\" We urge HCI communities to collectively design holistic approaches to a fintech support ecosystem for aging and accessibility.",
    "title": "Envisioning Financial Technology Support for Older Adults Through Cognitive and Life Transitions",
    "id": 189500,
    "sequence": 1290,
    "queryCoordinates": {
      "visualization": [
        -9.081431738250814,
        4.18659737537428
      ]
    }
  },
  {
    "session": "Data Privacy and Ethics",
    "abstract": "Users’ perceptions of fitness tracking privacy is a subject of active study, but how do various aspects of social identity inform these perceptions? We conducted an online survey (N=322) that explores the influence of identity on fitness tracking privacy perceptions and practices, considering participants’ gender, race, age, and whether or not they identify as LGTBQ*. Participants reported how com- fortable they felt sharing fitness data, commented on whether they believed their identity impacted this comfort, and brainstormed several data sharing risks and a possible mitigation for each risk. For each surveyed dimension of social identity, we find one or more reliable effects on participants’ level of comfort sharing fitness data, specifically when considering institutional groups like employers, insurers, and advertisers. Further, 64% of participants indicate at least one of their identity characteristics informs their comfort. We also find evidence that the perceived risks of sharing fitness data vary by identity, but do not find evidence of difference in the strategies used to manage these risks. This work highlights a path towards reasoning about the privacy challenges of fitness tracking with respect for the lived experiences of all users.",
    "title": "\"I'm not as afraid as a woman might be about sharing my exact location:\" On the Intersection of Identity and Privacy Concerns in Fitness Tracking",
    "id": 189501,
    "sequence": 1291,
    "queryCoordinates": {
      "visualization": [
        -15.956647306859043,
        -1.17703301759468
      ]
    }
  },
  {
    "session": "Auditory UI",
    "abstract": "Speech-to-text capabilities on mobile devices have proven helpful for hearing and speech accessibility, language translation, note-taking, and meeting transcripts. However, our foundational large-scale survey (n=263) shows that the inability to distinguish and indicate speaker direction makes them challenging in group conversations. SpeechCompass addresses this limitation through real-time, multi-microphone speech localization, where the direction of speech allows visual separation and guidance (e.g., arrows) in the user interface. We introduce efficient real-time audio localization algorithms and custom sound perception hardware, running on a low-power microcontroller with four integrated microphones, which we characterize in technical evaluations. Informed by a large-scale survey (n=494), we conducted an in-person study of group conversations with eight frequent users of mobile speech-to-text, who provided feedback on five visualization styles. The value of diarization and visualizing localization was consistent across participants, with everyone agreeing on the value and potential of directional guidance for group conversations.",
    "title": "SpeechCompass: Enhancing Mobile Captioning with Diarization and Directional Guidance via Multi-Microphone Localization",
    "id": 189502,
    "sequence": 1292,
    "queryCoordinates": {
      "visualization": [
        -7.913412079718248,
        1.1738437956428944
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "This study proposes a time prediction model for locomotion along a polyline path with body angular movements in Virtual Reality (VR). We divide such locomotion into two components: navigating in multiple line-segment paths and turning at line-segment intersections. In the first component, locomotion in each line-segment path consists of acceleration, maximum velocity, and deceleration phases. We formulated equations to estimate the locomotion time for each phase and then accumulated them to model the total time. In the second component, a linear relationship was revealed between task time and turning angles. We established an integrated model based on the equations of the two components and verified the effectiveness of the model with three experiments. The results indicate that our model outperformed two baseline models with a greater R^2 and a smaller gap between the predicted and actual time. Our study benefits VR locomotion design with body angular movements. ",
    "title": "Modeling Locomotion with Body Angular Movements in Virtual Reality",
    "id": 189503,
    "sequence": 1293,
    "queryCoordinates": {
      "visualization": [
        6.336814207804409,
        -10.190426178318951
      ]
    }
  },
  {
    "session": "Physical and Tangible",
    "abstract": "This study investigates the challenges in adopting SAP's design system, SAP Fiori, across various teams within the organization. Despite its maturity, adoption has been limited due to knowledge gaps, slow system evolution, lack of flexibility, and inefficiencies. A case study involving 76 stakeholder interviews identified these barriers and proposed solutions, including improved documentation, modular technical infrastructure, and an inner source model for shared ownership of the design system. Lessons learned emphasize the value of empowering teams to take ownership, which improved motivation and collaboration. However, capacity and skill gaps, particularly in maintaining high-quality components, remain a challenge. Scaling the design system expertise and refining key roles, like design system experts, will be critical for sustaining adoption and fostering a stronger design community.",
    "title": "Improving Design System Adoption with Inner Source",
    "id": 189504,
    "sequence": 1294,
    "queryCoordinates": {
      "visualization": [
        -6.425746102545524,
        12.438238903704216
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "Assistive technologies (ATs) have the potential to empower blind and low vision (BLV) people. Yet, they often remain underutilised due to their immobility and limited applicability across scenarios. This paper presents LifeInsight, an AI-powered assistive wearable for BLV people that uses a wearable camera, microphone and single-click interface for goal-oriented visual querying. To inform the design of LifeInsight, we first collected a corpus of BLV people’s daily experiences using video probes and interviews. Ten BLV people recorded their daily experiences over one week using GoPro cameras, providing empirical insights. Based on these, we report on LifeInsight and its evaluation with 13 BLV people across six scenarios. LifeInsight effectively responded to visual queries, such as distinguishing between jars or identifying the status of a candle. Drawing on our work, we conclude with key lessons and practical recommendations to guide future research and advance the development and evaluation of AI-powered assistive wearables.\r\n",
    "title": "LifeInsight: Design and Evaluation of an AI-Powered Assistive Wearable for Blind and Low Vision People Across Multiple Everyday Life Scenarios",
    "id": 189505,
    "sequence": 1295,
    "queryCoordinates": {
      "visualization": [
        -2.5375731366545806,
        -3.092041813450949
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "While several digital tools exist for children’s creative storytelling, few have explored how generative AI can enhance storytelling quality. Our formative research identified five design requirements for AI-powered storytelling tools for elementary students. We developed a system named StoryPrompt that enables children to co-create stories and comics with AI, boosting literacy and creativity. Pilot tests with children and HCI experts demonstrated good usability and positive learning experiences. In a mixed-methods evaluation with 40 children from Grades 2-6, we found that StoryPrompt significantly improved storytelling creativity and richness, compared to the storyboard method. Observations indicated more purposeful planning and strategic use of AI-generated words and images, facilitating efficient exploration of storytelling alternatives. While children preferred AI images, they recognized the limitations in representing storytelling details. Teacher interviews highlighted the system’s motivational potential and classroom flexibility. We discuss the benefits and considerations of using generative AI to enhance creative storytelling for children.",
    "title": "From Words to Wonder: Designing and Evaluating an AI-Empowered Creative Storytelling System for Elementary Children",
    "id": 189506,
    "sequence": 1296,
    "queryCoordinates": {
      "visualization": [
        -3.8277613429288357,
        -1.1611387090178484
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "VeraCrypt is a freely available open-source encryption tool popular with tech-savvy users. In a 4-year effort to improve VeraCrypt’s usability to reach less tech-savvy users, we conducted 3 user studies (N=77) and found that participants struggled to successfully encrypt their devices with VeraCrypt. We iteratively redesigned the UI and instructions and suggested significant usability improvements to the  VeraCrypt community. Since 7 professional developers struggled to compile the project, we created a step-by-step compilation guide and contributed 5 pull requests for bug fixes and interface improvements. However, our efforts to translate academic findings into practical applications were unsuccessful. In this work, we explore why our usability improvements failed. Due to code complexity and a lack of transparency, the OS community was concerned our changes could undermine security. Based on our findings, we provide recommendations for researchers collaborating with open-source communities.",
    "title": "Bridging the Gap Between Usable Security Research and Open-Source Practice — Lessons From a Long-Term Engagement With VeraCrypt",
    "id": 189507,
    "sequence": 1297,
    "queryCoordinates": {
      "visualization": [
        -1.1762056839547361,
        -11.942216720066362
      ]
    }
  },
  {
    "session": "Technologies for Elderly",
    "abstract": "Much research on older people with memory concerns is focused on tracking and informed by the priorities of others. In this paper, we seek to understand the potential that people with memory concerns see in tracking.  We conducted interviews with 29 participants with concerns about their memory and engaged in an affective writing approach. We find a range of potentials that can be traced to how participants are already self-tracking. Emotions associated with these potentials vary: from acceptance to resistance, and positive anticipation to aversion. Participants are emotionally motivated to foreclose possibilities in some instances and keep them open in others. While individual and unique, potential is structured by forces that include individual routines, relationships with others, and macro-level institutions and cultural contexts.  We reflect on these findings in the context of research on self-tracking with older adults, designing with ambiguity, and forces that structure the experience of living with memory concerns.",
    "title": "Tracking and its Potential for Older Adults with Memory Concerns",
    "id": 189508,
    "sequence": 1298,
    "queryCoordinates": {
      "visualization": [
        3.46117057077493,
        -9.381913359224841
      ]
    }
  },
  {
    "session": "DeIving into LLMs",
    "abstract": "As large language models (LLMs) advance, their potential applications have grown significantly. However, it remains difficult to evaluate LLM behavior on user-defined tasks and craft effective pipelines to do so. Many users struggle with where to start, often referred to as the \"blank page problem.\" ChainBuddy, an AI workflow generation assistant built into the ChainForge platform, aims to tackle this issue. From a single prompt or chat, ChainBuddy generates a starter evaluative LLM pipeline in ChainForge aligned to the user's requirements. ChainBuddy offers a straightforward and user-friendly way to plan and evaluate LLM behavior and make the process less daunting and more accessible across a wide range of possible tasks and use cases. We report a within-subjects user study comparing ChainBuddy to the baseline interface. We find that when using AI assistance, participants reported a less demanding workload, felt more confident, and produced higher quality pipelines evaluating LLM behavior. However, we also uncover a mismatch between subjective and objective ratings of performance: participants rated their successfulness similarly across conditions, while independent experts rated participant workflows significantly higher with AI assistance. Drawing connections to the Dunning–Kruger effect, we discuss implications for the future design of workflow generation assistants regarding the risk of over-reliance.",
    "title": "ChainBuddy: An AI-assisted Agent System for Generating LLM Pipelines",
    "id": 189509,
    "sequence": 1299,
    "queryCoordinates": {
      "visualization": [
        -3.3334213981176175,
        -4.9888176738152685
      ]
    }
  },
  {
    "session": "Sensing and Haptics",
    "abstract": "We introduce SqueezeMe, a soft and flexible inductive pressure sensor with high sensitivity made from ferromagnetic elastomers for wearable and embedded applications. Constructed with silicone polymers and ferromagnetic particles, this biocompatible sensor responds to pressure and deformation by varying inductance through ferromagnetic particle density changes, enabling precise measurements. We detail the fabrication process and demonstrate how silicones with varying Shore hardness and different ferromagnetic fillers affect the sensor's sensitivity. Applications like weight, air pressure, and pulse measurements showcase the sensor’s versatility for integration into soft robotics and flexible electronics.",
    "title": "SqueezeMe: Creating Soft Inductive Pressure Sensors with Ferromagnetic Elastomers",
    "id": 189510,
    "sequence": 1300,
    "queryCoordinates": {
      "visualization": [
        14.516002876814678,
        -10.643573670544495
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "Unlike other inputs for extended reality (XR) that work out of the box, eye tracking typically requires custom calibration per user or session. We present a multimodal inputs approach for implicit calibration of eye tracker in VR, leveraging UI interaction for continuous, background calibration. Our method analyzes gaze data alongside controller interaction with UI elements, and employing ML techniques it continuously refines the calibration matrix without interrupting users from their current tasks. Potentially eliminating the need for explicit calibration. We demonstrate the accuracy and effectiveness of this implicit approach across various tasks and real time applications achieving comparable eye tracking accuracy to native, explicit calibration. While our evaluation focuses on VR and controller-based interactions, we anticipate the broader applicability of this approach to various XR devices and input modalities.",
    "title": "Online-EYE: Multimodal Implicit Eye Tracking Calibration for XR",
    "id": 189511,
    "sequence": 1301,
    "queryCoordinates": {
      "visualization": [
        17.995716487438365,
        0.39266793062210015
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "Responsible AI (RAI) practices are increasingly important for practitioners in anticipating and addressing potential harms of AI, and emerging research suggests that AI practitioners often learn about RAI on-the-job. More generally, learning at work is social; thus, this work explores the interpersonal aspects of learning about RAI on-the-job. Through workshops with 21 industry-based RAI educators, we offer the first empirical investigation into interpersonal processes and dimensions of learning about RAI at work. This study finds key phases of RAI are sites for ongoing interpersonal learning, such as critical reflection about potential RAI impacts and collective sense-making about operationalizing RAI principles. We uncover a significant gap between these interpersonal learning processes and current approaches to learning about RAI. Finally, we identify barriers and supports for interpersonal learning about RAI. We close by discussing opportunities to better enable interpersonal learning about RAI on-the-job and the broader implications of interpersonal learning for RAI.",
    "title": "\"The Conduit by which Change Happens\": Processes, Barriers, and Support for Interpersonal Learning about Responsible AI",
    "id": 189512,
    "sequence": 1302,
    "queryCoordinates": {
      "visualization": [
        17.238242730449638,
        -7.990180696711449
      ]
    }
  },
  {
    "session": "WS16: Bridging HCI and Industrial Manufacturing",
    "abstract": "This workshop explores the integration of Human-Computer Interaction (HCI) principles within the manufacturing sector, examining the challenges and opportunities that arise in academia-industry collaborations. The workshop aims to foster dialogue on how HCI methods can enhance manufacturing practices, while addressing the specific hurdles these partnerships face. We will discuss areas of HCI research including: collaborative robots, industrial augmented reality, advances in digital fabrication, and systems for workplace communication as they apply to existing problems in industrial settings. The key goals include generating actionable insights for both academic and industrial participants, fostering practical, cross-disciplinary collaborations that will drive innovation in user-centered industrial systems.\r\nHosting this workshop at CHI 2025 in Japan offers a unique opportunity to engage with Japan’s world-class manufacturing sector, renowned for its precision and innovation, making it an ideal setting to bridge HCI research and industrial practices.",
    "title": "Bridging HCI and Industrial Manufacturing",
    "id": 189513,
    "sequence": 1303,
    "queryCoordinates": {
      "visualization": [
        -16.170760940024515,
        -13.398003232593185
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "The proliferation of “Internet of Things (IoT)” provides older adults with critical support for “health monitoring” and independent living, yet significant concerns about security and privacy persist. In this paper, we report on these issues through a two-phase user study, including a survey (N = 22) and semi-structured interviews (n = 9) with adults aged 65+. We found that while 81.82% of our participants are aware of security features like “two-factor authentication (2FA)” and encryption, 63.64% express serious concerns about unauthorized access to sensitive health data. Only 13.64% feel confident in existing protections, citing confusion over “data sharing policies” and frustration with “complex security settings” which lead to distrust and anxiety. To cope, our participants adopt various strategies, such as relying on family or professional support and limiting feature usage leading to disengagement. Thus, we recommend “adaptive security mechanisms,” simplified interfaces, and real-time transparency notifications to foster trust and ensure “privacy and security by design” in IoT health systems for older adults.",
    "title": "“Watch My Health, Not My Data”: Understanding Perceptions, Barriers, Emotional Impact, & Coping Strategies Pertaining to IoT Privacy and Security in Health Monitoring for Older Adults",
    "id": 189514,
    "sequence": 1304,
    "queryCoordinates": {
      "visualization": [
        -5.054953583588433,
        20.38252791652121
      ]
    }
  },
  {
    "session": "Sustainable Individual, Society, and Environment",
    "abstract": "The increasing accessibility of large machine learning (ML) models has resulted in their widespread adoption in everyday products, with a correspondingly negative environmental impact. Selecting more suitable ML models could not only improve training time and achievable accuracy, but also long-term sustainability. However, ML developers' model selection process remains underexplored, especially with respect to sustainability trade-offs. Our interviews with 13 ML developers showed that participants select models mainly based on familiarity, accuracy and interpretability, but often overlook sustainability. They critically reflected on the current trends of large models and the lack of available information regarding model sustainability. We present implications for the ML and HCI communities, emphasizing the importance of critical reflection on model selection in education and practice. Based on our insights, we provide initial recommendations for promoting model sustainability evaluation and how the HCI community can assist in making sustainable model alternatives more accessible.",
    "title": "\"Should I choose a smaller model?'': Understanding ML Model Selection and Its Impact on Sustainability",
    "id": 189515,
    "sequence": 1305,
    "queryCoordinates": {
      "visualization": [
        -0.392574486288023,
        8.99143399423672
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "Tools to inspect runtime state, like print statements and debuggers, are an essential part of programming. Yet, a major limitation is that they present data at a fixed, low level of abstraction which can overload the user with irrelevant details. In contrast, human drawings of data structures use many illustrative visual abstractions to show the most useful information. We attempt to bridge the gap by surveying 80 programmer-produced diagrams to develop a mechanical approach for capturing visual abstraction, termed abstraction moves. An abstraction move selects data objects of interest, and then revisualizes, simplifies, or annotates them. We implement these moves as a diagramming language for JavaScript code, named Chisel, and show that it can effectively reproduce 78 out of the 80 surveyed diagrams. In a preliminary study with four CS educators, we evaluate its usage and discover potential contexts of use. Our approach of mechanically moving between levels of abstraction in data displays opens the doors to new tools and workflows in programming education and software development.",
    "title": "The Shapes of Abstraction in Data Structure Diagrams",
    "id": 189516,
    "sequence": 1306,
    "queryCoordinates": {
      "visualization": [
        16.143709347588388,
        7.961196423942024
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Modern augmented reality (AR) devices with advanced display and sensing capabilities pose significant privacy risks to users and bystanders. While previous context-aware adaptations focused on usability and ergonomics, we explore the design space of privacy-driven adaptations that allow users to meet their dynamic needs. These techniques offer granular control over AR sensing capabilities across various AR input, output, and interaction modalities, aiming to minimize degradations to the user experience. Through an elicitation study with 10 AR researchers, we derive 62 privacy-focused adaptation techniques that preserve key AR functionalities and classify them into system-driven, user-driven, and mixed-initiative approaches to create an adaptation catalog. We also contribute a visualization tool that helps AR developers navigate the design space, validating its effectiveness in design workshops with six AR developers. Our findings indicate that the tool allowed developers to discover new techniques, evaluate tradeoffs, and make informed decisions that balance usability and privacy concerns in AR design.",
    "title": "Exploring the Design Space of Privacy-Driven Adaptation Techniques for Future Augmented Reality Interfaces",
    "id": 189517,
    "sequence": 1307,
    "queryCoordinates": {
      "visualization": [
        -7.990180696711444,
        17.238242730449638
      ]
    }
  },
  {
    "session": "WS02: Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "abstract": "Human bodies are deeply political as they carry historical and social meanings, including race, gender, sexuality, ethnicity, class, and abilities. The expanding body-centric research in HCI can be traced in the plurality of methods, theories and domains that take bodies as a central point of departure, when designing or studying interaction with technologies. This one-day workshop will bring together researchers and practitioners within the CHI community to discuss, map, and unpack emerging tensions and challenges on the topic of body politics for HCI. Interested participants are invited to submit examples from their own research, which, in the workshop, will be used as a point of departure to critically reflect on and expand body-centric methods, theories and domains through the lens of body politics. Workshop outcomes will include charting future directions for body-centric research to address challenges and opportunities of acknowledging that bodies are always political in design research.",
    "title": "Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "id": 189518,
    "sequence": 1308,
    "queryCoordinates": {
      "visualization": [
        -1.1771545092012614,
        -16.959195360083186
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "Perceiving and altering the sensation of internal physiological states, such as heartbeats, is key for biofeedback and interception. Yet, wearable devices used for this purpose can feel intrusive and typically fail to deliver stimuli aligned with the heart’s location in the chest.  To address this, we introduce Heartbeat Resonance, which uses low-frequency sound waves to create non-contact haptic sensations in the chest cavity, mimicking heartbeats. We conduct two experiments to evaluate the system's effectiveness. The first experiment shows that the system created realistic heartbeat sensations in the chest, with 78.05 Hz being the most effective frequency. In the second experiment, we evaluate the effects of entrainment by simulating faster and slower heart rates. Participants perceived the intended changes and reported high confidence in their perceptions for +15% and -30% heart rates. This system offers a non-intrusive solution for biofeedback while creating new possibilities for immersive VR environments.",
    "title": "Heartbeat Resonance: Inducing Non-contact Heartbeat Sensations in the Chest",
    "id": 189519,
    "sequence": 1309,
    "queryCoordinates": {
      "visualization": [
        -3.42044074744226,
        -7.231914344987545
      ]
    }
  },
  {
    "session": "Stereotypes and Gender",
    "abstract": "Voice interfaces come in many forms in Human-Computer Interaction (HCI), such as voice assistants and robots. These are often gendered, i.e. they sound masculine or feminine. Recently, there has been a surge in creating gender-ambiguous voices, aiming to make voice interfaces more inclusive and less prone to stereotyping. In this paper, we present the first systematic review of research on gender-ambiguous voices in HCI literature, with an in-depth analysis of 36 articles. We report on the definition and availability of gender-ambiguous voices, creation methods, user perception and evaluation techniques. We conclude with several concrete action points: clarifying key terminology and definitions for terms such as gender-ambiguous, gender-neutral, and non-binary; conducting an initial acoustic analysis of gender-ambiguous voices; taking initial steps toward standardising evaluation metrics for these voices; establishing an open-source repository of gender-ambiguous voices; and developing a framework for their creation and use. These recommendations provide important insights for fostering the development and adoption of inclusive voice technologies.",
    "title": "Breaking the Binary: A Systematic Review of Gender-Ambiguous Voices in Human-Computer Interaction",
    "id": 189520,
    "sequence": 1310,
    "queryCoordinates": {
      "visualization": [
        -9.463754491798854,
        18.74666239411584
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "As virtual reality (VR) continues to evolve as a platform for gathering and collaboration, new forms of communication using voice and avatars are being actively studied. However, the objective and dynamic assessment of social experiences in VR remains a significant challenge, while obtrusive self-report methods prevail. This study aims to identify verbal and nonverbal behavioral indices of perceived social experience in the context of virtual conversations. In our experiment, 52 participants engaged in a ten-minute dyadic conversation in VR and rated the level of social experiences, while turn-taking patterns and behavioral (gaze, pose) data were recorded. The results indicated that rapid response time, longer speech duration, longer gaze duration during turn-taking gaps, and higher nodding frequency during turns predicted the dynamic changes in users’ social experience. By providing objective and unobtrusive measures of social interactions, this study contributes to enhancing the understanding and improvement of social VR experiences.",
    "title": "Quantifying Social Connection With Verbal and Non-Verbal Behaviors in Virtual Reality Conversations",
    "id": 189521,
    "sequence": 1311,
    "queryCoordinates": {
      "visualization": [
        17.99496568104443,
        8.728184813466841
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "We introduce a novel method for fabricating functional flat-to-shape objects using a large computer-controlled sewing machine (11 ft / 3.4m wide), a process that is both rapid and scalable beyond the machine's sewable area. Flat-to-shape deployable objects can allow for quick and easy need-based activation, but the selective flexibility required can involve complex fabrication or tedious assembly. In our method, we sandwich rigid form-defining materials, such as plywood and acrylic, between layers of fabric. The sewing process secures these layers together, creating soft hinges between the rigid inserts which allow the object to transition smoothly into its three-dimensional functional form with little post-processing. ",
    "title": "Creating Furniture-Scale Deployable Objects with a Computer-Controlled Sewing Machine",
    "id": 189522,
    "sequence": 1312,
    "queryCoordinates": {
      "visualization": [
        7.231914344987545,
        -3.4204407474422602
      ]
    }
  },
  {
    "session": "Earable and Hearable",
    "abstract": "Wireless earbuds are an appealing platform for wearable computing on-the-go. However, their small size and out-of-view location mean they support limited different inputs. We propose finger identification input on earbuds as a novel technique to resolve these problems. This technique involves associating touches by different fingers with different responses. To enable it on earbuds, we adapted prior work on smartwatches to develop a wireless earbud featuring a magnetometer that detects fields from a magnetic ring. A first study reveals participants achieve rapid, precise earbud touches with different fingers, even while mobile (time: 0.98s, errors: 5.6%). Furthermore, touching fingers can be accurately classified (96.9%). A second study shows strong performance with a more expressive technique involving multi-finger double-taps (inter-touch time: 0.39s, errors: 2.8%) while maintaining high accuracy (94.7%). We close by exploring and evaluating the design of earbud finger identification applications and demonstrating the feasibility of our system on low-resource devices.",
    "title": "BudsID: Mobile-Ready and Expressive Finger Identification Input for Earbuds",
    "id": 189523,
    "sequence": 1313,
    "queryCoordinates": {
      "visualization": [
        5.98715353943162,
        -0.39241877538085834
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. In this paper, we propose to control the LLM via touch gestures performed directly on the text. We first chart a design space that covers fundamental touch input and text transformations. In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.",
    "title": "Exploring Mobile Touch Interaction with Large Language Models",
    "id": 189524,
    "sequence": 1314,
    "queryCoordinates": {
      "visualization": [
        -2.7382209514185085,
        -17.790507188419692
      ]
    }
  },
  {
    "session": "Trust and Responsibility in AI",
    "abstract": "Advances in artificial intelligence (AI) hold transformative potential for humanitarian practice. Yet aligning this potential with the demands of humanitarian practice in dynamic and often resource-austere contexts remains a challenge. While research on Responsible AI provides high-level guidance, humanitarian practice demands nuanced approaches for which human-computer interaction (HCI) can provide a strong foundation. However, existing literature lacks a comprehensive examination of how HCI principles can inform responsible AI adoption in humanitarian practice. To address this gap, we conducted a reflexive thematic analysis of 34 interviews with AI technology experts, humanitarian practitioners, and humanitarian policy developers. Our contributions are twofold. First, we empirically identify three cross-cutting themes—AI risks in humanitarian practice, organisational readiness, and collaboration—that highlight common tensions in adopting AI for humanitarian practice. Second, by analysing their interconnectivities, we reveal intertwined obstacles and propose a conceptual HCI-informed framework. ",
    "title": "Bridging AI and Humanitarianism: An HCI-Informed Framework for Responsible AI Adoption",
    "id": 189525,
    "sequence": 1315,
    "queryCoordinates": {
      "visualization": [
        21.828486595069407,
        2.7417463356180902
      ]
    }
  },
  {
    "session": "Accessibility 2",
    "abstract": "Existing commercial and in-house software development tools are often inaccessible to blind and low vision software professionals (BLVSPs), hindering their participation and career growth at work. Building on existing research on Do-It-Yourself (DIY) assistive technologies and customized tools made by programmers, we shed light on the currently unexplored intersection of how DIY tools built and used by BLVSPs support accessible software development. Through semi-structured interviews with 30 BLVSPs, we found that such tools serve many different purposes and are driven by motivations such as desiring to maintain a professional image and a sense of dignity at work. These tools had significant impacts on workplace accessibility and revealed a need for a more centralized community for sharing tools, tips, and tricks. Based on our findings, we introduce the \"Double Hacker Dilemma\" and highlight a need for developing more effective peer and organizational platforms that support DIY tool sharing.",
    "title": "The Dilemma of Building Do-It-Yourself (DIY) Solutions For Workplace Accessibility",
    "id": 189526,
    "sequence": 1316,
    "queryCoordinates": {
      "visualization": [
        -17.638425286967102,
        -9.427934736519953
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "In response to ongoing environmental crises, the digital fabrication community within HCI has recently begun to design with biomaterials. Biomaterials and their corresponding practices carry eco-socio-technical relations that shape the creation of more sustainable futures. From this perspective, we present three entangled contributions: (1) a new, easy-to-make, 3D printable eggshell biomaterial, (2) a circular, material-centered practice for designing with the eggshell biomaterial, and (3) a reflection on the eco-socio-technical relations that the eggshell biomaterial and corresponding biomaterial practice reveal. We outline our design process for sourcing ingredients, developing a recipe, 3D printing artifacts, characterizing properties, and testing disposal methods. Through five provocative applications, we critically reflect on how our eggshell biomaterial practice surfaces unique eco-socio-technical relations. We envision this eggshell biomaterial extending the current material library for 3D printing and promoting circular digital fabrication practices, while also highlighting the importance of ecological awareness and community engagement in designing for sustainability.",
    "title": "3D Printing Eggshells: Exploring Eco-Socio-Technical Relations through Biomaterial Design",
    "id": 189527,
    "sequence": 1317,
    "queryCoordinates": {
      "visualization": [
        16.40802887051027,
        -11.435759204552248
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "Deepfake—manipulating individuals' facial features and voices with AI—has introduced new challenges to online scams, with older adults being particularly vulnerable. However, existing safeguarding efforts often portray them as passive recipients, overlooking their perspectives on understanding deepfake-enabled scams and their expectations for protective interventions. To address this gap, we conducted a participatory design workshop with 10 older adults, where participants analyzed simulated deepfake scam videos and critiqued provocative safeguarding designs. Their insights revealed key factors contributing to their vulnerability and how they perceive protective measures. The findings underscored the importance of respecting older adults' autonomy and their role in decision-making, as well as the crucial role of enhanced digital literacy in self-protection. Moreover, while tailored safeguarding measures are essential, a broader societal approach focusing on shared responsibility is also needed. These design implications, viewed through the lens of older adults, contribute to more tailored safeguarding against Deepfake scams.",
    "title": "Hear Us, then Protect Us: Navigating Deepfake Scams and Safeguard Interventions with Older Adults through Participatory Design",
    "id": 189528,
    "sequence": 1318,
    "queryCoordinates": {
      "visualization": [
        -10.158096629210041,
        18.379691860083824
      ]
    }
  },
  {
    "session": "Meeting and Collaboration",
    "abstract": "Remote meetings using 3D avatars in Augmented Reality (AR) allow effective communication and enable users to retain awareness of their surroundings.\r\nHowever, positioning 3D avatars effectively and consistently for all users in AR is challenging since most spaces, such as offices or living rooms, are not large enough to accommodate multiple life-sized avatars without interference.\r\nTo address this issue, we contribute MiniMates---a novel approach leveraging miniature avatars, which make it possible to place multiple remote users in a limited physical space.\r\nWe see MiniMates as complementary to traditional 2D video conferencing and immersive telepresence.\r\nOur approach automatically adjusts the formation of avatars and redirects users' head and body orientation to facilitate communication.\r\nResults from our user study (n = 24) show that participants experience a higher sense of co-presence compared to video conferencing, and that MiniMates enabled them to communicate the direction of their interactions non-verbally as well as manage multiple simultaneous conversations.\r\n",
    "title": "MiniMates: Miniature Avatars for AR Remote Meetings within Limited Physical Spaces",
    "id": 189529,
    "sequence": 1319,
    "queryCoordinates": {
      "visualization": [
        -1.9591327532558538,
        -16.88673440470715
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "This paper examines the levels of exclusion encountered by disabled and older users of consumer-level VR and AR technology and identifies methods formed by people with diverse access needs to circumvent encountered barriers to use. First, we estimate exclusion rates for a selection of nine immersive experiences of VR and AR, computed using population statistics data for the United Kingdom (UK). We then present an empirical lab-based study evaluating the usability of the same VR and AR experiences. The study involved 60 UK-based participants with varying access needs and the study results were used to calculate the empirical exclusion rates. Both the estimated and empirical exclusion rates display high levels of exclusion, which for the more complex experiences in the study reached 100%. However, multiple participants overcame usability barriers and completed experiences through provided assistance and self-initiated adaptations, suggesting that future VR and AR can become more inclusive if designed to counter these barriers.",
    "title": "Exclusion Rates among Disabled and Older Users of Virtual and Augmented Reality",
    "id": 189530,
    "sequence": 1320,
    "queryCoordinates": {
      "visualization": [
        5.927609002839674,
        5.372471638776147
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "Electrical Muscle Stimulation (EMS) induces muscle movement through external currents, offering a novel approach to motor learning. Researchers investigated using EMS as an alternative to conventional non-movement-inducing feedback techniques, such as vibrotactile and electrotactile feedback. While EMS shows promise in areas such as dance, sports, and motor skill acquisition, neurophysiological models of motor learning conflict about the impact of externally induced movements on sensorimotor representations. This study evaluated EMS against electrotactile feedback and a control condition in a two-session experiment assessing fast learning, consolidation, and learning transfer. Our results suggest an overall positive impact of EMS in motor learning. Although traditional electrotactile feedback had a higher learning rate, EMS increased the learning plateau, as measured by a three-factor exponential decay model. This study provides empirical evidence supporting EMS as a plausible method for motor augmentation and skill transfer, contributing to understanding its role in motor learning.",
    "title": "Understanding the Influence of Electrical Muscle Stimulation on Motor Learning: Enhancing Motor Learning or Disrupting Natural Progression?",
    "id": 189531,
    "sequence": 1321,
    "queryCoordinates": {
      "visualization": [
        10.000264194352834,
        -14.966453021445819
      ]
    }
  },
  {
    "session": "Tech and AI Literacy",
    "abstract": "As Artificial Intelligence (AI) continues to influence various aspects of society, the need for AI literacy education for K-12 students has grown. An increasing number of AI literacy studies aim to enhance students' competencies in understanding, using, and critically evaluating AI systems. However, despite the vulnerabilities faced by students from underserved communities—due to factors such as socioeconomic status, gender, and race—these students remain underrepresented in existing research. To address this gap, this study focuses on leveraging the cultural capital that students acquire from their communities’ unique history and culture for AI literacy education. Education researchers have demonstrated that identifying and mobilizing cultural capital is an effective strategy for educating these populations. Through collaboration with 26 students from underserved communities—including those who are socioeconomically disadvantaged, female, or people of color—this paper identifies three types of cultural capital relevant to AI literacy education: 1) resistant capital, 2) communal capital, and 3) creative capital. The study also emphasizes that collaborative relationships between researchers and students are crucial for mobilizing cultural capital in AI literacy education research.",
    "title": "AI Literacy for Underserved Students: Leveraging Cultural Capital from Underserved Communities for AI Education Research",
    "id": 189532,
    "sequence": 1322,
    "queryCoordinates": {
      "visualization": [
        3.4834161270535446,
        -11.483284028786507
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "Co-viewing, traditionally defined as watching content together in the same physical space, enhances emotional connections through shared experiences. With the rise of remote viewing during the COVID-19 pandemic, existing solutions, such as second-screen platforms and rule-based AI companions, struggle to facilitate meaningful social interactions. This study explores the potential of Large Language Models, which offer human-like interactions and personalization. Our formative study with ten participants revealed the importance of managing arousal levels, highlighting the need to balance between high- and low-arousal levels across different viewing contexts. Based on these insights, we developed `BleacherBot', a sports co-viewing agent with distinct interaction styles that vary in arousal levels. Our main study with 27 participants demonstrated that matching users' preferred arousal levels with the agent's interaction style significantly enhanced their engagement and overall enjoyment. We propose design guidelines for AI co-viewing agents that consider their role as complements to human social interactions.",
    "title": "BleacherBot: AI Agent as a Sports Co-Viewing Partner",
    "id": 189533,
    "sequence": 1323,
    "queryCoordinates": {
      "visualization": [
        -1.9438414392261092,
        7.760250025556353
      ]
    }
  },
  {
    "session": "Learning, Creating, and Understanding Art",
    "abstract": "Sand painting is a highly aesthetic and valuable form of art but often constrained by the need for specific equipment and the associated learning curve. To address these challenges, we developed a VR sand painting system, SandTouch, offering an immersive and intuitive sand painting experience that closely mirrors the interaction with physical sand. Leveraging advanced gesture recognition technology, SandTouch allows users to create intricate sand art in a virtual environment, capturing the fine sensations of real sand manipulation along with realistic sound feedback. The integration of AI agent further enhances the experience by intelligently interpreting users' creative intentions based on real-time interactions, offering contextually relevant artistic suggestions. Comprehensive evaluations have demonstrated a significant increase in user engagement and immersion. Furthermore, the realistic sound feedback enhances emotional relief and deepens the painting experience.",
    "title": "SandTouch: Empowering Virtual Sand Art in VR with AI Guidance and Emotional Relief",
    "id": 189534,
    "sequence": 1324,
    "queryCoordinates": {
      "visualization": [
        -4.26023017055884,
        14.382296023022896
      ]
    }
  },
  {
    "session": "Digital Storytelling",
    "abstract": "Generative AI significantly enhances player agency in interactive narratives (IN) by enabling just-in-time content generation that adapts to player actions. While delegating generation to AI makes IN more interactive, it becomes challenging for authors to control the space of possible narratives - within which the final story experienced by the player emerges from their interaction with AI. In this paper, we present WhatELSE, an AI-bridged IN authoring system that creates narrative possibility spaces from example stories. WhatELSE provides three views (narrative pivot, outline, and variants) to help authors understand the narrative space and corresponding tools leveraging linguistic abstraction to control the boundaries of the narrative space. Taking innovative LLM-based narrative planning approaches, WhatELSE further unfolds the narrative space into executable game events. Through a user study (N=12) and technical evaluations, we found that WhatELSE enables authors to perceive and edit the narrative space and generates engaging interactive narratives at play-time.\r\n",
    "title": "WhatELSE: Shaping Narrative Spaces at Configurable Level of Abstraction for AI-bridged Interactive Storytelling",
    "id": 189535,
    "sequence": 1325,
    "queryCoordinates": {
      "visualization": [
        21.996495261950074,
        -0.39267822833461336
      ]
    }
  },
  {
    "session": "Design Thinking",
    "abstract": "This paper reports on inquiry into the design decisions that shape how quality of life issues are reported and government service requests managed in a large and densely populated city in the northeastern US. In particular, we reflect on research data collected over 5 years investigating chronic noise disturbance. Our findings highlight the effects of design choices associated with centralized, single-issue reporting and formal, standardized measures. We discuss how these design choices have broader impacts with regard to trust and transparency relations, and provide alternative inspirations for infrastructuring ongoing design in use by drawing on a model of contributory technology that offers new insight into social computing and creative participation at scale. This research contributes to HCI understanding of design for service interactions that is applicable to digital civics researchers, and can be translated to other contexts.",
    "title": "Design for Civic Quality of Life Things",
    "id": 189536,
    "sequence": 1326,
    "queryCoordinates": {
      "visualization": [
        -6.336814207804423,
        -10.190426178318942
      ]
    }
  },
  {
    "session": "Embodied Stimulation",
    "abstract": "Muscle synergy analysis provides a method for quantifying differences in muscle use between expert and novice athletes. However, the practical applications of muscle synergy analysis with feedback remain underexplored. In this paper, we present a golf putting training system that utilizes electrical muscle stimulation (EMS) feedback guided by muscle synergy analysis. Considering the individual differences, we use optimal transport to compute the muscle synergy similarity between users and experts. This approach allows users to model their muscle usage after the expert whose synergy is closest. Based on the muscle synergy differences between the expert and the user, EMS is applied to the muscles that need activation. As a result, users can practice putting with increased awareness of the muscles targeted by EMS, resulting in changes in muscle synergy and improved performance. User studies with 44 novices demonstrated that the proposed system significantly improved putting accuracy.",
    "title": "Improving Putting Accuracy with Electrical Muscle Stimulation Feedback Guided by Muscle Synergy Analysis",
    "id": 189537,
    "sequence": 1327,
    "queryCoordinates": {
      "visualization": [
        5.478852861078485,
        -7.140180062621116
      ]
    }
  },
  {
    "session": "Playing with Data",
    "abstract": "Sketching is one of the oldest techniques humans use to express themselves. \r\nWe sketch to visualize concepts, externalize memory, and communicate ideas. \r\nHowever, we barely use sketching to interact with computers. \r\nGiven how naturally sketching comes to humans, we believe untapped potential exists in being able to simply draw commands onto a user interface. \r\nIn this paper, we present results of an elicitation study about expressing common operations in spreadsheets through sketching. \r\nSpreadsheets are an interesting class of applications because they are widely used, support complex data and operations, and are available on touch-enabled devices. \r\nOur results show that despite considerable variation in syntactic details, participants gravitate towards recurring patterns (\\eg\\ enclosures and arrows, examples and cross-references, and temporal sequences of strokes). \r\nThe sketch patterns we identified can be a first step towards developing interpreters of sketched commands, and thus enable new means of interacting with spreadsheets and other applications.",
    "title": "How To Draw Commands? An Elicitation Study for Sketching on Spreadsheets",
    "id": 189538,
    "sequence": 1328,
    "queryCoordinates": {
      "visualization": [
        -7.853169308807448,
        -6.190939493098341
      ]
    }
  },
  {
    "session": "Living with Dementia or Visual Impairments",
    "abstract": "Autonomous navigation robots can increase the independence of blind people but often limit user control—following what is called in Japanese an \"omakase\" approach where decisions are left to the robot. This research investigates ways to enhance user control in social robot navigation, based on two studies conducted with blind participants. The first study, involving structured interviews (N=14), identified crowded spaces as key areas with significant social challenges. The second study (N=13) explored navigation tasks with an autonomous robot in these environments and identified design strategies across different modes of autonomy. Participants preferred an active role, termed the \"boss\" mode, where they managed crowd interactions, while the \"monitor\" mode helped them assess the environment, negotiate movements, and interact with the robot. These findings highlight the importance of shared control and user involvement for blind users, offering valuable insights for designing future social navigation robots.",
    "title": "Beyond Omakase: Designing Shared Control for Navigation Robots with Blind People",
    "id": 189539,
    "sequence": 1329,
    "queryCoordinates": {
      "visualization": [
        -2.7203715060963707,
        10.65831031959658
      ]
    }
  },
  {
    "session": "Inclusive and Participatory",
    "abstract": "Enabling opportunities for young children with disabilities to co-engage in learning activities alongside their non-disabled peers is essential for promoting equity in early childhood education. We investigate how collaborative technology can be designed to support young neurodivergent and neurotypical children in playing together. By integrating theories and methods from design, HCI, and the learning sciences, we iteratively designed, developed, and evaluated a novel tablet application called Incloodle-Classroom (Incloodle in short), that takes into account the needs of neurodiverse groups of children and the adults who support them during play. We deployed Incloodle in a kindergarten classroom of 15 neurodivergent and 16 neurotypical children over a 10-week period. Using interaction analysis, we present rich empirical understandings of how children interacted with each other, with adults, and with Incloodle. In doing so, we contribute new theoretical underpinnings to collaborative and accessible technology design, extending joint media engagement to encompass inclusivity and equity.",
    "title": "Incloodle-Classroom: Technology for Inclusive Joint Media Engagement in a Neurodiverse Kindergarten Classroom",
    "id": 189540,
    "sequence": 1330,
    "queryCoordinates": {
      "visualization": [
        15.192450889488587,
        -5.018907846382264
      ]
    }
  },
  {
    "session": "Ethical Considerations",
    "abstract": "As computing's societal impact grows, so does the need for computing students to recognize and address the ethical and sociotechnical implications of their work. While there are efforts to integrate ethics into computing curricula, we lack a standardized tool to measure those efforts, specifically, students' attitudes towards ethical reflection and their ability to effect change. This paper introduces the novel framework of Critically Conscious Computing and reports on the development and content validation of the Critical Reflection and Agency in Computing Index, a novel instrument designed to assess undergraduate computing students' attitudes towards practicing critically conscious computing. The resulting index is a theoretically grounded, expert-reviewed tool to support research and practice in computing ethics education. This enables researchers and educators to gain insights into students' perspectives, inform the design of targeted ethics interventions, and measure the effectiveness of computing ethics education initiatives.",
    "title": "Development of the Critical Reflection and Agency in Computing Index",
    "id": 189541,
    "sequence": 1331,
    "queryCoordinates": {
      "visualization": [
        -17.995716487438365,
        -0.39266793062209754
      ]
    }
  },
  {
    "session": "Music",
    "abstract": "This paper explores the relationship between music and keyboard typing behavior. In particular, we focus on how it affects keystroke-based authentication systems. To this end, we conducted an online experiment (N=43), where participants were asked to replicate paragraphs of text while listening to music at varying tempos and loudness levels across two sessions. Our findings reveal that listening to music leads to more errors and faster typing if the music is fast. Identification through a biometric model was improved when music was played either during its training or testing. This hints at the potential of music for increasing identification performance and a tradeoff between this benefit and user distraction. Overall, our research sheds light on typing behavior and introduces music as a subtle and effective tool to influence user typing behavior in the context of keystroke-based authentication.",
    "title": "Exploring the Effect of Music on User Typing and Identification through Keystroke Dynamics",
    "id": 189542,
    "sequence": 1332,
    "queryCoordinates": {
      "visualization": [
        -7.495597335532805,
        -8.050839743998976
      ]
    }
  },
  {
    "session": "More Than Human 2",
    "abstract": "Zoos aim to uphold high animal welfare standards while educating the public, yet the direct interactions that attract visitors can negatively impact the animals. Exploring technological solutions to reshape this human-animal relationship in zoos, we developed a novel device allowing lemurs to trigger olfactory, auditory, and visual stimuli in their enclosure. Over 63 days, lemurs engaged most with multimodal stimuli and with visual the least. We then created a similar device for zoo visitors to educate them about lemurs and their stimuli choices. Deploying for 20 days (no devices, lemur-only, visitor-only, and both devices), we examined the impact on visitor behaviour, education, empathy, and experience. From 968 questionnaires and 25,782 visitors, we found that using technology on the lemur and visitor sides jointly significantly enhanced all measured visitor factors, even if the visitors did not directly interact with the device or observe lemurs using theirs. This approach supports long-term conservation and visitor education efforts.",
    "title": "Reshaping Human-animal Relationships: Exploring Lemur and Human Enrichment through Smell, Sound, and Sight",
    "id": 189543,
    "sequence": 1333,
    "queryCoordinates": {
      "visualization": [
        1.1480502970952675,
        -2.771638597533861
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "A reader's interpretation of a visualization is informed by both intratextual information (the information directly represented in the visualization) and extratextual information (information not represented in the visualization but known by the reader). Yet, we do not know what kinds of intra- and extratextual information readers use or how they integrate it to form meaning. To explore this area, we conducted semi-structured interviews about four real-world visualizations. We used thematic analysis to understand the types of information that participants used and diffractive reading to reveal how participants blended intra- and extratextual information. Our thematic analysis showed that participants utilized a broad assortment of information from both expected and unexpected sources. Additionally, our diffractive reading exposed three ways that participants incorporated intra- and extratextual information: to decide what to look at, to make (in)accurate assumptions about what the visualization showed, and to discover insights beyond what was directly encoded.",
    "title": "Intra, Extra, Read all about it! How Readers Interpret Visualizations with Intra- and Extratextual Information",
    "id": 189544,
    "sequence": 1334,
    "queryCoordinates": {
      "visualization": [
        8.583452556734043,
        2.706352195538458
      ]
    }
  },
  {
    "session": "Misinformation, Privacy, Security",
    "abstract": "Providing corrections to people who have engaged with false claims in Online Social Networks (OSN) is a form of cognitive intervention employed to address the spread of misinformation. Although there is a large body of work that has studied the effectiveness of corrections for promoting accurate beliefs, there is still much uncertainty around the precise effects of corrections on individuals' behaviors in OSNs. Notably, the effect of offering frequent corrections on discerning information and identifying misinformation remains uncertain. We conducted two laboratory experiments to test whether experiencing frequent corrections to misinformation improved peoples' ability to discriminate between true and false news claims during extended extreme events like the COVID-19 pandemic. All participants recruited for the experiments were from USA. They received corrections at varying frequencies, depending on their assigned experimental condition. Results from both experiments suggest that increasing frequency of corrections may not affect people's ability to correctly assess information (or misinformation). Participant's beliefs (vaccine hesitancy, belief in mask effectiveness, and trust in fact-checking organization) were found to be the most significant contributing factors to the ability to learn from corrections. We discuss the implications of the findings from these experiments.",
    "title": " Beliefs trump facts: Effect of Frequent Corrections on Misinformation Beliefs during Extended Extreme Events",
    "id": 189545,
    "sequence": 1335,
    "queryCoordinates": {
      "visualization": [
        10.470864723162297,
        7.704608487732219
      ]
    }
  },
  {
    "session": "Inclusive Technology",
    "abstract": "Technologies designed to support marginalized communities have often led to unintended harm. This frequently occurs when misaddressing or failing to understand communities' experiences, needs, and desires. User-centered research often focus on needs versus desires (leveraging deficit versus assets-based approaches), which have been contested in HCI. To promote technology design that better balances the tensions between needs and desires, we contribute participatory zine-making as an effective approach for speculatively designing trans augmented reality (AR) technologies. We facilitated in-person and virtual workshops with trans participants (n=44) focused on designing AR technologies, observing participants' zine-making processes and artifacts to gather visual ethnographic data alongside transcripts and facilitator field notes. In participants' zines we identified ambivalence as critical in addressing trans people's needs and desires, and participants conveyed this ambivalence through metaphor and anti-assimilationist aesthetics. Our participatory zine-making approach enabled us to uncover perspectives and design implications crucial to designing trans technologies. ",
    "title": "Cataloging Augmented, Ambivalent Transgender Futures: Designing Inclusive AR Technologies for Trans Communities Through Speculative, Participatory Zine-Making",
    "id": 189546,
    "sequence": 1336,
    "queryCoordinates": {
      "visualization": [
        17.987015665034882,
        10.83823174995764
      ]
    }
  },
  {
    "session": "Designs for Aging and Accessibility",
    "abstract": "The investigation of technologies facilitating sexual interactions and sexuality-related explorations is becoming more established in Human-Computer Interaction (HCI), albeit with little systematic attention to the sexual lives of disabled people. In this space, we undertook a literature review utilising feminist content analysis to take stock and critically analyse the domains of sexuality, technology and disability when they intersect. Our approach aligns with the broader goals of promoting inclusivity, diversity, and equity in technology design and application. We present a descriptive and analytical outline of existing research on sexuality, technology and disability through which we identified unmarked norms governing research. These include a focus on individualised technologies oriented on heteronormative assumptions on sexual desires. In addition, we focus on common methods employed and describe the involvement, or lack thereof, of disabled people in research practice. This highlights gaps in our collective knowledge from which we can derive areas for future work",
    "title": "A Critical Review of Sexuality, Technology and Disability",
    "id": 189547,
    "sequence": 1337,
    "queryCoordinates": {
      "visualization": [
        -4.050699073258643,
        -5.708926082714819
      ]
    }
  },
  {
    "session": "Interactive Data Visualization",
    "abstract": "In this paper, we introduce the concept of realistic charts, referring to charts in the real world that cannot be digitally altered, such as those printed in newspapers or used in presentations. By enabling interaction with and graphical enhancement of these realistic charts as if they were digital, we transform realistic charts into “digital charts” by adding virtual graphical overlays. To achieve this, we identify 33 overlay strategies (e.g., highlights and trendlines) for five widely-used chart types (e.g., line charts) through systematic exploration and a formative study. To simplify overlay creation, we introduce a new grammar named Vega-Overlay. Leveraging this design space and grammar, we develop a system called HARVis, which allows users to generate virtual overlays through augmented reality devices using speech and optional gestures. A user study involving 33 participants from diverse fields, across 17 tasks, demonstrates the effectiveness and usability of HARVis.",
    "title": "Augmenting Realistic Charts with Virtual Overlays",
    "id": 189548,
    "sequence": 1338,
    "queryCoordinates": {
      "visualization": [
        10.83823174995764,
        17.987015665034882
      ]
    }
  },
  {
    "session": "VR Experiences",
    "abstract": "The decline of social connectedness caused by distance and physical limitations severely affects older adults' well-being and mental health. While virtual reality (VR) is promising for older adults to socialize remotely, existing social VR designs primarily focus on verbal communication (e.g., reminiscent, chat). Actively engaging in shared activities is also an important aspect of social connection. We designed RemoteChess, which constructs a social community and a culturally relevant activity (i.e., Chinese chess) for older adults to play while engaging in social interaction. We conducted a user study with groups of older adults interacting with each other through RemoteChess. Our findings indicate that RemoteChess enhanced participants’ social connectedness by offering familiar environments, culturally relevant social catalysts, and asymmetric interactions. We further discussed design guidelines for designing culturally relevant social activities in VR to promote social connectedness for older adults.",
    "title": "RemoteChess: Enhancing Older Adults' Social Connectedness via Designing a Virtual Reality Chinese Chess (Xiangqi) Community",
    "id": 189549,
    "sequence": 1339,
    "queryCoordinates": {
      "visualization": [
        13.730993925645226,
        2.7312645082257956
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "The absence of a human operator in automated vehicles (AVs) may require external Human-Machine Interfaces (eHMIs) to facilitate communication with other road users in uncertain scenarios, for example, regarding the right of way.\r\nGiven the plethora of adjustable parameters, balancing visual and auditory elements is crucial for effective communication with other road users. With N=37 participants, this study employed multi-objective Bayesian optimization to enhance eHMI designs and improve trust, safety perception, and mental demand. By reporting the Pareto front, we identify optimal design trade-offs. This research contributes to the ongoing standardization efforts of eHMIs, supporting broader adoption.",
    "title": "Improving External Communication of Automated Vehicles Using Bayesian Optimization",
    "id": 189550,
    "sequence": 1340,
    "queryCoordinates": {
      "visualization": [
        -7.305288156289772,
        -19.688391629423982
      ]
    }
  },
  {
    "session": "Advances in Programming and Software Development",
    "abstract": "As the importance of computer science (CS) education gains global recognition, the learner population is expanding to include all manner of backgrounds. However, students from non-English backgrounds face challenges in understanding instructional material, technical communication, and reading and writing code, which further impacts their learning outcomes. These issues have attracted attention in the fields of Human-Computer Interaction (HCI), programming languages, and computer education, which have demonstrated that using programming tools in mother tongues or local languages enhances learners' ability to grasp computing concepts. Consequently, extensive efforts have been dedicated to translating English technical terms across various languages and even developing non-English-based programming languages.",
    "title": "Understanding the Challenges Students Face in Non-English Programming Environments Due to the Programming Language Transition: A Case Study of Keywords in the Chinese Version of Scratch",
    "id": 189551,
    "sequence": 1341,
    "queryCoordinates": {
      "visualization": [
        -13.182256689929485,
        -7.15738140389412
      ]
    }
  },
  {
    "session": "Immersive Touch and Gesture Interaction",
    "abstract": "Olfactory experiences are increasingly in demand due to their immersive benefits. However, most interaction implementations are passive and rely on conventions established for other modalities. In this work, we investigated proactive olfactory interactions, where users actively engage with scents, focusing on mid-air gestures as an input modality miming real-world object- and scent-manipulation, e.g., fanning away an odor. Our study had participants develop a user-defined gesture set for interacting with scents in Virtual Reality (VR), covering various object types (solid, liquid, gas) and interaction modes (out-of-reach, \\revision{not graspable}, graspable), participants compared interacting with scents in VR using traditional controllers versus proactive gestures, revealing that proactive gestures enhanced user experience, presence, and task performance. Finally, an exploratory study showed strong participants' preferences for personalization, enhanced interaction capabilities, and multi-sensory integration. Based on these findings, we propose design guidelines and applications for proactive interactions with scents.",
    "title": "Mid-Air Gestures for Proactive Olfactory Interactions in Virtual Reality",
    "id": 189552,
    "sequence": 1342,
    "queryCoordinates": {
      "visualization": [
        -12.6135428420257,
        9.84370544929003
      ]
    }
  },
  {
    "session": "Design Beyond",
    "abstract": "Within HCI, ethnography has been embraced to grapple with the complexity of real-world settings and design technologies that operate effectively “in the wild.” However, some have criticized HCI’s engagement with ethnographic methods, arguing that ethnography has been circumscribed to an empirical, rather than analytical, enterprise whose perceived utility is limited to communicating uncomplicated facts to inform near-term design goals. We explore how “ethnographic lettering” might deepen HCI’s engagement with ethnography as a critical technical practice by allowing researchers to reframe technology users as interlocutors and the primary audience for the knowledge they produce. Ethnographic lettering can create avenues for more accountable and analytical reflections on the design of interactive systems. By experimenting with relational writing and research methods, we open the possibility for sociotechnical system design to be taken up not only as objects of study but as sites of critical inquiry and radical experimentation towards more just social formations.  \r\n",
    "title": "Dear Laura: Ethnographic Lettering as Critical Technical Practice in Design",
    "id": 189553,
    "sequence": 1343,
    "queryCoordinates": {
      "visualization": [
        -15.420417052727037,
        4.267404119598376
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "The proliferation of consumer Internet of Things (IoT) devices has raised security concerns. In response, governments have been advising consumers on security measures, but these recommendations are not guaranteed to be implementable owing to the diverse and rapidly evolving IoT landscape, risking wasted efforts and uncertainty caused by unsuccessful attempts to secure devices. Through interviews and a workshop with 14 stakeholders involved in a Dutch national public awareness campaign, we found that while stakeholders recognized the validity of these concerns, they opted to continue the campaign with minor modifications while expecting regulatory changes to resolve the observed problem. Their justifications reveal an institutional incentive structure that overlooks well-documented user realities in security and privacy HCI research. This raises important considerations for the design and delivery of such support strategies. By fostering a collaborative dialogue, we aim to contribute to the development of user-centered security practices.",
    "title": "“All Sorts of Other Reasons to Do It”: Explaining the Persistence of Sub-optimal IoT Security Advice",
    "id": 189554,
    "sequence": 1344,
    "queryCoordinates": {
      "visualization": [
        9.46375449179885,
        18.74666239411584
      ]
    }
  },
  {
    "session": "Methodology",
    "abstract": "Customer Experience Management (CXM) focuses on delivering consistent and high-quality experiences across customer touchpoints, aiming to cultivate loyalty and drive long-term business success. Effective CXM requires analyzing customer behaviors and perceptions. However, achieving holistic management of customer experiences remains challenging, even with advances in data analytics and digital transformation. Through a literature review, we developed a metrics framework to measure and manage customer experiences in web-based services comprehensively. This framework addresses key dimensions such as subjects, phases, and aspects of experience. Practitioners generally provided positive feedback on the framework's appropriateness and shared practical insights for real-world services. They emphasized the need for flexible adaptation of metrics and the importance of presenting data effectively. Additionally, we envision an AI-Enhanced Collaborative CXM model that integrates AI’s analytical capabilities with practitioners’ domain knowledge to create tailored insights. This model offers a promising direction for enhancing CXM strategies through a more collaborative, data-driven approach.",
    "title": "Building a Framework for Comprehensive CXM: Opportunities and Challenges for Web-based Services",
    "id": 189555,
    "sequence": 1345,
    "queryCoordinates": {
      "visualization": [
        1.1774160730237797,
        19.965312203694317
      ]
    }
  },
  {
    "session": "Better Work and Career",
    "abstract": "Human-Computer Interaction (HCI) scholarship has studied how Artificial Intelligence (AI) can be leveraged to support care work(ers) by recognizing, reducing, and redistributing workload. Assessment of AI's impact on workers requires scrutiny and is a growing area of inquiry within human-centered evaluations of AI. We add to these conversations by unpacking the sociotechnical gap between the broader aspirations of workers from an AI-based system and the narrower existing definitions of success. We conducted a mixed-methods study and drew on Amartya Sen's Capability Approach to analyze the gap. We shed light on the social factors---on top of performance on evaluation metrics---that guided the AI model choice and determined whose wellbeing must be evaluated while conducting such evaluations. We argue for assessing broader achievements enabled through AI's use when conducting human-centered evaluations of AI. We discuss and recommend the dimensions to consider while conducting such evaluations.",
    "title": "Nurturing Capabilities: Unpacking the Gap in Human-Centered Evaluations of AI-Based Systems",
    "id": 189556,
    "sequence": 1346,
    "queryCoordinates": {
      "visualization": [
        4.835696475121415,
        7.590523012315971
      ]
    }
  },
  {
    "session": "Children and Youth",
    "abstract": "The Chittagong Hill Tracts (CHT) of Bangladesh is home to numerous Indigenous ethnic communities, and their languages, rituals, and values are distinct from those of the mainstream population. These differences, coupled with the past eight decades of turbulent political history, have contributed to the decline of communal harmony among different stakeholders in this region, which has been further aggravated by the advent of social media. In this work, we study the unique challenges faced by Indigenous young community members in Bangladesh when using the social media. Through a qualitative approach involving interviews and focus group discussion sessions, we investigate the online experiences encountered by this population along with their protection and coping mechanisms. Our findings provide a nuanced portrayal of both the internal and external challenges faced by these users. We further connect our findings to the broader issues in HCI and offer a few design recommendations.\r\n",
    "title": "The Good, The Bad and The Ugly: The Opportunities, Challenges and the Mitigation Strategies of the Young Indigenous Social Media Users of the Chittagong Hill Tracts in Bangladesh",
    "id": 189557,
    "sequence": 1347,
    "queryCoordinates": {
      "visualization": [
        10.825223247697277,
        1.9530851587973357
      ]
    }
  },
  {
    "session": "Text Entry",
    "abstract": "With the rise of mixed reality (MR) and augmented reality (AR) applications, efficient text input in AR/MR environments remains challenging. We propose \\textit{FineType}, a text entry system using tapping gestures with finger combinations and postures on any flat surface. Using a wristband with an IMU and an infrared camera, we detect tapping events and employ a multi-task convolutional neural network to predict these gestures, enabling nearly full keyboard mapping (including letters, symbols, numbers, etc.) with one hand. \r\nWe collected gestures from participants (N=28) with 10 finger combinations and 3 finger postures for training. Cross-user validation showed accuracies of 98.26\\% for combinations, 95.53\\% for postures, and 94.19\\% for all categories. For 8 newly defined finger combinations and their postures, classification accuracies were 91.27\\% and 93.86\\%. Using user-adaptive few-shot learning, we improved the finger combination accuracy to 97.05\\%. The results demonstrate our potential to map tapping gestures composed of all finger combinations and three postures. Our user study (N=10) demonstrated an average typing speed of 35.1 WPM with a character error rate of 5.1\\% after two hours of practice.\r\n",
    "title": "FineType: Fine-grained Tapping Gesture Recognition for Text Entry",
    "id": 189558,
    "sequence": 1348,
    "queryCoordinates": {
      "visualization": [
        2.3800600208737057,
        1.826284287026162
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "Giving citizens a voice in urban development processes is crucial for enabling socially sustainable cities and communities. However, citizens' opportunities to express ideas are often limited to communication channels that offer poor incentives for participation. In this paper, we conducted an in-the-wild technology probe study (N=16) using a generative AI (GenAI) tool to allow citizens to visualise and submit urban development ideas by taking pictures and manipulating them with GenAI. The results highlight the potential of GenAI to empower, engage, and inspire citizens‘ creativity. We then conducted additional expert interviews (N=6) with city representatives and community associates. They voiced GenAI's value in early-stage citizen participation but raised concerns about excluding senior citizens. Building on these insights, we present the design and evaluation (N=10) of UrbAI, a co-creative system tailored to urban development participation and conclude with lessons learned to inform how GenAI could be embedded in future citizen participation processes.",
    "title": "UrbAI: Exploring the Possibilities of Generative AI Image Processing to Promote Citizen Participation",
    "id": 189559,
    "sequence": 1349,
    "queryCoordinates": {
      "visualization": [
        3.5056198425099163,
        15.611234080616457
      ]
    }
  },
  {
    "session": "Lessons Learned from Real Experience",
    "abstract": "AI assistants are being created to help software engineers conduct a variety of coding-related tasks, such as writing, documenting, and testing code. We describe the use of the watsonx Code Assistant (WCA), an LLM-powered coding assistant deployed internally within IBM. Through surveys of two user cohorts (N=669) and unmoderated usability testing (N=15), we examined developers' experiences with WCA and its impact on their productivity. We learned about their motivations for using (or not using) WCA, we examined their expectations of its speed and quality, and we identified new considerations regarding ownership of and responsibility for generated code. Our case study characterizes the impact of an LLM-powered assistant on developers' perceptions of productivity and it shows that although such tools do often provide net productivity increases, these benefits may not always be experienced by all users.",
    "title": "Examining the Use and Impact of an AI Code Assistant on Developer Productivity and Experience in the Enterprise",
    "id": 189560,
    "sequence": 1350,
    "queryCoordinates": {
      "visualization": [
        -5.718219597103952,
        -12.778965710858463
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "Designing notifications in Augmented Reality (AR) that are noticeable yet unobtrusive is challenging since achieving this balance heavily depends on the user’s context. However, current AR systems tend to be context-agnostic and require explicit feedback to\r\ndetermine whether a user has noticed a notification. This limitation restricts AR systems from providing timely notifications that are\r\nintegrated with users’ activities. To address this challenge, we studied how sensors can infer users’ detection of notifications while they work in an office setting. We collected 98 hours of data from 12 users, including their gaze, head position, computer interactions, and engagement levels. Our findings showed that combining gaze and engagement data most accurately classified noticeability (AUC = 0.81). Even without engagement data, the accuracy was still high (AUC = 0.76). Our study also examines time windowing methods and compares general and personalized models.",
    "title": "Sensing Noticeability in Ambient Information Environments",
    "id": 189561,
    "sequence": 1351,
    "queryCoordinates": {
      "visualization": [
        -0.3915785766601549,
        -2.974334584121431
      ]
    }
  },
  {
    "session": "Coding and Development",
    "abstract": "AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and interaction context support alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.",
    "title": "Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support",
    "id": 189562,
    "sequence": 1352,
    "queryCoordinates": {
      "visualization": [
        -5.036922252557854,
        17.280897378946715
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Digital technology has great potential to support human health, including the complex needs of older adults in aged care services and treatments. This scoping review aims to explore the current state and roles of digital technology in supporting aged care following the PRISMA-ScR guidelines. We included 47 studies from the last 10 years covering five databases discussing the development, implementation, evaluation, or review of digital technology in aged care services and the broader clinical system. Seven key roles of digital technology were identified, including health monitoring and assessment, remote healthcare services, assistive technology to support treatment, self-care management, social technology to facilitate interaction, clinical decision support, and aged care quality measurement carried out by twelve technology types. Our findings show the potential of digital technology in enhancing the capability and efficiency of aged care services for developing or improving socio-technical aged care systems. We conclude with six recommendations for future research.",
    "title": "Digital technology for supporting Aged Care Services: A Scoping Review",
    "id": 189563,
    "sequence": 1353,
    "queryCoordinates": {
      "visualization": [
        -15.388741450057196,
        -7.224031878618168
      ]
    }
  },
  {
    "session": "Recommendation and Personalization",
    "abstract": "As story writing requires diverse resources, a single system combining these resources could improve personalization. We leverage the broad capabilities of generative AI to support both more general story writing needs and an understudied but essential aspect: reflection on the moral (lesson) conveyed. Through a formative study (N=12), a user study (N=14), and external evaluation (N=19), we designed, implemented, then studied a prototype plugin for FigJam supporting visualization of the story structure through customizable node graph editing, LLM audience impersonation (chatbot and non-chatbot interfaces), and image and audio generative AI features. Our findings support writers' preference for leveraging unique interplays of our breadth of features to satisfy shifting needs across writing processes, from conveying a moral across audience groups to story writing in general. We discuss how our tool design and findings can inform model bias, personalized writing support, and visualization research.",
    "title": "Toward Personalizable AI Node Graph Creative Writing Support: Insights on Preferences for Generative AI Features and Information Presentation Across Story Writing Processes",
    "id": 189564,
    "sequence": 1354,
    "queryCoordinates": {
      "visualization": [
        0.39267619504895046,
        20.996328379167675
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "Electronic circuit simulation is a core skill for electronics-based education. However, conventional introductory simulators often rely on visual tasks and features and are inherently inaccessible to learners who are blind or have low vision (BLV). In this work, we present IncluSim, a novel, open-source BLV-accessible circuit simulator tool, incorporating tactile elements and a digital interface. We relied on extensive needfinding to identify barriers faced by BLV learners in electronics-based education. Next, with the larger BLV community, and as a team of BLV and sighted researchers, we adopted the co-design method over 2.5 years to design and develop the simulator tool. Over two studies, BLV participants completed different circuit design and simulation tasks using the IncluSim tool. Our findings indicate that IncluSim, via its hardware-digital medium, enables BLV learners to successfully design, simulate and debug circuits, overcoming the accessibility barriers of conventional simulators.",
    "title": "IncluSim: An Accessible Educational Electronic Circuit Simulator for Blind and Low-Vision Learners",
    "id": 189565,
    "sequence": 1355,
    "queryCoordinates": {
      "visualization": [
        -3.4834161270535593,
        -11.483284028786503
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "Drivers on food delivery platforms often run a loss on low-paying orders. In response, workers on DoorDash started a campaign, \\#DeclineNow, to purposefully decline orders below a certain pay threshold. For each declined order, the platform returns the request to other available drivers with slightly increased pay. While contributing to overall pay increase the implementation of the strategy comes with the risk of missing out on orders for each individual driver. In this work, we propose a first combinatorial model to study the strategic interaction between workers and the platform. Within our model, we formalize key quantities such as the collective benefit of the strategy, the benefit of freeriding, as well as the benefit of participation. We extend our theoretical results with simulations. Our key insights show that the collective benefit of the strategy is always positive, while the benefit of participation is positive only for small degrees of labor oversupply. Beyond this point, the utility of participants decreases faster with increasing degree of oversupply, compared to the return of freeriding. Our work highlights the significance of labor supply levels for the effectiveness of collective action on gig platforms. We discuss organizing in shifts as a means to reduce oversupply and empower collectives. ",
    "title": "Decline Now: A Combinatorial Model for Algorithmic Collective Action",
    "id": 189566,
    "sequence": 1356,
    "queryCoordinates": {
      "visualization": [
        1.960002402654779,
        -18.898634622151608
      ]
    }
  },
  {
    "session": "XR and Virtual Characteristics",
    "abstract": "VTubing, the practice of live streaming using virtual avatars, has gained worldwide popularity among streamers seeking to maintain anonymity. While previous research has primarily focused on the social and cultural aspects of VTubing, there is a noticeable lack of studies examining the practical challenges VTubers face in creating and operating their avatars. To address this gap, we surveyed VTubers’ equipment and expanded the live-streaming design space by introducing six new dimensions related to avatar creation and control. Additionally, we conducted interviews with 16 professional VTubers to comprehensively explore their practices, strategies, and challenges throughout the VTubing process. Our findings reveal that VTubers face significant burdens compared to real-person streamers due to fragmented tools and the multi-tasking nature of VTubing, leading to unique workarounds. Finally, we summarize these challenges and propose design opportunities to improve the effectiveness and efficiency of VTubing.",
    "title": "VTuber’s Atelier: The Design Space, Challenges, and Opportunities for VTubing",
    "id": 189567,
    "sequence": 1357,
    "queryCoordinates": {
      "visualization": [
        14.656546221839262,
        -8.613109359986625
      ]
    }
  },
  {
    "session": "Language Matters",
    "abstract": "English as a Second Language (ESL) learners often encounter unknown words that hinder their text comprehension. Automatically detecting these words as users read can enable computing systems to provide just-in-time definitions, synonyms, or contextual explanations, thereby helping users learn vocabulary in a natural and seamless manner. This paper presents EyeLingo, a transformer-based machine learning method that predicts the probability of unknown words based on text content and eye gaze trajectory in real time with high accuracy. A 20-participant user study revealed that our method can achieve an accuracy of 97.6%, and an F1-score of 71.1%. We implemented a real-time reading assistance prototype to show the effectiveness of EyeLingo. The user study shows improvement in willingness to use and usefulness compared to baseline methods.",
    "title": "Unknown Word Detection for English as a Second Language (ESL) Learners using Gaze and Pre-trained Language Models",
    "id": 189568,
    "sequence": 1358,
    "queryCoordinates": {
      "visualization": [
        6.126563953361276,
        3.3860322097366784
      ]
    }
  },
  {
    "session": "Mobile Input",
    "abstract": "Back-of-Device (BoD) interfaces have emerged as a promising solution to free up screen real estate in smartphones by offloading interactions from the display to the back, thereby reducing reliance on on-screen interfaces. However, existing BoD solutions face limitations, such as requiring specialized hardware, consuming excessive power, or offering limited input vocabularies. We introduce MagPie, a novel BoD interface that leverages the magnetic phenomenon induced by MagSafe, part of the wireless charging standard. Users can seamlessly attach MagPie to MagSafe-enabled smartphones and interact using tangible, modular interfaces that generate unique magnetic signals upon activation. MagPie then detects these signals and recognizes the input through magnetic sensing. Our experiments with real-world users demonstrate that i) MagPie achieves high performance in accuracy, usability, deployability, responsiveness, and robustness across diverse environments, and ii) its tangible, intuitive, and customizable design opens up possibilities for a whole new class of smartphone interaction scenarios.",
    "title": "MagPie: Extending a Smartphone’s Interaction Space via a Customizable Magnetic Back-of-Device Input Accessory",
    "id": 189569,
    "sequence": 1359,
    "queryCoordinates": {
      "visualization": [
        16.454131257784486,
        4.273355186688746
      ]
    }
  },
  {
    "session": "Platforms and Communities",
    "abstract": "Neighborhood safety technologies, such as Nextdoor and Citizen, aim to enhance user safety through features like real-time alerts, interactive maps, and personalized feeds. While these platforms can support users' sense of safety, they can also fuel a local culture of policing and lateral surveillance, which disproportionately impacts racialized and unhoused members of the community. In contrast, the theory and practice of Transformative Justice was developed to ensure the safety of those populations who are constructed to be dangerous by society. We conducted a case study of a neighborhood social work program in Jackson Grove, Atlanta to understand the design implications of a Transformative Justice-oriented approach to neighborhood safety. Our findings highlight an opportunity for designers to reconceptualize safety from merely protecting users towards: 1) meeting the basic needs of a community, and 2) building relationships to support accountability. These shifts create an opportunity for designers to reimagine neighborhood safety technologies and the associated practices for users. We surface a new wave of safety research in HCI that aims to support both safety \\textit{and} justice and contribute key design priorities towards this work. ",
    "title": "Building the Beloved Community: Designing Technologies for Neighborhood Safety",
    "id": 189570,
    "sequence": 1360,
    "queryCoordinates": {
      "visualization": [
        -7.886371075676547,
        -13.921391857739382
      ]
    }
  },
  {
    "session": "Physical and Tangible",
    "abstract": "A significant number of Virtual Reality (VR) applications focus on mindfulness, using biosensor technologies (e.g., ECG) to provide real-time feedback on users' physiological states. However, the measurement of data for the human body is complex. Commercial devices often lack precision, while medical-grade sensors require controlled environments, which can lead to disruptions and break immersion, affecting the flow of VR experiences. Thus, complicating the evaluation of mindfulness. “Pinch To Awaken XR” is a VR art game that utilizes wearable interfaces to measure breathing from a holistic perspective. Showcased as an Extended Reality (XR) performance, it uses first-person research methods by embodying both the researcher and performer, placing the body as the central source of inquiry. This case study reveals that integrating a performative approach can enhance the flow and engagement in mindfulness VR experiences, while also offering a novel approach for evaluating biosensing interfaces in HCI user studies, using a body-centered design.",
    "title": "Rethinking Breath in VR: A Performative Approach to Enhance User Flow with Bio-sensing Wearable Interfaces",
    "id": 189571,
    "sequence": 1361,
    "queryCoordinates": {
      "visualization": [
        19.845591444604672,
        -9.494867045611215
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "How are Reddit communities responding to AI-generated content? We explored this question through a large-scale analysis of subreddit community rules and their change over time. We collected the metadata and community rules for over 300,000 public subreddits and measured the prevalence of rules governing AI. We labeled subreddits and AI rules according to existing taxonomies from the HCI literature and a new taxonomy we developed specific to AI rules. While rules about AI are still relatively uncommon, the number of subreddits with these rules more than doubled over the course of a year. AI rules are more common in larger subreddits and communities focused on art or celebrity topics, and less common in those focused on social support. These rules often focus on AI images and evoke, as justification, concerns about quality and authenticity. Overall, our findings illustrate the emergence of varied concerns about AI, in different community contexts. Platform designers and HCI researchers should heed these concerns if they hope to encourage community self-determination in the age of generative AI. We make our datasets public to enable future large-scale studies of community self-governance.",
    "title": "AI Rules? Characterizing Reddit Community Policies Towards AI-Generated Content",
    "id": 189572,
    "sequence": 1362,
    "queryCoordinates": {
      "visualization": [
        9.460156642284703,
        -5.612970363669901
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "Recent work in Generative AI enables the stylization of 3D models based on image prompts. However, these methods do not incorporate tactile information, leading to designs that lack the expected tactile properties. We present TactStyle, a system that allows creators to stylize 3D models with images while incorporating the expected tactile properties. TactStyle accomplishes this using a modified image-generation model fine-tuned to generate heightfields for given surface textures. By optimizing 3D model surfaces to embody a generated texture, TactStyle creates models that match the desired style and replicate the tactile experience. We utilize a large-scale dataset of textures to train our texture generation model. In a psychophysical experiment, we evaluate the tactile qualities of a set of 3D-printed original textures and TactStyle's generated textures. Our results show that TactStyle successfully generates a wide range of tactile features from a single image input, enabling a novel approach to haptic design.",
    "title": "TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication",
    "id": 189573,
    "sequence": 1363,
    "queryCoordinates": {
      "visualization": [
        8.72496007072797,
        -4.886212414969553
      ]
    }
  },
  {
    "session": "Perception of Systems",
    "abstract": "Audits are critical mechanisms for identifying the risks and limitations of deployed artificial intelligence (AI) systems. However, the effective execution of AI audits remains incredibly difficult, and practitioners often need to make use of various tools to support their efforts. Drawing on interviews with 35 AI audit practitioners and a landscape analysis of 435 tools, we compare the current ecosystem of AI audit tooling to practitioner needs. While many tools are designed to help set standards and evaluate AI systems, they often fall short in supporting accountability. We outline challenges practitioners faced in their efforts to use AI audit tools and highlight areas for future tool development beyond evaluation—from harms discovery to advocacy. We conclude that the available resources do not currently support the full scope of AI audit practitioners' needs and recommend that the field move beyond tools for just evaluation and towards more comprehensive infrastructure for AI accountability. ",
    "title": "Towards AI Accountability Infrastructure: Gaps and Opportunities in AI Audit Tooling",
    "id": 189574,
    "sequence": 1364,
    "queryCoordinates": {
      "visualization": [
        10.583055172180261,
        5.6567608419119715
      ]
    }
  },
  {
    "session": "XR Experience",
    "abstract": "Augmented Reality (AR) is a promising medium for guiding users through tasks, yet its impact on fostering deeper task understanding remains underexplored. This paper investigates the impact of reflective prompts---strategic questions that encourage users to challenge assumptions, connect actions to outcomes, and consider hypothetical scenarios---on task comprehension and performance. We conducted a two-phase study: a formative survey and co-design sessions (N=9) to develop reflective prompts, followed by a within-subject evaluation (N=16) comparing AR instructions with and without these prompts in coffee-making and circuit assembly tasks. Our results show that reflective prompts significantly improved objective task understanding and resulted in more proactive information acquisition behaviors during task completion. These findings highlight the potential of incorporating reflective elements into AR instructions to foster deeper engagement and learning. Based on data from both studies, we synthesized design guidelines for integrating reflective elements into AR systems to enhance user understanding without compromising task performance.",
    "title": "From Following to Understanding: Investigating the Role of Reflective Prompts in AR-Guided Tasks to Promote User Understanding",
    "id": 189575,
    "sequence": 1365,
    "queryCoordinates": {
      "visualization": [
        -5.028704099521597,
        16.23921596258436
      ]
    }
  },
  {
    "session": "Security in HCI",
    "abstract": "This paper presents a comprehensive Systematization of Knowledge on tangible privacy and security interfaces (TaPSI). Tangible interfaces provide physical forms for digital interactions. They can offer significant benefits for privacy and security applications by making complex and abstract security concepts more intuitive, comprehensible, and engaging. Through a literature survey, we collected and analyzed 80 publications. We identified terminology used in these publications and addressed usable privacy and security domains, contributions, applied methods, implementation details, and opportunities or challenges inherent to TaPSI. Based on our findings, we define TaPSI and propose the TaPSI Research Framework, which guides future research by offering insights into when and how to conduct research on privacy and security involving TaPSI as well as a design space of TaPSI.",
    "title": "The TaPSI Research Framework - A Systematization of Knowledge on Tangible Privacy and Security Interfaces",
    "id": 189576,
    "sequence": 1366,
    "queryCoordinates": {
      "visualization": [
        -14.96645302144581,
        10.000264194352845
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "When taking photos in a crowd, unintended individuals, such as bystanders, are often captured alongside the main subject(s). In an effort to protect bystanders' privacy, existing methods have been developed to automatically detect bystanders. However, inconsistent definitions of who qualifies as a bystander limit their effectiveness. To better understand bystanders' perceptions, we conducted an online survey with 486 participants, analyzing their responses to 864 image-based scenarios and their comfort with sharing these images online. Our results revealed no significant correlation between comfort with public photo sharing and bystander status. We identified limitations in current bystander detection methodologies, as they often fail to recognize bystanders who are not clearly in the background, hence missing individuals with privacy concerns. Moreover, comfort with public sharing varied significantly depending on the image context. Our findings highlight the importance of considering the context of captured images to address privacy concerns in image sharing.",
    "title": "``I am not the primary focus\" - Understanding the Perspectives of Bystanders in Photos Shared Online",
    "id": 189577,
    "sequence": 1367,
    "queryCoordinates": {
      "visualization": [
        20.996328379167675,
        -0.3926761950489476
      ]
    }
  },
  {
    "session": "Inclusive Communication and Support",
    "abstract": "Computational thinking (CT) is regarded as a fundamental twenty-first century skill and has been implemented in many early childhood education curriculum. Yet, the needs of neurodivergent children have remained largely overlooked in the extensive research and technologies built to foster CT among children. To address this, we investigated how to support neurodiverse (i.e., groups involving neurodivergent and neurotypical) preschoolers aged 3-5 in learning CT concepts. Grounded in interviews with six teachers, we deployed an age-appropriate, programmable robot called KIBO in two preschool classrooms involving 12 neurodivergent and 17 neurotypical children for eight weeks. Using interaction analysis, we illustrate how neurodivergent children found enjoyment in assembling KIBO and learned to code with it while engaging in cooperative and competitive play with neurotypical peers and the adults. Through this, we discuss accessible adaptations needed to enhance CT among neurodivergent preschoolers and ways to reimagine technology-mediated social play for them.",
    "title": "Cultivating Computational Thinking and Social Play among Neurodiverse Preschoolers in Inclusive Classrooms",
    "id": 189578,
    "sequence": 1368,
    "queryCoordinates": {
      "visualization": [
        4.886212414969542,
        -8.724960070727976
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "Healthcare simulations help learners develop teamwork and clinical skills in a risk-free setting, promoting reflection on real-world practices through structured debriefs. However, despite video's potential, it is hard to use, leaving a gap in providing concise, data-driven summaries for supporting effective debriefing.\r\nAddressing this, we present TeamVision, an AI-powered multimodal learning analytics (MMLA) system that captures voice presence, automated transcriptions, body rotation, and positioning data, offering educators a dashboard to guide debriefs immediately after simulations.\r\nWe conducted an in-the-wild study with 56 teams (221 students) and recorded debriefs led by six teachers using TeamVision. Follow-up interviews with 15 students and five teachers explored perceptions of its usefulness, accuracy, and trustworthiness. This paper examines: i) how TeamVision was used in debriefing, ii) what educators found valuable/challenging, and iii) perceptions of its effectiveness. Results suggest TeamVision enables flexible debriefing and highlights the challenges and implications of using AI-powered systems in healthcare simulation.",
    "title": "TeamVision : An AI-powered Learning Analytics System for Supporting Reflection in Team-based Healthcare Simulation",
    "id": 189579,
    "sequence": 1369,
    "queryCoordinates": {
      "visualization": [
        14.966453021445814,
        10.00026419435284
      ]
    }
  },
  {
    "session": "Programming and Interaction",
    "abstract": "We introduce the concept of code shaping, an interaction paradigm for editing code using free-form sketch annotations directly on top of the code and console output. To evaluate this concept, we conducted a three-stage design study with 18 different programmers to investigate how sketches can communicate intended code edits to an AI model for interpretation and execution. The results show how different sketches are used, the strategies programmers employ during iterative interactions with AI interpretations, and interaction design principles that support the reconciliation between the code editor and sketches. Finally, we demonstrate the practical application of the code shaping concept with two use case scenarios, illustrating design implications from the study.",
    "title": "Code Shaping: Iterative Code Editing with Free-form AI-Interpreted Sketching",
    "id": 189580,
    "sequence": 1370,
    "queryCoordinates": {
      "visualization": [
        -9.992290362407228,
        -0.39259815759068706
      ]
    }
  },
  {
    "session": "Spirituality and Legacies",
    "abstract": "The rise of generative AI technology has sparked interest in using digital information to create AI-generated agents as digital legacy. These agents, often referred to as \"AI Afterlives\", present unique challenges compared to traditional digital legacy. Yet, there is limited human-centered research on \"AI Afterlife\" as digital legacy, especially from the perspectives of the individuals being represented by these agents. This paper presents a qualitative study examining users' perceptions, expectations, and concerns regarding AI-generated agents as digital legacy. We identify factors shaping people's attitudes, their perceived differences compared with the traditional digital legacy, and concerns they might have in real practices. We also examine the design aspects throughout the life cycle and interaction process. Based on these findings, we situate \"AI Afterlife\" in digital legacy, and delve into design implications for maintaining identity consistency and balancing intrusiveness and support in \"AI Afterlife\" as digital legacy.",
    "title": "\"AI Afterlives\" as Digital Legacy: Perceptions, Expectations, and Concerns",
    "id": 189581,
    "sequence": 1371,
    "queryCoordinates": {
      "visualization": [
        16.660420146115946,
        -12.783990009183125
      ]
    }
  },
  {
    "session": "Design",
    "abstract": "Intersectional design research shows that the lack of decision-making power of marginalized communities in the design of digital public services perpetuates social injustice. Drawing on two ethnographic studies, we analyze two cases of structural inaccessibility grounded in audism and cisnormativity: the absence of closed captions and Danish sign language on the Danish Parliament’s online TV, and gender binary input forms in Danish public sector job applications. Drawing on lessons learned from participating in complaint processes as researchers, we introduce the concept of redesign inertia as the institutional and structural mechanisms that reproduce discrimination and disempowerment in the maintenance of digital systems. We extend existing conceptualizations of inertia in sociotechnical systems by centering on how structural oppression shapes inaction. Drawing on critical access studies, we argue that user-centered and accessible complaint processes are essential elements of the co-design and maintenance of a digital infrastructure or public service promising digital inclusion.\r\n",
    "title": "How Can We Change the System? Understanding and Addressing Redesign Inertia in Digital Public Services",
    "id": 189582,
    "sequence": 1372,
    "queryCoordinates": {
      "visualization": [
        -12.071118839071428,
        15.946413075454142
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Supporting older adults in health self-management is crucial for promoting independent aging, particularly given the growing strain on healthcare systems. While voice assistants (VAs) hold the potential to support aging in place, they often lack tailored assistance and present usability challenges. We addressed these issues through a five-stage design process with older adults to develop a personal health assistant. Starting with in-home interviews (N = 17), we identified two primary challenges in older adult's health self-management: health awareness and medical adherence. To address these challenges, we developed a high-fidelity LLM-powered VA prototype to debrief doctor's after-visit summary and generate tailored medication reminders. We refined our prototype with feedback from co-design workshops (N = 10) and validated its usability through in-home studies (N = 5). Our work highlights key design features for personal health assistants and provides broader insights into desirable VA characteristics, including personalization, adapting to user context, and respect for user autonomy.",
    "title": "Voice Assistants for Health Self-Management: Designing for and with Older Adults",
    "id": 189583,
    "sequence": 1373,
    "queryCoordinates": {
      "visualization": [
        -1.1747357299804644,
        8.923003752364293
      ]
    }
  },
  {
    "session": "Understanding and Working with Algorithms",
    "abstract": "Complementary collaboration between humans and AI is essential for human-AI decision making. One feasible approach to achieving it involves accounting for the calibrated confidence levels of both AI and users. However, this process would likely be made more difficult by the fact that AI confidence may influence users' self-confidence and its calibration. To explore these dynamics, we conducted a randomized behavioral experiment. Our results indicate that in human-AI decision-making, users' self-confidence aligns with AI confidence and such alignment can persist even after AI ceases to be involved. This alignment then affects users' self-confidence calibration. We also found the presence of real-time correctness feedback of decisions reduced the degree of alignment. These findings suggest that users' self-confidence is not independent of AI confidence, which practitioners aiming to achieve better human-AI collaboration need to be aware of. We call for research focusing on the alignment of human cognition and behavior with AI.",
    "title": "As Confidence Aligns: Understanding the Effect of AI Confidence on Human Self-confidence in Human-AI Decision Making",
    "id": 189584,
    "sequence": 1374,
    "queryCoordinates": {
      "visualization": [
        19.688391629423982,
        -7.305288156289773
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "While interpretability methods identify a model’s learned concepts, they overlook the relationships between concepts that make up its abstractions and inform its ability to generalize to new data. To assess whether models’ have learned human-aligned abstractions, we introduce abstraction alignment, a methodology to compare model behavior against formal human knowledge. Abstraction alignment externalizes domain-specific human knowledge as an abstraction graph, a set of pertinent concepts spanning levels of abstraction. Using the abstraction graph as a ground truth, abstraction alignment measures the alignment of a model’s behavior by determining how much of its uncertainty is accounted for by the human abstractions. By aggregating abstraction alignment across entire datasets, users can test alignment hypotheses, such as which human concepts the model has learned and where misalignments recur. In evaluations with experts, abstraction alignment differentiates seemingly similar errors, improves the verbosity of existing model-quality metrics, and uncovers improvements to current human abstractions.",
    "title": "Abstraction Alignment: Comparing Model-Learned and Human-Encoded Conceptual Relationships",
    "id": 189585,
    "sequence": 1375,
    "queryCoordinates": {
      "visualization": [
        16.1175365452339,
        -10.06106434295347
      ]
    }
  },
  {
    "session": "Health and Well-being",
    "abstract": "Nudging participants with text-based reflective nudges enhances deliberation quality on online deliberation platforms. The effectiveness of multimodal reflective nudges, however, remains largely unexplored. Given the multi-sensory nature of human perception, incorporating diverse modalities into self-reflection mechanisms has the potential to better support various reflective styles. This paper explores how presenting reflective nudges of different types (direct: persona and indirect: storytelling) in different modalities (text, image, video and audio) affects deliberation quality. We conducted two user studies with 20 and 200 participants respectively. The first study identifies the preferred modality for each type of reflective nudges, revealing that text is most preferred for persona and video is most preferred for storytelling. The second study assesses the impact of these modalities on deliberation quality. Our findings reveal distinct effects associated with each modality, providing valuable insights for developing more inclusive and effective online deliberation platforms.",
    "title": "Enhancing Deliberativeness: Evaluating the Impact of Multimodal Reflection Nudges",
    "id": 189586,
    "sequence": 1376,
    "queryCoordinates": {
      "visualization": [
        13.182256689929481,
        7.157381403894126
      ]
    }
  },
  {
    "session": "Technology in Education",
    "abstract": "Multi-role pedagogical agents can create engaging and immersive learning experiences, helping learners better understand knowledge in history learning. However, existing pedagogical agents often struggle with multi-role interactions due to complex controls, limited feedback forms, and difficulty dynamically adapting to user inputs. In this study, we developed a VR prototype with LLM-powered adaptive role-switching and action-switching pedagogical agents to help users learn about the history of the Pavilion of Prince Teng. A 2 x 2 between-subjects study was conducted with 84 participants to assess how adaptive role-switching and action-switching affect participants’ learning outcomes and experiences. The results suggest that adaptive role-switching enhances participants’ perception of the pedagogical agent’s trustworthiness and expertise but may lead to inconsistent learning experiences. Adaptive action-switching increases participants’ perceived social presence, expertise, and humanness. The study did not uncover any effects of role-switching and action-switching on usability, learning motivation and cognitive load. Based on the findings, we proposed five design implications for incorporating adaptive role-switching and action-switching into future VR history education tools.",
    "title": "Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality",
    "id": 189587,
    "sequence": 1377,
    "queryCoordinates": {
      "visualization": [
        -14.749283686549392,
        11.977421706431148
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "The use of haptic and visual stimuli to create body illusions and enhance body ownership of virtual avatars in virtual reality (VR) has been extensively studied in the fields of psychology and Human-Computer Interaction (HCI). However, previous studies have relied on mechanical devices or corresponding proxies to provide haptic feedback. In this paper, we applied haptic retargeting to induce body illusions by redirecting users’ hand movements, altering their perception of the shape of body parts when touched. Our technique allows for the realization of more precise and complex deformations. We implemented mapping of the ear’s contour, thereby creating illusions of different ear shapes, such as elf ears and dog ears. To determine the scope of retargeting, we conducted a user study to identify the maximum tolerable deviation angle for virtual ears. Subsequently, we explored the impact of haptic retargeting on body ownership of virtual avatars.",
    "title": "DobbyEar: Inducing Body Illusion of Ear Deformation with Haptic Retargeting",
    "id": 189588,
    "sequence": 1378,
    "queryCoordinates": {
      "visualization": [
        -4.664426045664028,
        -5.219495154182159
      ]
    }
  },
  {
    "session": "Inclusive and Societal Perspective",
    "abstract": "Despite numerous efforts to mitigate their biases, ML systems continue to harm already-marginalized people.  While predominant ML approaches assume bias can be removed and fair models can be created, we show that these are not always possible, nor desirable, goals.  We reframe the problem of ML bias by creating models to identify biased language, drawing attention to a dataset’s biases rather than trying to remove them.  Then, through a workshop, we evaluated the models for a specific use case: workflows of information and heritage professionals.  Our findings demonstrate the limitations of ML for identifying bias due to its contextual nature, the way in which approaches to mitigating it can simultaneously privilege and oppress different communities, and its inevitability.  We demonstrate the need to expand ML approaches to bias and fairness, providing a mixed-methods approach to investigating the feasibility of removing bias or achieving fairness in a given ML use case.",
    "title": "Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals",
    "id": 189589,
    "sequence": 1379,
    "queryCoordinates": {
      "visualization": [
        6.988987705124716,
        -0.3924931306603425
      ]
    }
  },
  {
    "session": "Innovative Training Technologies",
    "abstract": "Remote, vs. in situ, instruction may be regarded to decrease trainee engagement and concentration, potentially reducing training effectiveness. As such, local evaluative observers are often deployed to create the situated atmosphere. However, these observers can also have a negative effect on the trainees' mental state and performance. This study investigates the impact of a local human observer's presence on trainees' mental state and task performance during military training conducted in a mixed reality (MR) environment, where a tele-presence avatar, controlled by the remote instructor, leads the training. An experiment was conducted comparing three conditions: remote training with (1) no observer, (2) a real observer, and (3) a virtual observer. The study found that although the observer, real or virtual, indeed negatively impacted the trainee's mental state, the remote trainer avatar helped maintain the immersion/concentration, ensuring the trainees achieved the performance comparable to the no observer condition. ",
    "title": "The Impact of Observer Presence on Trainees' Mental States and Performance in Remote Military Training with Virtual Humans in Mixed Reality Environment",
    "id": 189590,
    "sequence": 1380,
    "queryCoordinates": {
      "visualization": [
        0.39265965636659234,
        -15.995181099139268
      ]
    }
  },
  {
    "session": "Decision Making with AI",
    "abstract": "Recent advancements in artificial intelligence have sparked discussions on how clinical decision-making can be supported. New clinical decision support systems (CDSSs) have been developed and evaluated through workshops and interviews. However, limited research exists on how CDSSs affect decision-making as it unfolds, particularly in settings such as acute care, where decisions are made collaboratively under time pressure and uncertainty. Using a mixed-method study, we explored the impact of a CDSS on decision-making in anesthetic teams during simulated operating room crises. Fourteen anesthetic teams participated in high-fidelity simulations, half using a CDSS prototype for comparative analysis. Qualitative findings from conversation analysis and quantitative results on decision-making efficiency and workload revealed that the CDSS changed team structure, communication, and diagnostic processes. It homogenized decision-making, empowered nursing staff, and introduced friction between analytical and intuitive thinking. We discuss whether these changes are beneficial or detrimental and offer insights to guide future CDSS design.",
    "title": "How a Clinical Decision Support System Changed the Diagnosis Process: Insights from an Experimental Mixed-Method Study in a Full-Scale Anesthesiology Simulation",
    "id": 189591,
    "sequence": 1381,
    "queryCoordinates": {
      "visualization": [
        -1.9547456807350618,
        11.839719985018549
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "Large multimodal models (LMMs) have enabled new AI-powered applications that help people with visual impairments (PVI) receive natural language descriptions of their surroundings through audible text. We investigated how this emerging paradigm of visual assistance transforms how PVI perform and manage their daily tasks. Moving beyond usability assessments, we examined both the capabilities and limitations of LMM-based tools in personal and social contexts, while exploring design implications for their future development. Through interviews with 14 visually impaired users of Be My AI (an LMM-based application) and analysis of its image descriptions from both study participants and social media platforms, we identified two key limitations. First, these systems' context awareness suffers from hallucinations and misinterpretations of social contexts, styles, and human identities. Second, their intent-oriented capabilities often fail to grasp and act on users' intentions. Based on these findings, we propose design strategies for improving both human-AI and AI-AI interactions, contributing to the development of more effective, interactive, and personalized assistive technologies. ",
    "title": "Beyond Visual Perception: Insights from Smartphone Interaction of Visually Impaired Users with Large Multimodal Models",
    "id": 189592,
    "sequence": 1382,
    "queryCoordinates": {
      "visualization": [
        -16.454131257784482,
        4.273355186688747
      ]
    }
  },
  {
    "session": "Workplace Interactions and Wellbeing",
    "abstract": "Self-disclosure, the sharing of personal and professional information about yourself, can help foster and maintain working relationships. But how do computers mediate the way we self-disclose at work? We look \"beyond the watercooler\" to investigate computer-mediated self-disclosure (CMSD) at work. We conducted two studies: (1) a survey (n=455 knowledge workers) to understand perceptions towards disclosing various information types among colleagues, and (2) an interview study (n=12 knowledge workers) with five speculative design concepts to characterize attitudes and needs around CMSD. Study 1 indicated sharing about well-being was valuable, but that it was less familiar among remote workers compared to those in-person or hybrid. Study 1 informed the design concepts for Study 2, whose findings revealed that CMSD is a key part of workers’ socialization and should evolve alongside relationship stages. We discuss design opportunities for adaptive, intentional, and personal CMSD, along with policy implications for organizations. ",
    "title": "Beyond the Watercooler: Designing for Computer-Mediated Self-Disclosure among Work Colleagues",
    "id": 189593,
    "sequence": 1383,
    "queryCoordinates": {
      "visualization": [
        14.871672920607155,
        1.9578928833007736
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "The reference to assumptions in how practitioners use or interact with machine learning (ML) systems is ubiquitous in HCI and responsible ML discourse. However, what remains unclear from prior works is the conceptualization of assumptions and how practitioners identify and handle assumptions throughout their workflows. This leads to confusion about what assumptions are and what needs to be done with them. We use the concept of an argument from Informal Logic, a branch of Philosophy, to offer a new perspective to understand and explicate the confusions surrounding assumptions. Through semi structured interviews with 22 ML practitioners, we find what contributes most to these confusions is how independently assumptions are constructed, how reactively and reflectively they are handled, and how nebulously they are recorded. Our study brings the peripheral discussion of assumptions in ML to the center and presents recommendations for practitioners to better think about and work with assumptions.",
    "title": "Talking About the Assumption in the Room",
    "id": 189594,
    "sequence": 1384,
    "queryCoordinates": {
      "visualization": [
        1.9570647534969994,
        -13.862535754710237
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": "My research investigates the use of Afrofuturism, guided by human factors principles, to design digital health tools that address Black health equity. Rooted in Black-Centered Design (BCD), my work centers on incorporating the voices, values, and lived experiences of Black individuals in the design process. By integrating patient ergonomics, I aim to create a systematic approach to BCD, focusing on improving health equity for Black maternal mental health. My initial literature review examines design approaches used in Black digital health technologies, while my first field study identifies barriers, pain points, and resilience in accessing mental health resources for Black birthing individuals. Future research will include insights from designers and healthcare providers, leading to a co-design session leveraging Afrofuturism to develop digital tools that meet the mental health needs of Black birthing people. This work aims to establish a structured, human factors-based approach to BCD for health equity.",
    "title": "Designing for Black Health Futures: Exploring Black-Centered Design from a Human Factors Lens in Pursuits of Equitable Black Health Futures",
    "id": 189595,
    "sequence": 1385,
    "queryCoordinates": {
      "visualization": [
        0.39157857666015383,
        -2.9743345841214315
      ]
    }
  },
  {
    "session": "Body and Technology",
    "abstract": "Self-managing chronic conditions typically involves a diverse network of individuals and devices, forming a self-management ecosystem. For this ecosystem to be effective, components need to work together cohesively. The rapid advancement of technology means new devices need to be repeatedly integrated into existing self-management ecosystems. To examine this process, we used the case study of young adults with type 1 diabetes (T1D) in the UK who were given a smartwatch. Over six months, interviews and focus groups were performed to explore their smartwatch use alongside T1D management. Thematic analysis highlighted that smartwatches have potential as a display, interface and data source in T1D management, which is of particular importance as artificial intelligence plays a growing role in self-management ecosystems. It also emphasised the need for customisation, flexibility and adaptability, and automation in the design of technology to promote integration into existing self-management ecosystems for both T1D and other chronic conditions.",
    "title": "Integrating Technology into Self-Management Ecosystems: Young Adults with Type 1 Diabetes in the UK using Smartwatches",
    "id": 189596,
    "sequence": 1386,
    "queryCoordinates": {
      "visualization": [
        21.716718717951643,
        -3.51910899594893
      ]
    }
  },
  {
    "session": "Experience Together",
    "abstract": "Since the explosion in popularity of ChatGPT, large language models (LLMs) have continued to impact our everyday lives.  Equipped with external tools that are designed for a specific purpose (e.g., for flight booking or an alarm clock), LLM agents exercise an increasing capability to assist humans in their daily work.  Although LLM agents have shown a promising blueprint as daily assistants, there is a limited understanding of how they can provide daily assistance based on planning and sequential decision making capabilities. We draw inspiration from recent work that has highlighted the value of `\\textit{LLM-modulo}' setups in conjunction with humans-in-the-loop for planning tasks. We conducted an empirical study ($N$ = 248) of LLM agents as daily assistants in six commonly occurring tasks with different levels of risk typically associated with them (e.g., flight ticket booking and credit card payments). To ensure user agency and control over the LLM agent, we adopted LLM agents in a plan-then-execute manner, wherein the agents conducted step-wise planning and step-by-step execution in a simulation environment.  We analyzed how user involvement at each stage affects their trust and collaborative team performance. Our findings demonstrate that LLM agents can be a double-edged sword --- (1) they can work well when a high-quality plan and necessary user involvement in execution are available, and (2) users can easily mistrust the LLM agents with plans that seem plausible. We synthesized key insights for using LLM agents as daily assistants to calibrate user trust and achieve better overall task outcomes. Our work has important implications for the future design of daily assistants and human-AI collaboration with LLM agents.",
    "title": "Plan-Then-Execute: An Empirical Study of User Trust and Team Performance When Using LLM Agents As A Daily Assistant",
    "id": 189597,
    "sequence": 1387,
    "queryCoordinates": {
      "visualization": [
        -17.790507188419692,
        2.7382209514184996
      ]
    }
  },
  {
    "session": "Communication and Social Interaction",
    "abstract": "Effective communication is crucial for meeting security needs, yet gender-related communication challenges faced by women security experts within software development remain underexplored. In an interview study with 25 women security experts, we investigated gender-related communication challenges hindering the adoption of security requirements, and strategies to overcome these. Key challenges included the undervaluation of women’s security expertise, communication barriers, resistance to women’s security-related suggestions, and instances of hostility. Communication challenges with stakeholders who were men disrupted team collaboration, resulting in delays, weakened security measures, and increased organizational risk. Consequently, women security experts often had to adopt strategies, such as leveraging allied men and overpreparing, to assert their security competence. We further offer insights into women’s participation in security studies. Based on our findings, we provide recommendations on how to address gender-related challenges. ",
    "title": "Women Security Experts Are Not The Enemy: A Qualitative Study on Gender-Related Communication Challenges",
    "id": 189598,
    "sequence": 1388,
    "queryCoordinates": {
      "visualization": [
        -11.993575049716387,
        0.3926289938613174
      ]
    }
  },
  {
    "session": "Prototyping and Sustainable Development",
    "abstract": "The recent democratization of personal fabrication has significantly advanced the maker movement and reshaped applied research in HCI and beyond. However, this growth has also raised increasing sustainability concerns, as material waste is an inevitable byproduct of making and rapid prototyping. In this work, we examine the sustainability landscape within the modern maker community, focusing on grassroots makerspaces and maker-oriented research labs through in-depth interviews with diverse stakeholders involved in making and managing making-related activities. Our findings highlight four key themes: the various types of \"waste\" generated through the making process, the strategies (or lack thereof) for managing this waste, the motivations driving (un)sustainable practices, and the challenges faced. We synthesize these insights into design considerations and takeaways for technical HCI researchers and the broader community, focusing on future tools, infrastructures, and educational approaches to foster sustainable making.",
    "title": "Make Making Sustainable: Exploring Sustainability Practices, Challenges, and Opportunities in Making Activities",
    "id": 189599,
    "sequence": 1389,
    "queryCoordinates": {
      "visualization": [
        -10.992991082226908,
        0.39261567222878857
      ]
    }
  },
  {
    "session": "WS18: The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "abstract": "The Metaverse is envisioned as a shared, persistent experience that encompasses both augmented and virtual reality, representing the convergence of a virtually enhanced physical reality and interconnected persistent virtual spaces. It has the potential to break down physical boundaries, connecting people from all walks of life together through digital technology. As the Metaverse is still evolving, there is a unique opportunity to shape its development into an inclusive, all-encompassing space that is accessible for all. However a key challenge lies in designing the Metaverse from the ground up to ensure inclusivity and accessibility. This workshop aims to explore how to build an open, inclusive Metaverse and develop methods for evaluating its success. Key outcomes will include identifying new opportunities to enhance inclusivity, establishing evaluation methodologies, and outlining considerations for designing accessible environments and interactions within the Metaverse.",
    "title": "The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "id": 189600,
    "sequence": 1390,
    "queryCoordinates": {
      "visualization": [
        20.994852406701003,
        -6.573900852678042
      ]
    }
  },
  {
    "session": "Personal Data and Decision-Making",
    "abstract": "Homelessness systems in North America adopt coordinated data-driven approaches to efficiently match support services to clients based on their assessed needs and available resources. AI tools are increasingly being implemented to allocate resources, reduce costs and predict risks in this space. In this study, we conducted an ethnographic case study on the City of Toronto’s homelessness system’s data practices across different critical points. We show how the City’s data practices offer standardized processes for client care but frontline workers also engage in heuristic decision-making in their work to navigate uncertainties, client resistance to sharing information, and resource constraints. From these findings, we show the temporality of client data which constrain the validity of predictive AI models. Additionally, we highlight how the City adopts an iterative and holistic client assessment approach which contrasts to commonly used risk assessment tools in homelessness, providing future directions to design holistic decision-making tools for homelessness. ",
    "title": "The Datafication of Care in Public Homelessness Services",
    "id": 189601,
    "sequence": 1391,
    "queryCoordinates": {
      "visualization": [
        6.483861024079838,
        14.627356091256491
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "Traditional app privacy policies are often lengthy and non-interactive, leading users to skip them and remain uninformed. To address this, we proposed PrivCAP, a technique to enhance user comprehension by presenting policies in a concise, interactive format. PrivCAP adopted a CAPTCHA-based design, requiring users to interact with clickable chunks of concise policy content, thus reducing physical and cognitive load. A formative study (N=38) demonstrated that participants valued informed consent alongside concerns over data collection and sharing, marking the first such evaluation among Chinese users. This study further found a preference for concise visualizations and interactable formats. PrivCAP, leveraging few-shot prompting on Large Language Models (LLMs), accurately translates privacy policies into clickable, chunked formats optimized for smartphone screens. In an evaluation (N=28), PrivCAP outperformed traditional policy presentations in improving user understanding, reducing cognitive load, and maintaining efficiency, with participants favoring its engaging design and reporting more informed decision-making.",
    "title": "PrivCAPTCHA: Interactive CAPTCHA to Facilitate Effective Comprehension of APP Privacy Policy",
    "id": 189602,
    "sequence": 1392,
    "queryCoordinates": {
      "visualization": [
        -10.782766458219996,
        16.844344674325736
      ]
    }
  },
  {
    "session": "Fabrication and Interaction Tools",
    "abstract": "With generative AI acquiring the right training data is a critical part of designing the user experience. Training large language models to talk like humans requires exposing them to the interaction patterns distinctive of natural conversation. Although models are typically fine-tuned on question-answer or instruction pairs, they are less often trained on real-time human conversations. Natural conversation data are hard to find and \"conversation\" is used to mean very different kinds of interaction or content. We demonstrate a method for scoring language content using \\textit{generic conversational phrase detection}. We generate three scores: 1) range of unique features, 2) density of features within sections of the content, and 3) overall score combining these. Using our method, we score over 27,000 documents from 6 datasets, which vary widely in terms of whether or not they contain conversation content. Our results show this approach is effective in distinguishing conversation content from non-conversation and from conversation-like content.",
    "title": "Finding the Conversation: A Method for Scoring Documents for Natural Conversation Content",
    "id": 189603,
    "sequence": 1393,
    "queryCoordinates": {
      "visualization": [
        8.910556490355512,
        -9.465832400385253
      ]
    }
  },
  {
    "session": "High-Stake Situations",
    "abstract": "Emotion artificial intelligence (AI) is deployed in many high-impact areas. However, we know little about people's general attitudes towards and comfort with it across application domains. We conducted a survey with a U.S. representative sample, oversampling for marginalized groups who are more likely to experience emotion AI harms (i.e., people of color, disabled people, minoritized genders) (n=599). We find: 1) although comfort was distinct across 11 contexts, even the most favorable context (healthcare) yielded low comfort levels; 2) participants were significantly more comfortable with inferences of happiness and surprise compared to other emotions; 3) individuals with disabilities and minoritized genders were significantly less comfortable than others across a variety of contexts; and 4) perceived accuracy explained a large proportion of the variance in comfort levels across contexts. We argue that attending to identity is key in examining emotion AI's societal and ethical impacts, and discuss implications for emotion AI deployment and regulation.\r\n",
    "title": "Public Perceptions About Emotion AI Use Across Contexts in the United States",
    "id": 189604,
    "sequence": 1394,
    "queryCoordinates": {
      "visualization": [
        14.241717591081397,
        -12.576703862931762
      ]
    }
  },
  {
    "session": "AR, VR, and Social VR",
    "abstract": "Immersive realities enable social interactions that are radically different from traditional communication technologies, but how we experience immersion together is not yet indistinguishable from face-to-face interactions.  Some social signals are not stable across realities, may change in semantics, or are missing all together.  Understanding how social signals impact behaviours and experiences of social connection in immersive environments is key to creating experiences that are meaningful, satisfying, and productive.  We completed a lab study where 6 groups of 6 participants (N=36) completed co-located social tasks in an instrumented face-to-face environment and its digital twin, creating a rich open dataset of 1.8 million rows across 45 columns.  Our quantitative results demonstrate the stability of position as a social signal, measure lower social synchronisation in XR compared to face-to-face, and propose a method for bench marking XR against face-to-face interactions.  This enables direct quantitative comparisons between experiences of co-located physical and virtual interactions for the first time.",
    "title": "Understanding Social Interactions in Reality Versus Virtuality",
    "id": 189605,
    "sequence": 1395,
    "queryCoordinates": {
      "visualization": [
        12.071118839071426,
        -15.946413075454144
      ]
    }
  },
  {
    "session": "Design",
    "abstract": "Recently, there has been increased interest in design tools for creating textures using toolpath manipulation for extrusion-based 3D printers. Most tools are limited in their ability to edit existing 3D models and the variety of possible textures. Here, we present ConTextural, a design tool for adding texture to existing 3D models using toolpath manipulation. Using a coloring-based user interface, ConTextural allows users to draw textures on 3D models. Inspired by knitting structures, we introduce the concept of texture primitives, constructing texture structures that enable abundant possibilities for texture patterns. We include a curated texture library, enabling users to easily craft intricate and personalized designs. We assess the tool’s impact on users' expressiveness, engagement, and satisfaction using a user study and demonstrate how it helps to produce uniquely distinct designs from a single 3D model. Additionally, we provide design examples highlighting functional applications for adding textures to existing 3D models.",
    "title": "ConTextural: A Toolpath-Based Texture Editing Tool for Extrusion 3D Printers",
    "id": 189606,
    "sequence": 1396,
    "queryCoordinates": {
      "visualization": [
        -1.1764853857852884,
        12.946655249022182
      ]
    }
  },
  {
    "session": "Haptic Interactions",
    "abstract": "Grain-based compliance illusion mimics the mechanical vibrations when a compliant object deforms with grain-like, short (~15 ms) impulse-response vibrations. Previous work has demonstrated its robust effect on various types of devices. However, the impact of the device's inherent compliance (i.e., base compliance) on perceived compliance remains unclear. This paper investigates the influence of base compliance on the perception of illusory compliance through three psychophysical experiments. The results show that (1) the compliance illusion remained effective with base compliance, (2) the description of compliance was affected by both illusory and base compliance, and (3) it is possible to render the compliance with the same magnitude but multiple different feelings.",
    "title": "Diversifying Grain-Based Compliance Illusion by Varying Base Compliance",
    "id": 189607,
    "sequence": 1397,
    "queryCoordinates": {
      "visualization": [
        13.55624930971166,
        3.4968706943411756
      ]
    }
  },
  {
    "session": "WS14: Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "abstract": "Teens' mobile technology use can help teens connect with one another, but it also raises concerns around overuse, addiction, and exposure to harmful content. Traditional tools and methods for parental controls and guidance for mobile technology use among children, such as screen time limits, often fail to address teens' nuanced experiences on the benefits and harm of their mobile technology use. This workshop brings together interdisciplinary researchers, practitioners, and teen advocates to examine how the CHI community can foster healthy teen mobile-technology relationships. Our goals are to: (1) co-design research agenda, (2) foster cross-sociocultural collaboration, (3) generate guidance for stakeholders (e.g., public, policymakers, parents, healthcare providers), and (4) plan actionable steps for ongoing impact. The workshop will explore themes like engaging broader stakeholders, embracing marginalized voices, and navigating the implications of emerging technologies through panel presentations and interactive sessions. By examining these themes, we aim to re-explore the HCI community's discourse on teen mobile technology use and well-being, fostering a comprehensive understanding and inclusive approaches to navigate the multifaceted challenges in the modern digital landscape in diverse sociocultural contexts. ",
    "title": "Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "id": 189608,
    "sequence": 1398,
    "queryCoordinates": {
      "visualization": [
        -9.427934736519955,
        17.638425286967102
      ]
    }
  },
  {
    "session": "Fabrication Techniques",
    "abstract": "We introduce a novel component for smart garments: smart interlining, and validate its technical feasibility through a series of experiments. Our work involved the implementation of a prototype that employs a textile vibration sensor based on Triboelectric Nanogenerators (TENGs), commonly used for activity detection. We explore several unique features of smart interlining, including how sensor signals and patterns are influenced by factors such as the size and shape of the interlining sensor, the location of the vibration source within the sensor area, and various propagation media, such as airborne and surface vibrations. We present our study results and discuss how these findings support the feasibility of smart interlining. Additionally, we demonstrate that smart interlinings on a shirt can detect a variety of user activities involving the hand, mouth, and upper body, achieving an accuracy rate of 93.9% in the tested activities.",
    "title": "IntelliLining: Activity Sensing through Textile Interlining Sensors Using TENGs",
    "id": 189609,
    "sequence": 1399,
    "queryCoordinates": {
      "visualization": [
        1.1611387090178493,
        3.8277613429288357
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "Risk reporting is essential for documenting AI models, yet only 14% of model cards mention risks, out of which 96% copy content from a small set of cards, leading to a lack of actionable insights. Existing proposals for improving model cards do not resolve these issues. To address this, we introduce RiskRAG, a Retrieval Augmented Generation risk reporting solution guided by five design requirements we identified from literature and co-design with 16 developers: identifying diverse model-specific risks, clearly presenting and prioritizing them, contextualizing for real-world uses, and offering actionable mitigation strategies. Drawing from 450K model cards and 600 real-world incidents, RiskRAG pre-populates contextualized risk reports. A preliminary study with 50 developers showed that they preferred RiskRAG over standard model cards, as it better met all the design requirements. A final evaluation with 38 developers, 40 designers, and 37 media professionals showed that RiskRAG improved the quality of their way of selecting the AI model for a given task, encouraging a more careful and deliberative decision-making.",
    "title": "RiskRAG: A Data-Driven Solution for Improved AI Model Risk Reporting",
    "id": 189610,
    "sequence": 1400,
    "queryCoordinates": {
      "visualization": [
        17.126778248144465,
        12.152097219775923
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "Modern GUIs often have a hierarchical structure, i.e., the z-axis of the GUI interaction space. However, conventional mice do not support effective navigation along the z-axis, leading to increased physical movements and cognitive load. To address this inefficiency, we present the OtMouse, a novel mouse that supports finger-lifting operations by detecting finger height through proximity sensors embedded beneath the mouse buttons, and 'Over the Mouse' (OtM) interface, a set of interaction techniques along the z-axis of the GUI interaction space with the OtMouse. Initially, We evaluated the performance of finger-lifting operations (n = 8) with the OtMouse for two- and three-level lifting discrimination tasks. Subsequently, we conducted a user study (n = 16) to compare the usability of the OtM interface and traditional mouse interface for three representative tasks: 'Context Switch,' 'Video Preview,' and 'Map Zooming.' The results showed that OtM interface was both qualitatively and quantitatively superior to using traditional mouse in the Context Switch and Video Preview tasks. This research contributes to the ongoing efforts to enhance mouse-based GUI navigation experiences.",
    "title": "Over the Mouse: Navigating across the GUI with Finger-Lifting Operation Mouse",
    "id": 189611,
    "sequence": 1401,
    "queryCoordinates": {
      "visualization": [
        1.9585708031874636,
        -15.87967255357936
      ]
    }
  },
  {
    "session": "HCI Methods and Practices",
    "abstract": "Language is more than communication; it is a form of power. Whereas science has been scrutinized for privileging White and western values and norms, what has been less explored is scientific linguistic performance (e.g. writing). The enforcement of English as the “normative standard” has prioritized hegemonic values and assumptions, thereby shaping the expectations of scientific performance. HCI/CSCW is dominated by heteropatriarchal western practices, overlooking entangled values and assumptions impacting non-western colleagues. Our work presents a design fiction (fictitious case study) envisioning a research contribution which embodies non-western linguistic nuances as an alternative “normative standard” for scientific communication. Through this work, not only are we championing care in developing responsible linguistic practices in HCI/CSCW, but also epistemically challenging readers with intentional confusion. We establish a call to action for acknowledging and embracing different writing practices that are more inclusive of the diverse representation of scholars in HCI/CSCW.",
    "title": "The Power of Language: Resisting Western Heteropatriarchal Normative Writing Standards",
    "id": 189612,
    "sequence": 1402,
    "queryCoordinates": {
      "visualization": [
        17.280897378946715,
        5.036922252557858
      ]
    }
  },
  {
    "session": "Artistic View",
    "abstract": "What would linguistic diversity and inclusion look like for Human-Computer Interaction (HCI) research and researchers? As neurotypical and neurodiverse non-native- and native-English researchers, we conduct research in a variety of languages and contexts with diverse user groups and communities, and face several challenges when that research is written, read, reviewed, and published in English. In this paper, we present our first-person reflections on writing for research in English. We have two main goals: (1) to showcase the rich linguistic diversity of HCI research and researchers, and (2) to document challenges of translating socio-culturally nuanced findings and insights into English from other languages. This paper presents our vision of linguistic diversity and inclusion in HCI research at CHI - a mélange of thoughts utilizing diverse vocabularies and languages.",
    "title": "Lost in translation: Researchers’ reflections on writing in English for CHI",
    "id": 189613,
    "sequence": 1403,
    "queryCoordinates": {
      "visualization": [
        18.32375914234272,
        8.01497666206282
      ]
    }
  },
  {
    "session": "Designs for Blind and Low Vision People",
    "abstract": "3D printed models (3DPMs) are increasingly used to support the education of students who are blind or have low vision (BLV). As 3DPMs are more widely-adopted, educators are using more complex multi-part models. However, with this increased complexity comes additional challenges for their use, such as supporting audio labels of multiple parts as well as guiding the assembly and disassembly of the model. This work explores the co-design and evaluation of a system that supports the use of multi-part 3DPMs by BLV students. Working with BLV adults and children, as well as educators, an iPad application was developed to support interaction with an insect model, including speech interaction and support for assembly. Evaluation showed that the system was strongly enjoyed by students and educators were enthusiastic as they believed it would increase classroom engagement and inclusion, and its support for voice annotation could be used for assessment.",
    "title": "Enhancing Tactile Learning: A Co-Designed System for Supporting Speech Interaction with Multi-Part 3D Printed Models by Students who are Blind",
    "id": 189614,
    "sequence": 1404,
    "queryCoordinates": {
      "visualization": [
        12.687865683272912,
        -15.460209067254738
      ]
    }
  },
  {
    "session": "WS22: Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "abstract": "The increasing use of generative AI (GAI) as an accessibility tool offers transformative opportunities, but it also introduces significant risks and barriers that remain unaddressed. This workshop explores the multi-faceted nature of GAI use for accessibility, focusing on its potential to create access solutions where none exist while surfacing the risks of bias, inaccessibility, and misinformation. Our goal is to establish best practices for inclusive GAI design that centers disabled people’s agency, addressing key questions such as how to ensure GAI tools are accessible by default and how to mitigate risks without undermining autonomy. By bringing together experts in accessibility, AI, human-computer interaction (HCI), and disability studies, this workshop aims to develop design guidelines, recommendations, and practices that will influence future GAI systems. Participants will collaboratively define an agenda for creating GAI tools that advance equity, minimize harm, and embrace the diverse needs of the disability community.",
    "title": "Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "id": 189615,
    "sequence": 1405,
    "queryCoordinates": {
      "visualization": [
        -16.14370934758839,
        -7.961196423942019
      ]
    }
  },
  {
    "session": "Vision Accessibility",
    "abstract": "The introduction of Highly Automated Vehicles (HAVs) has the potential to increase the independence of blind and visually impaired people (BVIPs). However, ensuring safety and situation awareness when exiting these vehicles in unfamiliar environments remains challenging. To address this, we conducted an interactive workshop with N=5 BVIPs to identify their information needs when exiting an HAV and evaluated three prior-developed low-fidelity prototypes. The insights from this workshop guided the development of PathFinder, a multimodal interface combining visual, auditory, and tactile modalities tailored to BVIP's unique needs. In a three-factorial within-between-subject study with N=16 BVIPs, we evaluated PathFinder against an auditory-only baseline in urban and rural scenarios. PathFinder significantly reduced mental demand and maintained high perceived safety in both scenarios, while the auditory baseline led to lower perceived safety in the urban scenario compared to the rural one. Qualitative feedback further supported PathFinder's effectiveness in providing spatial orientation during exiting.",
    "title": "Light My Way. Developing and Exploring a Multimodal Interface to Assist People With Visual Impairments to Exit Highly Automated Vehicles",
    "id": 189616,
    "sequence": 1406,
    "queryCoordinates": {
      "visualization": [
        17.994965681044427,
        -8.728184813466843
      ]
    }
  },
  {
    "session": "Security and Safety, Technology and Society",
    "abstract": "Software developing small and medium enterprises (SMEs) play a crucial role as suppliers to larger corporations and public administration. It is therefore necessary for them to be able to demonstrate that their products meet certain security criteria, both to gain trust of their customers and to comply to standards that demand such a demonstration. In this study we have investigated ways for SMEs to demonstrate their security when operating in a business-to-business model, conducting semi-structured interviews (N=16) with practitioners from different SMEs in Denmark and validating our findings in a follow-up workshop (N=6). Our findings indicate five distinctive security demonstration approaches, namely: Certifications, Reports, Questionnaires, Interactive Sessions and Social Proof. We discuss the challenges, benefits, and recommendations related to these approaches, concluding that none of them is a one-size-fits all solution and that more research into relative advantages of these approaches and their combinations is needed.",
    "title": "No Silver Bullet: Towards Demonstrating Secure Software Development for Small and Medium Enterprises in a Business-to-Business Model",
    "id": 189617,
    "sequence": 1407,
    "queryCoordinates": {
      "visualization": [
        -14.927884781355823,
        -5.75832058455981
      ]
    }
  },
  {
    "session": "Shaping Diverse Cognitive Process",
    "abstract": "Advanced Artificial Intelligence (AI) systems, specifically large language models (LLMs), have the capability to generate not just misinformation, but also deceptive explanations that can justify and propagate false information and discredit true information. We examined the impact of deceptive AI generated explanations on individuals' beliefs in a pre-registered online experiment with 11,780 observations from 589 participants. We found that in addition to being more persuasive than accurate and honest explanations, AI-generated deceptive explanations can significantly amplify belief in false news headlines and undermine true ones as compared to AI systems that simply classify the headline incorrectly as being true/false. Moreover, our results show that logically invalid explanations are deemed less credible - diminishing the effects of deception. This underscores the importance of teaching logical reasoning and critical thinking skills to identify logically invalid arguments, fostering greater resilience against advanced AI-driven misinformation.",
    "title": "Deceptive Explanations by Large Language Models Lead People to Change their Beliefs About Misinformation More Often than Honest Explanations",
    "id": 189618,
    "sequence": 1408,
    "queryCoordinates": {
      "visualization": [
        14.627356091256491,
        6.483861024079838
      ]
    }
  },
  {
    "session": "Mental and Emotional Wellbeing",
    "abstract": "The aftermath of industry-wide mass layoffs has led to an increasingly discontent and disillusioned tech workforce. Our empirical study with 29 laid off tech workers presents critical reflections on tech work and the tech industry in the aftermath of mass layoffs. Through weekly creative reflection activities over 5 weeks as well as focus groups, we find that tech workers experience alienation and unfulfillment with their work. Tech workers expressed conflicted emotions in assessing their attachment to tech work as a site of labor, oscillating between discomfort with the current status of the tech industry and lack of agency in choosing alternatives. We argue that tech workers are embroiled in cruelly optimistic relationships with tech work, and trace the implications of this on conflicting sociotechnical imaginaries shaping tech work, affective attachments in the tech industry, and tech worker resistance and organizing.",
    "title": "The Cruel Optimism of Tech Work: Tech Workers' Affective Attachments in the Aftermath of 2022-23 Tech Layoffs",
    "id": 189619,
    "sequence": 1409,
    "queryCoordinates": {
      "visualization": [
        1.9438414392261119,
        7.760250025556352
      ]
    }
  },
  {
    "session": "Automated Vehicles and XR",
    "abstract": "As vehicle automation technology continues to mature, there is a\r\nnecessity for robust remote monitoring and intervention features.\r\nThese are essential for intervening during vehicle malfunctions,\r\nchallenging road conditions, or in areas that are difficult to navigate.\r\nThis evolution in the role of the human operator—from a constant\r\ndriver to an intermittent teleoperator—necessitates the development of suitable interaction interfaces. While some interfaces were\r\nsuggested, a comparative study is missing. We designed, implemented, and evaluated three interaction concepts (path planning, trajectory guidance, and waypoint guidance) with up to four concurrent requests of automated vehicles in a within-subjects study\r\nwith N=23 participants. The results showed a clear preference for\r\nthe path planning concept. It also led to the highest usability but\r\nlower satisfaction. With trajectory guidance, the fewest requests\r\nwere resolved. The study’s findings contribute to the ongoing development of HMIs focused on the remote assistance of automated vehicles.",
    "title": "Introducing ROADS: A Systematic Comparison of Remote Control Interaction Concepts for Automated Vehicles at Road Works",
    "id": 189620,
    "sequence": 1410,
    "queryCoordinates": {
      "visualization": [
        -2.7312645082258014,
        -13.730993925645224
      ]
    }
  },
  {
    "session": "Understanding and Working with Algorithms",
    "abstract": "Algorithmic fairness research often disregards concerns related to systemic injustice. We study how contextualizing algorithms within systemic injustice impacts lay perceptions of algorithmic discrimination. Using the hiring domain as a case-study, we conduct a 2x3 between-participants experiment (N=716), studying how people's views of algorithmic fairness are influenced by information about (i) systemic injustice in historical hiring decisions and (ii) algorithms' propensity to perpetuate biases learned from past human decisions. We find that shedding light on systemic injustice has heterogeneous effects: participants from historically advantaged groups became more negative about discriminatory algorithms, while those from disadvantaged groups reported more positive attitudes. Explaining that algorithms learn from past human decisions had null effects on people's views, adding nuances to calls for improving public understanding of algorithms. Our findings reveal that contextualizing algorithms in systemic injustice can have unintended consequences and show how different ways of framing existing inequalities influence perceptions of injustice.\r\n\r\n",
    "title": "Lay Perceptions of Algorithmic Discrimination in the Context of Systemic Injustice",
    "id": 189621,
    "sequence": 1411,
    "queryCoordinates": {
      "visualization": [
        3.505619842509916,
        -15.611234080616457
      ]
    }
  },
  {
    "session": "Engaging Users for Security and Privacy",
    "abstract": "Even for users of password managers, primary passwords are a common root of trust; these must be secure against offline attacks. Randomly generated passwords provide strength guarantees but are less memorable. Cognitive psychology studies have found that providing a choice aids recall, however no studies have investigated the impact of choice on password recall in isolation. To address this, we conducted a longitudinal user study (N=861 at initial follow-up) where users selected and memorized a password from a list of 1, 8, 32, or 128 random passwords. The users entered their password multiple times after selection to improve memory, and we followed up 7 and 28 days later. We found no evidence that selecting from a list improved memorability, which suggests designers and researchers should explore other avenues. Finally, we identify potential directions for new interfaces that help users generate random passwords that will be easier to use.",
    "title": "Choose From a List: A User Study of Random Password Memorability",
    "id": 189622,
    "sequence": 1412,
    "queryCoordinates": {
      "visualization": [
        5.381236449196127,
        -2.653732141314013
      ]
    }
  },
  {
    "session": "Lessons Learned from Real Experience",
    "abstract": "Many women from diverse cultures seek support in online communities for stigmatized sexual and reproductive health, but often encounter subtle microaggressions that invalidate their experiences and discourage them from seeking care. This study focuses on unmarried Korean women, who face similar challenges in these spaces, often resulting in severe health complications. Through an asynchronous remote focus group with 26 unmarried Korean women, we explored design tensions in developing features to counteract microaggressions in online health communities supporting stigmatized health care. Our findings revealed four key design tensions: balancing content filtering with open communication, promoting personal growth while preserving free expression, providing adaptive support, and encouraging reflection without restricting dialogue. We propose design recommendations to address the design tensions. These tensions, and their proposed resolutions, offer insights for designing provocative prototypes that provide further guidance in creating safer online spaces for supporting stigmatized health care for women.",
    "title": "Exploring Design Tensions in Countering Microaggressions in Online Communities for Stigmatized Health Support",
    "id": 189623,
    "sequence": 1413,
    "queryCoordinates": {
      "visualization": [
        6.539367376890127,
        -17.839189283991164
      ]
    }
  },
  {
    "session": "Living with Dementia or Visual Impairments",
    "abstract": "This paper explores the integration of co-design and art-making in developing technologies that support personhood in dementia care. While technologies for dementia care have advanced, there remains a gap in creating solutions that are directly informed by the experiences of people living with dementia and support their individuality. In collaboration with the specialist arts organisation Bright Shadow CIO, our work involves engaging people living with dementia in the design process. Over five weeks of co-design sessions, 44 participants worked alongside artists to craft four physical boxes that represent ``meaningful places.'' The physical boxes were then transformed into VR environments, allowing participants to immerse themselves in and interact with their creations from a first-person perspective. Our findings demonstrate that VR alone is insufficient in dementia care. For VR to be meaningful, it must be be part of a broader intervention that includes trust-building, sensory engagement, and creative involvement. Within this process, art-making serves as both a method and medium, providing a means of self-expression and connection to identity. Our findings challenge conventional approaches to dementia-focused VR, advocating for a shift toward inclusive and care-driven technology design.",
    "title": "Creating with Care: Co-Designing Immersive Experiences through Art-Making with People Living with Dementia",
    "id": 189624,
    "sequence": 1414,
    "queryCoordinates": {
      "visualization": [
        -10.190426178318951,
        -6.3368142078044105
      ]
    }
  },
  {
    "session": "Vulnerable Populations",
    "abstract": "This paper presents a case study of a community-based participatory design approach to exploring generative AI at a trauma-informed arts center. Through a week-long workshop engagement between Google, UC Irvine, and Homeboy Art Academy, the study investigates how centering marginalized voices can improve AI development and address equity issues. Key findings highlight the importance of insider relationships in building trust, respecting community resourcefulness, and fostering bidirectional relationships. By integrating diverse perspectives early in the development process, this approach aims to create more inclusive and effective AI technologies. The study contributes to our understanding of community-based participatory AI design and offers strategies for responsible engagement with underserved populations in emerging technology development.",
    "title": "Generative Dreams: Rethinking GenAI Design Through a Community-based Approach with Recently Incarcerated, Gang Affiliated, and At-risk Young Adults at a Trauma Informed Arts Center",
    "id": 189625,
    "sequence": 1415,
    "queryCoordinates": {
      "visualization": [
        -7.270985214936701,
        -17.55371111771445
      ]
    }
  },
  {
    "session": "Technology in Education and Academic Practice",
    "abstract": "Surveying prior literature to establish a foundation for new knowledge is essential for scholarly progress. However, survey articles are resource-intensive and challenging to create, and can quickly become outdated as new research is published, risking information staleness and inaccuracy. Keeping survey articles current with the latest evidence is therefore desirable, though there is a limited understanding of why, when, and how these surveys should be updated. Toward this end, through a series of in-depth retrospective interviews with 11 researchers, we present an empirical examination of the work practices in authoring and updating survey articles in computing research. We find that while computing researchers acknowledge the value in maintaining an updated survey, continuous updating remains unmanageable and misaligned with academic incentives. Our findings suggest key leverage points within current workflows that present opportunities for enabling technologies to facilitate more efficient and effective updates.",
    "title": "Toward Living Narrative Reviews: An Empirical Study of the Processes and Challenges in Updating Survey Articles in Computing Research",
    "id": 189626,
    "sequence": 1416,
    "queryCoordinates": {
      "visualization": [
        17.96146061829486,
        -1.1772563261425861
      ]
    }
  },
  {
    "session": "Moving and Looking",
    "abstract": "Modern video games often feature moving target acquisition (MTA) tasks, where users must press a button when a moving target reaches an acquisition line. User performance models in MTA are useful for quantitative skill analysis and computational game level design, but have so far been constructed only for cases where there is a single lane for a target to appear and follow. In this study, the first user performance model is presented and validated for an MTA task with multiple lanes. The model is built as an integration of the existing MTA model and the drift-diffusion model, a model of human decision-making process under time-pressure. In a user study, we showed that the model can fit lane recognition error rates and input timing distributions with significantly higher coefficients of determination ($R^2$) and accuracy than a baseline model.",
    "title": "Modeling User Performance in Multi-Lane Moving-Target Acquisition",
    "id": 189627,
    "sequence": 1417,
    "queryCoordinates": {
      "visualization": [
        5.718219597103946,
        -12.778965710858465
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "We present a methodology for designing an AI feedback system aimed at assisting basketball beginners in refining their shooting techniques during independent practice sessions. Mastering shooting mechanics requires consistent, precise repetition, which traditionally depends on coaching feedback and the breakdown of movements into steps during the early stages. However, due to limited coaching resources, this guidance is often unavailable, leading to ineffective and even detrimental motor learning. To bridge this gap, we propose a Standard Operating Procedure (SOP) framework grounded in expert human knowledge, or knowledge-based SOP, which allows our AI-driven system to verify and guide players' movements in real-time. Through a formative study involving interviews with 13 coaches and players, we identified key challenges faced by beginners, such as uncertainty in movement correctness and lack of guidance during unsupervised practice. Our AI system addresses these issues by providing immediate, actionable feedback using SOP tailored to individual players. In a study with 28 participants, we confirmed that our system improves shooting form, increases confidence in adjustments, and enhances self-awareness during practice. This work highlights the potential of integrating coaching expertise with AI to empower athletes with more effective tools for self-directed practice.",
    "title": "Bridging Coaching Knowledge and AI Feedback to Enhance Motor Learning in Basketball Shooting Mechanics Through a Knowledge-Based SOP Framework",
    "id": 189628,
    "sequence": 1418,
    "queryCoordinates": {
      "visualization": [
        -5.043883547053371,
        18.31827608602306
      ]
    }
  },
  {
    "session": "Digital Health for Diverse Needs",
    "abstract": "As the global population ages, there is increasing need for accessible technologies that promote cognitive health and detect early signs of cognitive decline. This research demonstrates the potential for in-residence monitoring and assessment of cognitive health using large language model (LLM)-powered socially assistive robots (SARs). We conducted a 5-week within-subjects study involving 22 older adults in retirement homes to investigate the feasibility of LLM-powered SARs for promoting and assessing cognitive health. We designed tasks that involved verbal dialogue based on clinically validated cognitive tools. Our findings reveal improved task performance after three robot-administered sessions, with significantly more detailed picture descriptions, fewer word repetitions in semantic fluency, and reduced need for hints. We found that older adults were more socially engaged in robot-administered tasks compared to those administered by a human, and they accepted and were willing to engage with SARs in this context, which had not been tested before.",
    "title": "Promoting Cognitive Health in Elder Care with Large Language Model-Powered Socially Assistive Robots",
    "id": 189629,
    "sequence": 1419,
    "queryCoordinates": {
      "visualization": [
        14.927884781355823,
        -5.758320584559808
      ]
    }
  },
  {
    "session": "Assistive Technologies",
    "abstract": "Generative AI (GenAI) tools promise to advance non-visual information access but introduce new challenges due to output errors, hallucinations, biases, and constantly changing capabilities. Through interviews with 20 blind screen reader users who use various GenAI applications for diverse tasks, we show how they approached information access with everyday uncertainty, or a mindset of skepticism and criticality towards both AI- and human-mediated assistance as well as information itself. Instead of expecting information to be 'correct' and 'complete', participants extracted cues from error-prone information sources; treated all information as tentative; acknowledged and explored information subjectivity; and constantly adjusted their expectations and strategies considering the politics around access. The concept of everyday uncertainty situates GenAI tools among the interconnected assistive applications, humans, and sociomaterial conditions that both enable and hinder the ongoing production of access. We discuss the implications of everyday uncertainty for future design and research.\r\n",
    "title": "Everyday Uncertainty: How Blind People Use GenAI Tools for Information Access",
    "id": 189630,
    "sequence": 1420,
    "queryCoordinates": {
      "visualization": [
        -9.035628526325404,
        6.273549006284608
      ]
    }
  },
  {
    "session": "Neurodiversity",
    "abstract": "Autistic individuals often experience negative self-talk (NST), leading to increased anxiety and depression. While therapy is recommended, it presents challenges for many autistic individuals. Meanwhile, a growing number are turning to large language models (LLMs) for mental health support. To understand how autistic individuals perceive AI's role in coping with NST, we surveyed 200 autistic adults and interviewed practitioners. We also analyzed LLM responses to participants' hypothetical prompts about their NST. Our findings show that participants view LLMs as useful for managing NST by identifying and reframing negative thoughts. Both participants and practitioners recognize AI's potential to support therapy and emotional expression. Participants also expressed concerns about LLMs' understanding of neurodivergent thought patterns, particularly due to the neurotypical bias of LLMs. Practitioners critiqued LLMs' responses as overly wordy, vague, and overwhelming. This study contributes to the growing research on AI-assisted mental health support, with specific insights for supporting the autistic community.",
    "title": "Reimagining Support: Exploring Autistic Individuals' Visions for AI in Coping with Negative Self-Talk",
    "id": 189631,
    "sequence": 1421,
    "queryCoordinates": {
      "visualization": [
        16.454131257784486,
        -4.2733551866887405
      ]
    }
  },
  {
    "session": "Optimization with/for AI",
    "abstract": "There is currently no easy way to look up signs in sign language. Feature-based dictionaries help overcome this challenge by enabling users to look up a sign by inputting descriptive visual features, such as handshape and movement. However, feature-based dictionaries are typically cumbersome, including large numbers of complex features that the user must sort through. In this work, we explore simplifying the set of features used in feature-based American Sign Language (ASL) dictionaries. We present two studies: 1) a simulation study focused on lookup accuracy for various reduced feature sets, and 2) a user study focused on understanding human preferences between feature sets. Our results suggest that it is possible to dramatically reduce the number of features needed to search for signs without significantly impacting the accuracy of search results, and that smaller feature sets can improve the user experience in some cases.",
    "title": "Exploring Reduced Feature Sets for American Sign Language Dictionaries",
    "id": 189632,
    "sequence": 1422,
    "queryCoordinates": {
      "visualization": [
        6.989732362413616,
        -9.754160215099391
      ]
    }
  },
  {
    "session": "Participatory Design and Applications",
    "abstract": "There is a growing interest among researchers to define and promote equitable practices in participatory design (PD). Our work contributes to this research by exploring the values of facilitators with varying professional backgrounds. We conducted interviews with 15 facilitators who are novice in their design background but who possess a range of domain expertise and community memberships. The interviews focused on their experiences leading a series of PD sessions with rural educators, community college instructors, community organization members, and rural librarians. We identified five key values that facilitators saw as fundamental to their PD practice: community and shared culture, co-production of knowledge, respect and non-hierarchy, trust building, and creating practical and sustainable solutions. This study demonstrates how values that are core to PD are refracted through novice facilitators' professional expertise and community membership. We offer two strategies for novice facilitators as they strive to practice more equitable PD.\r\n",
    "title": "Domain Experts, Design Novices: How Community Practitioners Enact Participatory Design Values",
    "id": 189633,
    "sequence": 1423,
    "queryCoordinates": {
      "visualization": [
        -6.457666452124424,
        13.53877926524791
      ]
    }
  },
  {
    "session": "Crowdsourcing and Tech in the Wild",
    "abstract": "The think-aloud (TA) protocol is a useful method for evaluating user interfaces, including data visualizations. However, TA studies are time-consuming to conduct and hence often have a small number of participants. Crowdsourcing TA studies would help alleviate these problems, but the technical overhead and the unknown quality of results have restricted TA to synchronous studies. \r\nTo address this gap we introduce CrowdAloud, a system for creating and analyzing asynchronous, crowdsourced TA studies. CrowdAloud captures audio and provenance (log) data as participants interact with a stimulus. Participant audio is automatically transcribed and visualized together with events data and a full recreation of the state of the stimulus as seen by participants. \r\nTo gauge the value of crowdsourced TA studies, we conducted two experiments: one to compare lab-based and crowdsourced TA studies, and one to compare crowdsourced TA studies with crowdsourced text prompts. Our results suggest that crowdsourcing is a viable approach for conducting TA studies at scale.",
    "title": "Crowdsourced Think-Aloud Studies",
    "id": 189634,
    "sequence": 1424,
    "queryCoordinates": {
      "visualization": [
        5.708926082714819,
        -4.050699073258644
      ]
    }
  },
  {
    "session": "Human-Agent Interaction",
    "abstract": "AI systems powered by large language models can act as capable assistants for writing and editing. In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s). One question that arises in these scenarios is the extent to which AI should be credited for its contributions. We examined knowledge workers' views of attribution through a survey study (N=155) and found that they assigned different levels of credit across different contribution types, amounts, and initiative. Compared to a human partner, we observed a consistent pattern in which AI was assigned less credit for equivalent contributions. Participants felt that disclosing AI involvement was important and used a variety of criteria to make attribution judgments, including the quality of contributions, personal values, and technology considerations. Our results motivate and inform new approaches for crediting AI contributions to co-created work.",
    "title": "Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation",
    "id": 189635,
    "sequence": 1425,
    "queryCoordinates": {
      "visualization": [
        3.8020298280001525,
        -3.2472402416509203
      ]
    }
  },
  {
    "session": "Programming and Software Use",
    "abstract": "This paper presents findings from a thinking-aloud protocol exploring mental models in 28 elementary school math teachers during their initial attempt at composing and testing trigger-action rules for a smart tangible educational device. In the study, two sets of event-driven primitives were implemented in an End-User Development platform for guiding teachers with no programming experience in defining new functions of the device: \"concrete\", based on actual actions performed on the device, and \"abstract\", based on general definitions of events/actions. With a thematic analysis, we identified three different metaphors that drive participants' interaction with the device. We discuss how the metaphors influenced performance and how the order of exposition to the two primitive sets impacted their grasping of the trigger-action logic. Our findings suggest the importance of guiding teachers in assuming effective metaphors for performing End-User Development tasks, to empower them to adopt an active role toward digital devices in education.",
    "title": "“React”, “Command”, or “Instruct”? Teachers’ Mental Models on End-User Development",
    "id": 189636,
    "sequence": 1426,
    "queryCoordinates": {
      "visualization": [
        -1.176205683954725,
        11.942216720066362
      ]
    }
  },
  {
    "session": "AI Ethics and Concerns",
    "abstract": "AI systems are often introduced with high expectations, yet many fail to deliver, resulting in unintended harm and missed opportunities for benefit. We frequently observe significant \"AI Mismatches\", where the system’s actual performance falls short of what is needed to ensure safety and co-create value. These mismatches are particularly difficult to address once development is underway, highlighting the need for early-stage intervention. Navigating complex, multi-dimensional risk factors that contribute to AI Mismatches is a persistent challenge. To address it, we propose an AI Mismatch approach to anticipate and mitigate risks early on, focusing on the gap between realistic model performance and required task performance. Through an analysis of 774 AI cases, we extracted a set of critical factors, which informed the development of seven matrices that map the relationships between these factors and highlight high-risk areas. Through case studies, we demonstrate how our approach can help reduce risks in AI development.",
    "title": "AI Mismatches: Identifying Potential Algorithmic Harms Before AI Development",
    "id": 189637,
    "sequence": 1427,
    "queryCoordinates": {
      "visualization": [
        1.9615705608064609,
        -0.3901806440322565
      ]
    }
  },
  {
    "session": "Perception in VR",
    "abstract": "A core use case for Virtual Reality applications is recreating real-life scenarios for training or entertainment. Promoting physiological responses for users in VR that match those of real-life spectators can maximize engagement and contribute to more co-presence. Current research focuses on visualizations and measurements of physiological data to ensure experience accuracy. However, placebo effects are known to influence performance and self-perception in HCI studies, creating a need to investigate the effect of visualizing different types of data (real, unmatched, and fake) on user perception during event recreation in VR.\r\nWe investigate these conditions through a balanced between-groups study (n=44) of uninformed and informed participants. The informed group was provided with the information that the data visualizations represented previously recorded human physiological data. Our findings reveal a placebo effect, where the informed group demonstrated enhanced engagement and co-presence. Additionally, the fake data condition in the informed group evoked a positive emotional response.",
    "title": "A Placebo Concert: The Placebo Effect for Visualization of Physiological Audience Data during Experience Recreation in Virtual Reality",
    "id": 189638,
    "sequence": 1428,
    "queryCoordinates": {
      "visualization": [
        20.996328379167675,
        0.3926761950489476
      ]
    }
  },
  {
    "session": "Digital Fabrication",
    "abstract": "Users interact with static objects daily, but their preferences and needs may vary. Making the objects dynamic or adaptable requires updating all objects. Instead, we propose a novel wearable interface that empowers users to adjust perceived material properties.\r\nTo explore such wearable interfaces, we design unit cell structures that can be tiled to create surfaces with switchable properties. Each unit can be switched between two states while worn, through an integrated bistable spring and tendon-driven trigger mechanism. Our switchable properties include stiffness, height, shape, texture, and their combinations. Our wearable material interfaces are passive, 3D printed, and personalizable. We present a design tool to support users in designing their customized wearable material properties. We demonstrate several example prototypes, e.g., a sleeve allowing users to adapt to how different surfaces feel, a shoe sole for users walking on different ground conditions, a prototype supporting both pillow and protective helmet properties, or a collar that can be transformed into a neck pillow with variable support. ",
    "title": "Wearable Material Properties: Passive Wearable Microstructures as Adaptable Interfaces for the Physical Environment",
    "id": 189639,
    "sequence": 1429,
    "queryCoordinates": {
      "visualization": [
        -10.696523261502508,
        -9.032407769589224
      ]
    }
  },
  {
    "session": "Agent Design",
    "abstract": "Coding assistants are increasingly leveraged in game design, both generating code and making high-level plans. To what degree can these tools align with developer workflows, and what new modes of human-computer interaction can emerge from their use? We present DreamGarden, an AI system capable of assisting with the development of diverse game environments in Unreal Engine. At the core of our method is an LLM-driven planner, capable of breaking down a single, high-level prompt---a dream, memory, or imagined scenario provided by a human user---into a hierarchical action plan, which is then distributed across specialized submodules facilitating concrete implementation. This system is presented to the user as a garden of plans and actions, both growing independently and responding to user intervention via seed prompts, pruning, and feedback. Through a user study, we explore design implications of this system, charting courses for future work in semi-autonomous assistants and open-ended simulation design.",
    "title": "DreamGarden: A Designer Assistant for Growing Games from a Single Prompt",
    "id": 189640,
    "sequence": 1430,
    "queryCoordinates": {
      "visualization": [
        -13.921391857739383,
        -7.886371075676543
      ]
    }
  },
  {
    "session": "Digital Health and Well-being",
    "abstract": "In the face of intensified datafication and automation in public-\r\nsector industries, frameworks like design justice and the feminist\r\npractice of refusal provide help to identify and mitigate structural\r\nharm and challenge inequities reproduced in digitized infrastruc-\r\ntures. This paper applies those frameworks to emerging efforts\r\nacross the U.S. healthcare industry to automate prior authoriza-\r\ntion - a process whereby insurance companies determine whether\r\na treatment or service is “medically necessary” before agreeing to\r\ncover it. Federal regulatory interventions turn to datafication and\r\nautomation to reduce the harms of this widely unpopular process\r\nshown to delay vital treatments and create immense administrative\r\nburden for healthcare providers and patients. This paper explores\r\nemerging prior authorization reforms as a case study, applying\r\nthe frameworks of design justice and refusal to highlight the in-\r\nherent conservatism of interventions oriented towards improving\r\nthe user experience of extractive systems. I further explore how\r\nthe abolitionist framework of non-reformist reform helps to clarify\r\nalternative interventions that would mitigate the harms of prior\r\nauthorization in ways that do not reproduce or extend the power\r\nof insurance companies. I propose a set of four tenets for non-\r\nreformist design to mitigate structural harms and advance design\r\njustice in a broad set of domains.",
    "title": "“A Bridge to Nowhere”: A Healthcare Case Study for Non-Reformist Design",
    "id": 189641,
    "sequence": 1431,
    "queryCoordinates": {
      "visualization": [
        -11.186146795015487,
        -8.418439278177681
      ]
    }
  },
  {
    "session": "Design",
    "abstract": "Recent work has highlighted the potential of modelling interactive behaviour analogously to natural language. We propose interactive behaviour summarisation as a novel computational task and demonstrate its usefulness for automatically uncovering latent user goals while interacting with graphical user interfaces. We introduce SummAct – a novel hierarchical method to summarise low-level input actions into high-level goals to tackle this task. SummAct first identifies sub-goals from user actions using a large language model and in-context learning. In a second step, high-level goals are obtained by fine-tuning the model using a novel UI element weighting mechanism to preserve detailed context information embedded within UI elements during summarisation. Through a series of evaluations, we demonstrate that SummAct significantly outperforms baseline methods across desktop and mobile user interfaces and interactive tasks by up to 21.9%. We further introduce two exciting example use cases enabled by our method: interactive behaviour forecasting and automatic behaviour synonym identification.",
    "title": "SummAct: Uncovering User Intentions Through Interactive Behaviour Summarisation",
    "id": 189642,
    "sequence": 1432,
    "queryCoordinates": {
      "visualization": [
        21.57727616887107,
        4.291987084354822
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "Digital food journaling can help support reflection and improvement of wellbeing relating to eating habits. However, it is often viewed as burdensome, and abandoned before gaining benefits. Advances in conversational user interfaces (CUIs) have the potential to support people journaling in a natural and interactive manner, but we lack understanding of how people would ideally prefer to use CUIs when journaling. We conducted 33 co-design sessions with 18 participants to ideate CUI interactions supportive of their health goals and in everyday situations. Our findings reveal that participants expect CUIs to be adaptive by learning goals and personal references, and support depth in detail and goal alignment while respecting situational constraints and intent. While participants expressed concern around navigating long-term data solely through conversations, they envisioned that CUIs could provide empathetic, non-judgmental feedback. We discuss opportunities for CUIs to support empathetic food journaling and accountability while following guardrails for delegated tasks.",
    "title": "Foody Talk: Exploring Opportunities for Conversational Food Journaling",
    "id": 189643,
    "sequence": 1433,
    "queryCoordinates": {
      "visualization": [
        11.739952735240914,
        12.295263713085188
      ]
    }
  },
  {
    "session": "Explainable AI",
    "abstract": "The pervasiveness of large language models and generative AI in online media has amplified the need for effective automated fact-checking to assist fact-checkers in tackling the increasing volume and sophistication of misinformation. The complex nature of fact-checking demands that automated fact-checking systems provide explanations that enable fact-checkers to scrutinise their outputs. However, it is unclear how these explanations should align with the decision-making and reasoning processes of fact-checkers to be effectively integrated into their workflows. Through semi-structured interviews with fact-checking professionals, we bridge this gap by: (i) providing an account of how fact-checkers assess evidence, make decisions, and explain their processes; (ii) examining how fact-checkers use automated tools in practice; and (iii) identifying fact-checker explanation requirements for automated fact-checking tools. The findings show unmet explanation needs and identify important criteria for replicable fact-checking explanations that trace the model's reasoning path, reference specific evidence, and highlight uncertainty and information gaps.",
    "title": "Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking",
    "id": 189644,
    "sequence": 1434,
    "queryCoordinates": {
      "visualization": [
        -15.231650878252283,
        11.357676325861576
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "Generative AI in Virtual Reality offers the potential for collaborative object-building, yet challenges remain in aligning AI contributions with user expectations. In particular, users often struggle to understand and collaborate with AI when its actions are not transparently represented. This paper thus explores the co-creative object-building process through a Wizard-of-Oz study, focusing on how AI can effectively convey its intent to users during object customization in Virtual Reality. Inspired by human-to-human collaboration, we focus on three representation modes: the presence of an embodied avatar, whether the AI’s contributions are visualized immediately or incrementally, and whether the areas modified are highlighted in advance. The findings provide insights into how these factors affect user perception and interaction with object-generating AI tools in Virtual Reality as well as satisfaction and ownership of the created objects. The results offer design implications for co-creative world-building systems, aiming to foster more effective and satisfying collaborations between humans and AI in Virtual Reality.",
    "title": "CreepyCoCreator? Investigating AI Representation Modes for 3D Object Co-Creation in Virtual Reality",
    "id": 189645,
    "sequence": 1435,
    "queryCoordinates": {
      "visualization": [
        -9.460156642284703,
        5.6129703636699
      ]
    }
  },
  {
    "session": "In Person Doctoral Consortium",
    "abstract": " My research aims to assess the performance of Artificial intelligence (AI) audits using an equity approach. I explore equity as a guiding value in the deployment of accountability mechanisms to assess compliance with the EU AI Act (AIA). I use feminist theory to conceptualise equity as a translational value between different fields in the AI ecosystem that can foster reliable AI. The research integrate legal, ethical, and technical considerations to develop and validate a framework that ensures the reliability of AI audits while protecting fundamental rights. The methodology includes legal analysis, feminist research, and empirical investigation through co-design and participatory workshops. The research timeline spans three years, with a focus on building a concept of equity, developing indicators for the framework, and collecting inputs from workshops. By leveraging equity as a guiding value, my research aims to develop actionable frameworks useful to the community involved in the AI development and deployment.",
    "title": "Practicing equity in the AI ecosystem: Co-designing solutions for sociotechnical challenges",
    "id": 189646,
    "sequence": 1436,
    "queryCoordinates": {
      "visualization": [
        -10.45076548726043,
        12.115341544103751
      ]
    }
  },
  {
    "session": "Health and Expression Support",
    "abstract": "Despite the prevalence of sleep-tracking devices, many individuals struggle to translate data into actionable improvements in sleep health. Current methods often provide data-driven suggestions but may not be feasible and adaptive to real-life constraints and individual contexts. We present HealthGuru, a novel large language model-powered chatbot to enhance sleep health through data-driven, theory-guided, and adaptive recommendations with conversational behavior change support. HealthGuru's multi-agent framework integrates wearable device data, contextual information, and a contextual multi-armed bandit model to suggest tailored sleep-enhancing activities. The system facilitates natural conversations while incorporating data-driven insights and theoretical behavior change techniques. Our eight-week in-the-wild deployment study with 16 participants compared HealthGuru to a baseline chatbot. Results show improved metrics like sleep duration and activity scores, higher quality responses, and increased user motivation for behavior change with HealthGuru. We also identify challenges and design considerations for personalization and user engagement in health chatbots.",
    "title": "Exploring Personalized Health Support through Data-Driven, Theory-Guided LLMs: A Case Study in Sleep Health",
    "id": 189647,
    "sequence": 1437,
    "queryCoordinates": {
      "visualization": [
        -5.69098016714943,
        -11.688145478950537
      ]
    }
  },
  {
    "session": "Human-AI Collaboration",
    "abstract": "Despite Generative AI (GenAI) systems' potential for enhancing content creation, users often struggle to effectively integrate GenAI into their creative workflows. Core challenges include misalignment of AI-generated content with user intentions (intent elicitation and alignment), user uncertainty around how to best communicate their intents to the AI system (prompt formulation), and insufficient flexibility of AI systems to support diverse creative workflows (workflow flexibility). Motivated by these challenges, we created IntentTagger: a system for slide creation based on the notion of Intent Tags—small, atomic conceptual units that encapsulate user intent—for exploring granular and non-linear micro-prompting interactions for Human-GenAI co-creation workflows. Our user study with 12 participants provides insights into the value of flexibly expressing intent across varying levels of ambiguity, meta-intent elicitation, and the benefits and challenges of intent tag-driven workflows. We conclude by discussing the broader implications of our findings and design considerations for GenAI-supported content creation workflows.",
    "title": "Intent Tagging: Exploring Micro-Prompting Interactions for Supporting Granular Human-GenAI Co-Creation Workflows",
    "id": 189648,
    "sequence": 1438,
    "queryCoordinates": {
      "visualization": [
        -5.3812364491961295,
        2.653732141314008
      ]
    }
  },
  {
    "session": "Personal Data and Ethical Design",
    "abstract": "Digital capturing of memorable personal items is a key way to archive personal memories. Although current digitization methods (e.g., photos, videos, 3D scanning) can replicate the physical appearance of an item, they often cannot preserve its real-world interactivity. We present Interactive Digital Item (IDI), a concept of reconstructing both the physical appearance and, more importantly, the interactivity of an item. We first conducted a formative study to understand users' expectations of IDI, identifying key physical interactivity features, including geometry, interfaces, and embedded content of items. Informed by these findings, we developed InteRecon, an AR prototype enabling personal reconstruction functions for IDI creation. An exploratory study was conducted to assess the feasibility of using InteRecon and explore the potential of IDI to enrich personal memory archives. Results show that InteRecon is feasible for IDI creation, and the concept of IDI brings new opportunities for augmenting personal memory archives.",
    "title": "InteRecon: Towards Reconstructing Interactivity of Personal Memorable Items in Mixed Reality",
    "id": 189649,
    "sequence": 1439,
    "queryCoordinates": {
      "visualization": [
        -0.3920685613182426,
        3.9807389066887877
      ]
    }
  },
  {
    "session": "Mental Well-being",
    "abstract": "As mental health concerns grow among Asian American communities, there is an urgent need for culturally-relevant support. While digital mental health treatments (DMHTs) offer new opportunities for interventions, they have largely been focused on non-minority populations in the U.S. (e.g., Caucasians, females, who are middle-aged). Through co-design sessions with Asian Mental Health Collective (AMHC), this study examines the unique mental health challenges faced by Asian Americans, intergenerational connections and elements of culturally-relevant mental health support. The co-design sessions resulted in two prototypes: A multifunctional community hub, to strengthen connections and resource access, and a storytelling app, for sharing and preserving cultural narratives. These prototypes drew from community co-design sessions to include elements of storytelling, community-centered approaches, and intergenerational engagement in addressing mental health concerns among Asian Americans. Leveraging the heterogeneous and similar cultural experiences among Asian Americans, this paper presents and discusses nuances and considerations for digital mental health technology (DMHT) designs for minority communities.",
    "title": "Healing Through Stories: Co-designing Digital Mental Health with Asian Americans",
    "id": 189650,
    "sequence": 1440,
    "queryCoordinates": {
      "visualization": [
        7.305288156289783,
        -19.68839162942398
      ]
    }
  },
  {
    "session": "Well-being and Data Tracking",
    "abstract": "𝜇EMAs allow participants to answer a short survey quickly with\r\na tap on a smartwatch screen or a brief speech input. The short\r\ninteraction time and low cognitive burden enable researchers to\r\ncollect self-reports at high frequency (once every 5-15 minutes)\r\nwhile maintaining participant engagement. Systems with single\r\ninput modality, however, may carry different contextual biases\r\nthat could affect compliance. We combined two input modalities to\r\ncreate a multimodal-𝜇EMA system, allowing participants to choose\r\nbetween speech or touch input to self-report. To investigate system\r\nusability, we conducted a 7-day field study where we asked 20\r\nparticipants to label their posture and/or physical activity once\r\nevery five minutes throughout their waking day. Despite the intense\r\nprompting interval, participants responded to 72.4% of the prompts.\r\nWe found participants gravitated towards different modalities based\r\non personal preferences and contextual states, highlighting the need\r\nto consider these factors when designing context-aware multimodal\r\n𝜇EMA systems.",
    "title": "Feasibility and Utility of Multimodal Micro Ecological Momentary Assessment on a Smartwatch",
    "id": 189651,
    "sequence": 1441,
    "queryCoordinates": {
      "visualization": [
        16.89332309464452,
        -8.695725088797952
      ]
    }
  },
  {
    "session": "Visualization",
    "abstract": "Judging the similarity of visualizations is crucial to various applications, such as visualization-based search and visualization recommendation systems. Recent studies show deep-feature-based similarity metrics correlate well with perceptual judgments of image similarity and serve as effective loss functions for tasks like image super-resolution and style transfer. We explore the application of such metrics to judgments of visualization similarity. We extend a similarity metric using five ML architectures and three pre-trained weight sets. We replicate results from previous crowdsourced studies on scatterplot and visual channel similarity perception. Notably, our metric using pre-trained ImageNet weights outperformed gradient-descent tuned MS-SSIM, a multi-scale similarity metric based on luminance, contrast, and structure. Our work contributes to understanding how deep-feature-based metrics can enhance similarity assessments in visualization, potentially improving visual analysis tools and techniques. Supplementary materials are available at https://osf.io/dj2ms/.",
    "title": "Seeing Eye to AI? Applying Deep-Feature-Based Similarity Metrics to Information Visualization",
    "id": 189652,
    "sequence": 1442,
    "queryCoordinates": {
      "visualization": [
        15.388741450057195,
        -7.224031878618173
      ]
    }
  },
  {
    "session": "Design for Diverse Physical Interactions",
    "abstract": "Automating the authoring of haptic motion effects, while enabling designers to carefully consider user feelings to provide high-quality user experiences, is crucial for effective multisensory content. We present a motion effect-tuning method that elicits desired perceptual or affective attributes from users watching a video. To this end, we test three modulation methods: (1) Altering the extent of low-frequency motion fluctuations, (2) Changing the motion amplitude in a high-frequency band, and (3) Sampling and interpolating significant motion peaks. Our tuning method transforms an input draft waveform using the modulation techniques to obtain an output motion effect that elicits the goal adjective scores. This method requires two regression models accounting for the effects of motion modulation and audiovisual stimuli, respectively, and we obtain them by conducting perceptual experiments. Lastly, we confirm the method's effectiveness through another user study and explore potential users' feedback and suggestions for future applications through open-ended survey questions.",
    "title": "Automatic Tuning of Haptic Motion Effects to Evoke Specific Feelings in Multisensory Content",
    "id": 189653,
    "sequence": 1443,
    "queryCoordinates": {
      "visualization": [
        -1.148050297095271,
        -2.7716385975338595
      ]
    }
  },
  {
    "session": "Video Making",
    "abstract": "The rise of video generative models that produce high-quality content has made it increasingly difficult to discern video authenticity. AI-extended videos, which mix real-world footage with generative content, pose new challenges in distinguishing real from manipulated segments. AI-extended videos might be utilized to deceive humans, but they also have the capacity to assist video creators and offer people novel video experiences.\r\nDespite these concerns, research on how people recognize and evaluate AI-extended videos remains limited. To address this, we conducted a user study where participants interacted with AI-extended videos on a web-based system, identifying boundaries between raw and generated content, followed by a survey and one-on-one interviews. Our quantitative and qualitative analyses revealed how individuals perceive these videos, the factors influencing their perception, evaluations and attitudes. We believe that these insights will aid the future development of AI-extended video technologies and ecosystems.",
    "title": "Where is the Boundary? Understanding How People Recognize and Evaluate Generative AI-extended Videos",
    "id": 189654,
    "sequence": 1444,
    "queryCoordinates": {
      "visualization": [
        0.3925413946193413,
        -7.990363649641379
      ]
    }
  },
  {
    "session": "Privacy and Safety",
    "abstract": "As autonomous vehicles are being deployed in the field for public use, passengers are interacting with traffic in new ways. In recent years, user experience related to risky traffic interactions has been studied using virtual simulations, desktop studies, and surveys—yet field tests have remained out of reach. In this paper, we present results from a field test of an autonomous urban passenger ferry open to public use. Specifically, we investigate two questions: (i) are passengers' safety perceptions negatively affected by interactions with risky traffic? and (ii) can simulating risky behavior in the field (so-called \"adversarial evaluation\") present a viable way to study user experience? After repeatedly sending a kayaker on a collision course with the ferry (N~=~20 interventions), we sampled naïve passengers about their experiences (intervention group; N~=~37) and compared the result to those who experienced a normal crossing (control group, N~=~178). The results favored the intervention group, which scored higher in safety perception. However, the latter also reported that there is a need for more feedback about the ferry's current state and future intentions to avoid surprises both for passengers and for other traffic. As autonomous vehicles are field-tested and deployed, the study reflects a growing need to test user experience in the operational environment. We discuss implications for design, emphasizing the use of external human-machine interfaces (eHMIs) and special considerations for the maritime domain.",
    "title": "Mind the Kayak! Informing UX Design of Autonomous Vehicles through Edge Case Testing in the Field",
    "id": 189655,
    "sequence": 1445,
    "queryCoordinates": {
      "visualization": [
        -1.950903220161282,
        9.807852804032304
      ]
    }
  },
  {
    "session": "Co-ideation",
    "abstract": "Large shared displays, such as digital whiteboards, are useful for supporting co-located team collaborations by helping members perform cognitive tasks such as brainstorming, organizing ideas, and making comparisons. While recent advancement in Large Language Models (LLMs) has catalyzed AI support for these displays, most existing systems either only offer limited capabilities or diminish human control, neglecting the potential benefits of natural group dynamics. Our formative study identified cognitive challenges teams encounter, such as diverse ideation, knowledge sharing, mutual awareness, idea organization, and synchronization of live discussions with the external workspace. In response, we introduce LADICA, a large shared display interface that helps collaborative teams brainstorm, organize, and analyze ideas through multiple analytical lenses, while fostering mutual awareness of ideas and concepts. Furthermore, LADICA facilitates the real-time extraction of key information from verbal discussions and identifies relevant entities. A lab study confirmed LADICA's usability and usefulness.",
    "title": "LADICA: A Large Shared Display Interface for Generative AI Cognitive Assistance in Co-located Team Collaboration",
    "id": 189656,
    "sequence": 1446,
    "queryCoordinates": {
      "visualization": [
        -1.1758463372162393,
        10.936973319490871
      ]
    }
  },
  {
    "session": "Sports",
    "abstract": "Adaptive sports are crucial for the psychological well-being of individuals with tetraplegia---limited motor function in both arms and legs. TetraSki provides these individuals access to extreme adaptive sports through a power-assisted ski instrument, which an athlete can control independently. While athletes in other sporting contexts commonly use technology to improve their performance, no studies have explored how technology might benefit athletes with tetraplegia when training for adaptive competitive sports like TetraSki. We conducted semi-structured interviews with six TetraSki athletes and four tethers who participated in TetraSki Express 2022, the world's first and only adaptive alpine ski competition for athletes with tetraplegia. Our study provides an in-depth understanding of athletes' and tethers' current practices and challenges while working to improve their performance in this competitive environment, and points to opportunities for self-tracking technologies to support their athletic endeavors better.",
    "title": "Understanding the Training Experiences of Competitive Skiers with Tetraplegia",
    "id": 189657,
    "sequence": 1447,
    "queryCoordinates": {
      "visualization": [
        4.20951775601598,
        -10.162674857624157
      ]
    }
  },
  {
    "session": "Bias and Identity",
    "abstract": "Affirmative consent—or “yes means yes”—was initially devised to mitigate sexual violence stemming from misunderstandings of consent. More recently, HCI research has considered adapting affirmative consent to mitigate nonconsensual acts online. Given that affirmative consent has historically been under-adopted and critiqued as unrealistic in its original context of in-person sexual activity, it is imperative that users be involved in producing guidance for affirmative consent practice in computer-mediated contexts. We report a focus group study about affirmative consent in VR dating with 16 stakeholders identifying as women and/or LGBTQIA+ (demographics at elevated risk of nonconsensual acts). Findings suggest that affirmative consent may be obsolete: participants elucidated several reasons why affirmative consent is impractical, if not impossible, to practice in virtual environments. Participants offered provocations to guide creation of new, inherently computer-mediated consent models for mitigating unwanted acts, posing significant opportunity for HCI to have public health impact.",
    "title": "Saying No to \"Yes Means Yes\": Limitations of Affirmative Consent for Mitigating Unwanted Behavior Online According to Women and LGBTQIA+ Stakeholders",
    "id": 189658,
    "sequence": 1448,
    "queryCoordinates": {
      "visualization": [
        10.437085085210516,
        3.4737954637652746
      ]
    }
  },
  {
    "session": "Risk and Privacy",
    "abstract": "Bystander privacy has become a critical concern amidst the widespread activities of video sharing, engaging billions of users daily. Concerns arise when individuals inadvertently appear in public videos without consent. Existing methods for determining bystander permissions require significant adaptation and modifications by videographers and video sharing platforms, potentially limiting their adoption. This study explores leveraging platform censorship capabilities to enforce bystander privacy. We introduce selfFlag, a type of violative media signal designed to trigger automatic content flagging. Bystanders exhibiting such signals, captured in public videos, can be automatically identified and removed by platforms, thereby indirectly enforcing privacy preferences, primarily through the efforts of bystanders themselves. We conduct thorough measurements on current censorship practices, propose music-based triggering content, and develop an auxiliary tool for videographers to produce high-quality content with privacy compliance.",
    "title": "Bystander Privacy in Video Sharing Era: Automated Consent Compliance through Platform Censorship",
    "id": 189659,
    "sequence": 1449,
    "queryCoordinates": {
      "visualization": [
        12.115341544103755,
        10.450765487260426
      ]
    }
  },
  {
    "session": "XR",
    "abstract": "Text entry for extended reality (XR) is far from perfect, and a variety of text entry techniques (TETs) have been proposed to fit various contexts of use. However, comparing between TETs remains challenging due to the lack of a consolidated collection of techniques, and limited understanding of how interaction attributes of a technique (e.g., presence of visual feedback) impact user performance. To address these gaps, this paper examines the current landscape of XR TETs by creating a database of 176 different techniques. We analyze this database to highlight trends in the design of these techniques, the metrics used to evaluate them, and how various interaction attributes impact these metrics. We discuss implications for future techniques and present TEXT: Text Entry for XR Trove, an interactive online tool to navigate our database.",
    "title": "Text Entry for XR Trove (TEXT): Collecting and Analyzing Techniques for Text Input in XR",
    "id": 189660,
    "sequence": 1450,
    "queryCoordinates": {
      "visualization": [
        3.956074890600414,
        4.511038844873863
      ]
    }
  },
  {
    "session": "WS13: Meta-HCI: First Workshop on Meta-Research in HCI",
    "abstract": "Human-Computer Interaction (HCI) is a rapidly evolving field. It has undergone many changes, and several current challenges deserve more attention from the community. Meta-research – the study of research practices – offers insights into how a field can refine its methodological frameworks, enhance rigor, and address its challenges. We believe CHI deserves a dedicated space for meta-research. This workshop establishes an open space for HCI scholars in the top conference of the field to explore and discuss meta-research in HCI. We are equally focused on the past, present, and future: what we study, how we document it, how we evaluate, and how we distribute our work. Collateral effects such as mounting career pressures to publish always more are interesting, too. Short term results of this workshop include a research roadmap specifically for HCI meta-research. In the long term, we hope to see this workshop be the initial spark to establishing a permanent HCI meta-research community.",
    "title": "Meta-HCI: First Workshop on Meta-Research in HCI",
    "id": 189661,
    "sequence": 1451,
    "queryCoordinates": {
      "visualization": [
        4.97488462074617,
        12.010433922646726
      ]
    }
  },
  {
    "session": "Digital Matters",
    "abstract": "Technology use is always gendered: ideas about a person's abilities shape their approach to technologies and thus their digital agency. Yet, approaches towards fostering digital agency often focus only on competencies, falling short of accounting for the relationality and situatedness of agency. Based on a survey with 411 persons, we assessed gendered stereotype threat and agency-related experiences. We designed a workshop concept for providing spaces for agency exploration. We developed roles that address various gender-related stereotypes and embedded the workshop in a playful sci-fi setting. Through participant observations and group interviews, we analysed its potential. \r\nOur results show the relevance of understanding gendered notions and the need for a nuanced understanding of digital agency beyond dualistic thinking. Addressing stereotypes in digital agency must acknowledge the sociality and relationality of gender. Moreover, gendered aspects of identity can even serve as a basis for playful agency enactment and exploration, particularly through making.",
    "title": "Play It Till You Make It: The Potential of Playful Role Enactment to Foster Digital Agency",
    "id": 189662,
    "sequence": 1452,
    "queryCoordinates": {
      "visualization": [
        19.08741402565643,
        8.75617643798789
      ]
    }
  },
  {
    "session": "Technology for Artistic Expression",
    "abstract": "The use of motion capture in live dance performances has created an emerging discipline enabling dancers to play different avatars on the digital stage. Unlike classical workflows, avatars enable performers to act as different characters in customized narratives, but research has yet to address how movement, improvisation, and perception change when dancers act as avatars. We created five avatars representing differing genders, shapes, and body limitations, and invited 15 dancers to improvise with each in practice and performance settings. Results show that dancers used avatars to distance themselves from their own habitual movements, exploring new ways of moving through differing physical constraints. Dancers explored using gender-stereotyped movements like powerful or feminine actions, experimenting with gender identity. However, focusing on avatars can coincide with a lack of continuity in improvisation. This work shows how emerging practices with performance technology enable dancers to improvise with new constraints, stepping outside the classical stage.",
    "title": "\"Becoming My Own Audience\": How Dancers React to Avatars Unlike Themselves in Motion Capture-Supported Live Improvisational Performance.",
    "id": 189663,
    "sequence": 1453,
    "queryCoordinates": {
      "visualization": [
        -3.4737954637652764,
        -10.437085085210516
      ]
    }
  },
  {
    "session": "Working with AI (or not)",
    "abstract": "Providing accurate and actionable advice about phishing emails is challenging. The majority of advice is generic and hard to implement. Phishing emails that pass through filters and land in user inboxes are usually sophisticated and exploit differences between how humans and computers interpret emails. Therefore, users need accurate and relevant guidance to take the right action. This study investigates the effectiveness of guidance based on features extracted from emails, which even in AI-driven systems can sometimes be inaccurate, leading to poor advice. We examined three conditions: control (generic advice), perfect advice, and realistic advice, through an online survey of 489 participants on Prolific, and measured user accuracy and confidence in phishing detection with and without guidance. Our findings indicate that having advice specific to the email is more effective than generic guidance (control). Inaccuracies in the guidance can also impact user decisions and reduce detection accuracy.",
    "title": "Judging Phishing Under Uncertainty: How Do Users Handle Inaccurate Automated Advice?",
    "id": 189664,
    "sequence": 1454,
    "queryCoordinates": {
      "visualization": [
        -5.372471638776149,
        -5.927609002839671
      ]
    }
  },
  {
    "session": "HCI Methods",
    "abstract": "Researchers ask a lot from their study participants: data, time, attention, ideas, and (almost) anything that helps them to pursue their research goals. But what do they give back? This question becomes especially critical in longer-term participatory research with low-resourced communities. This paper offers methodological reflections on a collaboration with a Men’s Shed that was tailored around both my research agenda and the interests of my community partner. As part of my research, we designed a booklet that eventually became their promotion brochure. By reviewing both the trouble and the gains of this process for both partners, I argue for re-imagining community-based participatory research as an opportunity for fostering give-and-take relationships with participants. The case demonstrates the method's capacity to critically extend existing HCI work on Men’s Sheds while also making participation worthwhile for my partners. The careful documentation of this process contributes methodological nuance to discussions around configuring participation.",
    "title": "Configuring Participatory Research as Give and Take Relationships: Methodological Reflections on Co-Designing Booklets with a Men Shed",
    "id": 189665,
    "sequence": 1455,
    "queryCoordinates": {
      "visualization": [
        1.1725435631331553,
        6.901097129627651
      ]
    }
  },
  {
    "session": "Writing Support and Content Moderation",
    "abstract": "Much of the research in online moderation focuses on punitive actions. However, emerging research has shown that positive reinforcement is effective at encouraging desirable behavior on online platforms. We extend this research by studying the ``creator heart'' feature on YouTube, quantifying their primary effects on comments that receive hearts and on videos where hearts have been given out by creators. Overall, creator hearts increased creator agency over feed presentation in YouTube comments sections, and also served as an incentive mechanism to drive user engagement. We find that creator hearts increased the visibility of comments, and increased the amount of positive engagement they received from other users. We also find that the presence of a creator-hearted comment soon after a video is published can incentivize viewers to comment, increasing the total engagement with the video over time. We discuss how creators can use hearts to shape behavior in their communities by highlighting, rewarding, and incentivizing desired behaviors from users. We discuss avenues for extending our study to understanding positive signals from moderators and curators on other platforms.",
    "title": "Creator Hearts: Investigating the Impact Positive Signals from YouTube Creators in Shaping Comment Section Behavior",
    "id": 189666,
    "sequence": 1456,
    "queryCoordinates": {
      "visualization": [
        4.251474431534606,
        -13.338851718120548
      ]
    }
  },
  {
    "session": "Decision Making",
    "abstract": "This case study presents our user-centered design model for Socially Intelligent Agent (SIA) development frameworks through our experience developing Estuary, an open source multimodal framework for building low-latency real-time socially interactive agents. We leverage the Rapid Assessment Process (RAP) to collect the thoughts of leading researchers in the field of SIAs regarding the current state of the art for SIA development as well as their evaluation of how well Estuary may potentially address current research gaps. We achieve this through a series of end-user interviews conducted by a fellow researcher in the community. We hope that the findings of our work will not only assist the continued development of Estuary but also guide the development of other future frameworks and technologies for SIAs.",
    "title": "Optimizing SIA Development: A Case Study in User-Centered Design for Estuary, a Multimodal Socially Interactive Agent Framework",
    "id": 189667,
    "sequence": 1457,
    "queryCoordinates": {
      "visualization": [
        -4.289291617583284,
        20.557285263850616
      ]
    }
  },
  {
    "session": "Innovative Learning Apporaches",
    "abstract": "In addition to trained work skills, employed individuals with intellectual disabilities (IDs) possess unique competencies that are often insufficiently supported or overlooked by both themselves and their work environments. This study proposes using reflective practices to help employees with IDs and employers rediscover competencies beyond job-related skills. To facilitate participation, we employed personalized crafting with iron beads, supported by a custom-developed application integrated with text-to-image generative AI. We conducted two workshops involving 5–7 employees with IDs to explore and enhance our approach to competency discovery. In the first workshop, facilitators manually created templates for participants, while in the second, we leveraged an AI-assisted application for self-creation of personalized templates. Findings from group discussions reveal  (1) the development of a framework that positions AI-enhanced crafting activities as an effective way for uncovering and fostering competencies, and (2) insights into reflection on self-concept as a foundation for competency development.",
    "title": "A Reflective Journey for Individuals with Intellectual Disabilities: Rediscovering Competency Through AI-Enhanced Iron Beads Crafting",
    "id": 189668,
    "sequence": 1458,
    "queryCoordinates": {
      "visualization": [
        -7.913412079718247,
        -1.173843795642896
      ]
    }
  },
  {
    "session": "Future of HCI and Research Practices",
    "abstract": "Science is a complex system comprised of many scientists who individually make decisions that, due to the size and nature of the academic system, largely do not affect the system as a whole. However, certain decisions at the meso-level of research communities, such as the Human-Computer Interaction (HCI) community, may result in deep and long-lasting behavioral changes in scientists. In this article, we provide empirical evidence on how a change in editorial policies introduced at the ACM CHI Conference in 2016 destabilized the CHI research community and launched it on an expansive path, denoted by a year-by-year increase in the mean number of references included in CHI articles. If this near-linear trend continues undisrupted, an article at CHI 2030 will include on average almost 130 references. The trend toward more citations reflects a citation culture where quantity is prioritized over quality, contributing to both author and peer reviewer fatigue. Our exploratory analysis highlights the profound impact of meso-level policy adjustments on the evolution of scientific fields and disciplines, urging all stakeholders to carefully consider the broader implications of such changes.",
    "title": "Past, Present, and Future of Citation Practices in HCI",
    "id": 189669,
    "sequence": 1459,
    "queryCoordinates": {
      "visualization": [
        8.728184813466836,
        -17.994965681044434
      ]
    }
  },
  {
    "session": "Global and Transdisciplinary Perspectives on Dark Patterns and Deceptive Design Practice",
    "abstract": "Dark patterns and deceptive designs (DPs) refer to user interfaces (UIs) that trick people into interactions that benefit the service providers. Today, academic research, legal action, and media coverage has raised awareness among a diversity of stakeholders worldwide. Yet, the lens has focused on Western and English contexts. We propose a Special Interest Group (SIG) that centres on cross-cultural and interdisciplinary engagement. The organizing team, who hail from a plurality of nations and disciplines, will spark discussion by sharing their knowledge—findings, frameworks, methods, and tools—and culturally-sensitive perspectives on deception in modern digital products and services. Attendees will participate in a small group drawing activity, whereby culturally-specific DPs and disciplinary perspectives can be surfaced and communicated without reliance on a specific language or cultural frame. This SIG is expected to draw in a diversity of designers, researchers, security experts, and legal scholars concerned about ethical design practice.",
    "title": "Global and Transdisciplinary Perspectives on Dark Patterns and Deceptive Design Practice",
    "id": 189750,
    "sequence": 1460,
    "queryCoordinates": {
      "visualization": [
        -13.398003232593183,
        -16.17076094002452
      ]
    }
  },
  {
    "session": "Wearable Bio-HCI: Challenges & Opportunities",
    "abstract": "Biological Human-Computer Interaction (Bio-HCI) investigates the dynamic relationship between humans, computers, and biological systems. There has been a growing interest in integrating biological components into wearable human-computer interactions to expand their functional capabilities, material options, and design processes. Researchers have explored novel systems such as biofluid sensing for personal health, sustainable fabrication practices using biomaterials for creating wearables, and integrating living matter into wearable forms. However, as a rapidly growing, multidisciplinary field, Wearable Bio-HCI faces unique challenges and opportunities that demand collective efforts from a diverse group of researchers and practitioners. In this special interest group, we aim to gather researchers who are in this field or interested in integrating Bio-HCI approaches for creating novel interactive wearables. Our goal is to identify, brainstorm, and discuss challenges and opportunities that are unique to wearable Bio-HCI explorations. We aim to generate ideas on community engagement and cross-disciplinary collaboration for future research.",
    "title": "Wearable Bio-HCI: Challenges & Opportunities",
    "id": 189751,
    "sequence": 1461,
    "queryCoordinates": {
      "visualization": [
        1.1768864359176647,
        -14.953760005996921
      ]
    }
  },
  {
    "session": "Bidirectional Human-AI Alignment: Emerging Challenges and Opportunities",
    "abstract": "Recent advancements in general-purpose AI have highlighted the urgent need to align AI systems with the goals, ethical principles, and values of individuals and society. Existing alignment research has been primarily approached as an AI-centered, static, and uni-\r\ndirectional process. However, this unidirectional perspective falls short of taking into account the dynamic and evolving interaction between humans and AI, necessitating a shift toward a bidirectional, interconnected mode of human-AI alignment. This SIG aims\r\nto outline the emerging areas of bidirectinoal human-AI alignment research, propose a blueprint of future goals and challenges for fundamental alignment research, and establish a shared platform to bring together experts from HCI, AI, social sciences, and more to\r\nadvance interdisciplinary research and collaboration on human-AI alignment.",
    "title": "Bidirectional Human-AI Alignment: Emerging Challenges and Opportunities",
    "id": 189752,
    "sequence": 1462,
    "queryCoordinates": {
      "visualization": [
        15.231650878252278,
        -11.357676325861583
      ]
    }
  },
  {
    "session": "Challenges and Opportunities in the Responsible Use of AI and Human-Computer Interaction",
    "abstract": "The use of Artificial Intelligence (AI) is fraught with ethical challenges. Despite potential promises to enhance human abilities and increase how Human-Computer Interaction (HCI) utilizes human-centered inputs, issues arise wherein AI or its outputs violate human norms. In response, academic, industrial, and military researchers have sought to understand how to best develop, test, and use AI technologies in ways that are consistent with our ideals, values, and morals. Fields of inquiry, such as machine ethics, have burgeoned as a result. Yet, moral and ethical challenges associated with AI and HCI persist. HCI requires considering ethics for better human-centered design, yet remains limited without a more inclusive ethical scientific foundation. The current panel brings together diverse perspectives in discussing issues associated with the responsible use of AI and HCI. The participants, along with the expert panelists, will play a key role in shaping the direction of the conversation thought active participation.  ",
    "title": "Challenges and Opportunities in the Responsible Use of AI and Human-Computer Interaction",
    "id": 189753,
    "sequence": 1463,
    "queryCoordinates": {
      "visualization": [
        -3.827761342928835,
        1.161138709017851
      ]
    }
  },
  {
    "session": "Transforming Human-AI Collaboration using \"Large Whatever Models\" (LWMs)",
    "abstract": "This Special Interest Group (SIG) focuses on re-imagining Human-AI collaboration in the age of off-the-shelf generative AI technologies reflecting the growing integration of AI into daily life and societal systems. The SIG addresses human-AI collaboration at three levels: interaction, collaboration, and symbiosis. Key topics include designing systems that adapt to human contexts, re-imagining collaboration interfaces, fostering inclusive urban environments, and balancing technological governance with equitable access. We also pose the question: what is the next big thing after GenAI to enhance collective intelligence, and societal equity and empower people? Our goal here is to build a sustainable, specialized, and interdisciplinary community beyond the scope of the SIG that focuses on creating a sustainable, equitable global impact through augmenting human capabilities with efficient, safe, and trustworthy collaborations with AI systems.",
    "title": "Transforming Human-AI Collaboration using “Large Whatever Models” (LWMs)",
    "id": 189754,
    "sequence": 1464,
    "queryCoordinates": {
      "visualization": [
        -17.280897378946715,
        -5.036922252557856
      ]
    }
  },
  {
    "session": "The Churns and Turns of HCI",
    "abstract": "The ACM Conference on Human Factors in Computing Systems (CHI) is the premier venue for research in Human-Computer Interaction (HCI). 11,290 full papers have been published and collectively cited almost one million times. Highly cited papers undoubtedly represent influential work, affecting the creation of review standards and conference submission and acceptance practices within and beyond CHI. However, the factors contributing to high citation counts and what constitutes a highly cited CHI paper remain largely unclear. In this panel discussion, we will engage the CHI community in exploring the relationship between paper characteristics, citation numbers, and effective impact on HCI as a discipline, and on HCI as an influential endeavour in technology design and development. To ground this discussion, we present findings from a literature review of the 100 most cited CHI full papers, looking at past and present fields and subfields of influence. We will also share insights from HCI experts. Our goals are to shed light on the meaning of impactful work at CHI and in HCI more broadly, to reflect on key trends in HCI over the years, and to discuss themes that have driven pivotal shifts in HCI research. We will lead the conversation toward a deeper understanding of citation practices, the role of citations in focusing and driving HCI research, and the implications of citation when it comes to shaping what is considered impactful HCI.",
    "title": "The Churns and Turns of HCI: Which CHI Papers Make the Most Impact in an Ever-growing Sea of HCI Publications",
    "id": 189755,
    "sequence": 1465,
    "queryCoordinates": {
      "visualization": [
        -14.24312413777219,
        9.280808951595285
      ]
    }
  },
  {
    "session": "Barriers to Implementation of Accessibility Research in Industry Practice – and Vice Versa",
    "abstract": "As public policy advances the rights of people with disabilities, and as corporations begin to recognize disabled people as core market segments, industry practice in accessible technology design and development improves day by day.  Yet, as with other research domains there are lags and gaps in the implementation of accessibility between the lab and industry practice. In this panel, we describe multiple barriers to collaboration between academia and industry and how these barriers manifest as issues in implementation of research findings in industry and lack of adoption of best practices in academia, and vice versa. We then discuss how these specific cases complicate the imagined divide between academic and industry approaches to accessibility. How can notions of accessibility be expanded in both contexts to include overlooked dimensions like ethics, dark patterns, and cognition? This discussion moves towards more inclusive, impactful, and actionable accessibility practices across industry, academia, and public policy.",
    "title": "Panel: Barriers to Implementation of Accessibility Research in Industry Practice – and Vice Versa",
    "id": 189756,
    "sequence": 1466,
    "queryCoordinates": {
      "visualization": [
        -12.071118839071433,
        -15.94641307545414
      ]
    }
  },
  {
    "session": "Beyond Deficit-Based Design",
    "abstract": "Design practice and inquiry is often motivated by a perceived problem or deficit of a community in question, with attempts to \"fix\" or \"improve\" these communities according to dominant group standards. Such approaches frequently fail to meet community needs and risk causing unintended harm to the target populations. While co-creation methodologies show promise for facilitating more equitable collaborations between researchers and communities, their implementation and implications remain complex and challenging. In this panel, we bring together scholars, practitioners, and researchers to examine the potential of co-creation approaches for meaningful and equitable engagement. Through focused discussion on challenging deficit narratives and pursuing inclusive design practices, we aim to build a community of practice and chart future directions for ethical community-centered design.",
    "title": "Beyond Deficit-Based Design: Re-imagining Co-Creation Approaches with Underrepresented Groups",
    "id": 189757,
    "sequence": 1467,
    "queryCoordinates": {
      "visualization": [
        11.640574572235634,
        7.7779832622744305
      ]
    }
  },
  {
    "session": "Technoskepticism or Justified Caution?",
    "abstract": "Recent advances in AI provide a unique opportunity to reshape mental health care systems and practices. However, there remains considerable skepticism that AI will positively impact the futures of patients, workers, and technologies. An interdisciplinary approach toward design and development of human-centered AI is necessary, yet discussions about the future of mental health work are often stratified by discipline (e.g., clinical vs. HCI research) or mental health domain (i.e., PTSD, depression, etc.). With this panel, we will bring together HCI, AI, organizational, and clinical researchers and practitioners to focus on the future of patients, workers, and AI-based technology in mental health care. We will discuss current challenges associated with mental health care AI across diverse clinical domains. This panel aims to move toward common ground for the future of human-centered AI in mental health work among those spanning perspectives from technoskepticism to justified caution.",
    "title": "Technoskepticism or Justified Caution? The Future of Human-Centered AI in Mental Health Care",
    "id": 189758,
    "sequence": 1468,
    "queryCoordinates": {
      "visualization": [
        -5.028704099521597,
        -16.23921596258436
      ]
    }
  },
  {
    "session": "Human Subjects Research in the Age of Generative AI",
    "abstract": "Rapid advances in generative artificial intelligence suggest new possibilities for how human subjects research can be conducted in HCI studies. The panel invites both computer and social scientists to discuss future directions for applying simulated responses from large language models (LLM) for human subjects research. We discuss current challenges and opportunities in LLM simulations and brainstorm how insights across different disciplines might inform breakthroughs. We pay close attention to when and how applications of LLM simulations might augment human subjects research instead of steering it toward unintended directions. Discussions from the panel will provide preliminary ideas for when and how HCI researchers can apply LLM simulations to human subjects research pipelines. Through this engagement, we also aim to build a research community with shared interests.",
    "title": "Human Subjects Research in the Age of Generative AI: Opportunities and Challenges of Applying LLM-Simulated Data to HCI Studies",
    "id": 189759,
    "sequence": 1469,
    "queryCoordinates": {
      "visualization": [
        6.788007455329418,
        7.343225094356855
      ]
    }
  },
  {
    "session": "Forging an HCI Research Agenda with Artists Impacted by Generative AI",
    "abstract": "Alongside the proliferation of commercial generative AI products in the past two years, HCI research focused on the usage of such tools has been conducted at a remarkable volume. This new area of study has been critical to various degrees of the systems which create and uphold these technologies. However, as the deployment of generative AI products has engendered many observable harms, HCI work in this area is now more relevant than ever. While thoughtful research can uncover and promote symbiotic applications of AI technologies, uncritical work can contribute to normalization of harmful uses, skew public perception of technologies, or serve to advance business interests.\r\n  \r\nThe aim of this panel is to revisit the attitudes the HCI community holds towards generative AI and provide a forum to interact with an industry that has seen the first upheavals caused by this technology, the creative arts.",
    "title": "Forging an HCI Research Agenda with Artists Impacted by Generative AI",
    "id": 189760,
    "sequence": 1470,
    "queryCoordinates": {
      "visualization": [
        18.963487670851492,
        -1.1773424979433107
      ]
    }
  },
  {
    "session": "Regenerative Material Ecologies in HCI",
    "abstract": "Regenerative thinking is gaining momentum in HCI, shifting the focus from merely mitigating environmental harm to actively fostering cohabitation within more-than-human ecosystems. This shift challenges HCI researchers to develop new methodologies that engage with both material and cultural regeneration—harnessing the regenerative capacities of ecologies while preserving valuable knowledge systems. It also underscores the need for a fundamental onto-epistemological shift beyond anthropocentric notions of sustainability. To support HCI researchers in adopting regenerative approaches while addressing these challenges, this panel brings together a diverse group of design researchers working hands-on with materials ranging from biological to algorithmic. Through concrete examples and actionable insights, the panelists provide practical guidance on engaging with regenerative material ecologies. By interweaving multiple perspectives through a diffractive approach, the panel also explores the opportunities this emerging perspective offers for HCI, particularly at the intersection of sustainability, posthumanism, and decoloniality.",
    "title": "Regenerative Material Ecologies in HCI",
    "id": 189761,
    "sequence": 1471,
    "queryCoordinates": {
      "visualization": [
        17.654135047258148,
        3.5116257962903084
      ]
    }
  },
  {
    "session": "Bridging Gaps in HCI",
    "abstract": " Asia's Human-Computer Interaction (HCI) landscape is rapidly evolving, yet it faces distinct challenges in curriculum development, research establishment, and career navigation. This panel discussion, hosted by Asia SIGCHI Committee (ASC) at CHI2025, will bring together distinguished experts to address these challenges and explore strategies for fostering a robust and inclusive HCI community in Asia. Panelists will discuss the integration of culturally relevant content in HCI education, approaches to enhancing research visibility on international platforms, and initiatives to bridge gaps between academic training and industry expectations. Through an engaging discussion and audience interaction, the panel aims to identify actionable solutions, promote collaboration, and inspire future initiatives that strengthen HCI’s growth across the region. Participants will gain valuable insights into overcoming systemic barriers while building sustainable and impactful HCI programs tailored to Asia's unique sociocultural dynamics. This panel seeks to advance the global relevance and contributions of HCI in Asia.",
    "title": "Bridging Gaps in HCI: Advancing Education, Research, and Careers in Asia",
    "id": 189762,
    "sequence": 1472,
    "queryCoordinates": {
      "visualization": [
        -10.190426178318942,
        6.336814207804421
      ]
    }
  },
  {
    "session": "Beyond Culture: Centering Power, Reciprocity, and Justice in HCI and Mental Health Research",
    "abstract": "Mental health concerns are globally widespread, with most individuals in need never receiving care. Researchers in Human-Computer Interaction (HCI) have investigated how technology might connect people to care, emphasizing that mental health technologies must be considerate of structural factors (such as culture, power, and justice) for digital interventions to be acceptable and effective. In this Special Interest Group (SIG), we convene researchers at the intersection of HCI and mental health to engage in collaborative ideation around how mental health technologies could tangibly integrate considerations of power, reciprocity, and justice. Through guided discussions, we will consider who digital mental health technologies are built for, what users immediately get from HCI and mental health research, and how technologies can balance being personalized while being scalable. We hope to lay the foundation for concrete guidelines around how technology and mental health researchers can be considerate of structural and cultural factors. ",
    "title": "Beyond Culture: Centering Power, Reciprocity, and Justice in HCI and Mental Health Research",
    "id": 189763,
    "sequence": 1473,
    "queryCoordinates": {
      "visualization": [
        16.36669237869269,
        -14.701407435386677
      ]
    }
  },
  {
    "session": "Anime SIG: Researching Japanese Animation From Technical, Cultural, and Industrial Perspectives",
    "abstract": "Japanese animation, or anime for short, has attracted global attention with its immense international growth. Despite its popularity, academic research has been limited to media studies, with grand questions like ``what is anime,'' i.e., observational and analytical perspectives, and more recently in computer science from the perspective of ``how to generate the anime look,'' focusing on representing visual characteristics with computer vision and machine learning methods. This Special Interest Group (SIG) aims to deepen this multifaceted cultural phenomenon from multidisciplinary perspectives, including ``who'' makes anime, ``how'' creativity support tools can aid the process, and ``what'' about non-visual aspects like anime voices. Organized by experts from industry and academia, this SIG invites participants to the emerging area of anime research and aims to open up a new alley for human-computer interaction (HCI) research through collective discussion on potential directions and community fostering of anime-interested researchers.",
    "title": "Anime SIG: Researching Japanese Animation From Technical, Cultural, and Industrial Perspectives",
    "id": 189764,
    "sequence": 1474,
    "queryCoordinates": {
      "visualization": [
        -15.388413672113039,
        9.337918646889385
      ]
    }
  },
  {
    "session": "Unanticipated Lessons from Communities: Navigating Society-CenteredResearch in the AI Era",
    "abstract": " As AI technologies increasingly integrate into daily life, their deployment often overlooks the complexities of the communities they aim to serve. This gap is particularly acute for marginalized communities, where AI can exacerbate inequalities due to techno-solutionism – the tendency to frame technology as a one-size-fits-all solution. This Special Interest Group (SIG) will explore unexpected lessons from community-led AI initiatives, emphasizing strategies for meaningful collaboration, shared ownership, and equitable partnerships. Through discussions and storytelling, the SIG aims to advance community-centered approaches to AI development and foster a robust, sustained network of researchers and practitioners.",
    "title": "Unanticipated Lessons from Communities: Navigating Society-CenteredResearch in the AI Era",
    "id": 189765,
    "sequence": 1475,
    "queryCoordinates": {
      "visualization": [
        -6.483861024079846,
        -14.627356091256488
      ]
    }
  },
  {
    "session": "Designing for Neurodiversity in Academia: Addressing Challenges and Opportunities in Human-Computer Interaction",
    "abstract": "Academia is primarily structured around neurotypical norms, posing significant challenges for neurodivergent academics, who often face additional barriers that hinder their success. This Special Interest Group (SIG) examines the experiences of neurodiverse researchers in Human-Computer Interaction and explores how HCI can contribute to more inclusive academic environments. By bringing together HCI researchers, neurodiverse academics, and allies, this SIG aims to develop strategies for a more neurodivergent-inclusive, affirming, and supportive academic landscape. Since enhanced well-being can boost productivity, addressing these challenges may unlock greater research output and contributions, particularly by harnessing the talent and creativity of neurodivergent individuals. We will focus on challenges faced across career stages and roles (from students to senior academics, research to teaching staff), and explore the role of technology in academia — assessing how it alleviates and exacerbates barriers. Additionally, we aim to critically examine how policies and governance within the HCI community impact neurodiversity inclusion.",
    "title": "Designing for Neurodiversity in Academia: Addressing Challenges and Opportunities in Human-Computer Interaction",
    "id": 189766,
    "sequence": 1476,
    "queryCoordinates": {
      "visualization": [
        19.811386808871546,
        -2.7402468336393633
      ]
    }
  },
  {
    "session": "Co-Creating Equity Initiatives: Community Accountability and Volunteer Training for Safer Conferences",
    "abstract": "This SIG will be hosted by the SIGCHI Equity Committee and will aim to co-create an improved Equity Volunteer Training Program, focusing on community accountability and fostering safer conference environments. Building on previous equity initiatives, this session will facilitate opportunities for informal yet structured discussions about the evolving needs of conference equity, especially as it pertains to fostering safer environments for all attendees. We aim to leverage the diverse experiences of attendees to refine the role of Equity Volunteers, inform discussions of common intervention scenarios, and establish practical strategies that promote safety, inclusion, and community accountability at conferences. The outcome will be a strengthened training framework that empowers Equity Volunteers with actionable tools to enhance conference safety and inclusivity. This SIG will foster community building, dialogue, and actionable outcomes to create a shared understanding of equity challenges and possibilities for Equity Volunteers within SIGCHI.",
    "title": "Co-Creating Equity Initiatives: Community Accountability and Volunteer Training for Safer Conferences",
    "id": 189767,
    "sequence": 1477,
    "queryCoordinates": {
      "visualization": [
        -0.39262899386131245,
        11.993575049716387
      ]
    }
  },
  {
    "session": "SIG PhysioCHI: Human-Centered Physiological Computing in Practice",
    "abstract": "In recent years, integrating physiological signals in Human-Computer Interaction research has significantly advanced our understanding of user experiences and interactions. However, the interdisciplinary nature of this research presents numerous challenges, including the need for standardized protocols and reporting guidelines. By fostering cross-disciplinary collaboration, we seek to enhance the reproducibility, transparency, and ethical considerations of physiological data in HCI. The purpose of this SIG is to offer a lightweight opportunity for CHI attendees to connect with the community around the center point of physiological computing. This SIG will address key topics such as technical challenges, ethical implications, reproducibility, and open science. We aim to meet as a community and connect with HCI researchers and practitioners to network and exchange bi-directional ideas. Ultimately, our goal is to create a foundation for future research and to establish a community around physiological computing.",
    "title": "SIG PhysioCHI: Human-Centered Physiological Computing in Practice",
    "id": 189768,
    "sequence": 1478,
    "queryCoordinates": {
      "visualization": [
        2.6537321413140074,
        5.38123644919613
      ]
    }
  },
  {
    "session": "Conducting Ethical Research on Emerging Technologies for Children",
    "abstract": "This SIG will provide child-computer interaction researchers and practitioners, as well as other interested CHI attendees, an opportunity to discuss topics related to conducting ethical research on emerging technologies for children. While the community has extensively debated on ethical issues, we have not had ample discussion of how to ethically manage research on emerging technologies, often designed for adults, that may also be used by children or affect children. More specifically, we would like to discuss ethical aspects related to motivations for research, how research is conducted, and how it is reported. We hope these discussions will go well beyond legal requirements from ethics boards and help provide foundational guidance for research on emerging technologies with children, but also inform similar research with other vulnerable communities. ",
    "title": "Conducting Ethical Research on Emerging Technologies for Children",
    "id": 189769,
    "sequence": 1479,
    "queryCoordinates": {
      "visualization": [
        16.778236307100176,
        2.7369301092840193
      ]
    }
  },
  {
    "session": "Transnational lgbTq+ SIG",
    "abstract": "This Special Interest Group (SIG) serves to support the needs of the LGBTQ+ communities within CHI. Following tradition, the primary focus is on community-building and support, with research as a secondary interest. This year's event builds on the Queer-in-HCI SIGs of previous years, but adopts a new name to emphasize two points of focus this year. First, it is transnational: we place special emphasis on enabling connections among LGBTQ+ people from different nations. Second, it is lgbTq+: we welcome attendance from all members of the LGBTQ+ community and allies, but place special emphasis on the needs of the transgender community, which are significantly impacted by global political events at the time of this writing.",
    "title": "Transnational lgbTq+ SIG",
    "id": 189770,
    "sequence": 1480,
    "queryCoordinates": {
      "visualization": [
        4.511038844873862,
        -3.9560748906004166
      ]
    }
  },
  {
    "session": "Research Methods for People in a Hurry",
    "abstract": "Regardless of what area of computer-human interaction, psychology, computer science, or human factors you may be most closely part of, a solid understanding of research methods drawing from the traditions of experimental psychology and human factors will serve you well—as a student, practitioner, or instructor. Our aim in designing this workshop is to provide a primer on research methods for people with limited experience and which can be a refresher for those with substantial experience. The course is intended to be highly interactive and will provide opportunities for using the techniques we will discuss. This course builds on what we have learned from the successful 2022 CHI course Research Methods for People in a Hurry.",
    "title": "Research Methods for People in a Hurry",
    "id": 190030,
    "sequence": 1481,
    "queryCoordinates": {
      "visualization": [
        7.5905230123159715,
        4.835696475121414
      ]
    }
  },
  {
    "session": "Sketching in HCI",
    "abstract": "Sketching is one of few analogue skills that retains its power in a world where technology is king. Why? Because sketching is more than just the generation of visuals – sketching employs the mind to make sense of the world around us, it works through our problems, inspires others, presents information and even brings joy. By harnessing the power of sketching for your own research, study or practice, you enable an externalisation of human thought, which can be shared, adapted and built upon. In this course we invite you to ’take a line for a walk’ but bring yourself along for the ride. Sketch alongside us as we guide you through a journey of discovery, enabling you to go on to share you knowledge with others. It starts with a scribble...",
    "title": "Sketching in HCI: Scribble, Sketch, Elaborate, Teach",
    "id": 190035,
    "sequence": 1482,
    "queryCoordinates": {
      "visualization": [
        2.731264508225796,
        -13.730993925645226
      ]
    }
  },
  {
    "session": "Conversational Voice Interfaces",
    "abstract": "HCI research has for long been dedicated to better and more nat- urally facilitating information transfer between humans and ma- chines. Unfortunately, humans’ most natural form of communi- cation, speech, is also one of the most difficult modalities to be understood by machines – despite, and perhaps, because it is the highest-bandwidth communication channel we possess. As signifi- cant research efforts in engineering have been spent on improving machines’ ability to understand speech, research is only begin- ning to make the same improvements in understanding how to appropriately design these speech interfaces to be user-friendly and adoptable. Issues such as variations in error rates when pro- cessing speech, and difficulties in learnability and explainability (to name a few), are often in contrast with claims of success from industry. Along with this, designers themselves are making the transition to designing for speech and voice-enabled interfaces. Recent research has demonstrated the struggle for designers to translate their current experiences in graphical user interface de- sign into speech interface design. Research has also noted the lack of any user-centered design principles or consideration for usability or usefulness in the same ways as graphical user interfaces have benefited from heuristic design guidelines.\r\nThe goal of this course is to inform the CHI community of the current state of speech and natural language research, to dispel some of the myths surrounding speech-based interaction, as well as to inform participants about currently existing design tools, meth- ods and resources for speech interfaces (and provide hands-on experience with working with them). Through this, we hope that HCI researchers and practitioners will learn how to combine re- cent advances in speech processing with user-centred principles in designing more usable and useful speech-based interactive systems.",
    "title": "Conversational Voice Interfaces: Translating Research Into Actionable Design",
    "id": 190038,
    "sequence": 1483,
    "queryCoordinates": {
      "visualization": [
        -4.974884620746163,
        12.01043392264673
      ]
    }
  },
  {
    "session": "Interaction Techniques",
    "abstract": "",
    "title": "Interaction Techniques – History, Design and Evaluation",
    "id": 190041,
    "sequence": 1484,
    "queryCoordinates": {
      "visualization": [
        9.843705449290033,
        -12.613542842025698
      ]
    }
  },
  {
    "session": "Build Your AI Robot",
    "abstract": "How can we design robots that intuitively understand and respond to human needs? This interdisciplinary course bridges robotics and human-computer interaction, teaching participants to build and program a Raspberry Pi-based robot controllable through flexible natural language prompts. Students will gain hands-on experience in rapid prototyping, computer vision, 3D sensing, and natural language processing, culminating in the creation of an interactive prompt-controlled navigation robot. By emphasizing practical HCI applications and intuitive user interface design, the course prepares students for the growing field of human-robot interaction, equipping them with valuable skills for designing next-generation interactive systems.",
    "title": "Build Your AI Robot: Introduction to Robotics and AI Prototyping with Raspberry Pi",
    "id": 190044,
    "sequence": 1485,
    "queryCoordinates": {
      "visualization": [
        -2.7312645082257947,
        13.730993925645226
      ]
    }
  },
  {
    "session": "Build Your AI Robot",
    "abstract": "How can we design robots that intuitively understand and respond to human needs? This interdisciplinary course bridges robotics and human-computer interaction, teaching participants to build and program a Raspberry Pi-based robot controllable through flexible natural language prompts. Students will gain hands-on experience in rapid prototyping, computer vision, 3D sensing, and natural language processing, culminating in the creation of an interactive prompt-controlled navigation robot. By emphasizing practical HCI applications and intuitive user interface design, the course prepares students for the growing field of human-robot interaction, equipping them with valuable skills for designing next-generation interactive systems.",
    "title": "Build Your AI Robot: Introduction to Robotics and AI Prototyping with Raspberry Pi",
    "id": 190046,
    "sequence": 1486,
    "queryCoordinates": {
      "visualization": [
        5.758320584559809,
        14.927884781355823
      ]
    }
  },
  {
    "session": "How to Write Higher-Quality CHI Papers (with AI Research Tools)",
    "abstract": "Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper's readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.",
    "title": "How to write higher-quality CHI papers (with AI research tools)",
    "id": 190049,
    "sequence": 1487,
    "queryCoordinates": {
      "visualization": [
        -20.38252791652121,
        5.054953583588432
      ]
    }
  },
  {
    "session": "How to Write Higher-Quality CHI Papers (with AI Research Tools)",
    "abstract": "Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper's readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.",
    "title": "How to write higher-quality CHI papers (with AI research tools)",
    "id": 190050,
    "sequence": 1488,
    "queryCoordinates": {
      "visualization": [
        -5.04983154030316,
        19.351981847205195
      ]
    }
  },
  {
    "session": "How to Design, Build, and Use Interactive Electrical Stimulation",
    "abstract": "Electrical stimulation is now becoming one of the key approaches to creating haptic sensations in interactive experiences. The recent rise of this approach has allowed many HCI researchers to push haptics into more and more domains, including when devices need to be small, portable, or even wearable. At its core, all these techniques share one underlying principle from neuroscience: they act on the users’ nervous system to create sensations electrically. As such, using these techniques requires not only getting hands-on experience with hardware, but also learning the fundamental principles, safety, and their possibilities and limitations. In our course, participants will get hands-on experience in using these technologies via hardware toolkits that we will supply.",
    "title": "How to Design, Build, and Use Interactive Electrical Stimulation",
    "id": 190054,
    "sequence": 1489,
    "queryCoordinates": {
      "visualization": [
        -13.338851718120548,
        4.251474431534611
      ]
    }
  },
  {
    "session": "Design Thinking with Generative AI",
    "abstract": "",
    "title": "Design Thinking with Generative AI: Powerful ChatGPT Skills for UX",
    "id": 190056,
    "sequence": 1490,
    "queryCoordinates": {
      "visualization": [
        15.420417052727037,
        -4.267404119598377
      ]
    }
  },
  {
    "session": "Evaluating Interactive Technology with Children",
    "abstract": "While evaluating technology with adults is well understood, evaluating interactive technology with child users has received far less attention and raises a range of unusual and unexpected challenges. With more children than ever before using interactive technology on a daily basis, this course, for practitioners and researchers, aims to provide a succinct and useful introduction to evaluating technology with children. The course begins with the developmental and ethical challenges of working with children, then covers a range of foundational evaluation techniques, along with how techniques are used and how results are reported both in publications and to child audiences. ",
    "title": "Evaluating Interactive Technology with Children",
    "id": 190059,
    "sequence": 1491,
    "queryCoordinates": {
      "visualization": [
        3.2472402416509185,
        3.8020298280001548
      ]
    }
  },
  {
    "session": "How to: Peer Review for CHI (and Beyond) 2025",
    "abstract": "A key challenge for people that are new to reviewing is pitching the review at the right level, and getting the tone and structure of a review right. This course aims to help participants understand a) the different expectations of different venues and submission types, b) the processes they use to make decisions, and c) good techniques for producing a review for these different circumstances. Combined with pre-workshop training videos provided via SIGCHI's Youtube Channel, the practical work of this course will involve: 1) critiquing anonymised but real reviews (as a senior reviewer), and 2) constructing prototype reviews based on advice (as a reviewer).",
    "title": "How to: Peer Review for CHI (and Beyond) 2025",
    "id": 190062,
    "sequence": 1492,
    "queryCoordinates": {
      "visualization": [
        -16.475606624150046,
        7.249440417457271
      ]
    }
  },
  {
    "session": "Empirical Research Methods for Human-Computer Interaction",
    "abstract": "",
    "title": "Empirical Research Methods for Human-Computer Interaction",
    "id": 190065,
    "sequence": 1493,
    "queryCoordinates": {
      "visualization": [
        7.837478470739225,
        -12.789602465311388
      ]
    }
  },
  {
    "session": "Ethical Co-Development of AI Applications with Indigenous Communities",
    "abstract": "",
    "title": "Ethical Co-Development of AI Applications with Indigenous Communities",
    "id": 190067,
    "sequence": 1494,
    "queryCoordinates": {
      "visualization": [
        6.988987705124716,
        0.3924931306603425
      ]
    }
  },
  {
    "session": "Multimodal AI for Human Sensing and Interaction",
    "abstract": "",
    "title": "Multimodal AI for Human Sensing and Interaction",
    "id": 190071,
    "sequence": 1495,
    "queryCoordinates": {
      "visualization": [
        3.5276850573934193,
        -1.8855869473039917
      ]
    }
  },
  {
    "session": "Let's Get Psychophysiological",
    "abstract": "",
    "title": "Let's get PsychophysioLet's Get Psychophysiological! A Hands-On Wearables Laboratory Experience with Recording, Processing, and Interpreting Electrophysiology Signals",
    "id": 190074,
    "sequence": 1496,
    "queryCoordinates": {
      "visualization": [
        2.6951188271377635,
        -7.532352521464165
      ]
    }
  },
  {
    "session": "Introduction to Computational Cognitive Modeling",
    "abstract": "",
    "title": "Introduction to Computational Cognitive Modeling",
    "id": 190077,
    "sequence": 1497,
    "queryCoordinates": {
      "visualization": [
        2.6537321413140016,
        -5.381236449196133
      ]
    }
  },
  {
    "session": "UX Research Meets AI",
    "abstract": "",
    "title": "UX Research Meets AI: Level Up Your Skills",
    "id": 190081,
    "sequence": 1498,
    "queryCoordinates": {
      "visualization": [
        3.092041813450949,
        -2.537573136654581
      ]
    }
  },
  {
    "session": "WS02: Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "abstract": "Human bodies are deeply political as they carry historical and social meanings, including race, gender, sexuality, ethnicity, class, and abilities. The expanding body-centric research in HCI can be traced in the plurality of methods, theories and domains that take bodies as a central point of departure, when designing or studying interaction with technologies. This one-day workshop will bring together researchers and practitioners within the CHI community to discuss, map, and unpack emerging tensions and challenges on the topic of body politics for HCI. Interested participants are invited to submit examples from their own research, which, in the workshop, will be used as a point of departure to critically reflect on and expand body-centric methods, theories and domains through the lens of body politics. Workshop outcomes will include charting future directions for body-centric research to address challenges and opportunities of acknowledging that bodies are always political in design research.",
    "title": "Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "id": 190086,
    "sequence": 1499,
    "queryCoordinates": {
      "visualization": [
        -4.952484357652745,
        -10.930365899054106
      ]
    }
  },
  {
    "session": "WS02: Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "abstract": "Human bodies are deeply political as they carry historical and social meanings, including race, gender, sexuality, ethnicity, class, and abilities. The expanding body-centric research in HCI can be traced in the plurality of methods, theories and domains that take bodies as a central point of departure, when designing or studying interaction with technologies. This one-day workshop will bring together researchers and practitioners within the CHI community to discuss, map, and unpack emerging tensions and challenges on the topic of body politics for HCI. Interested participants are invited to submit examples from their own research, which, in the workshop, will be used as a point of departure to critically reflect on and expand body-centric methods, theories and domains through the lens of body politics. Workshop outcomes will include charting future directions for body-centric research to address challenges and opportunities of acknowledging that bodies are always political in design research.",
    "title": "Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "id": 190087,
    "sequence": 1500,
    "queryCoordinates": {
      "visualization": [
        -0.392667930622111,
        -17.995716487438365
      ]
    }
  },
  {
    "session": "WS02: Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "abstract": "Human bodies are deeply political as they carry historical and social meanings, including race, gender, sexuality, ethnicity, class, and abilities. The expanding body-centric research in HCI can be traced in the plurality of methods, theories and domains that take bodies as a central point of departure, when designing or studying interaction with technologies. This one-day workshop will bring together researchers and practitioners within the CHI community to discuss, map, and unpack emerging tensions and challenges on the topic of body politics for HCI. Interested participants are invited to submit examples from their own research, which, in the workshop, will be used as a point of departure to critically reflect on and expand body-centric methods, theories and domains through the lens of body politics. Workshop outcomes will include charting future directions for body-centric research to address challenges and opportunities of acknowledging that bodies are always political in design research.",
    "title": "Body Politics: Unpacking Tensions and Future Perspectives for Body-Centric Design Research in HCI",
    "id": 190088,
    "sequence": 1501,
    "queryCoordinates": {
      "visualization": [
        15.781081602735139,
        8.657797840548977
      ]
    }
  },
  {
    "session": "WS05: New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "abstract": "Explainable AI (XAI) is more than just “opening” the black box — who opens it matters just as much, if not more, as the ways of opening it. Human-centered XAI (HCXAI) advocates that algorithmic transparency alone is not sufficient for making AI explainable. In our fifth CHI workshop on Human-Centered XAI (HCXAI), we shift our focus to new, emerging frontiers of explainability: (1) participatory approaches toward explainability in civic AI applications; (2) addressing hallucinations in LLMs using explainability benchmarks; (3) connecting HCXAI research with Responsible AI practices, algorithmic auditing, and public policy; and (4) improving representation of XAI issues from the Global South. We have built a strong community of HCXAI researchers through our workshop series whose work has made important conceptual, methodological, and technical impact on the field. In this installment, we will push the frontiers of work in HCXAI with an emphasis on operationalizing perspectives sociotechnically.",
    "title": "New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "id": 190094,
    "sequence": 1502,
    "queryCoordinates": {
      "visualization": [
        16.88673440470715,
        -1.9591327532558547
      ]
    }
  },
  {
    "session": "WS05: New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "abstract": "Explainable AI (XAI) is more than just “opening” the black box — who opens it matters just as much, if not more, as the ways of opening it. Human-centered XAI (HCXAI) advocates that algorithmic transparency alone is not sufficient for making AI explainable. In our fifth CHI workshop on Human-Centered XAI (HCXAI), we shift our focus to new, emerging frontiers of explainability: (1) participatory approaches toward explainability in civic AI applications; (2) addressing hallucinations in LLMs using explainability benchmarks; (3) connecting HCXAI research with Responsible AI practices, algorithmic auditing, and public policy; and (4) improving representation of XAI issues from the Global South. We have built a strong community of HCXAI researchers through our workshop series whose work has made important conceptual, methodological, and technical impact on the field. In this installment, we will push the frontiers of work in HCXAI with an emphasis on operationalizing perspectives sociotechnically.",
    "title": "New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "id": 190095,
    "sequence": 1503,
    "queryCoordinates": {
      "visualization": [
        15.995181099139268,
        -0.3926596563665966
      ]
    }
  },
  {
    "session": "WS05: New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "abstract": "Explainable AI (XAI) is more than just “opening” the black box — who opens it matters just as much, if not more, as the ways of opening it. Human-centered XAI (HCXAI) advocates that algorithmic transparency alone is not sufficient for making AI explainable. In our fifth CHI workshop on Human-Centered XAI (HCXAI), we shift our focus to new, emerging frontiers of explainability: (1) participatory approaches toward explainability in civic AI applications; (2) addressing hallucinations in LLMs using explainability benchmarks; (3) connecting HCXAI research with Responsible AI practices, algorithmic auditing, and public policy; and (4) improving representation of XAI issues from the Global South. We have built a strong community of HCXAI researchers through our workshop series whose work has made important conceptual, methodological, and technical impact on the field. In this installment, we will push the frontiers of work in HCXAI with an emphasis on operationalizing perspectives sociotechnically.",
    "title": "New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs and Hallucinations for XAI, and Responsible AI Audits",
    "id": 190097,
    "sequence": 1504,
    "queryCoordinates": {
      "visualization": [
        6.48386102407984,
        -14.62735609125649
      ]
    }
  },
  {
    "session": "WS07: Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "abstract": "  Recent developments in XR-related technologies enable us to extend the use of XR beyond laboratory settings and, therefore, beyond the common paradigm of head-mounted displays (HMD) or AR glasses. As the industry is pushing XR glasses to become the next-generation computer interface and mobile phone replacement, we see an opportunity to reconsider the future of XR interfaces beyond just this form factor and explore whether new affordances can be leveraged. In fact, while glasses represent the most convenient and practical wearable interface, users remain limited to a specific set of displays, raising concerns about privacy, social acceptability, and overreliance on the visual channel. Conversely, we believe that there is an opportunity to leverage the physicality of the world, including the human body and the surrounding space, to create more engaging XR experiences. In this workshop, our goal is to gather fresh insights and perspectives from HCI researchers, practitioners, and professionals on strategies and techniques to enhance interactions in XR beyond the conventional glasses framework. We will bring together experienced academics and emerging researchers within the interdisciplinary field of HCI. We anticipate developing research pathways to leverage physicality to investigate possibilities and obstacles beyond XR glasses, ultimately shaping a new approach to engaging with XR.\r\n",
    "title": "Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "id": 190102,
    "sequence": 1505,
    "queryCoordinates": {
      "visualization": [
        4.251474431534607,
        13.338851718120548
      ]
    }
  },
  {
    "session": "WS07: Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "abstract": "  Recent developments in XR-related technologies enable us to extend the use of XR beyond laboratory settings and, therefore, beyond the common paradigm of head-mounted displays (HMD) or AR glasses. As the industry is pushing XR glasses to become the next-generation computer interface and mobile phone replacement, we see an opportunity to reconsider the future of XR interfaces beyond just this form factor and explore whether new affordances can be leveraged. In fact, while glasses represent the most convenient and practical wearable interface, users remain limited to a specific set of displays, raising concerns about privacy, social acceptability, and overreliance on the visual channel. Conversely, we believe that there is an opportunity to leverage the physicality of the world, including the human body and the surrounding space, to create more engaging XR experiences. In this workshop, our goal is to gather fresh insights and perspectives from HCI researchers, practitioners, and professionals on strategies and techniques to enhance interactions in XR beyond the conventional glasses framework. We will bring together experienced academics and emerging researchers within the interdisciplinary field of HCI. We anticipate developing research pathways to leverage physicality to investigate possibilities and obstacles beyond XR glasses, ultimately shaping a new approach to engaging with XR.\r\n",
    "title": "Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "id": 190103,
    "sequence": 1506,
    "queryCoordinates": {
      "visualization": [
        -7.96119642394204,
        -16.143709347588384
      ]
    }
  },
  {
    "session": "WS07: Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "abstract": "  Recent developments in XR-related technologies enable us to extend the use of XR beyond laboratory settings and, therefore, beyond the common paradigm of head-mounted displays (HMD) or AR glasses. As the industry is pushing XR glasses to become the next-generation computer interface and mobile phone replacement, we see an opportunity to reconsider the future of XR interfaces beyond just this form factor and explore whether new affordances can be leveraged. In fact, while glasses represent the most convenient and practical wearable interface, users remain limited to a specific set of displays, raising concerns about privacy, social acceptability, and overreliance on the visual channel. Conversely, we believe that there is an opportunity to leverage the physicality of the world, including the human body and the surrounding space, to create more engaging XR experiences. In this workshop, our goal is to gather fresh insights and perspectives from HCI researchers, practitioners, and professionals on strategies and techniques to enhance interactions in XR beyond the conventional glasses framework. We will bring together experienced academics and emerging researchers within the interdisciplinary field of HCI. We anticipate developing research pathways to leverage physicality to investigate possibilities and obstacles beyond XR glasses, ultimately shaping a new approach to engaging with XR.\r\n",
    "title": "Beyond Glasses: Future Directions for XR Interactions within the Physical World",
    "id": 190104,
    "sequence": 1507,
    "queryCoordinates": {
      "visualization": [
        -3.386032209736678,
        6.126563953361276
      ]
    }
  },
  {
    "session": "WS10: Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "abstract": "AI-Augmented Reasoning systems are cognitive assistants that support human reasoning by providing AI-based feedback that can help users improve their critical reasoning skills. Made possible with new techniques like argumentation mining, fact-checking, crowdsourcing, attention nudging, and large language models, AI augmented reasoning systems can provide real-time feedback on logical reasoning, help users identify and avoid flawed arguments and misinformation, suggest counter-arguments, provide evidence-based explanations, and foster deeper reflection. The goal of this workshop is to bring together researchers from AI, HCI, cognitive and social science to discuss recent advances in AI-augmented reasoning, to identify open problems in this area, and to cultivate an emerging community on this important topic.",
    "title": "Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "id": 190109,
    "sequence": 1508,
    "queryCoordinates": {
      "visualization": [
        -10.4708647231623,
        -7.704608487732215
      ]
    }
  },
  {
    "session": "WS10: Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "abstract": "AI-Augmented Reasoning systems are cognitive assistants that support human reasoning by providing AI-based feedback that can help users improve their critical reasoning skills. Made possible with new techniques like argumentation mining, fact-checking, crowdsourcing, attention nudging, and large language models, AI augmented reasoning systems can provide real-time feedback on logical reasoning, help users identify and avoid flawed arguments and misinformation, suggest counter-arguments, provide evidence-based explanations, and foster deeper reflection. The goal of this workshop is to bring together researchers from AI, HCI, cognitive and social science to discuss recent advances in AI-augmented reasoning, to identify open problems in this area, and to cultivate an emerging community on this important topic.",
    "title": "Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "id": 190110,
    "sequence": 1509,
    "queryCoordinates": {
      "visualization": [
        -12.361892829330237,
        -8.49609355387249
      ]
    }
  },
  {
    "session": "WS10: Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "abstract": "AI-Augmented Reasoning systems are cognitive assistants that support human reasoning by providing AI-based feedback that can help users improve their critical reasoning skills. Made possible with new techniques like argumentation mining, fact-checking, crowdsourcing, attention nudging, and large language models, AI augmented reasoning systems can provide real-time feedback on logical reasoning, help users identify and avoid flawed arguments and misinformation, suggest counter-arguments, provide evidence-based explanations, and foster deeper reflection. The goal of this workshop is to bring together researchers from AI, HCI, cognitive and social science to discuss recent advances in AI-augmented reasoning, to identify open problems in this area, and to cultivate an emerging community on this important topic.",
    "title": "Human-AI Interaction for Augmented Reasoning: Improving Human Reflective and Critical Thinking with Artificial Intelligence",
    "id": 190111,
    "sequence": 1510,
    "queryCoordinates": {
      "visualization": [
        -12.52252041361771,
        -3.4909142771668975
      ]
    }
  },
  {
    "session": "WS11: Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "abstract": "As Artificial Intelligence (AI) becomes more deeply embedded in educational settings, it is crucial to explore how it can enhance—rather than replace—the role of educators. This workshop focuses on advancing AI-driven tools that support personalized learning and designing AI systems capable of understanding students' emotional and cognitive needs. The workshop will explore two main themes: (1) empowering teachers with AI technologies for delivering customized feedback and individualized instruction, and (2) examining ethical and practical considerations for developing empathetic AI that complements the human aspects of teaching. Participants will discuss opportunities and challenges in building effective AI-augmented learning environments, considering ethical concerns such as privacy, equity, and the maintenance of human agency. The workshop aims to unite educators, researchers, and technologists in developing innovative solutions and fostering interdisciplinary dialogue. Key outcomes include establishing best practices for AI integration in education and disseminating research findings that shape the future of human-AI collaboration in teaching.",
    "title": "Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "id": 190116,
    "sequence": 1511,
    "queryCoordinates": {
      "visualization": [
        -18.51106621001346,
        4.282572564300321
      ]
    }
  },
  {
    "session": "WS11: Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "abstract": "As Artificial Intelligence (AI) becomes more deeply embedded in educational settings, it is crucial to explore how it can enhance—rather than replace—the role of educators. This workshop focuses on advancing AI-driven tools that support personalized learning and designing AI systems capable of understanding students' emotional and cognitive needs. The workshop will explore two main themes: (1) empowering teachers with AI technologies for delivering customized feedback and individualized instruction, and (2) examining ethical and practical considerations for developing empathetic AI that complements the human aspects of teaching. Participants will discuss opportunities and challenges in building effective AI-augmented learning environments, considering ethical concerns such as privacy, equity, and the maintenance of human agency. The workshop aims to unite educators, researchers, and technologists in developing innovative solutions and fostering interdisciplinary dialogue. Key outcomes include establishing best practices for AI integration in education and disseminating research findings that shape the future of human-AI collaboration in teaching.",
    "title": "Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "id": 190117,
    "sequence": 1512,
    "queryCoordinates": {
      "visualization": [
        -11.406089484000471,
        -9.741720724952748
      ]
    }
  },
  {
    "session": "WS11: Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "abstract": "As Artificial Intelligence (AI) becomes more deeply embedded in educational settings, it is crucial to explore how it can enhance—rather than replace—the role of educators. This workshop focuses on advancing AI-driven tools that support personalized learning and designing AI systems capable of understanding students' emotional and cognitive needs. The workshop will explore two main themes: (1) empowering teachers with AI technologies for delivering customized feedback and individualized instruction, and (2) examining ethical and practical considerations for developing empathetic AI that complements the human aspects of teaching. Participants will discuss opportunities and challenges in building effective AI-augmented learning environments, considering ethical concerns such as privacy, equity, and the maintenance of human agency. The workshop aims to unite educators, researchers, and technologists in developing innovative solutions and fostering interdisciplinary dialogue. Key outcomes include establishing best practices for AI integration in education and disseminating research findings that shape the future of human-AI collaboration in teaching.",
    "title": "Augmented Educators and AI: Shaping the Future of Human-AI Collaboration in Learning",
    "id": 190118,
    "sequence": 1513,
    "queryCoordinates": {
      "visualization": [
        -15.038690497648538,
        7.927028958943922
      ]
    }
  },
  {
    "session": "WS12: Scaling Distributed Collaboration in Mixed Reality",
    "abstract": "Distributed collaboration in Mixed Reality (MR) promises to revolutionise how people connect across different physical environments, offering experiences akin to face-to-face interactions. However, previous work has mostly focused on enabling this vision in overly simplified settings such as with only two users interacting in identical distributed environments. Scaling current systems to work with large groups and for common real-life scenarios is a persistent challenge that requires addressing multiple tensions. We identified six challenges: 1) supporting locally congruent actions from heterogeneous remote spaces, 2) communicating accurate user behaviours through virtual representation instead of physical bodies, 3) facilitating organic group interactions within limited physical space, 4) maintaining conversational dynamics even in asynchronous exchanges, 5) providing equal access to physical objects for all participants, and 6) enabling efficient task switching within a complex ecology of applications, devices, and accessibility needs. This workshop aims to gather researchers and practitioners to explore actionable strategies for resolving these challenges. Through a mix of presentations, hands-on activities, and group discussions, participants will generate new ideas and develop a research agenda to articulate the future of MR collaboration systems. The workshop outcomes will include a list of concrete next steps for the community to bring distributed MR collaboration at scale.",
    "title": "Scaling Distributed Collaboration in Mixed Reality",
    "id": 190123,
    "sequence": 1514,
    "queryCoordinates": {
      "visualization": [
        -12.783990009183125,
        -16.660420146115946
      ]
    }
  },
  {
    "session": "WS12: Scaling Distributed Collaboration in Mixed Reality",
    "abstract": "Distributed collaboration in Mixed Reality (MR) promises to revolutionise how people connect across different physical environments, offering experiences akin to face-to-face interactions. However, previous work has mostly focused on enabling this vision in overly simplified settings such as with only two users interacting in identical distributed environments. Scaling current systems to work with large groups and for common real-life scenarios is a persistent challenge that requires addressing multiple tensions. We identified six challenges: 1) supporting locally congruent actions from heterogeneous remote spaces, 2) communicating accurate user behaviours through virtual representation instead of physical bodies, 3) facilitating organic group interactions within limited physical space, 4) maintaining conversational dynamics even in asynchronous exchanges, 5) providing equal access to physical objects for all participants, and 6) enabling efficient task switching within a complex ecology of applications, devices, and accessibility needs. This workshop aims to gather researchers and practitioners to explore actionable strategies for resolving these challenges. Through a mix of presentations, hands-on activities, and group discussions, participants will generate new ideas and develop a research agenda to articulate the future of MR collaboration systems. The workshop outcomes will include a list of concrete next steps for the community to bring distributed MR collaboration at scale.",
    "title": "Scaling Distributed Collaboration in Mixed Reality",
    "id": 190124,
    "sequence": 1515,
    "queryCoordinates": {
      "visualization": [
        -16.23921596258436,
        -5.028704099521592
      ]
    }
  },
  {
    "session": "WS12: Scaling Distributed Collaboration in Mixed Reality",
    "abstract": "Distributed collaboration in Mixed Reality (MR) promises to revolutionise how people connect across different physical environments, offering experiences akin to face-to-face interactions. However, previous work has mostly focused on enabling this vision in overly simplified settings such as with only two users interacting in identical distributed environments. Scaling current systems to work with large groups and for common real-life scenarios is a persistent challenge that requires addressing multiple tensions. We identified six challenges: 1) supporting locally congruent actions from heterogeneous remote spaces, 2) communicating accurate user behaviours through virtual representation instead of physical bodies, 3) facilitating organic group interactions within limited physical space, 4) maintaining conversational dynamics even in asynchronous exchanges, 5) providing equal access to physical objects for all participants, and 6) enabling efficient task switching within a complex ecology of applications, devices, and accessibility needs. This workshop aims to gather researchers and practitioners to explore actionable strategies for resolving these challenges. Through a mix of presentations, hands-on activities, and group discussions, participants will generate new ideas and develop a research agenda to articulate the future of MR collaboration systems. The workshop outcomes will include a list of concrete next steps for the community to bring distributed MR collaboration at scale.",
    "title": "Scaling Distributed Collaboration in Mixed Reality",
    "id": 190125,
    "sequence": 1516,
    "queryCoordinates": {
      "visualization": [
        -9.46375449179885,
        -18.74666239411584
      ]
    }
  },
  {
    "session": "WS13: Meta-HCI: First Workshop on Meta-Research in HCI",
    "abstract": "Human-Computer Interaction (HCI) is a rapidly evolving field. It has undergone many changes, and several current challenges deserve more attention from the community. Meta-research – the study of research practices – offers insights into how a field can refine its methodological frameworks, enhance rigor, and address its challenges. We believe CHI deserves a dedicated space for meta-research. This workshop establishes an open space for HCI scholars in the top conference of the field to explore and discuss meta-research in HCI. We are equally focused on the past, present, and future: what we study, how we document it, how we evaluate, and how we distribute our work. Collateral effects such as mounting career pressures to publish always more are interesting, too. Short term results of this workshop include a research roadmap specifically for HCI meta-research. In the long term, we hope to see this workshop be the initial spark to establishing a permanent HCI meta-research community.",
    "title": "Meta-HCI: First Workshop on Meta-Research in HCI",
    "id": 190130,
    "sequence": 1517,
    "queryCoordinates": {
      "visualization": [
        12.447235004080849,
        13.0025513170756
      ]
    }
  },
  {
    "session": "WS13: Meta-HCI: First Workshop on Meta-Research in HCI",
    "abstract": "Human-Computer Interaction (HCI) is a rapidly evolving field. It has undergone many changes, and several current challenges deserve more attention from the community. Meta-research – the study of research practices – offers insights into how a field can refine its methodological frameworks, enhance rigor, and address its challenges. We believe CHI deserves a dedicated space for meta-research. This workshop establishes an open space for HCI scholars in the top conference of the field to explore and discuss meta-research in HCI. We are equally focused on the past, present, and future: what we study, how we document it, how we evaluate, and how we distribute our work. Collateral effects such as mounting career pressures to publish always more are interesting, too. Short term results of this workshop include a research roadmap specifically for HCI meta-research. In the long term, we hope to see this workshop be the initial spark to establishing a permanent HCI meta-research community.",
    "title": "Meta-HCI: First Workshop on Meta-Research in HCI",
    "id": 190131,
    "sequence": 1518,
    "queryCoordinates": {
      "visualization": [
        6.425746102545528,
        12.438238903704212
      ]
    }
  },
  {
    "session": "WS13: Meta-HCI: First Workshop on Meta-Research in HCI",
    "abstract": "Human-Computer Interaction (HCI) is a rapidly evolving field. It has undergone many changes, and several current challenges deserve more attention from the community. Meta-research – the study of research practices – offers insights into how a field can refine its methodological frameworks, enhance rigor, and address its challenges. We believe CHI deserves a dedicated space for meta-research. This workshop establishes an open space for HCI scholars in the top conference of the field to explore and discuss meta-research in HCI. We are equally focused on the past, present, and future: what we study, how we document it, how we evaluate, and how we distribute our work. Collateral effects such as mounting career pressures to publish always more are interesting, too. Short term results of this workshop include a research roadmap specifically for HCI meta-research. In the long term, we hope to see this workshop be the initial spark to establishing a permanent HCI meta-research community.",
    "title": "Meta-HCI: First Workshop on Meta-Research in HCI",
    "id": 190132,
    "sequence": 1519,
    "queryCoordinates": {
      "visualization": [
        -7.83747847073924,
        -12.789602465311377
      ]
    }
  },
  {
    "session": "WS17: Human-Centered Evaluation and Auditing of Language Models",
    "abstract": "The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues and guide future model development, responsible evaluation and auditing of LLMs are essential. This workshop aims to address the current \"evaluation crisis\" in LLM research and practice by bringing together HCI and AI researchers and practitioners to rethink LLM evaluation and auditing from a human-centered perspective. The workshop will explore topics around understanding stakeholders' needs and goals with evaluation and auditing LLMs, establishing human-centered evaluation and auditing methods, developing tools and resources to support these methods, building community and fostering collaboration. By soliciting papers, organizing invited keynote and panel, and facilitating group discussions, this workshop aims to develop a future research agenda for addressing the challenges in LLM evaluation and auditing. Following a successful first iteration of this workshop at CHI 2024, we introduce the theme of \"mind the context\" for this second iteration, where participants will be encouraged to tackle the challenges and nuances of LLM evaluation and auditing in specific contexts.",
    "title": "Human-Centered Evaluation and Auditing of Language Models",
    "id": 190137,
    "sequence": 1520,
    "queryCoordinates": {
      "visualization": [
        -14.037920695671874,
        -11.266622499313064
      ]
    }
  },
  {
    "session": "WS17: Human-Centered Evaluation and Auditing of Language Models",
    "abstract": "The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues and guide future model development, responsible evaluation and auditing of LLMs are essential. This workshop aims to address the current \"evaluation crisis\" in LLM research and practice by bringing together HCI and AI researchers and practitioners to rethink LLM evaluation and auditing from a human-centered perspective. The workshop will explore topics around understanding stakeholders' needs and goals with evaluation and auditing LLMs, establishing human-centered evaluation and auditing methods, developing tools and resources to support these methods, building community and fostering collaboration. By soliciting papers, organizing invited keynote and panel, and facilitating group discussions, this workshop aims to develop a future research agenda for addressing the challenges in LLM evaluation and auditing. Following a successful first iteration of this workshop at CHI 2024, we introduce the theme of \"mind the context\" for this second iteration, where participants will be encouraged to tackle the challenges and nuances of LLM evaluation and auditing in specific contexts.",
    "title": "Human-Centered Evaluation and Auditing of Language Models",
    "id": 190138,
    "sequence": 1521,
    "queryCoordinates": {
      "visualization": [
        -13.53877926524791,
        -6.457666452124423
      ]
    }
  },
  {
    "session": "WS17: Human-Centered Evaluation and Auditing of Language Models",
    "abstract": "The recent advancements in Large Language Models (LLMs) have significantly impacted numerous, and will impact more, real-world applications. However, these models also pose significant risks to individuals and society. To mitigate these issues and guide future model development, responsible evaluation and auditing of LLMs are essential. This workshop aims to address the current \"evaluation crisis\" in LLM research and practice by bringing together HCI and AI researchers and practitioners to rethink LLM evaluation and auditing from a human-centered perspective. The workshop will explore topics around understanding stakeholders' needs and goals with evaluation and auditing LLMs, establishing human-centered evaluation and auditing methods, developing tools and resources to support these methods, building community and fostering collaboration. By soliciting papers, organizing invited keynote and panel, and facilitating group discussions, this workshop aims to develop a future research agenda for addressing the challenges in LLM evaluation and auditing. Following a successful first iteration of this workshop at CHI 2024, we introduce the theme of \"mind the context\" for this second iteration, where participants will be encouraged to tackle the challenges and nuances of LLM evaluation and auditing in specific contexts.",
    "title": "Human-Centered Evaluation and Auditing of Language Models",
    "id": 190139,
    "sequence": 1522,
    "queryCoordinates": {
      "visualization": [
        -8.036352079666884,
        19.40147018273702
      ]
    }
  },
  {
    "session": "WS18: The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "abstract": "The Metaverse is envisioned as a shared, persistent experience that encompasses both augmented and virtual reality, representing the convergence of a virtually enhanced physical reality and interconnected persistent virtual spaces. It has the potential to break down physical boundaries, connecting people from all walks of life together through digital technology. As the Metaverse is still evolving, there is a unique opportunity to shape its development into an inclusive, all-encompassing space that is accessible for all. However a key challenge lies in designing the Metaverse from the ground up to ensure inclusivity and accessibility. This workshop aims to explore how to build an open, inclusive Metaverse and develop methods for evaluating its success. Key outcomes will include identifying new opportunities to enhance inclusivity, establishing evaluation methodologies, and outlining considerations for designing accessible environments and interactions within the Metaverse.",
    "title": "The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "id": 190144,
    "sequence": 1523,
    "queryCoordinates": {
      "visualization": [
        14.107874627542545,
        -16.88099148431576
      ]
    }
  },
  {
    "session": "WS18: The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "abstract": "The Metaverse is envisioned as a shared, persistent experience that encompasses both augmented and virtual reality, representing the convergence of a virtually enhanced physical reality and interconnected persistent virtual spaces. It has the potential to break down physical boundaries, connecting people from all walks of life together through digital technology. As the Metaverse is still evolving, there is a unique opportunity to shape its development into an inclusive, all-encompassing space that is accessible for all. However a key challenge lies in designing the Metaverse from the ground up to ensure inclusivity and accessibility. This workshop aims to explore how to build an open, inclusive Metaverse and develop methods for evaluating its success. Key outcomes will include identifying new opportunities to enhance inclusivity, establishing evaluation methodologies, and outlining considerations for designing accessible environments and interactions within the Metaverse.",
    "title": "The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "id": 190145,
    "sequence": 1524,
    "queryCoordinates": {
      "visualization": [
        13.496363468204308,
        -17.373778320622147
      ]
    }
  },
  {
    "session": "WS18: The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "abstract": "The Metaverse is envisioned as a shared, persistent experience that encompasses both augmented and virtual reality, representing the convergence of a virtually enhanced physical reality and interconnected persistent virtual spaces. It has the potential to break down physical boundaries, connecting people from all walks of life together through digital technology. As the Metaverse is still evolving, there is a unique opportunity to shape its development into an inclusive, all-encompassing space that is accessible for all. However a key challenge lies in designing the Metaverse from the ground up to ensure inclusivity and accessibility. This workshop aims to explore how to build an open, inclusive Metaverse and develop methods for evaluating its success. Key outcomes will include identifying new opportunities to enhance inclusivity, establishing evaluation methodologies, and outlining considerations for designing accessible environments and interactions within the Metaverse.",
    "title": "The Third Workshop on Building an Inclusive and Accessible Metaverse for All",
    "id": 190146,
    "sequence": 1525,
    "queryCoordinates": {
      "visualization": [
        21.21611288927035,
        -5.8203568507211365
      ]
    }
  },
  {
    "session": "WS19: Advancing Post-growth HCI",
    "abstract": "The field of Human-Computer Interaction (HCI) both shapes and is shaped by the forces of economic growth. Extending the calls to move beyond the growth imperative in HCI, this workshop aims to bring HCI researchers, designers, and practitioners together in a critical dialogue on examining the often-hidden ways growth patterns manifest in HCI. We ask how the HCI community can use its research, design, and praxis to build a more emancipatory future. The workshop aims to nurture the Post-growth HCI Collective of scholars and practitioners to work together, in solidarity, to reflect and resist the commodification and drive for infinite capital accumulation in/through digital technologies for the betterment of HCI and the broader computing community. Through collective action, we aim to operationalize post-growth principles in HCI, contributing to more tangible pathways toward socio-ecologically just and sustainable technology-mediated futures for the planet and its residents.",
    "title": "Advancing Post-growth HCI",
    "id": 190151,
    "sequence": 1526,
    "queryCoordinates": {
      "visualization": [
        -20.82034208885002,
        -2.741050036621087
      ]
    }
  },
  {
    "session": "WS19: Advancing Post-growth HCI",
    "abstract": "The field of Human-Computer Interaction (HCI) both shapes and is shaped by the forces of economic growth. Extending the calls to move beyond the growth imperative in HCI, this workshop aims to bring HCI researchers, designers, and practitioners together in a critical dialogue on examining the often-hidden ways growth patterns manifest in HCI. We ask how the HCI community can use its research, design, and praxis to build a more emancipatory future. The workshop aims to nurture the Post-growth HCI Collective of scholars and practitioners to work together, in solidarity, to reflect and resist the commodification and drive for infinite capital accumulation in/through digital technologies for the betterment of HCI and the broader computing community. Through collective action, we aim to operationalize post-growth principles in HCI, contributing to more tangible pathways toward socio-ecologically just and sustainable technology-mediated futures for the planet and its residents.",
    "title": "Advancing Post-growth HCI",
    "id": 190152,
    "sequence": 1527,
    "queryCoordinates": {
      "visualization": [
        1.9603428065912154,
        19.903694533443936
      ]
    }
  },
  {
    "session": "WS19: Advancing Post-growth HCI",
    "abstract": "The field of Human-Computer Interaction (HCI) both shapes and is shaped by the forces of economic growth. Extending the calls to move beyond the growth imperative in HCI, this workshop aims to bring HCI researchers, designers, and practitioners together in a critical dialogue on examining the often-hidden ways growth patterns manifest in HCI. We ask how the HCI community can use its research, design, and praxis to build a more emancipatory future. The workshop aims to nurture the Post-growth HCI Collective of scholars and practitioners to work together, in solidarity, to reflect and resist the commodification and drive for infinite capital accumulation in/through digital technologies for the betterment of HCI and the broader computing community. Through collective action, we aim to operationalize post-growth principles in HCI, contributing to more tangible pathways toward socio-ecologically just and sustainable technology-mediated futures for the planet and its residents.",
    "title": "Advancing Post-growth HCI",
    "id": 190153,
    "sequence": 1528,
    "queryCoordinates": {
      "visualization": [
        3.5088867185306736,
        16.633932607670353
      ]
    }
  },
  {
    "session": "WS21: News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "abstract": "The news and information ecosystem is undergoing significant upheaval across processes of news production and consumption. For instance, AI integration in newsrooms and the rise of independent creators on digital platforms exemplify shifts in production and dissemination, while evolving audience behaviors of information-seeking show how consumption is changing. This workshop aims to convene researchers and designers in HCI and news to examine these socio-technical shifts across stakeholders, activities, and technologies, and explore how design can support newswork and public engagement with news. Participants will engage in collaborative activities to reflect on current challenges facing news producers and audiences, synthesize the state of research in news and HCI, and identify future research directions. By bringing together diverse perspectives, we aim to nuance our understanding of the evolving news ecosystem and design socio-technical systems that strengthen journalism's democratic function.",
    "title": "News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "id": 190158,
    "sequence": 1529,
    "queryCoordinates": {
      "visualization": [
        -15.98964536214065,
        5.773321504383247
      ]
    }
  },
  {
    "session": "WS21: News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "abstract": "The news and information ecosystem is undergoing significant upheaval across processes of news production and consumption. For instance, AI integration in newsrooms and the rise of independent creators on digital platforms exemplify shifts in production and dissemination, while evolving audience behaviors of information-seeking show how consumption is changing. This workshop aims to convene researchers and designers in HCI and news to examine these socio-technical shifts across stakeholders, activities, and technologies, and explore how design can support newswork and public engagement with news. Participants will engage in collaborative activities to reflect on current challenges facing news producers and audiences, synthesize the state of research in news and HCI, and identify future research directions. By bringing together diverse perspectives, we aim to nuance our understanding of the evolving news ecosystem and design socio-technical systems that strengthen journalism's democratic function.",
    "title": "News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "id": 190159,
    "sequence": 1530,
    "queryCoordinates": {
      "visualization": [
        1.176886435917675,
        14.95376000599692
      ]
    }
  },
  {
    "session": "WS21: News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "abstract": "The news and information ecosystem is undergoing significant upheaval across processes of news production and consumption. For instance, AI integration in newsrooms and the rise of independent creators on digital platforms exemplify shifts in production and dissemination, while evolving audience behaviors of information-seeking show how consumption is changing. This workshop aims to convene researchers and designers in HCI and news to examine these socio-technical shifts across stakeholders, activities, and technologies, and explore how design can support newswork and public engagement with news. Participants will engage in collaborative activities to reflect on current challenges facing news producers and audiences, synthesize the state of research in news and HCI, and identify future research directions. By bringing together diverse perspectives, we aim to nuance our understanding of the evolving news ecosystem and design socio-technical systems that strengthen journalism's democratic function.",
    "title": "News Futures: (Re-)Designing Socio-technical Systems for News Production and Consumption",
    "id": 190160,
    "sequence": 1531,
    "queryCoordinates": {
      "visualization": [
        -11.266622499313073,
        -14.037920695671865
      ]
    }
  },
  {
    "session": "WS25: Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "abstract": "Interconnectedness and relationality have become integral to technology development and innovation, which has led to indigenous and cultural philosophies and approaches becoming important in developing effective and inclusive design practices. This workshop challenges the dominant paradigms in Human-Computer Interaction (HCI) by exploring the potential of indigeneity and culture to inform design methodologies. We invite participants to reflect on how such approaches can move HCI research toward more inclusive, culturally diverse, and mutually beneficial synergies. Through constructive conflict and co-creation, we aim to illuminate the potential of indigenous and cultural approaches in HCI practice, inspiring vital shifts towards decolonial and pluralistic design. We welcome HCI researchers and practitioners and indigenous scholars and experts interested in disrupting traditional methods and embracing indigenous and cultural lenses to join this critical conversation.",
    "title": "Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "id": 190165,
    "sequence": 1532,
    "queryCoordinates": {
      "visualization": [
        -0.39267619504894835,
        -20.996328379167675
      ]
    }
  },
  {
    "session": "WS25: Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "abstract": "Interconnectedness and relationality have become integral to technology development and innovation, which has led to indigenous and cultural philosophies and approaches becoming important in developing effective and inclusive design practices. This workshop challenges the dominant paradigms in Human-Computer Interaction (HCI) by exploring the potential of indigeneity and culture to inform design methodologies. We invite participants to reflect on how such approaches can move HCI research toward more inclusive, culturally diverse, and mutually beneficial synergies. Through constructive conflict and co-creation, we aim to illuminate the potential of indigenous and cultural approaches in HCI practice, inspiring vital shifts towards decolonial and pluralistic design. We welcome HCI researchers and practitioners and indigenous scholars and experts interested in disrupting traditional methods and embracing indigenous and cultural lenses to join this critical conversation.",
    "title": "Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "id": 190166,
    "sequence": 1533,
    "queryCoordinates": {
      "visualization": [
        18.74666239411584,
        9.463754491798849
      ]
    }
  },
  {
    "session": "WS25: Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "abstract": "Interconnectedness and relationality have become integral to technology development and innovation, which has led to indigenous and cultural philosophies and approaches becoming important in developing effective and inclusive design practices. This workshop challenges the dominant paradigms in Human-Computer Interaction (HCI) by exploring the potential of indigeneity and culture to inform design methodologies. We invite participants to reflect on how such approaches can move HCI research toward more inclusive, culturally diverse, and mutually beneficial synergies. Through constructive conflict and co-creation, we aim to illuminate the potential of indigenous and cultural approaches in HCI practice, inspiring vital shifts towards decolonial and pluralistic design. We welcome HCI researchers and practitioners and indigenous scholars and experts interested in disrupting traditional methods and embracing indigenous and cultural lenses to join this critical conversation.",
    "title": "Weaving Indigeneity and Culture into the Fabric of HCI Futures",
    "id": 190167,
    "sequence": 1534,
    "queryCoordinates": {
      "visualization": [
        -0.3924931306603421,
        6.988987705124716
      ]
    }
  },
  {
    "session": "WS27: Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "abstract": "Education, healthcare, poverty, and equity are just some of the social problems in which XR researchers leverage augmented reality, virtual reality, and mixed reality to create novel solutions. In this workshop proposal, we intend on gathering XR researchers who are interested in making a positive impact with their research, and to use this opportunity to discuss leveraging unique affordances of XR technology and common challenges. In our motivation, we refer to recent human computer interaction gatherings that discuss applications of XR to social benefit. Then, we present a background of research across XR technologies and diverse social problems to illustrate example affordances and challenges. To attend the workshop, attendees will submit a position paper on a particular XR affordances and how it can help address a social problem, and optionally submit a demo artifact as a sample for group discussion. The workshop will include a keynote, discussion based activities and demos, and conclude with a speculative exercise, where attendees will work together to describe XR technology in the context of an ethical future.",
    "title": "Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "id": 190173,
    "sequence": 1535,
    "queryCoordinates": {
      "visualization": [
        -1.9560385425721751,
        12.852000358697945
      ]
    }
  },
  {
    "session": "WS27: Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "abstract": "Education, healthcare, poverty, and equity are just some of the social problems in which XR researchers leverage augmented reality, virtual reality, and mixed reality to create novel solutions. In this workshop proposal, we intend on gathering XR researchers who are interested in making a positive impact with their research, and to use this opportunity to discuss leveraging unique affordances of XR technology and common challenges. In our motivation, we refer to recent human computer interaction gatherings that discuss applications of XR to social benefit. Then, we present a background of research across XR technologies and diverse social problems to illustrate example affordances and challenges. To attend the workshop, attendees will submit a position paper on a particular XR affordances and how it can help address a social problem, and optionally submit a demo artifact as a sample for group discussion. The workshop will include a keynote, discussion based activities and demos, and conclude with a speculative exercise, where attendees will work together to describe XR technology in the context of an ethical future.",
    "title": "Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "id": 190174,
    "sequence": 1536,
    "queryCoordinates": {
      "visualization": [
        -7.760250025556352,
        1.9438414392261125
      ]
    }
  },
  {
    "session": "WS27: Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "abstract": "Education, healthcare, poverty, and equity are just some of the social problems in which XR researchers leverage augmented reality, virtual reality, and mixed reality to create novel solutions. In this workshop proposal, we intend on gathering XR researchers who are interested in making a positive impact with their research, and to use this opportunity to discuss leveraging unique affordances of XR technology and common challenges. In our motivation, we refer to recent human computer interaction gatherings that discuss applications of XR to social benefit. Then, we present a background of research across XR technologies and diverse social problems to illustrate example affordances and challenges. To attend the workshop, attendees will submit a position paper on a particular XR affordances and how it can help address a social problem, and optionally submit a demo artifact as a sample for group discussion. The workshop will include a keynote, discussion based activities and demos, and conclude with a speculative exercise, where attendees will work together to describe XR technology in the context of an ethical future.",
    "title": "Purposeful XR: Affordances, Challenges, and Speculations for an Ethical Future",
    "id": 190175,
    "sequence": 1537,
    "queryCoordinates": {
      "visualization": [
        3.517630689399466,
        20.703291388882953
      ]
    }
  },
  {
    "session": "WS28: Gathering Textiles at CHI: Convening a Meeting to Share, Make, and Speculate",
    "abstract": "CHI is becoming home to an emerging community of researchers and practitioners engaging with textiles as a design and research material. This work is spread across a range of areas from digital fabrication to haptics. This workshop offers the opportunity for the broad community of HCI researchers to share techniques and ideas that underpin textile practices at CHI. Knitting, weaving, embroidery, hand-stitching, quilting, garment making, dying, felting, paper making, etc. offer distinct functional and aesthetic qualities while engaging similar modes of working. We propose this workshop to create a  meeting place for CHI researchers engaging textiles in any capacity. We suggest a day of skill sharing and collective speculating grounded in the textiles techniques and histories of Japan. ",
    "title": "Gathering Textiles at CHI: Convening a Meeting to Share, Make, and Speculate",
    "id": 190181,
    "sequence": 1538,
    "queryCoordinates": {
      "visualization": [
        -7.983097498603996,
        -4.155737519115303
      ]
    }
  },
  {
    "session": "WS29: Everyday AR through AI-in-the-Loop",
    "abstract": "This workshop brings together experts and practitioners from augmented reality (AR) and artificial intelligence (AI) to shape the future of AI-in-the-loop everyday AR experiences. With recent advancements in both AR hardware and AI capabilities, we envision that everyday AR---always-available and seamlessly integrated into users' daily environments---is becoming increasingly feasible. This workshop will explore how AI can drive such everyday AR experiences. We discuss a range of topics, including adaptive and context-aware AR, generative AR content creation, always-on AI assistants, AI-driven accessible design, and real-world-oriented AI agents. Our goal is to identify the opportunities and challenges in AI-enabled AR, focusing on creating novel AR experiences that seamlessly blend the digital and physical worlds. Through the workshop, we aim to foster collaboration, inspire future research, and build a community to advance the research field of AI-enhanced AR.",
    "title": "Everyday AR through AI-in-the-Loop",
    "id": 190187,
    "sequence": 1539,
    "queryCoordinates": {
      "visualization": [
        -11.686523751328002,
        2.724915156412485
      ]
    }
  },
  {
    "session": "WS29: Everyday AR through AI-in-the-Loop",
    "abstract": "This workshop brings together experts and practitioners from augmented reality (AR) and artificial intelligence (AI) to shape the future of AI-in-the-loop everyday AR experiences. With recent advancements in both AR hardware and AI capabilities, we envision that everyday AR---always-available and seamlessly integrated into users' daily environments---is becoming increasingly feasible. This workshop will explore how AI can drive such everyday AR experiences. We discuss a range of topics, including adaptive and context-aware AR, generative AR content creation, always-on AI assistants, AI-driven accessible design, and real-world-oriented AI agents. Our goal is to identify the opportunities and challenges in AI-enabled AR, focusing on creating novel AR experiences that seamlessly blend the digital and physical worlds. Through the workshop, we aim to foster collaboration, inspire future research, and build a community to advance the research field of AI-enhanced AR.",
    "title": "Everyday AR through AI-in-the-Loop",
    "id": 190188,
    "sequence": 1540,
    "queryCoordinates": {
      "visualization": [
        -9.930684569549262,
        -1.175373974578373
      ]
    }
  },
  {
    "session": "WS29: Everyday AR through AI-in-the-Loop",
    "abstract": "This workshop brings together experts and practitioners from augmented reality (AR) and artificial intelligence (AI) to shape the future of AI-in-the-loop everyday AR experiences. With recent advancements in both AR hardware and AI capabilities, we envision that everyday AR---always-available and seamlessly integrated into users' daily environments---is becoming increasingly feasible. This workshop will explore how AI can drive such everyday AR experiences. We discuss a range of topics, including adaptive and context-aware AR, generative AR content creation, always-on AI assistants, AI-driven accessible design, and real-world-oriented AI agents. Our goal is to identify the opportunities and challenges in AI-enabled AR, focusing on creating novel AR experiences that seamlessly blend the digital and physical worlds. Through the workshop, we aim to foster collaboration, inspire future research, and build a community to advance the research field of AI-enhanced AR.",
    "title": "Everyday AR through AI-in-the-Loop",
    "id": 190189,
    "sequence": 1541,
    "queryCoordinates": {
      "visualization": [
        -0.3926711233235274,
        18.99594191897069
      ]
    }
  },
  {
    "session": "WS33: Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "abstract": "We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI. ",
    "title": "Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "id": 190194,
    "sequence": 1542,
    "queryCoordinates": {
      "visualization": [
        -19.90369453344394,
        -1.960342806591203
      ]
    }
  },
  {
    "session": "WS33: Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "abstract": "We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI. ",
    "title": "Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "id": 190195,
    "sequence": 1543,
    "queryCoordinates": {
      "visualization": [
        -6.126563953361276,
        3.386032209736679
      ]
    }
  },
  {
    "session": "WS33: Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "abstract": "We invite researchers, designers, practitioners, and provocateurs to explore what it means to understand and shape the impact of Generative AI (GenAI) on human cognition. GenAI radically widens the scope and capability of automation for work, learning, and creativity. While impactful, it also changes workflows and the quality of thinking involved, raising questions about its effects on cognition, including critical thinking and learning. Yet, GenAI also offers opportunities for designing tools for thought that protect and augment cognition. Such systems provoke critical thinking, provide personalized tutoring, or enable novel ways of sensemaking, among other approaches. How does GenAI change workflows and human cognition? What are opportunities and challenges for designing GenAI systems that protect and augment human cognition? Which theories, perspectives, and methods are relevant? This workshop aims to develop a multidisciplinary community interested in exploring these questions to protect against the erosion, and fuel the augmentation, of human cognition using GenAI. ",
    "title": "Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI",
    "id": 190196,
    "sequence": 1544,
    "queryCoordinates": {
      "visualization": [
        -12.576703862931762,
        -14.241717591081397
      ]
    }
  },
  {
    "session": "WS36: Digital communication moving beyond human-centric replication",
    "abstract": "This agenda-setting workshop will bring together HCI researchers and designers with colleagues from sociology, media and communications to generate an interdisciplinary research agenda for digital communication beyond human-centric replication. It argues that the dominance of a human-centric replication paradigm in digital communication is problematic, constraining, limits digital innovation, and continues to unquestionably place humans at the centre of digital futures with negative social implications for modes of digital communication and how we relate to one another. This workshop will explore and foster alternative visions of digital communication, drawing inspiration from animal and plant sensory worlds (through inspirational talks, hands-on-activities, discussion) to generate ideas towards a new way of thinking and working in sensorial immersion beyond the human-centric. We will address key research opportunities and challenges and build the foundations for a road-map for this novel area of research.",
    "title": "Digital communication moving beyond human-centric replication",
    "id": 190201,
    "sequence": 1545,
    "queryCoordinates": {
      "visualization": [
        -9.131421435130806,
        11.900300104368531
      ]
    }
  },
  {
    "session": "WS36: Digital communication moving beyond human-centric replication",
    "abstract": "This agenda-setting workshop will bring together HCI researchers and designers with colleagues from sociology, media and communications to generate an interdisciplinary research agenda for digital communication beyond human-centric replication. It argues that the dominance of a human-centric replication paradigm in digital communication is problematic, constraining, limits digital innovation, and continues to unquestionably place humans at the centre of digital futures with negative social implications for modes of digital communication and how we relate to one another. This workshop will explore and foster alternative visions of digital communication, drawing inspiration from animal and plant sensory worlds (through inspirational talks, hands-on-activities, discussion) to generate ideas towards a new way of thinking and working in sensorial immersion beyond the human-centric. We will address key research opportunities and challenges and build the foundations for a road-map for this novel area of research.",
    "title": "Digital communication moving beyond human-centric replication",
    "id": 190202,
    "sequence": 1546,
    "queryCoordinates": {
      "visualization": [
        -2.7284543268430164,
        12.71044991282101
      ]
    }
  },
  {
    "session": "WS36: Digital communication moving beyond human-centric replication",
    "abstract": "This agenda-setting workshop will bring together HCI researchers and designers with colleagues from sociology, media and communications to generate an interdisciplinary research agenda for digital communication beyond human-centric replication. It argues that the dominance of a human-centric replication paradigm in digital communication is problematic, constraining, limits digital innovation, and continues to unquestionably place humans at the centre of digital futures with negative social implications for modes of digital communication and how we relate to one another. This workshop will explore and foster alternative visions of digital communication, drawing inspiration from animal and plant sensory worlds (through inspirational talks, hands-on-activities, discussion) to generate ideas towards a new way of thinking and working in sensorial immersion beyond the human-centric. We will address key research opportunities and challenges and build the foundations for a road-map for this novel area of research.",
    "title": "Digital communication moving beyond human-centric replication",
    "id": 190203,
    "sequence": 1547,
    "queryCoordinates": {
      "visualization": [
        -14.99485987463336,
        -0.39265422461809096
      ]
    }
  },
  {
    "session": "WS37: Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "abstract": "Mitigating new harms in immersive and embodied virtual spaces (e.g., embodied harassment in social VR, new AI-powered online attacks, and harmful virtual world design to manipulate users) is a critically needed HCI research agenda for achieving safer online environments in the future, which requires cross-disciplinary, community-wide discussion, and collective reflections. Building upon our CHI 2024 workshop on identifying and understanding these new harms, this workshop aims to gather researchers and practitioners from various domains to collectively design and develop concrete and actionable sociotechnical solutions that specifically target new harms in immersive and embodied virtual worlds. This includes but is not limited to the four themes identified in our CHI 2024 workshop: monetizing embodied harms, blurring reality with the online world, platforming perpetrators by investigating their motivations and emotions, and embodied harms specifically targeting children. Through this workshop, we will not only synthesize and map our existing interdisciplinary efforts and challenges in this space but also collaboratively create a roadmap detailing our developed sociotechnical solutions to address these new harms in immersive and embodied virtual spaces as a community.",
    "title": "Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "id": 190209,
    "sequence": 1548,
    "queryCoordinates": {
      "visualization": [
        -3.50168045783858,
        14.58554880596515
      ]
    }
  },
  {
    "session": "WS37: Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "abstract": "Mitigating new harms in immersive and embodied virtual spaces (e.g., embodied harassment in social VR, new AI-powered online attacks, and harmful virtual world design to manipulate users) is a critically needed HCI research agenda for achieving safer online environments in the future, which requires cross-disciplinary, community-wide discussion, and collective reflections. Building upon our CHI 2024 workshop on identifying and understanding these new harms, this workshop aims to gather researchers and practitioners from various domains to collectively design and develop concrete and actionable sociotechnical solutions that specifically target new harms in immersive and embodied virtual worlds. This includes but is not limited to the four themes identified in our CHI 2024 workshop: monetizing embodied harms, blurring reality with the online world, platforming perpetrators by investigating their motivations and emotions, and embodied harms specifically targeting children. Through this workshop, we will not only synthesize and map our existing interdisciplinary efforts and challenges in this space but also collaboratively create a roadmap detailing our developed sociotechnical solutions to address these new harms in immersive and embodied virtual spaces as a community.",
    "title": "Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "id": 190210,
    "sequence": 1549,
    "queryCoordinates": {
      "visualization": [
        -8.03635207966688,
        -19.401470182737025
      ]
    }
  },
  {
    "session": "WS37: Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "abstract": "Mitigating new harms in immersive and embodied virtual spaces (e.g., embodied harassment in social VR, new AI-powered online attacks, and harmful virtual world design to manipulate users) is a critically needed HCI research agenda for achieving safer online environments in the future, which requires cross-disciplinary, community-wide discussion, and collective reflections. Building upon our CHI 2024 workshop on identifying and understanding these new harms, this workshop aims to gather researchers and practitioners from various domains to collectively design and develop concrete and actionable sociotechnical solutions that specifically target new harms in immersive and embodied virtual worlds. This includes but is not limited to the four themes identified in our CHI 2024 workshop: monetizing embodied harms, blurring reality with the online world, platforming perpetrators by investigating their motivations and emotions, and embodied harms specifically targeting children. Through this workshop, we will not only synthesize and map our existing interdisciplinary efforts and challenges in this space but also collaboratively create a roadmap detailing our developed sociotechnical solutions to address these new harms in immersive and embodied virtual spaces as a community.",
    "title": "Developing Sociotechnical Solutions to Mitigate New Harms in Immersive and Embodied Virtual Spaces: A Workshop at CHI 2025",
    "id": 190211,
    "sequence": 1550,
    "queryCoordinates": {
      "visualization": [
        -11.483284028786509,
        -3.4834161270535406
      ]
    }
  },
  {
    "session": "WS39: HCI Across Borders: Building a Collective Vision for the Future",
    "abstract": "The HCI Across Borders (HCIxB) workshop at CHI 2025 will focus on \"Building a Collective Vision for the Future.\" HCIxB has gathered a diverse audience annually by conducting workshops and symposia since CHI 2016. This year, we hope to regroup as a community to reflect on the growth of HCIxB over the past ten years, engage in mentoring sessions for present early career researchers, and collectively form a vision for the future. This full-day hybrid workshop aims to gather researchers and practitioners to explore how we can collectively shape the future of HCI across diverse cultures and geographies. We will have a panel discussion featuring invited speakers sharing insights from a recent HCIxB Book Chapter summarizing our future. Attendees will showcase their research through posters, highlighting HCIxB's trends worldwide, particularly in the Global South. Lastly, we will collaborate to create a vision for our community's future and provide initial resources to future HCIxB organizers.",
    "title": "HCI Across Borders: Building a Collective Vision for the Future",
    "id": 190217,
    "sequence": 1551,
    "queryCoordinates": {
      "visualization": [
        4.209517756015988,
        10.162674857624154
      ]
    }
  },
  {
    "session": "WS39: HCI Across Borders: Building a Collective Vision for the Future",
    "abstract": "The HCI Across Borders (HCIxB) workshop at CHI 2025 will focus on \"Building a Collective Vision for the Future.\" HCIxB has gathered a diverse audience annually by conducting workshops and symposia since CHI 2016. This year, we hope to regroup as a community to reflect on the growth of HCIxB over the past ten years, engage in mentoring sessions for present early career researchers, and collectively form a vision for the future. This full-day hybrid workshop aims to gather researchers and practitioners to explore how we can collectively shape the future of HCI across diverse cultures and geographies. We will have a panel discussion featuring invited speakers sharing insights from a recent HCIxB Book Chapter summarizing our future. Attendees will showcase their research through posters, highlighting HCIxB's trends worldwide, particularly in the Global South. Lastly, we will collaborate to create a vision for our community's future and provide initial resources to future HCIxB organizers.",
    "title": "HCI Across Borders: Building a Collective Vision for the Future",
    "id": 190218,
    "sequence": 1552,
    "queryCoordinates": {
      "visualization": [
        5.656760841911973,
        10.58305517218026
      ]
    }
  },
  {
    "session": "WS39: HCI Across Borders: Building a Collective Vision for the Future",
    "abstract": "The HCI Across Borders (HCIxB) workshop at CHI 2025 will focus on \"Building a Collective Vision for the Future.\" HCIxB has gathered a diverse audience annually by conducting workshops and symposia since CHI 2016. This year, we hope to regroup as a community to reflect on the growth of HCIxB over the past ten years, engage in mentoring sessions for present early career researchers, and collectively form a vision for the future. This full-day hybrid workshop aims to gather researchers and practitioners to explore how we can collectively shape the future of HCI across diverse cultures and geographies. We will have a panel discussion featuring invited speakers sharing insights from a recent HCIxB Book Chapter summarizing our future. Attendees will showcase their research through posters, highlighting HCIxB's trends worldwide, particularly in the Global South. Lastly, we will collaborate to create a vision for our community's future and provide initial resources to future HCIxB organizers.",
    "title": "HCI Across Borders: Building a Collective Vision for the Future",
    "id": 190219,
    "sequence": 1553,
    "queryCoordinates": {
      "visualization": [
        17.254687719555836,
        10.113147467559692
      ]
    }
  },
  {
    "session": "WS41: Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "abstract": "The popularity of accessibility research has grown recently, improving digital inclusion for people with disabilities. However, researchers, including those who have disabilities, have attempted to include people with disabilities in all aspects of design, and they have identified a myriad of practical accessibility barriers posed by tools and methods leveraged by human-computer interaction (HCI) researchers during prototyping. To build a more inclusive technological landscape, we must question the effectiveness of existing prototyping tools and methods, repurpose/retrofit existing resources, and build new tools and methods to support the participation of both researchers and people with disabilities within the prototyping design process of novel technologies. This full-day workshop at CHI 2025 will provide a platform for HCI researchers, designers, and practitioners to discuss barriers and opportunities for creating accessible prototyping and promote hands-on ideation and fabrication exercises aimed at futuring accessible prototyping. ",
    "title": "Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "id": 190224,
    "sequence": 1554,
    "queryCoordinates": {
      "visualization": [
        -1.1768864359176732,
        14.95376000599692
      ]
    }
  },
  {
    "session": "WS41: Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "abstract": "The popularity of accessibility research has grown recently, improving digital inclusion for people with disabilities. However, researchers, including those who have disabilities, have attempted to include people with disabilities in all aspects of design, and they have identified a myriad of practical accessibility barriers posed by tools and methods leveraged by human-computer interaction (HCI) researchers during prototyping. To build a more inclusive technological landscape, we must question the effectiveness of existing prototyping tools and methods, repurpose/retrofit existing resources, and build new tools and methods to support the participation of both researchers and people with disabilities within the prototyping design process of novel technologies. This full-day workshop at CHI 2025 will provide a platform for HCI researchers, designers, and practitioners to discuss barriers and opportunities for creating accessible prototyping and promote hands-on ideation and fabrication exercises aimed at futuring accessible prototyping. ",
    "title": "Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "id": 190225,
    "sequence": 1555,
    "queryCoordinates": {
      "visualization": [
        -11.688145478950537,
        5.69098016714943
      ]
    }
  },
  {
    "session": "WS41: Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "abstract": "The popularity of accessibility research has grown recently, improving digital inclusion for people with disabilities. However, researchers, including those who have disabilities, have attempted to include people with disabilities in all aspects of design, and they have identified a myriad of practical accessibility barriers posed by tools and methods leveraged by human-computer interaction (HCI) researchers during prototyping. To build a more inclusive technological landscape, we must question the effectiveness of existing prototyping tools and methods, repurpose/retrofit existing resources, and build new tools and methods to support the participation of both researchers and people with disabilities within the prototyping design process of novel technologies. This full-day workshop at CHI 2025 will provide a platform for HCI researchers, designers, and practitioners to discuss barriers and opportunities for creating accessible prototyping and promote hands-on ideation and fabrication exercises aimed at futuring accessible prototyping. ",
    "title": "Access InContext: Futuring Accessible Prototyping Tools and Methods",
    "id": 190226,
    "sequence": 1556,
    "queryCoordinates": {
      "visualization": [
        -4.664426045664028,
        5.21949515418216
      ]
    }
  },
  {
    "session": "WS16: Bridging HCI and Industrial Manufacturing",
    "abstract": "This workshop explores the integration of Human-Computer Interaction (HCI) principles within the manufacturing sector, examining the challenges and opportunities that arise in academia-industry collaborations. The workshop aims to foster dialogue on how HCI methods can enhance manufacturing practices, while addressing the specific hurdles these partnerships face. We will discuss areas of HCI research including: collaborative robots, industrial augmented reality, advances in digital fabrication, and systems for workplace communication as they apply to existing problems in industrial settings. The key goals include generating actionable insights for both academic and industrial participants, fostering practical, cross-disciplinary collaborations that will drive innovation in user-centered industrial systems.\r\nHosting this workshop at CHI 2025 in Japan offers a unique opportunity to engage with Japan’s world-class manufacturing sector, renowned for its precision and innovation, making it an ideal setting to bridge HCI research and industrial practices.",
    "title": "Bridging HCI and Industrial Manufacturing",
    "id": 190232,
    "sequence": 1557,
    "queryCoordinates": {
      "visualization": [
        -17.995716487438365,
        0.3926679306221019
      ]
    }
  },
  {
    "session": "WS01: Research Products and Time: When, For How Long, And Then What?",
    "abstract": "This workshop focuses on the temporal dimensions of Research through Design (RtD) in Human-Computer Interaction. Building on the success of previous objects of design workshops at CHI, it explores how time impacts the creation, evolution, and deployment of design artifacts. Participants will discuss long-term and unconventional deployments, addressing methodological, ethical, and organizational challenges. Through hands-on, studio-style critique and collaborative sessions, the workshop aims to generate insights into how temporal aspects of design contribute to knowledge production. The event will also initiate long-term design deployments, with findings to be reported at a follow-up workshop in 2026, marking the 10th anniversary of this series.",
    "title": "Research Products and Time: When, For How Long, And Then What?",
    "id": 190235,
    "sequence": 1558,
    "queryCoordinates": {
      "visualization": [
        -18.801493573216852,
        -2.7393136761395898
      ]
    }
  },
  {
    "session": "WS01: Research Products and Time: When, For How Long, And Then What?",
    "abstract": "This workshop focuses on the temporal dimensions of Research through Design (RtD) in Human-Computer Interaction. Building on the success of previous objects of design workshops at CHI, it explores how time impacts the creation, evolution, and deployment of design artifacts. Participants will discuss long-term and unconventional deployments, addressing methodological, ethical, and organizational challenges. Through hands-on, studio-style critique and collaborative sessions, the workshop aims to generate insights into how temporal aspects of design contribute to knowledge production. The event will also initiate long-term design deployments, with findings to be reported at a follow-up workshop in 2026, marking the 10th anniversary of this series.",
    "title": "Research Products and Time: When, For How Long, And Then What?",
    "id": 190236,
    "sequence": 1559,
    "queryCoordinates": {
      "visualization": [
        -9.807852804032304,
        -1.9509032201612837
      ]
    }
  },
  {
    "session": "WS01: Research Products and Time: When, For How Long, And Then What?",
    "abstract": "This workshop focuses on the temporal dimensions of Research through Design (RtD) in Human-Computer Interaction. Building on the success of previous objects of design workshops at CHI, it explores how time impacts the creation, evolution, and deployment of design artifacts. Participants will discuss long-term and unconventional deployments, addressing methodological, ethical, and organizational challenges. Through hands-on, studio-style critique and collaborative sessions, the workshop aims to generate insights into how temporal aspects of design contribute to knowledge production. The event will also initiate long-term design deployments, with findings to be reported at a follow-up workshop in 2026, marking the 10th anniversary of this series.",
    "title": "Research Products and Time: When, For How Long, And Then What?",
    "id": 190237,
    "sequence": 1560,
    "queryCoordinates": {
      "visualization": [
        10.000264194352841,
        14.966453021445814
      ]
    }
  },
  {
    "session": "WS03: Future of Money and HCI",
    "abstract": "Money and financial activities reflect social connections and societal norms. Collaborative financial activities and decision-making are highly common in our day-to-day activities. However, existing financial technologies (fintech) are often limited to individual-centric approaches and goals. Recent HCI work has repeatedly noted the need for creating new interaction strategies and design paradigms to better support our financial behaviors, habits, and goals. However, there has not been much concrete work yet, specifically when it comes to supporting collaborative behaviors and social norms that underpin much of our daily financial activities. In this in-person workshop, we will bring together an interdisciplinary group of researchers interested in reshaping the current landscape of digital money and fintech with a focus on social and collaborative interactions. Specifically, we will identify limitations of existing fintech approaches and potential strategies to address these limitations. We will also discuss key challenges for fintech design and development, including collaboration, privacy, agency, trust, and accessibility. The workshop will lead to identifying novel HCI research and implementation directions focusing on the future of financial technologies.",
    "title": "Future of Money and HCI",
    "id": 190242,
    "sequence": 1561,
    "queryCoordinates": {
      "visualization": [
        -13.858192987669305,
        -5.740251485476338
      ]
    }
  },
  {
    "session": "WS03: Future of Money and HCI",
    "abstract": "Money and financial activities reflect social connections and societal norms. Collaborative financial activities and decision-making are highly common in our day-to-day activities. However, existing financial technologies (fintech) are often limited to individual-centric approaches and goals. Recent HCI work has repeatedly noted the need for creating new interaction strategies and design paradigms to better support our financial behaviors, habits, and goals. However, there has not been much concrete work yet, specifically when it comes to supporting collaborative behaviors and social norms that underpin much of our daily financial activities. In this in-person workshop, we will bring together an interdisciplinary group of researchers interested in reshaping the current landscape of digital money and fintech with a focus on social and collaborative interactions. Specifically, we will identify limitations of existing fintech approaches and potential strategies to address these limitations. We will also discuss key challenges for fintech design and development, including collaboration, privacy, agency, trust, and accessibility. The workshop will lead to identifying novel HCI research and implementation directions focusing on the future of financial technologies.",
    "title": "Future of Money and HCI",
    "id": 190243,
    "sequence": 1562,
    "queryCoordinates": {
      "visualization": [
        -7.96119642394202,
        16.14370934758839
      ]
    }
  },
  {
    "session": "WS03: Future of Money and HCI",
    "abstract": "Money and financial activities reflect social connections and societal norms. Collaborative financial activities and decision-making are highly common in our day-to-day activities. However, existing financial technologies (fintech) are often limited to individual-centric approaches and goals. Recent HCI work has repeatedly noted the need for creating new interaction strategies and design paradigms to better support our financial behaviors, habits, and goals. However, there has not been much concrete work yet, specifically when it comes to supporting collaborative behaviors and social norms that underpin much of our daily financial activities. In this in-person workshop, we will bring together an interdisciplinary group of researchers interested in reshaping the current landscape of digital money and fintech with a focus on social and collaborative interactions. Specifically, we will identify limitations of existing fintech approaches and potential strategies to address these limitations. We will also discuss key challenges for fintech design and development, including collaboration, privacy, agency, trust, and accessibility. The workshop will lead to identifying novel HCI research and implementation directions focusing on the future of financial technologies.",
    "title": "Future of Money and HCI",
    "id": 190244,
    "sequence": 1563,
    "queryCoordinates": {
      "visualization": [
        -13.326040464736488,
        10.555408354592714
      ]
    }
  },
  {
    "session": "WS04: Defining a UX Research Point of View (POV)",
    "abstract": "A User Experience Research Point of View (UXR PoV) is a perspective based on data, evidence, and insight that shapes how you observe, interpret, and represent the needs of your target users. We need to equip UX Practitioners with the essential tools needed to develop and articulate a persuasive PoV. Our mission is to support professionals in preparing and establishing a compelling narrative that aligns with the needs of their stakeholders. We are developing a UXR playbook that defines a set of plays and instructions for practitioners to build, establish, and land a compelling UX Research POV. The proposed workshop offers an opportunity to hear from HCI Researchers, UX Research professionals and cross-functional partners involved in design processes to extend the foundations already laid and create a more detailed UXR POV playbook. ",
    "title": "Defining a UX Research Point of View (POV)",
    "id": 190249,
    "sequence": 1564,
    "queryCoordinates": {
      "visualization": [
        3.4441508912858083,
        8.31491579260158
      ]
    }
  },
  {
    "session": "WS04: Defining a UX Research Point of View (POV)",
    "abstract": "A User Experience Research Point of View (UXR PoV) is a perspective based on data, evidence, and insight that shapes how you observe, interpret, and represent the needs of your target users. We need to equip UX Practitioners with the essential tools needed to develop and articulate a persuasive PoV. Our mission is to support professionals in preparing and establishing a compelling narrative that aligns with the needs of their stakeholders. We are developing a UXR playbook that defines a set of plays and instructions for practitioners to build, establish, and land a compelling UX Research POV. The proposed workshop offers an opportunity to hear from HCI Researchers, UX Research professionals and cross-functional partners involved in design processes to extend the foundations already laid and create a more detailed UXR POV playbook. ",
    "title": "Defining a UX Research Point of View (POV)",
    "id": 190250,
    "sequence": 1565,
    "queryCoordinates": {
      "visualization": [
        -4.974884620746175,
        -12.010433922646724
      ]
    }
  },
  {
    "session": "WS04: Defining a UX Research Point of View (POV)",
    "abstract": "A User Experience Research Point of View (UXR PoV) is a perspective based on data, evidence, and insight that shapes how you observe, interpret, and represent the needs of your target users. We need to equip UX Practitioners with the essential tools needed to develop and articulate a persuasive PoV. Our mission is to support professionals in preparing and establishing a compelling narrative that aligns with the needs of their stakeholders. We are developing a UXR playbook that defines a set of plays and instructions for practitioners to build, establish, and land a compelling UX Research POV. The proposed workshop offers an opportunity to hear from HCI Researchers, UX Research professionals and cross-functional partners involved in design processes to extend the foundations already laid and create a more detailed UXR POV playbook. ",
    "title": "Defining a UX Research Point of View (POV)",
    "id": 190251,
    "sequence": 1566,
    "queryCoordinates": {
      "visualization": [
        -3.50168045783859,
        -14.585548805965146
      ]
    }
  },
  {
    "session": "WS06: Envisioning the Future of Interactive Health",
    "abstract": "This workshop will gather the health and well-being (henceforth “Health”) research community to prepare and kickstart an independent conference. While there is substantial research at the intersection of HCI and Health, there is not yet a SIGCHI-sponsored conference dedicated to the HCI and Health community. The workshop will bring together the broad community of academic and industry researchers across Human–Computer Interaction, medical informatics, health informatics, and digital health. This widespread Health community also brings diverse approaches to epistemology and research, requiring that we work towards defining the scope, audience, and methods that will establish a shared language while welcoming areas of growth. This workshop will be an opportunity for the fledgling community to start important discussions around what constitutes a contribution for the Health community",
    "title": "Envisioning the Future of Interactive Health",
    "id": 190256,
    "sequence": 1567,
    "queryCoordinates": {
      "visualization": [
        4.992701457272383,
        13.079485164124398
      ]
    }
  },
  {
    "session": "WS06: Envisioning the Future of Interactive Health",
    "abstract": "This workshop will gather the health and well-being (henceforth “Health”) research community to prepare and kickstart an independent conference. While there is substantial research at the intersection of HCI and Health, there is not yet a SIGCHI-sponsored conference dedicated to the HCI and Health community. The workshop will bring together the broad community of academic and industry researchers across Human–Computer Interaction, medical informatics, health informatics, and digital health. This widespread Health community also brings diverse approaches to epistemology and research, requiring that we work towards defining the scope, audience, and methods that will establish a shared language while welcoming areas of growth. This workshop will be an opportunity for the fledgling community to start important discussions around what constitutes a contribution for the Health community",
    "title": "Envisioning the Future of Interactive Health",
    "id": 190257,
    "sequence": 1568,
    "queryCoordinates": {
      "visualization": [
        21.410336646256876,
        5.059395684659371
      ]
    }
  },
  {
    "session": "WS06: Envisioning the Future of Interactive Health",
    "abstract": "This workshop will gather the health and well-being (henceforth “Health”) research community to prepare and kickstart an independent conference. While there is substantial research at the intersection of HCI and Health, there is not yet a SIGCHI-sponsored conference dedicated to the HCI and Health community. The workshop will bring together the broad community of academic and industry researchers across Human–Computer Interaction, medical informatics, health informatics, and digital health. This widespread Health community also brings diverse approaches to epistemology and research, requiring that we work towards defining the scope, audience, and methods that will establish a shared language while welcoming areas of growth. This workshop will be an opportunity for the fledgling community to start important discussions around what constitutes a contribution for the Health community",
    "title": "Envisioning the Future of Interactive Health",
    "id": 190258,
    "sequence": 1569,
    "queryCoordinates": {
      "visualization": [
        -2.678784026555628,
        6.467156727579007
      ]
    }
  },
  {
    "session": "WS08: How do design stories work? Exploring narrative forms of knowledge in HCI",
    "abstract": "Design is storied, and stories are designed. While elements of stories have long been part of the field through methods like personas, scenarios and design fictions, there has been a recent surge of new approaches including fabulations, epics, memoirs, site-writing and design events. In this workshop we aim to understand how stories are built, what narrative traditions they draw from, how they co-constitute research processes and what kind of knowledge can emerge from them. Specifically, we will explore the role of storytelling in HCI, the craft of writing stories, relations between fiction, truth and knowledge and finally the risks, tensions and limitations of writing stories. We will outline an overview of this new wave of stories in HCI and what they are activating and advocating for, build a set of tips, tricks and advice for writing stories and keep track of ongoing issues and open questions for further research.",
    "title": "How do design stories work? Exploring narrative forms of knowledge in HCI",
    "id": 190263,
    "sequence": 1570,
    "queryCoordinates": {
      "visualization": [
        -15.995181099139268,
        -0.3926596563665933
      ]
    }
  },
  {
    "session": "WS08: How do design stories work? Exploring narrative forms of knowledge in HCI",
    "abstract": "Design is storied, and stories are designed. While elements of stories have long been part of the field through methods like personas, scenarios and design fictions, there has been a recent surge of new approaches including fabulations, epics, memoirs, site-writing and design events. In this workshop we aim to understand how stories are built, what narrative traditions they draw from, how they co-constitute research processes and what kind of knowledge can emerge from them. Specifically, we will explore the role of storytelling in HCI, the craft of writing stories, relations between fiction, truth and knowledge and finally the risks, tensions and limitations of writing stories. We will outline an overview of this new wave of stories in HCI and what they are activating and advocating for, build a set of tips, tricks and advice for writing stories and keep track of ongoing issues and open questions for further research.",
    "title": "How do design stories work? Exploring narrative forms of knowledge in HCI",
    "id": 190264,
    "sequence": 1571,
    "queryCoordinates": {
      "visualization": [
        -6.564007126858536,
        19.947777080129764
      ]
    }
  },
  {
    "session": "WS08: How do design stories work? Exploring narrative forms of knowledge in HCI",
    "abstract": "Design is storied, and stories are designed. While elements of stories have long been part of the field through methods like personas, scenarios and design fictions, there has been a recent surge of new approaches including fabulations, epics, memoirs, site-writing and design events. In this workshop we aim to understand how stories are built, what narrative traditions they draw from, how they co-constitute research processes and what kind of knowledge can emerge from them. Specifically, we will explore the role of storytelling in HCI, the craft of writing stories, relations between fiction, truth and knowledge and finally the risks, tensions and limitations of writing stories. We will outline an overview of this new wave of stories in HCI and what they are activating and advocating for, build a set of tips, tricks and advice for writing stories and keep track of ongoing issues and open questions for further research.",
    "title": "How do design stories work? Exploring narrative forms of knowledge in HCI",
    "id": 190265,
    "sequence": 1572,
    "queryCoordinates": {
      "visualization": [
        -8.99143399423672,
        0.3925744862880246
      ]
    }
  },
  {
    "session": "WS09: GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "abstract": "This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways.  Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together.\r\n\r\nFollowing successful workshops in 2022--2024, we convene the interdisciplinary research domain of generative AI and HCI. Participation is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",
    "title": "GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "id": 190270,
    "sequence": 1573,
    "queryCoordinates": {
      "visualization": [
        16.844344674325733,
        10.782766458220003
      ]
    }
  },
  {
    "session": "WS09: GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "abstract": "This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways.  Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together.\r\n\r\nFollowing successful workshops in 2022--2024, we convene the interdisciplinary research domain of generative AI and HCI. Participation is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",
    "title": "GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "id": 190271,
    "sequence": 1574,
    "queryCoordinates": {
      "visualization": [
        4.952484357652737,
        10.93036589905411
      ]
    }
  },
  {
    "session": "WS09: GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "abstract": "This workshop applies human centered themes to a new and powerful technology, generative artificial intelligence (AI), and - among other approaches - particularly to Large Language Models (LLMs) and Foundation Models (FMs). Unlike AI systems that produce decisions or descriptions, generative AI systems can produce new and creative content that can include images, texts, music, video, code, and other forms of design. The results are often similar to results produced by humans. However, it is not yet clear how humans make sense of generative AI algorithms or their outcomes. It is also not yet clear how humans can control and more generally, interact with, these powerful capabilities in ethical ways.  Finally, it is not clear what kinds of collaboration patterns will emerge when creative humans and creative technologies work together.\r\n\r\nFollowing successful workshops in 2022--2024, we convene the interdisciplinary research domain of generative AI and HCI. Participation is open to seasoned scholars and early career researchers. We solicit descriptions of completed projects, works-in-progress, and provocations. Together we will develop theories and practices in this intriguing new domain.",
    "title": "GenAICHI 2025: Generative AI and HCI at CHI 2025",
    "id": 190272,
    "sequence": 1575,
    "queryCoordinates": {
      "visualization": [
        6.386309944090407,
        11.323208259941701
      ]
    }
  },
  {
    "session": "WS14: Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "abstract": "Teens' mobile technology use can help teens connect with one another, but it also raises concerns around overuse, addiction, and exposure to harmful content. Traditional tools and methods for parental controls and guidance for mobile technology use among children, such as screen time limits, often fail to address teens' nuanced experiences on the benefits and harm of their mobile technology use. This workshop brings together interdisciplinary researchers, practitioners, and teen advocates to examine how the CHI community can foster healthy teen mobile-technology relationships. Our goals are to: (1) co-design research agenda, (2) foster cross-sociocultural collaboration, (3) generate guidance for stakeholders (e.g., public, policymakers, parents, healthcare providers), and (4) plan actionable steps for ongoing impact. The workshop will explore themes like engaging broader stakeholders, embracing marginalized voices, and navigating the implications of emerging technologies through panel presentations and interactive sessions. By examining these themes, we aim to re-explore the HCI community's discourse on teen mobile technology use and well-being, fostering a comprehensive understanding and inclusive approaches to navigate the multifaceted challenges in the modern digital landscape in diverse sociocultural contexts. ",
    "title": "Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "id": 190277,
    "sequence": 1576,
    "queryCoordinates": {
      "visualization": [
        -6.564007126858523,
        -19.947777080129768
      ]
    }
  },
  {
    "session": "WS14: Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "abstract": "Teens' mobile technology use can help teens connect with one another, but it also raises concerns around overuse, addiction, and exposure to harmful content. Traditional tools and methods for parental controls and guidance for mobile technology use among children, such as screen time limits, often fail to address teens' nuanced experiences on the benefits and harm of their mobile technology use. This workshop brings together interdisciplinary researchers, practitioners, and teen advocates to examine how the CHI community can foster healthy teen mobile-technology relationships. Our goals are to: (1) co-design research agenda, (2) foster cross-sociocultural collaboration, (3) generate guidance for stakeholders (e.g., public, policymakers, parents, healthcare providers), and (4) plan actionable steps for ongoing impact. The workshop will explore themes like engaging broader stakeholders, embracing marginalized voices, and navigating the implications of emerging technologies through panel presentations and interactive sessions. By examining these themes, we aim to re-explore the HCI community's discourse on teen mobile technology use and well-being, fostering a comprehensive understanding and inclusive approaches to navigate the multifaceted challenges in the modern digital landscape in diverse sociocultural contexts. ",
    "title": "Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "id": 190278,
    "sequence": 1577,
    "queryCoordinates": {
      "visualization": [
        -20.17926376084709,
        -5.813545739921843
      ]
    }
  },
  {
    "session": "WS14: Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "abstract": "Teens' mobile technology use can help teens connect with one another, but it also raises concerns around overuse, addiction, and exposure to harmful content. Traditional tools and methods for parental controls and guidance for mobile technology use among children, such as screen time limits, often fail to address teens' nuanced experiences on the benefits and harm of their mobile technology use. This workshop brings together interdisciplinary researchers, practitioners, and teen advocates to examine how the CHI community can foster healthy teen mobile-technology relationships. Our goals are to: (1) co-design research agenda, (2) foster cross-sociocultural collaboration, (3) generate guidance for stakeholders (e.g., public, policymakers, parents, healthcare providers), and (4) plan actionable steps for ongoing impact. The workshop will explore themes like engaging broader stakeholders, embracing marginalized voices, and navigating the implications of emerging technologies through panel presentations and interactive sessions. By examining these themes, we aim to re-explore the HCI community's discourse on teen mobile technology use and well-being, fostering a comprehensive understanding and inclusive approaches to navigate the multifaceted challenges in the modern digital landscape in diverse sociocultural contexts. ",
    "title": "Mobile Technology and Teens: Understanding the Changing Needs of Sociocultural and Technical Landscape",
    "id": 190279,
    "sequence": 1578,
    "queryCoordinates": {
      "visualization": [
        -17.0447423309119,
        -5.785910375456908
      ]
    }
  },
  {
    "session": "WS15: Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "abstract": "Children and young people today are uniquely datafied, tracked, and digitally monitored like no generation before them. Children are increasingly vulnerable to data collection through seemingly benign toys and devices equipped with voice recognition, geolocation, sensors, and cameras, but typically lack awareness or control over these data exchanges, as consent is usually provided by adult caregivers (who may also lack data rights literacy). Although there have been advancements in legislation and design guidelines, there is a significant need for interdisciplinary approaches to directly empower children in understanding, valuing and benefiting from their personal data, as well as learning to manage it. We ask, how can the CHI community support children to be informed and included in design for and with their personal data? How do we support children to participate in their personal data – and do they want to? This workshop aims to gather designers, researchers and practitioners working on projects relating to children’s personal data, and to map out the current practices and methods at play across the CHI community on this critical topic.",
    "title": "Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "id": 190285,
    "sequence": 1579,
    "queryCoordinates": {
      "visualization": [
        1.9591327532558593,
        16.88673440470715
      ]
    }
  },
  {
    "session": "WS15: Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "abstract": "Children and young people today are uniquely datafied, tracked, and digitally monitored like no generation before them. Children are increasingly vulnerable to data collection through seemingly benign toys and devices equipped with voice recognition, geolocation, sensors, and cameras, but typically lack awareness or control over these data exchanges, as consent is usually provided by adult caregivers (who may also lack data rights literacy). Although there have been advancements in legislation and design guidelines, there is a significant need for interdisciplinary approaches to directly empower children in understanding, valuing and benefiting from their personal data, as well as learning to manage it. We ask, how can the CHI community support children to be informed and included in design for and with their personal data? How do we support children to participate in their personal data – and do they want to? This workshop aims to gather designers, researchers and practitioners working on projects relating to children’s personal data, and to map out the current practices and methods at play across the CHI community on this critical topic.",
    "title": "Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "id": 190286,
    "sequence": 1580,
    "queryCoordinates": {
      "visualization": [
        -7.990363649641379,
        0.39254139461934373
      ]
    }
  },
  {
    "session": "WS15: Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "abstract": "Children and young people today are uniquely datafied, tracked, and digitally monitored like no generation before them. Children are increasingly vulnerable to data collection through seemingly benign toys and devices equipped with voice recognition, geolocation, sensors, and cameras, but typically lack awareness or control over these data exchanges, as consent is usually provided by adult caregivers (who may also lack data rights literacy). Although there have been advancements in legislation and design guidelines, there is a significant need for interdisciplinary approaches to directly empower children in understanding, valuing and benefiting from their personal data, as well as learning to manage it. We ask, how can the CHI community support children to be informed and included in design for and with their personal data? How do we support children to participate in their personal data – and do they want to? This workshop aims to gather designers, researchers and practitioners working on projects relating to children’s personal data, and to map out the current practices and methods at play across the CHI community on this critical topic.",
    "title": "Grasping Data: Mapping Out HCI Methods for Children and Young People’s Interactions with their Personal Data",
    "id": 190287,
    "sequence": 1581,
    "queryCoordinates": {
      "visualization": [
        -8.418439278177683,
        11.186146795015485
      ]
    }
  },
  {
    "session": "WS20: Resisting AI Solutionism: Where Do We Go From Here?",
    "abstract": "The latest advances in Artificial Intelligence (AI), such as Large Language Models (LLMs), have provoked a massive expansion and adoption of AI applications across the board, with seemingly no sector left untouched by recent developments. Anywhere we look, from healthcare to the creative industries, from education to entertainment, from sustainability to knowledge work, AI is being adopted and adapted, funded and fundraised for, developed and designed for, researched and used for doing research. As AI continues to be treated as a necessary and unquestioned solution for a range of societal problems, we seek to ponder and challenge its perceived suitability and inevitability. Moreover, we wonder how we can go about resisting AI solutionism (i.e., the idea that technology provides solutions to complex social problems) and who gets to resist it, in particular if the structures that surround people and their specific positions constrain them from doing so. This workshop will focus on gathering and sharing lessons from experiences resisting, or attempting to resist, AI solutionism; taking stock and revisiting previous learnings from decades of work within and beyond HCI; and envisioning ways, perspectives, tools, and practices to orient ourselves and each other towards more pluralistic futures.",
    "title": "Resisting AI Solutionism: Where Do We Go From Here?",
    "id": 190292,
    "sequence": 1582,
    "queryCoordinates": {
      "visualization": [
        -12.01043392264673,
        -4.974884620746166
      ]
    }
  },
  {
    "session": "WS20: Resisting AI Solutionism: Where Do We Go From Here?",
    "abstract": "The latest advances in Artificial Intelligence (AI), such as Large Language Models (LLMs), have provoked a massive expansion and adoption of AI applications across the board, with seemingly no sector left untouched by recent developments. Anywhere we look, from healthcare to the creative industries, from education to entertainment, from sustainability to knowledge work, AI is being adopted and adapted, funded and fundraised for, developed and designed for, researched and used for doing research. As AI continues to be treated as a necessary and unquestioned solution for a range of societal problems, we seek to ponder and challenge its perceived suitability and inevitability. Moreover, we wonder how we can go about resisting AI solutionism (i.e., the idea that technology provides solutions to complex social problems) and who gets to resist it, in particular if the structures that surround people and their specific positions constrain them from doing so. This workshop will focus on gathering and sharing lessons from experiences resisting, or attempting to resist, AI solutionism; taking stock and revisiting previous learnings from decades of work within and beyond HCI; and envisioning ways, perspectives, tools, and practices to orient ourselves and each other towards more pluralistic futures.",
    "title": "Resisting AI Solutionism: Where Do We Go From Here?",
    "id": 190293,
    "sequence": 1583,
    "queryCoordinates": {
      "visualization": [
        -15.781081602735139,
        8.657797840548977
      ]
    }
  },
  {
    "session": "WS20: Resisting AI Solutionism: Where Do We Go From Here?",
    "abstract": "The latest advances in Artificial Intelligence (AI), such as Large Language Models (LLMs), have provoked a massive expansion and adoption of AI applications across the board, with seemingly no sector left untouched by recent developments. Anywhere we look, from healthcare to the creative industries, from education to entertainment, from sustainability to knowledge work, AI is being adopted and adapted, funded and fundraised for, developed and designed for, researched and used for doing research. As AI continues to be treated as a necessary and unquestioned solution for a range of societal problems, we seek to ponder and challenge its perceived suitability and inevitability. Moreover, we wonder how we can go about resisting AI solutionism (i.e., the idea that technology provides solutions to complex social problems) and who gets to resist it, in particular if the structures that surround people and their specific positions constrain them from doing so. This workshop will focus on gathering and sharing lessons from experiences resisting, or attempting to resist, AI solutionism; taking stock and revisiting previous learnings from decades of work within and beyond HCI; and envisioning ways, perspectives, tools, and practices to orient ourselves and each other towards more pluralistic futures.",
    "title": "Resisting AI Solutionism: Where Do We Go From Here?",
    "id": 190294,
    "sequence": 1584,
    "queryCoordinates": {
      "visualization": [
        -18.99594191897069,
        0.3926711233235309
      ]
    }
  },
  {
    "session": "WS22: Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "abstract": "The increasing use of generative AI (GAI) as an accessibility tool offers transformative opportunities, but it also introduces significant risks and barriers that remain unaddressed. This workshop explores the multi-faceted nature of GAI use for accessibility, focusing on its potential to create access solutions where none exist while surfacing the risks of bias, inaccessibility, and misinformation. Our goal is to establish best practices for inclusive GAI design that centers disabled people’s agency, addressing key questions such as how to ensure GAI tools are accessible by default and how to mitigate risks without undermining autonomy. By bringing together experts in accessibility, AI, human-computer interaction (HCI), and disability studies, this workshop aims to develop design guidelines, recommendations, and practices that will influence future GAI systems. Participants will collaboratively define an agenda for creating GAI tools that advance equity, minimize harm, and embrace the diverse needs of the disability community.",
    "title": "Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "id": 190299,
    "sequence": 1585,
    "queryCoordinates": {
      "visualization": [
        -7.5905230123159715,
        4.835696475121414
      ]
    }
  },
  {
    "session": "WS22: Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "abstract": "The increasing use of generative AI (GAI) as an accessibility tool offers transformative opportunities, but it also introduces significant risks and barriers that remain unaddressed. This workshop explores the multi-faceted nature of GAI use for accessibility, focusing on its potential to create access solutions where none exist while surfacing the risks of bias, inaccessibility, and misinformation. Our goal is to establish best practices for inclusive GAI design that centers disabled people’s agency, addressing key questions such as how to ensure GAI tools are accessible by default and how to mitigate risks without undermining autonomy. By bringing together experts in accessibility, AI, human-computer interaction (HCI), and disability studies, this workshop aims to develop design guidelines, recommendations, and practices that will influence future GAI systems. Participants will collaboratively define an agenda for creating GAI tools that advance equity, minimize harm, and embrace the diverse needs of the disability community.",
    "title": "Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "id": 190300,
    "sequence": 1586,
    "queryCoordinates": {
      "visualization": [
        -1.1771545092012572,
        16.959195360083186
      ]
    }
  },
  {
    "session": "WS22: Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "abstract": "The increasing use of generative AI (GAI) as an accessibility tool offers transformative opportunities, but it also introduces significant risks and barriers that remain unaddressed. This workshop explores the multi-faceted nature of GAI use for accessibility, focusing on its potential to create access solutions where none exist while surfacing the risks of bias, inaccessibility, and misinformation. Our goal is to establish best practices for inclusive GAI design that centers disabled people’s agency, addressing key questions such as how to ensure GAI tools are accessible by default and how to mitigate risks without undermining autonomy. By bringing together experts in accessibility, AI, human-computer interaction (HCI), and disability studies, this workshop aims to develop design guidelines, recommendations, and practices that will influence future GAI systems. Participants will collaboratively define an agenda for creating GAI tools that advance equity, minimize harm, and embrace the diverse needs of the disability community.",
    "title": "Generative AI and Accessibility Workshop: Surfacing Opportunities and Risks",
    "id": 190301,
    "sequence": 1587,
    "queryCoordinates": {
      "visualization": [
        -11.35767632586158,
        15.23165087825228
      ]
    }
  },
  {
    "session": "WS23: Sensorimotor Devices: Coupling Sensing and Actuation to Augment Bodily Experience",
    "abstract": "An emerging space in interface research is wearable devices that closely couple their sensing and actuation abilities. A well-known example is MetaLimbs, where sensed movements of the foot are directly mapped to the actuation of supernumerary robotic limbs. These systems are different from wearables focused on sensing, such as fitness trackers, or wearables focused on actuation, such as VR headsets. They are characterized by tight coupling between the user's action and the resulting digital feedback from the device, in time, space, and mode. The properties of this coupling are critical for the user's experience, including the user's sense of agency, body ownership, and experience of the surrounding world. Understanding such systems is an open challenge, which requires knowledge not only of computer science and HCI, but also Psychology, Physiology, Design, Engineering, Cognitive Neuroscience, and Control Theory. This workshop aims to foster discussion between these diverse disciplines and to identify links and synergies in their work, ultimately developing a common understanding of future research directions for systems that intrinsically couple sensing and action.",
    "title": "Sensorimotor Devices: Coupling Sensing and Actuation to Augment  Bodily Experience",
    "id": 190306,
    "sequence": 1588,
    "queryCoordinates": {
      "visualization": [
        15.831536400142383,
        -15.276205523982936
      ]
    }
  },
  {
    "session": "WS23: Sensorimotor Devices: Coupling Sensing and Actuation to Augment Bodily Experience",
    "abstract": "An emerging space in interface research is wearable devices that closely couple their sensing and actuation abilities. A well-known example is MetaLimbs, where sensed movements of the foot are directly mapped to the actuation of supernumerary robotic limbs. These systems are different from wearables focused on sensing, such as fitness trackers, or wearables focused on actuation, such as VR headsets. They are characterized by tight coupling between the user's action and the resulting digital feedback from the device, in time, space, and mode. The properties of this coupling are critical for the user's experience, including the user's sense of agency, body ownership, and experience of the surrounding world. Understanding such systems is an open challenge, which requires knowledge not only of computer science and HCI, but also Psychology, Physiology, Design, Engineering, Cognitive Neuroscience, and Control Theory. This workshop aims to foster discussion between these diverse disciplines and to identify links and synergies in their work, ultimately developing a common understanding of future research directions for systems that intrinsically couple sensing and action.",
    "title": "Sensorimotor Devices: Coupling Sensing and Actuation to Augment  Bodily Experience",
    "id": 190307,
    "sequence": 1589,
    "queryCoordinates": {
      "visualization": [
        20.472383211731294,
        -8.054906928824357
      ]
    }
  },
  {
    "session": "WS23: Sensorimotor Devices: Coupling Sensing and Actuation to Augment Bodily Experience",
    "abstract": "An emerging space in interface research is wearable devices that closely couple their sensing and actuation abilities. A well-known example is MetaLimbs, where sensed movements of the foot are directly mapped to the actuation of supernumerary robotic limbs. These systems are different from wearables focused on sensing, such as fitness trackers, or wearables focused on actuation, such as VR headsets. They are characterized by tight coupling between the user's action and the resulting digital feedback from the device, in time, space, and mode. The properties of this coupling are critical for the user's experience, including the user's sense of agency, body ownership, and experience of the surrounding world. Understanding such systems is an open challenge, which requires knowledge not only of computer science and HCI, but also Psychology, Physiology, Design, Engineering, Cognitive Neuroscience, and Control Theory. This workshop aims to foster discussion between these diverse disciplines and to identify links and synergies in their work, ultimately developing a common understanding of future research directions for systems that intrinsically couple sensing and action.",
    "title": "Sensorimotor Devices: Coupling Sensing and Actuation to Augment  Bodily Experience",
    "id": 190308,
    "sequence": 1590,
    "queryCoordinates": {
      "visualization": [
        15.27620552398293,
        -15.831536400142388
      ]
    }
  },
  {
    "session": "WS24: Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "abstract": "Designing and developing user-friendly interfaces has long been a cornerstone of HCI research. However, we are now at a turning point for how user interfaces can be designed and evaluated with new AI-based models and tools. The latest AI models have shown capabilities to model user behaviors, automate end-user tasks, and even generate user interfaces. We are at a pivotal moment to reflect on current UI design and development practices and discuss the opportunities, challenges, and risks brought by AI. Both incremental improvements and transformative opportunities exist for designers, developers, and the hand-off process in between. In this proposed workshop, we encourage participants to envision AI-enabled UI prototyping tools, workflows, and practices. By bringing together academic researchers and industry practitioners, we aim to identify opportunities to enhance prototyping tools and reshape UI creation workflows for the future as well as discuss potential negative consequences of these tools.",
    "title": "Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "id": 190313,
    "sequence": 1591,
    "queryCoordinates": {
      "visualization": [
        -17.55371111771445,
        7.270985214936708
      ]
    }
  },
  {
    "session": "WS24: Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "abstract": "Designing and developing user-friendly interfaces has long been a cornerstone of HCI research. However, we are now at a turning point for how user interfaces can be designed and evaluated with new AI-based models and tools. The latest AI models have shown capabilities to model user behaviors, automate end-user tasks, and even generate user interfaces. We are at a pivotal moment to reflect on current UI design and development practices and discuss the opportunities, challenges, and risks brought by AI. Both incremental improvements and transformative opportunities exist for designers, developers, and the hand-off process in between. In this proposed workshop, we encourage participants to envision AI-enabled UI prototyping tools, workflows, and practices. By bringing together academic researchers and industry practitioners, we aim to identify opportunities to enhance prototyping tools and reshape UI creation workflows for the future as well as discuss potential negative consequences of these tools.",
    "title": "Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "id": 190314,
    "sequence": 1592,
    "queryCoordinates": {
      "visualization": [
        -11.230871121087906,
        4.227000575054807
      ]
    }
  },
  {
    "session": "WS24: Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "abstract": "Designing and developing user-friendly interfaces has long been a cornerstone of HCI research. However, we are now at a turning point for how user interfaces can be designed and evaluated with new AI-based models and tools. The latest AI models have shown capabilities to model user behaviors, automate end-user tasks, and even generate user interfaces. We are at a pivotal moment to reflect on current UI design and development practices and discuss the opportunities, challenges, and risks brought by AI. Both incremental improvements and transformative opportunities exist for designers, developers, and the hand-off process in between. In this proposed workshop, we encourage participants to envision AI-enabled UI prototyping tools, workflows, and practices. By bringing together academic researchers and industry practitioners, we aim to identify opportunities to enhance prototyping tools and reshape UI creation workflows for the future as well as discuss potential negative consequences of these tools.",
    "title": "Designing and Developing User Interfaces with AI: Advancing Tools, Workflows, and Practices",
    "id": 190315,
    "sequence": 1593,
    "queryCoordinates": {
      "visualization": [
        -18.094189494621478,
        5.796577139375424
      ]
    }
  },
  {
    "session": "WS26: Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "abstract": "Automated systems and AI-assisted workflows are evolving from support tools to sophisticated collaborators in so-called \"hybrid\" teams with human and AI-based members. This evolution presents new challenges and opportunities in the field of \"Automation Experience\", particularly in how these team members communicate, coordinate, and collaborate. This workshop aims to contribute to the design of automated systems that augment users' capabilities, maintain human autonomy, and create positive automation experiences in human-AI teams. Through presentations, a keynote talk, discussions, and interactive collaborative activities, researchers and practitioners from different fields will address challenges regarding communication, coordination, and collaboration within hybrid human-AI teams. The workshop aims to spark innovative research directions and foster collaborative interdisciplinary initiatives that will advance our understanding of automation experiences in an increasingly AI-dominated landscape.",
    "title": "Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "id": 190320,
    "sequence": 1594,
    "queryCoordinates": {
      "visualization": [
        -13.99449276936274,
        0.392647587862164
      ]
    }
  },
  {
    "session": "WS26: Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "abstract": "Automated systems and AI-assisted workflows are evolving from support tools to sophisticated collaborators in so-called \"hybrid\" teams with human and AI-based members. This evolution presents new challenges and opportunities in the field of \"Automation Experience\", particularly in how these team members communicate, coordinate, and collaborate. This workshop aims to contribute to the design of automated systems that augment users' capabilities, maintain human autonomy, and create positive automation experiences in human-AI teams. Through presentations, a keynote talk, discussions, and interactive collaborative activities, researchers and practitioners from different fields will address challenges regarding communication, coordination, and collaboration within hybrid human-AI teams. The workshop aims to spark innovative research directions and foster collaborative interdisciplinary initiatives that will advance our understanding of automation experiences in an increasingly AI-dominated landscape.",
    "title": "Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "id": 190321,
    "sequence": 1595,
    "queryCoordinates": {
      "visualization": [
        -10.325318635406306,
        10.880615565184316
      ]
    }
  },
  {
    "session": "WS26: Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "abstract": "Automated systems and AI-assisted workflows are evolving from support tools to sophisticated collaborators in so-called \"hybrid\" teams with human and AI-based members. This evolution presents new challenges and opportunities in the field of \"Automation Experience\", particularly in how these team members communicate, coordinate, and collaborate. This workshop aims to contribute to the design of automated systems that augment users' capabilities, maintain human autonomy, and create positive automation experiences in human-AI teams. Through presentations, a keynote talk, discussions, and interactive collaborative activities, researchers and practitioners from different fields will address challenges regarding communication, coordination, and collaboration within hybrid human-AI teams. The workshop aims to spark innovative research directions and foster collaborative interdisciplinary initiatives that will advance our understanding of automation experiences in an increasingly AI-dominated landscape.",
    "title": "Hybrid Automation Experiences – Communication, Coordination, and Collaboration within Human-AI Teams",
    "id": 190322,
    "sequence": 1596,
    "queryCoordinates": {
      "visualization": [
        -12.438238903704214,
        6.425746102545526
      ]
    }
  },
  {
    "session": "WS30: Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "abstract": "Over the past decade, a noticeable increase in literature can be seen in wearable foot interfaces, which have evolved from activity tracking to enhancing human capabilities. Our legs, being the largest body limbs, play an essential role in various functions such as locomotion, maintaining balance, supporting proper posture and providing ground-contact using our feet. Hence, foot augmentations offer the opportunity to augment our entire body. However, most prior research focuses on specific application areas, thus affording a research agenda to further understand the full potential of feet in designing augmentations and to contextualize it in the broader human augmentation space. To achieve this, in this workshop, we invite researchers, designers, and practitioners, novice and expert, interested in designing human and foot augmentations. We will discuss how early foot interfaces helped in augmenting humans, and based on current work and trends in foot augmentation, we will formulate strategies for the next steps and discuss the applicability of such strategies in the broader space of human augmentation. ",
    "title": "Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "id": 190327,
    "sequence": 1597,
    "queryCoordinates": {
      "visualization": [
        -13.862535754710239,
        1.9570647534969914
      ]
    }
  },
  {
    "session": "WS30: Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "abstract": "Over the past decade, a noticeable increase in literature can be seen in wearable foot interfaces, which have evolved from activity tracking to enhancing human capabilities. Our legs, being the largest body limbs, play an essential role in various functions such as locomotion, maintaining balance, supporting proper posture and providing ground-contact using our feet. Hence, foot augmentations offer the opportunity to augment our entire body. However, most prior research focuses on specific application areas, thus affording a research agenda to further understand the full potential of feet in designing augmentations and to contextualize it in the broader human augmentation space. To achieve this, in this workshop, we invite researchers, designers, and practitioners, novice and expert, interested in designing human and foot augmentations. We will discuss how early foot interfaces helped in augmenting humans, and based on current work and trends in foot augmentation, we will formulate strategies for the next steps and discuss the applicability of such strategies in the broader space of human augmentation. ",
    "title": "Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "id": 190329,
    "sequence": 1598,
    "queryCoordinates": {
      "visualization": [
        -11.186146795015484,
        8.418439278177685
      ]
    }
  },
  {
    "session": "WS30: Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "abstract": "Over the past decade, a noticeable increase in literature can be seen in wearable foot interfaces, which have evolved from activity tracking to enhancing human capabilities. Our legs, being the largest body limbs, play an essential role in various functions such as locomotion, maintaining balance, supporting proper posture and providing ground-contact using our feet. Hence, foot augmentations offer the opportunity to augment our entire body. However, most prior research focuses on specific application areas, thus affording a research agenda to further understand the full potential of feet in designing augmentations and to contextualize it in the broader human augmentation space. To achieve this, in this workshop, we invite researchers, designers, and practitioners, novice and expert, interested in designing human and foot augmentations. We will discuss how early foot interfaces helped in augmenting humans, and based on current work and trends in foot augmentation, we will formulate strategies for the next steps and discuss the applicability of such strategies in the broader space of human augmentation. ",
    "title": "Walking the Future: Bridging Foot Augmentation into Next Steps of Human Augmentation",
    "id": 190330,
    "sequence": 1599,
    "queryCoordinates": {
      "visualization": [
        -12.152097219775927,
        17.126778248144458
      ]
    }
  },
  {
    "session": "WS32: Maternal Machines: Imagining Experiences in Perinatal Care",
    "abstract": "Perinatal care is a term that broadly refers to the period of time from pregnancy up to a year after giving birth. Imaginaries, fictional scenarios, patents and actual designs to support affected stakeholders during this period reflect how this topic has for a long time fed into society’s dreams, fears and desires about care. Smart monitors of infants’ sleep, respiration, heart rate or temperature, cots with facial recognition, swing chairs that are ‘Alexa compatible’, chatbots for postpartum depression, ‘maternal’ Alexas or nanny robots are examples of the potentials that this topic offers for imagining scenarios for care and wellbeing. Often rich with insights about societal dreams, fears and desires about what we would like technologies to do for us, imagined scenarios can also indicate ways in which we regard those already engaged in roles of care, echoing cultural and gendered tropes. As AI and related technologies increasingly become entangled in situations of care, the imagined possibilities in contexts of such complex, sensitive and emotionally charged spaces are worth examining, whilst interrogating how HCI technologies in perinatal care could expand beyond quantifiable data and tap into sensorial, non-numerical forms of knowledge.\r\nIn this workshop, we will look at ideated scenarios with technologies related to maternal and infant care in contemporary, historical and cultural contexts including those from Japan, and we will create our own imagined scenarios of care. Through a mixture of activities that include presentations, drawing, hands-on interactions and group conversations we will discuss opportunities and implications in the design of technologies for maternal/parental and infant care around the perinatal period. Our imagined scenarios will explore in particular two interrelated themes in the research: non-numerical forms of knowledge and touch.\r\n",
    "title": "Maternal Machines: Imagining Experiences in Perinatal Care",
    "id": 190335,
    "sequence": 1600,
    "queryCoordinates": {
      "visualization": [
        -11.323208259941705,
        -6.386309944090403
      ]
    }
  },
  {
    "session": "WS32: Maternal Machines: Imagining Experiences in Perinatal Care",
    "abstract": "Perinatal care is a term that broadly refers to the period of time from pregnancy up to a year after giving birth. Imaginaries, fictional scenarios, patents and actual designs to support affected stakeholders during this period reflect how this topic has for a long time fed into society’s dreams, fears and desires about care. Smart monitors of infants’ sleep, respiration, heart rate or temperature, cots with facial recognition, swing chairs that are ‘Alexa compatible’, chatbots for postpartum depression, ‘maternal’ Alexas or nanny robots are examples of the potentials that this topic offers for imagining scenarios for care and wellbeing. Often rich with insights about societal dreams, fears and desires about what we would like technologies to do for us, imagined scenarios can also indicate ways in which we regard those already engaged in roles of care, echoing cultural and gendered tropes. As AI and related technologies increasingly become entangled in situations of care, the imagined possibilities in contexts of such complex, sensitive and emotionally charged spaces are worth examining, whilst interrogating how HCI technologies in perinatal care could expand beyond quantifiable data and tap into sensorial, non-numerical forms of knowledge.\r\nIn this workshop, we will look at ideated scenarios with technologies related to maternal and infant care in contemporary, historical and cultural contexts including those from Japan, and we will create our own imagined scenarios of care. Through a mixture of activities that include presentations, drawing, hands-on interactions and group conversations we will discuss opportunities and implications in the design of technologies for maternal/parental and infant care around the perinatal period. Our imagined scenarios will explore in particular two interrelated themes in the research: non-numerical forms of knowledge and touch.\r\n",
    "title": "Maternal Machines: Imagining Experiences in Perinatal Care",
    "id": 190336,
    "sequence": 1601,
    "queryCoordinates": {
      "visualization": [
        -17.254687719555832,
        10.113147467559699
      ]
    }
  },
  {
    "session": "WS32: Maternal Machines: Imagining Experiences in Perinatal Care",
    "abstract": "Perinatal care is a term that broadly refers to the period of time from pregnancy up to a year after giving birth. Imaginaries, fictional scenarios, patents and actual designs to support affected stakeholders during this period reflect how this topic has for a long time fed into society’s dreams, fears and desires about care. Smart monitors of infants’ sleep, respiration, heart rate or temperature, cots with facial recognition, swing chairs that are ‘Alexa compatible’, chatbots for postpartum depression, ‘maternal’ Alexas or nanny robots are examples of the potentials that this topic offers for imagining scenarios for care and wellbeing. Often rich with insights about societal dreams, fears and desires about what we would like technologies to do for us, imagined scenarios can also indicate ways in which we regard those already engaged in roles of care, echoing cultural and gendered tropes. As AI and related technologies increasingly become entangled in situations of care, the imagined possibilities in contexts of such complex, sensitive and emotionally charged spaces are worth examining, whilst interrogating how HCI technologies in perinatal care could expand beyond quantifiable data and tap into sensorial, non-numerical forms of knowledge.\r\nIn this workshop, we will look at ideated scenarios with technologies related to maternal and infant care in contemporary, historical and cultural contexts including those from Japan, and we will create our own imagined scenarios of care. Through a mixture of activities that include presentations, drawing, hands-on interactions and group conversations we will discuss opportunities and implications in the design of technologies for maternal/parental and infant care around the perinatal period. Our imagined scenarios will explore in particular two interrelated themes in the research: non-numerical forms of knowledge and touch.\r\n",
    "title": "Maternal Machines: Imagining Experiences in Perinatal Care",
    "id": 190337,
    "sequence": 1602,
    "queryCoordinates": {
      "visualization": [
        -15.87967255357936,
        -1.9585708031874576
      ]
    }
  },
  {
    "session": "WS34: Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "abstract": "Trained and optimized for typical and fluent speech, speech AI works poorly for people with speech diversities, often cutting them off from speaking and misinterpreting their speech. The increasing deployment of speech AI in automated phone menus, AI-conducted job interviews, and everyday devices poses tangible risks to people with speech diversities. To mitigate these risks, this workshop aims to build a multidisciplinary coalition and set the research agenda for fair and accessible speech AI. Bringing together a broad group of academics and practitioners with diverse perspectives including HCI, AI, and other relevant fields such as disability studies, speech language pathology, and law, this workshop will establish a shared understanding of the technical challenges for fair and accessible speech AI, as well as its ramifications in design, user experience, policy, society. In addition, the workshop will invite and highlight first-person accounts from people with speech diversities, facilitating direct dialogues and collaboration between speech AI developers and the impacted communities. The key outcomes of this workshop include a summary paper that synthesizes our leanings and outlines the roadmap for improving speech AI for people with speech diversities, as well as a community of scholars, practitioners, activists, and policy makers interested in drivings progress in this domain.",
    "title": "Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "id": 190342,
    "sequence": 1603,
    "queryCoordinates": {
      "visualization": [
        12.15209721977592,
        17.126778248144465
      ]
    }
  },
  {
    "session": "WS34: Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "abstract": "Trained and optimized for typical and fluent speech, speech AI works poorly for people with speech diversities, often cutting them off from speaking and misinterpreting their speech. The increasing deployment of speech AI in automated phone menus, AI-conducted job interviews, and everyday devices poses tangible risks to people with speech diversities. To mitigate these risks, this workshop aims to build a multidisciplinary coalition and set the research agenda for fair and accessible speech AI. Bringing together a broad group of academics and practitioners with diverse perspectives including HCI, AI, and other relevant fields such as disability studies, speech language pathology, and law, this workshop will establish a shared understanding of the technical challenges for fair and accessible speech AI, as well as its ramifications in design, user experience, policy, society. In addition, the workshop will invite and highlight first-person accounts from people with speech diversities, facilitating direct dialogues and collaboration between speech AI developers and the impacted communities. The key outcomes of this workshop include a summary paper that synthesizes our leanings and outlines the roadmap for improving speech AI for people with speech diversities, as well as a community of scholars, practitioners, activists, and policy makers interested in drivings progress in this domain.",
    "title": "Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "id": 190343,
    "sequence": 1604,
    "queryCoordinates": {
      "visualization": [
        -12.778965710858465,
        -5.718219597103947
      ]
    }
  },
  {
    "session": "WS34: Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "abstract": "Trained and optimized for typical and fluent speech, speech AI works poorly for people with speech diversities, often cutting them off from speaking and misinterpreting their speech. The increasing deployment of speech AI in automated phone menus, AI-conducted job interviews, and everyday devices poses tangible risks to people with speech diversities. To mitigate these risks, this workshop aims to build a multidisciplinary coalition and set the research agenda for fair and accessible speech AI. Bringing together a broad group of academics and practitioners with diverse perspectives including HCI, AI, and other relevant fields such as disability studies, speech language pathology, and law, this workshop will establish a shared understanding of the technical challenges for fair and accessible speech AI, as well as its ramifications in design, user experience, policy, society. In addition, the workshop will invite and highlight first-person accounts from people with speech diversities, facilitating direct dialogues and collaboration between speech AI developers and the impacted communities. The key outcomes of this workshop include a summary paper that synthesizes our leanings and outlines the roadmap for improving speech AI for people with speech diversities, as well as a community of scholars, practitioners, activists, and policy makers interested in drivings progress in this domain.",
    "title": "Speech AI for All: Promoting Accessibility, Fairness, Inclusivity, and Equity",
    "id": 190344,
    "sequence": 1605,
    "queryCoordinates": {
      "visualization": [
        -10.658310319596582,
        -2.7203715060963654
      ]
    }
  },
  {
    "session": "WS35: Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "abstract": "Rapid advancements in and adoption of frontier AI systems have amplified the need for AI governance measures across the public sector, academia, and industry. Prior work in technical AI governance has proposed agendas for governing technical components in AI development, such as data, models, and compute. However, recent calls for more sociotechnical approaches recognize the critical role of social infrastructures surrounding technical ones in shaping governance decisions and efforts. While scholars and practitioners have advocated for sociotechnical AI governance, concrete research directions in this area are only beginning to emerge. This workshop aims to gather the expertise of researchers in HCI and adjacent disciplines to chart promising paths forward for sociotechnical AI governance. To make problems in this area more tangible, we outline four core governance challenges for contributions: anticipating high-priority risks to address with governance, identifying where to focus governance efforts and who should lead those efforts, designing appropriate interventions and tools to implement governance actions in practice, and evaluating the effectiveness of these interventions and tools in context. Through papers, panel discussions, keynotes, and collaborative drafting of a research agenda, this workshop will build community and empower actionable efforts to tackle AI governance through a sociotechnical lens.",
    "title": "Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "id": 190349,
    "sequence": 1606,
    "queryCoordinates": {
      "visualization": [
        -15.98964536214065,
        -5.773321504383243
      ]
    }
  },
  {
    "session": "WS35: Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "abstract": "Rapid advancements in and adoption of frontier AI systems have amplified the need for AI governance measures across the public sector, academia, and industry. Prior work in technical AI governance has proposed agendas for governing technical components in AI development, such as data, models, and compute. However, recent calls for more sociotechnical approaches recognize the critical role of social infrastructures surrounding technical ones in shaping governance decisions and efforts. While scholars and practitioners have advocated for sociotechnical AI governance, concrete research directions in this area are only beginning to emerge. This workshop aims to gather the expertise of researchers in HCI and adjacent disciplines to chart promising paths forward for sociotechnical AI governance. To make problems in this area more tangible, we outline four core governance challenges for contributions: anticipating high-priority risks to address with governance, identifying where to focus governance efforts and who should lead those efforts, designing appropriate interventions and tools to implement governance actions in practice, and evaluating the effectiveness of these interventions and tools in context. Through papers, panel discussions, keynotes, and collaborative drafting of a research agenda, this workshop will build community and empower actionable efforts to tackle AI governance through a sociotechnical lens.",
    "title": "Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "id": 190350,
    "sequence": 1607,
    "queryCoordinates": {
      "visualization": [
        -13.993278136992078,
        -15.658485462546482
      ]
    }
  },
  {
    "session": "WS35: Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "abstract": "Rapid advancements in and adoption of frontier AI systems have amplified the need for AI governance measures across the public sector, academia, and industry. Prior work in technical AI governance has proposed agendas for governing technical components in AI development, such as data, models, and compute. However, recent calls for more sociotechnical approaches recognize the critical role of social infrastructures surrounding technical ones in shaping governance decisions and efforts. While scholars and practitioners have advocated for sociotechnical AI governance, concrete research directions in this area are only beginning to emerge. This workshop aims to gather the expertise of researchers in HCI and adjacent disciplines to chart promising paths forward for sociotechnical AI governance. To make problems in this area more tangible, we outline four core governance challenges for contributions: anticipating high-priority risks to address with governance, identifying where to focus governance efforts and who should lead those efforts, designing appropriate interventions and tools to implement governance actions in practice, and evaluating the effectiveness of these interventions and tools in context. Through papers, panel discussions, keynotes, and collaborative drafting of a research agenda, this workshop will build community and empower actionable efforts to tackle AI governance through a sociotechnical lens.",
    "title": "Sociotechnical AI Governance: Challenges and Opportunities for HCI",
    "id": 190351,
    "sequence": 1608,
    "queryCoordinates": {
      "visualization": [
        -16.454131257784486,
        -4.273355186688743
      ]
    }
  },
  {
    "session": "WS38: Technology Mediated Caregiving For Older Adults Aging in Place",
    "abstract": "The caregiving environment for an older adult aging in place includes a network of caregivers working with the older adult to support their needs and maintain independence. As older adults experience cognitive and functional changes, their caregiving network expands to include spouses or siblings (who are often older adults themselves), children, friends, neighbors and community members—each bringing unique values, expectations, and goals. In this network of care, technology-enabled support offers the potential to mediate care responsibilities, such as coordinating activities and assisting with everyday tasks. However, designing these systems requires addressing value tensions among caregivers, cultural norms around aging, participatory research practices and balancing autonomy with safety concerns for older adults in later life. This workshop brings together researchers and practitioners to discuss (1) opportunities and challenges for designing technological systems for caregiving for older adults; (2) longitudinal interactions with these systems as older adults progress through stages of functional and cognitive changes; (3) potential for such systems to support caregivers while centering older adults' privacy and autonomy needs; and (4) the influence of cultural norms on caregiving and technology use.",
    "title": "Technology Mediated Caregiving For Older Adults Aging in Place",
    "id": 190356,
    "sequence": 1609,
    "queryCoordinates": {
      "visualization": [
        -3.5088867185306754,
        16.633932607670353
      ]
    }
  },
  {
    "session": "WS38: Technology Mediated Caregiving For Older Adults Aging in Place",
    "abstract": "The caregiving environment for an older adult aging in place includes a network of caregivers working with the older adult to support their needs and maintain independence. As older adults experience cognitive and functional changes, their caregiving network expands to include spouses or siblings (who are often older adults themselves), children, friends, neighbors and community members—each bringing unique values, expectations, and goals. In this network of care, technology-enabled support offers the potential to mediate care responsibilities, such as coordinating activities and assisting with everyday tasks. However, designing these systems requires addressing value tensions among caregivers, cultural norms around aging, participatory research practices and balancing autonomy with safety concerns for older adults in later life. This workshop brings together researchers and practitioners to discuss (1) opportunities and challenges for designing technological systems for caregiving for older adults; (2) longitudinal interactions with these systems as older adults progress through stages of functional and cognitive changes; (3) potential for such systems to support caregivers while centering older adults' privacy and autonomy needs; and (4) the influence of cultural norms on caregiving and technology use.",
    "title": "Technology Mediated Caregiving For Older Adults Aging in Place",
    "id": 190357,
    "sequence": 1610,
    "queryCoordinates": {
      "visualization": [
        -5.740251485476346,
        13.858192987669302
      ]
    }
  },
  {
    "session": "WS38: Technology Mediated Caregiving For Older Adults Aging in Place",
    "abstract": "The caregiving environment for an older adult aging in place includes a network of caregivers working with the older adult to support their needs and maintain independence. As older adults experience cognitive and functional changes, their caregiving network expands to include spouses or siblings (who are often older adults themselves), children, friends, neighbors and community members—each bringing unique values, expectations, and goals. In this network of care, technology-enabled support offers the potential to mediate care responsibilities, such as coordinating activities and assisting with everyday tasks. However, designing these systems requires addressing value tensions among caregivers, cultural norms around aging, participatory research practices and balancing autonomy with safety concerns for older adults in later life. This workshop brings together researchers and practitioners to discuss (1) opportunities and challenges for designing technological systems for caregiving for older adults; (2) longitudinal interactions with these systems as older adults progress through stages of functional and cognitive changes; (3) potential for such systems to support caregivers while centering older adults' privacy and autonomy needs; and (4) the influence of cultural norms on caregiving and technology use.",
    "title": "Technology Mediated Caregiving For Older Adults Aging in Place",
    "id": 190358,
    "sequence": 1611,
    "queryCoordinates": {
      "visualization": [
        -1.9530851587973366,
        10.825223247697277
      ]
    }
  },
  {
    "session": "WS40: Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "abstract": "Local and federal agencies are rapidly adopting AI systems to augment or automate critical decisions, efficiently use resources, and improve public service delivery. AI systems are being used to support tasks associated with urban planning, security, surveillance, energy and critical infrastructure, and support decisions that directly affect citizens and their ability to access essential services. Local governments act as the governance tier closest to citizens and must play a critical role in upholding democratic values and building community trust especially as it relates to smart city initiatives that seek to transform public services through the adoption of AI. Community-centered and participatory approaches have been central for ensuring the appropriate adoption of technology; however, AI innovation introduces new challenges in this context because participatory AI design methods require more robust formulation and face higher standards for implementation in the public sector compared to the private sector. This requires us to reassess traditional methods used in this space as well as develop new resources and methods. This workshop will explore emerging practices in participatory algorithm design – or the use of public participation and community engagement - in the scoping, design, adoption, and implementation of public sector algorithms.",
    "title": " Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "id": 190363,
    "sequence": 1612,
    "queryCoordinates": {
      "visualization": [
        -17.83918928399116,
        -6.5393673768901275
      ]
    }
  },
  {
    "session": "WS40: Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "abstract": "Local and federal agencies are rapidly adopting AI systems to augment or automate critical decisions, efficiently use resources, and improve public service delivery. AI systems are being used to support tasks associated with urban planning, security, surveillance, energy and critical infrastructure, and support decisions that directly affect citizens and their ability to access essential services. Local governments act as the governance tier closest to citizens and must play a critical role in upholding democratic values and building community trust especially as it relates to smart city initiatives that seek to transform public services through the adoption of AI. Community-centered and participatory approaches have been central for ensuring the appropriate adoption of technology; however, AI innovation introduces new challenges in this context because participatory AI design methods require more robust formulation and face higher standards for implementation in the public sector compared to the private sector. This requires us to reassess traditional methods used in this space as well as develop new resources and methods. This workshop will explore emerging practices in participatory algorithm design – or the use of public participation and community engagement - in the scoping, design, adoption, and implementation of public sector algorithms.",
    "title": " Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "id": 190364,
    "sequence": 1613,
    "queryCoordinates": {
      "visualization": [
        -17.96146061829486,
        -1.1772563261425717
      ]
    }
  },
  {
    "session": "WS40: Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "abstract": "Local and federal agencies are rapidly adopting AI systems to augment or automate critical decisions, efficiently use resources, and improve public service delivery. AI systems are being used to support tasks associated with urban planning, security, surveillance, energy and critical infrastructure, and support decisions that directly affect citizens and their ability to access essential services. Local governments act as the governance tier closest to citizens and must play a critical role in upholding democratic values and building community trust especially as it relates to smart city initiatives that seek to transform public services through the adoption of AI. Community-centered and participatory approaches have been central for ensuring the appropriate adoption of technology; however, AI innovation introduces new challenges in this context because participatory AI design methods require more robust formulation and face higher standards for implementation in the public sector compared to the private sector. This requires us to reassess traditional methods used in this space as well as develop new resources and methods. This workshop will explore emerging practices in participatory algorithm design – or the use of public participation and community engagement - in the scoping, design, adoption, and implementation of public sector algorithms.",
    "title": " Emerging Practices in Participatory AI Design in Public Sector Innovation",
    "id": 190365,
    "sequence": 1614,
    "queryCoordinates": {
      "visualization": [
        -2.706352195538458,
        8.583452556734043
      ]
    }
  },
  {
    "session": "WS31: Affective interaction and affective computing - past, present and future",
    "abstract": "HCI researchers recognize affect and emotion as fundamental parts of human experience however conceptualizing emotions as ineffable, embodied, situated, or culturally bound does not fit within some of the dominant paradigm of Affective computing and emotion AI research focused mostly on recognition and classification of basic emotions. An alternative term, \\textit{Affective Interaction}, has emerged to bring together a growing body of research which treats emotion and affect within HCI in similar ways. This workshop brings the research community together to examine various perspectives on affect, and specifically contrast Affective Interaction with Affective Computing. The aim is to discuss opportunities and limitations associated with each perspective, reconcile with advances in the science of emotion, and to speculate on future research directions. We believe that bringing together HCI researchers around Affective Interaction is vitally important because the broad reach of Affective Computing techniques may be obscuring advances in emotion research that show evidence that emotion defies easy categories and is culturally situated. ",
    "title": "Affective interaction and affective computing - past, present and future",
    "id": 190370,
    "sequence": 1615,
    "queryCoordinates": {
      "visualization": [
        1.947956525442922,
        -8.786664064079401
      ]
    }
  },
  {
    "session": "Running Online User Studies with the reVISit Framework",
    "abstract": "Running online user studies can be done using commercial survey tools or building custom software. However, these methods have limitations and require significant labor. This course introduces reVISit, an open-source alternative that streamlines study design. ReVISit eliminates tedious tasks by providing built-in components for UI, data hosting, participant recruiting, and more. Study designers can focus on research questions and stimulus design using a domain-specific language to quickly create studies as static websites. Throughout the course, participants will develop and deploy an interactive, fully instrumented study, improving their skills through hands-on experience with reVISit.",
    "title": "Running Online User Studies with the reVISit Framework",
    "id": 191128,
    "sequence": 1616,
    "queryCoordinates": {
      "visualization": [
        7.058336768619223,
        10.916953881956172
      ]
    }
  },
  {
    "session": "Running Online User Studies with the reVISit Framework",
    "abstract": "Running online user studies can be done using commercial survey tools or building custom software. However, these methods have limitations and require significant labor. This course introduces reVISit, an open-source alternative that streamlines study design. ReVISit eliminates tedious tasks by providing built-in components for UI, data hosting, participant recruiting, and more. Study designers can focus on research questions and stimulus design using a domain-specific language to quickly create studies as static websites. Throughout the course, participants will develop and deploy an interactive, fully instrumented study, improving their skills through hands-on experience with reVISit.",
    "title": "Running Online User Studies with the reVISit Framework",
    "id": 191129,
    "sequence": 1617,
    "queryCoordinates": {
      "visualization": [
        -2.974334584121431,
        0.3915785766601547
      ]
    }
  },
  {
    "session": "Design, Fabrication, Interaction Techniques",
    "abstract": "UI task automation enables efficient task execution by simulating human interactions with graphical user interfaces (GUIs), without modifying the existing application code. However, its broader adoption is constrained by the need for expertise in both scripting languages and workflow design. To address this challenge, we present Prompt2Task, a system designed to comprehend various task-related textual prompts (e.g., goals, procedures), thereby generating and performing the corresponding automation tasks. Prompt2Task incorporates a suite of intelligent agents that mimic human cognitive functions, specializing in interpreting user intent, managing external information for task generation, and executing operations on smartphones. The agents can learn from user feedback and continuously improve their performance based on the accumulated knowledge. Experimental results indicated a performance jump from a 22.28% success rate in the baseline to 95.24% with Prompt2Task, requiring an average of 0.69 user interventions for each new task. Prompt2Task presents promising applications in fields such as tutorial creation, smart assistance, and customer service.",
    "title": "Prompt2Task: Automating UI Tasks on Smartphones from Textual Prompts",
    "id": 191697,
    "sequence": 1618,
    "queryCoordinates": {
      "visualization": [
        -11.357676325861581,
        -15.231650878252278
      ]
    }
  },
  {
    "session": "Social Media, Online Community, Sensemaking",
    "abstract": "Social media platforms are frequently used to share information and opinions around vaccinations. The more often a message is reshared, the wider the reach of the message and potential influence it may have on shaping people’s opinions to get vaccinated or not. We used a negative binomial regression to investigate whether a message's linguistic characteristics (degree of concreteness, emotional arousal, and sentiment) and user characteristics (political ideology and number of followers) may influence users’ decisions to reshare tweets related to the COVID-19 vaccine. We analyzed US English-language tweets related to the COVID-19 vaccine between May 2020 and October 2021 (N = 236,054).\r\n\r\nTweets with positive and high-arousal words were more often retweeted than negative, low-arousal tweets. Tweets with abstract words were more often retweeted than tweets with concrete words. In addition, while Liberal users were more likely to have tweets with a positive sentiment reshared, Conservative users were more likely to have tweets with a negative sentiment reshared. Our results can inform public health messaging on how to best phrase vaccine information to impact engagement and information resharing, and potentially persuade a wider set of people to get vaccinated.\r\n",
    "title": "Wording Matters: The Effect of Linguistic Characteristics and Political Ideology on Resharing of COVID-19 Vaccine Tweets",
    "id": 191698,
    "sequence": 1619,
    "queryCoordinates": {
      "visualization": [
        12.946655249022182,
        1.1764853857852917
      ]
    }
  },
  {
    "session": "Inclusive and Participatory",
    "abstract": "Despite recent advancements, real-world use of Artificial Intelligence (AI) in radiology remains low, often due to the mismatch between AI offerings and the situated challenges faced by healthcare professionals. To bridge this gap, we conducted a field study at nine medical sites in Denmark and Kenya with two goals: (1) to understand the challenges faced by radiologists during chest X-ray practice; (2) to envision alternative AI futures that align with collaborative clinical work. This study uniquely grounds the AI design insights in the comprehensive characterisation of diagnostic work across multiple geographical and institutional contexts. Building on ideas articulated by interviewed radiologists (N=18), we conceptualised five visions that transcend the traditional notions of AI support. These visions emphasise that the clinical usefulness of AI-based systems depends on their configurability and flexibility across three dimensions: type of clinical site, expertise of medical professionals, and situational and patient contexts. Addressing these dependencies requires expanding the clinical AI design space by envisioning futures rooted in the realities of practice rather than solely following the trajectory of AI development.",
    "title": "Towards Clinically Useful AI: From Radiology Practices in Global South and North to Visions of AI Support",
    "id": 191699,
    "sequence": 1620,
    "queryCoordinates": {
      "visualization": [
        20.557285263850616,
        4.289291617583287
      ]
    }
  },
  {
    "session": "Communication and Collaboration with Human and Agent",
    "abstract": "Why were Hollywood film workers striking or supporting strikes against artificial intelligence (AI) in 2023? To investigate this question, we conduct participant observation on the picket line and interview 15 film workers, including 12 union members from SAG-AFTRA, WGA, and IATSE, as well as 3 non-unionized workers, across roles. From screenwriting to acting, our interlocutors described how studio use of AI might exacerbate wage squeeze, estrangement from embodied co-creation, rush for results, and inauthentic creativity. We find that film worker resistance to emergent and projected uses of AI echoes earlier technical developments, such as the incorporation of sound, color, HD, DVD, and CGI. These innovations initially sparked anxieties about the demise of cinema, but ultimately created new aesthetic possibilities and professions. We end with a reflection on core concerns for worker engagement, including topics of prophesy and the “soul” of sociotechnical labor.",
    "title": "'AI is Soulless': Hollywood Film Workers Strike and Emerging Perceptions of Generative Cinema",
    "id": 191700,
    "sequence": 1621,
    "queryCoordinates": {
      "visualization": [
        0.392628993861314,
        11.993575049716387
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "With the aim of helping to ease the fear of death, our art game Between communicates a peaceful atmosphere surrounding death and loss. In the game, players explore a digital graveyard and interact with gravestones by typing the names of the deceased. Each name is accompanied by a string of melodies and flower petals reflecting personal traits. The designer's fear of loss toward her own mother motivated this project, and throughout the development, the fear was greatly eased. We aim to communicate this transformative effect to a broader audience with similar fears—those who may not have experienced a close loss yet but share the concern. The game seeks to connect these individuals, share the fear of death, and eventually provide comfort.",
    "title": "Between: Easing the Fear of Death Through Peaceful Play",
    "id": 194039,
    "sequence": 1622,
    "queryCoordinates": {
      "visualization": [
        11.230871121087906,
        -4.227000575054808
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Deceptive patterns are interface design strategies that manipulate the user into decisions against their best interest. Serious games educating players about this topic are a viable countermeasure recently explored in HCI. However, existing approaches are purely digital. The Deceptive Dungeon is a room-sized game that brings deceptive patterns to the physical world. Evoking a dystopian setting in which AI uses deceptive patterns to identify and eliminate human survivors, it combines four exhibits showcasing different deceptive patterns. For players who are unfamiliar with this topic, the dungeon aims to raise awareness and spark interest. For players experienced with deceptive patterns, we hope to provide an additional and novel perspective.",
    "title": "The Deceptive Dungeon: Bringing Deceptive Patterns to the Physical World",
    "id": 194046,
    "sequence": 1623,
    "queryCoordinates": {
      "visualization": [
        8.583452556734043,
        -2.7063521955384573
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Eidolon is an innovative first-person thriller game that explores prolonged grief through a thought-provoking narrative. The digital game integrates escape room mechanics based on the five stages of grief, providing an immersive experience that encourages players to reflect on emotional loss. By combining the realism of Unreal Engine and MetaHumans with live-action footage, Eidolon offers a unique approach to narrative that tackles complex psychological themes. Our game will potentially raise awareness of Prolonged Grief Disorder and contribute to the emerging research on how emotionally challenging video games can positively impact players in meaningful ways.",
    "title": "Eidolon: Exploring the Complexities of Prolonged Grief Disorder Through a Digital Game",
    "id": 194056,
    "sequence": 1624,
    "queryCoordinates": {
      "visualization": [
        5.555702330196018,
        -8.314696123025454
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Approaches to biofeedback-based empathy training often struggle to motivate participants to learn their partner's emotional cues. CardioComm is a mixed-reality collaborative game where communication is conditioned by players' cardiac activity. Players match images through verbal descriptions while monitoring their partner's stress via heart rate variability. When stress exceeds a threshold, visual and auditory communication is restricted between partners; creating consequences for poor interpersonal regulation. By making emotional awareness integral to gameplay success, CardioCommXR creates intrinsic motivation for learning emotional cues.",
    "title": "CardioCommXR: Training Empathy Through Gamified Emotional Regulation",
    "id": 194070,
    "sequence": 1625,
    "queryCoordinates": {
      "visualization": [
        7.760250025556352,
        -1.9438414392261134
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Contemporary video games often equate narrative agency with complex player choices, thereby complicating interface design. This study challenges this trend by developing Kevin, a slot game that integrates simplistic haptic interaction into interactive storytelling. Kevin is designed based on the common 243-way slot games, with gameplay centered around the protagonist Kevin’s college life. Furthermore, we root our narrative design in the intersectionality framework by exploring the multifaceted nature of Kevin’s identities. Based on player feedback, we found that the contrast between the simple button interaction and the game’s visual storytelling creates compelling narrative tension. However, we also identified certain limitations in balancing critical perspectives with dramatic plots and addressing ludic literacy. Accordingly, we propose directions for future research and design looking to repurpose slot games.",
    "title": "From Gambling to Storytelling: Reimagine Slot Games for Intersectional Narratives in Kevin",
    "id": 194071,
    "sequence": 1626,
    "queryCoordinates": {
      "visualization": [
        15.038690497648545,
        -7.927028958943909
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Wandering Spirit is a mixed-reality game that fosters collaboration through the shared use of a physical prop. The game's core mechanic centers on a flexible loop manipulated simultaneously by two co-located players, serving as a bridging element between physical and virtual interactions. Through three distinct game stages, the loop transforms into different virtual tools—a trampoline, a bubble/wind generator, and a fiery hoop—each requiring precise synchronization between players to interact with virtual elemental spirits.\r\nThe shared prop creates natural constraints that guide player coordination while maintaining individual agency. Initial observations suggest that the physical sharing of a single prop creates emergent social dynamics and enhanced spatial awareness between players, contributing to both mechanical cooperation and social presence. The game demonstrates how shared physical props can serve as effective mediators between physical and virtual spaces, potentially opening new design opportunities for embodied collaborative experiences in mixed reality.",
    "title": "Wandering Spirit: Exploring Cooperative Mixed-Reality Gameplay with Shared Physical Props",
    "id": 194073,
    "sequence": 1627,
    "queryCoordinates": {
      "visualization": [
        18.74666239411584,
        -9.46375449179885
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "In daily life, our hands are often occupied—whether holding a child and a dog leash or riding a bicycle—making it difficult to interact with devices. This challenge has led HCI research to explore \"hands-free\" interactions like voice commands, though these are limited in noisy environments and certain social settings. A recent lab study using motion capture demonstrated the potential of toe movements for interaction. Building on this, we investigate toe-based interactions by embedding pressure sensors into a sock. Our work tackles practical implementation challenges and explores the feasibility of an interactive sock that captures toe movements. We demonstrate that the usage of pressure sensors expand the interaction possibilities, enabling a richer interaction vocabulary.",
    "title": "GestureSock: Exploring toe gestures as alternative input method",
    "id": 194078,
    "sequence": 1628,
    "queryCoordinates": {
      "visualization": [
        1.1705419320967645,
        -5.884711682419384
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Wandering poses a critical safety risk for individuals with Alzheimer’s disease, leading to injuries, fatalities, and immense caregiver stress. This paper introduces Watch-Out, a comprehensive safety system combining a smartwatch, an NFC-enabled smart door lock, and a caregiver mobile app to address wandering behaviors. The system employs NFC tagging and voice prompts to ensure cognitive engagement during exits, reducing the likelihood of unsupervised wandering. Features include real-time GPS tracking, geofencing alerts, health monitoring, and community-based emergency response mechanisms. Grounded in user-centered design and insights from caregivers and experts, Watch-Out enhances patient autonomy while alleviating caregiver burdens. By integrating technology with empathy, the system ensures safety and dignity for patients while fostering peace of mind for caregivers. This solution redefines Alzheimer’s care, paving the way for safer, more supportive communities.",
    "title": "Watch-Out: Real-Time Tracking and Assistance for Wandering Alzheimer’s Patients Using Wearable Technology",
    "id": 194086,
    "sequence": 1629,
    "queryCoordinates": {
      "visualization": [
        2.73693010928402,
        16.778236307100176
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "Virtual agents, computer-generated entities that simulate human-like social behaviours, are increasingly important as mediators between users and virtual environments. Beyond functional roles, these agents also serve important social purposes --- as users interact with virtual agents, they inevitably form emotional bonds. To better understand such dynamics and the consequences of such interactions, my thesis investigates how users engage with, form connections with, and reflect on their experiences with virtual agents. Through a series of interconnected projects, I explore the nature of virtual social interactions and the extent to which they mirror real-world social behaviour. I consider how the malleable dimensions of virtual worlds shape how users perceive and engage in virtual social interactions, draw insights toward broader human motivation, and develop guidelines for designing virtual agents. My future plans involve refining virtual agents through generative models and exploring interactions with an agentive self mediated through a virtual environment.  ",
    "title": "Understanding and Supporting Interactions with Virtual Agents",
    "id": 194107,
    "sequence": 1630,
    "queryCoordinates": {
      "visualization": [
        -7.6127194099637405,
        9.276125440352848
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "Meetings are important for collaboration, decision-making, and conflict resolution within groups. While remote meetings offer advantages such as reduced travel time and increased flexibility, they introduce frictions in communication due to limitations of the medium. This doctoral research aims to examine these frictions and develop new mechanisms to empower the key constituent elements of meetings-attendees, and the shared environment-to enhance the effectiveness and efficiency of remote meetings. By exploring methods to improve non-verbal communication, audience feedback, task space management, and the formation of common context, my work contributes to the design of remote meeting systems that alleviates the effect of existing frictions. The research involves the development and evaluation of prototypes, leveraging technologies such as gesture recognition and generative AI, to address the identified challenges.",
    "title": "Designing Mechanisms to Empower Attendees of Remote Meetings to Promote More Effective and Helpful Meetings",
    "id": 194108,
    "sequence": 1631,
    "queryCoordinates": {
      "visualization": [
        -10.583055172180263,
        -5.656760841911967
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "Amyotrophic lateral sclerosis (ALS) severely limits motor and communication abilities, creating significant barriers to emotional expression and social participation. This study presents the Brain Body Jockey Project, a multi-modal system integrating EEG, and accelerometer sensors to enable high agency robotic arm control for ALS patients. By separating action selection from action execution, the system preserves patient agency and supports intuitive emotional expression.\r\n\r\nThis video proposes the potential of new forms of expression. Through iterative development aimed at establishing methods of expression for individuals with ALS, the system is refined via stage performances, showcasing the possibilities of gestures such as waving, pointing, and making peace signs. \r\nInsights from these controlled performances expected to pave the way for practical applications in daily life, including communication, environmental control, and rehabilitation. The Brain Body Jockey Project represents a significant advancement in assistive technologies, fostering creativity, self-expression, and improved quality of life for ALS patients.",
    "title": "Brain Body Jockey Project -WE CAN EXPAND-",
    "id": 194121,
    "sequence": 1632,
    "queryCoordinates": {
      "visualization": [
        -10.555408354592709,
        -13.326040464736494
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Although gaze-based typing has recently improved due to advancements in AR/VR and built-in device cameras, important difficulties remain. It is also a vital modality for disabled users. However, typing with your eyes is more difficult than expected and feels unnatural, often causing eye strain after a short period of time. Much research has been done on eye typing with traditional QWERTY keyboards, but other layouts and their impact on eye strain have not been thoroughly explored. In this study, we report on a user study with both the QWERTY layout and the HERO layout. The HERO keyboard was specifically designed for modern touch devices to minimize finger travel time, which inspired us to determine if that translates well to eye movement. Our results show no significant difference between QWERTY and HERO with speed, error rate, frustration, learnability, and usability. However, eye strain was significantly lower with HERO.",
    "title": "Eye Need a HERO: Speed, Accuracy, and Eye Strain with QWERTY and HERO Keyboard Layouts",
    "id": 194129,
    "sequence": 1633,
    "queryCoordinates": {
      "visualization": [
        7.61271940996374,
        -9.27612544035285
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "The use of artificial intelligence (AI) and voice user interfaces (VUIs) in hiring processes is a rapidly growing trend. Since the COVID-19 pandemic, an increasing number of companies have adopted automated systems for conducting job interviews. In traditional interview settings, research has shown that gendered interactions between the interviewer and the interviewee can influence performance and hiring decisions. Addressing this issue within the digital job-seeking context, our study investigates whether similar effects occur in interactions with LLM-based voice chatbots during mock job interviews. We conducted a study using two gendered AI interviewer conditions: a feminine AI voice and a masculine AI voice. The study examined how the AI interviewer’s gender presentation influenced interviewees’ lexical diversity, willingness to disclose personal information, and confidence levels. Preliminary findings indicate that gender stereotypes persist in interactions with AI chatbots, and the different gendered conditions significantly impact participants' confidence levels in mock job interview settings.",
    "title": "Exploring Gender Biases in LLM-based Voice Chatbots for Job Interviews",
    "id": 194130,
    "sequence": 1634,
    "queryCoordinates": {
      "visualization": [
        -1.1770330175946808,
        15.956647306859043
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Detecting mild cognitive impairment (MCI), an early stage of neurodegenerative disorders, is crucial for timely intervention. This study investigates the potential of a multimodal approach integrating VR, EEG, and MRI (VEEM) biomarkers to enhance MCI detection performance. However, as it is challenging to acquire all the modalities, we evaluated the detection performance across complete VEEM biomarkers and datasets with a missing modality. The model using complete VEEM biomarkers of 59 participants achieved 91.67% accuracy, 85.70% sensitivity, 100.0% specificity, 93.06% precision, and 91.72% F1-score. Notably, the model utilizing VR and EEG with missing data in MRI showed better performance compared to models lacking VR or EEG biomarkers. Our findings suggest a sequential diagnostic approach: VR and EEG biomarkers for early MCI detection, and complete VEEM biomarkers for mid-to-late stage MCI diagnosis. This study underscores the clinical potential of integrating VEEM biomarkers, addressing key challenges of missing data.",
    "title": "Beyond Missing Data: A Multimodal Approach Using VR-EEG-MRI (VEEM) Biomarkers for Detecting MCI",
    "id": 194131,
    "sequence": 1635,
    "queryCoordinates": {
      "visualization": [
        4.112821953545772,
        -6.861828880002178
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "Today's AI technology is increasingly able to generate language resources to support human language use and communication. Yet, for non-native speakers, access to these AI-generated resources does not free them from linguistic challenges. Building upon my completed work that revealed non-native speakers' conflicting needs to manage their language production with AI tools and their communication with other people, I argue that these tools can best support non-native speakers when they facilitate long-term language development in addition to assisting with specific communication tasks. In my ongoing dissertation work, I plan to use experience sampling method and participatory design to engage non-native speakers and domain experts such as language educators and AI developers in collaborative design exploration towards this goal.",
    "title": "Designing AI-Based Language Tools for Non-Native Speakers' Language Use and Development",
    "id": 194132,
    "sequence": 1636,
    "queryCoordinates": {
      "visualization": [
        12.789602465311384,
        7.8374784707392315
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "Physical space has a critical yet often overlooked role in fostering social interaction, particularly in HCI, where digital solutions rarely incorporate the physical environment. This dissertation aims to address this gap by exploring the design space of \"socio-spatial interfaces\"—interactive systems that leverage human interaction in physical environments to facilitate social interactions. Socio-spatial interfaces employ spatial mediation techniques, including projected imagery, reflections, mixed reality, and audio, to \"scaffold\" social interactions by integrating digital and physical environments. Through a Research through Design (RtD) approach, this dissertation investigates how these interfaces facilitate interactions among strangers through design exemplars such as SocialStools and MirrorBot. By drawing from architecture and social psychology, this work aims to lay a foundation for socially adaptive environments, offering new pathways in HCI for fostering inclusivity and community through shared spaces.",
    "title": "Designing Socio-Spatial Interfaces for Embodied and Situated Social Interaction",
    "id": 194140,
    "sequence": 1637,
    "queryCoordinates": {
      "visualization": [
        -7.990180696711448,
        -17.238242730449638
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "My research explores the intersection of diffraction theories, creativity, and artificial intelligence (AI) to develop new methodologies for design research in Human-Computer Interaction (HCI). By employing Karen Barad's theory of agential realism and the concept of diffraction, I research how diffractive methodologies can offer deeper insights into the complex relationships between humans and AI. My aim is to contribute to the ongoing  formalisation of diffractive methodologies for design research, demonstrating their potential to generate novel insights and design directions that may be overlooked by traditional user-centered approaches.",
    "title": "Diffraction, Creativity and AI: Towards New Methods for Design Research",
    "id": 194143,
    "sequence": 1638,
    "queryCoordinates": {
      "visualization": [
        -3.511625796290316,
        -17.654135047258144
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "This project addresses the environmental impact of unused digital files within universities. It is projected that just data centres alone, where cloud storage is managed, will consume the same amount of electricity as Japan by 2026. User research with university affiliates, comprising a survey of 34 and interviews with 5 participants, revealed a lack of awareness regarding the environmental costs, difficulties in managing files, and personal motivations rather than environmental for decluttering. In response, Digibyte was developed to centralise digital storage, while promoting awareness and habit change through game-like features and positive reinforcement. Digibyte empowers users by supporting their decluttering process and reflect on their digital storage habits. In the future, the platform\r\ncan be expanded to other sectors to support sustainable digital file habits.",
    "title": "Digibyte: Promoting Awareness and Habit Change for Sustainable Digital File Decluttering",
    "id": 194150,
    "sequence": 1639,
    "queryCoordinates": {
      "visualization": [
        -1.9286367918189757,
        -5.681580776970631
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Prolonged sitting can lead to serious physical and mental health problems. However, current intervention studies predominantly focus on workplace sedentary behaviour, neglecting its prevalence at home. To address this, we conducted a mixed-method study with a diary study (5 participants), an online questionnaire (56 responses), and interviews (5 participants). Our findings revealed a lack of motivation and awareness about the long-term risks of sedentary behaviour. Participants expressed a desire for real-time data and non-invasive, engaging reminders. Using an iterative design process, we created SoleMate, an app featuring contextual reminders, a customisable avatar, educational quizzes, data visualisation and data-monitoring slippers. In controlled experiments with 11 participants, combined with Nielsen’s 10 usability heuristics, users found context-aware reminders ineffective but appreciated educational interactions through the avatar and the slippers' ability to track sitting time. Based on feedback, we added gradual reminders with exercise guidance from the avatar and a monthly history of sitting data. Aligned with Sustainable Development Goal 3: Health and Well-being, SoleMate integrates non-invasive live tracking with an engaging avatar interface to promote healthier habits and long-term behaviour change.\r\n",
    "title": "SoleMate: A Detection and Reminder App to Reduce Sedentary Behaviour At Home ",
    "id": 194168,
    "sequence": 1640,
    "queryCoordinates": {
      "visualization": [
        -17.0447423309119,
        5.785910375456911
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "Scaling programming education has become a signi!cant challenge due to rapidly increasing learning needs and limited instructional resources. With the numerous data generated in programming education, scaling code understanding is crucial for instructors to make informed decisions, such as providing feedback and adapting course materials. However, this is impractical due to the wide variation among students’ code and the complexity of activities like tracking coding progress and analyzing solution trajectories.\r\nArti!cial Intelligence (AI) has great potential for analyzing large volumes of data, but it also presents di\"culties in making this data quickly understandable for humans. My research aims to scale code understanding in meaningful ways for introductory programming\r\nthrough combining techniques from AI and visualization. I design and develop interactive systems that enable instructors navigate large, complex collections of code and identify patterns, thereby enhancing teaching activities and improving learning outcomes.",
    "title": "Scaling Code Understanding for Introductory Programming in the AI Era",
    "id": 194169,
    "sequence": 1641,
    "queryCoordinates": {
      "visualization": [
        5.690980167149429,
        11.688145478950537
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "Virtual reality has been shown to have a positive impact on the effectiveness of cognitive rehabilitation, as well as improving user engagement and motivation during the process. Operators have full control over the virtual environment, allowing them to adjust the task difficulty or manipulate the simulation to assist the user during the therapy. Adjusting the difficulty and supporting users through alterations could enhance virtual training effectiveness. Our research aims to investigate how the combination of these two methods can enhance rehabilitation outcomes, both in terms of objective results and the psychological state of the users.",
    "title": "Integrating Dynamic Difficulty Adjustment and Alien Motion in Virtual Reality for Cognitive Rehabilitation Therapy",
    "id": 194170,
    "sequence": 1642,
    "queryCoordinates": {
      "visualization": [
        -8.695725088797953,
        16.89332309464452
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "This study presents a participatory co-creation installation based on Artificial Intelligence Generated Content (AIGC) for alleviating children's Nyctophobia through art therapy. By conducting interviews with parents, children, and psychologists, the study analyzes the causes of nyctophobia and proposes a solution that integrates intelligent technologies. The study employs real-time interactive technologies to transform children's behaviors into positive visual experiences, aiding them in building a sense of security in dark environments. The study's contribution lies in proposing a design framework that integrates serious games and exposure therapy, offering new perspectives for psychological interventions targeting children's mental health.",
    "title": "The Immersive Art Therapy Driven by AIGC: An Innovative Approach to Alleviating Children's Nyctophobia",
    "id": 194183,
    "sequence": 1643,
    "queryCoordinates": {
      "visualization": [
        -12.361892829330232,
        8.496093553872498
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Public transportation systems remain significantly inaccessible to Deaf and Hard of Hearing (DHH) individuals, who often miss critical auditory information like announcements and alarms, impacting their safety and autonomy. Current assistive devices and mobile applications fall short in providing real-time alerts tailored to their needs. This paper presents a system integrated with Google Maps to enhance auditory awareness for DHH users using sound recognition and multimodal notifications. Grounded in user-centered research, including interviews with DHH individuals and accessibility experts, the design introduces features like animated sound alerts, audio history logs, and user-validated sound feedback – these prioritize accessibility, usability, and inclusivity. Expert evaluations confirmed the prototype’s potential to improve navigation and foster independence for DHH individuals. This work highlights the importance of context-aware design in creating equitable urban spaces and sets the foundation for broader applications beyond public transportation.",
    "title": "Sound to Sight: Enhancing Contextual Awareness for the DHH Community in Public Transportation",
    "id": 194186,
    "sequence": 1644,
    "queryCoordinates": {
      "visualization": [
        -9.928702829192499,
        13.799306509009243
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "The Reweaving Nishijin Project revitalizes the industry by combining digital technologies and parametric design. Traditionally used for Japanese attire, Nishijin textiles face declining demand due to competition from Western clothing. This study developed a 3D simulation system to generate garment structures from a single piece of fabric, enabling pre-production design evaluation, reducing waste, and expanding applications. Using Kyoto’s Hatcho Nenshi (twisted yarn) and conductive threads, the project produced innovative 3D smart textiles and wearable sensory garments. This fusion of tradition and technology creates sustainable, modern applications for Nishijin weaving. Demonstrations included: 1) A tool for sharing 3D smart textile designs to drive innovation in traditional communities. 2) Displays of high-quality textiles showcasing traditional craftsmanship for visitor interaction.  ",
    "title": "Reweaving Nishijin: Parametric Design System to Shape the Future of Kyoto Traditional Textiles",
    "id": 194187,
    "sequence": 1645,
    "queryCoordinates": {
      "visualization": [
        17.238242730449638,
        7.990180696711444
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Recent work in Generative AI enables the stylization of 3D models based on image prompts. However, these methods do not incorporate tactile information, leading to designs that lack the expected tactile properties. We present TactStyle, a system that allows creators to stylize 3D models with images while incorporating the expected tactile properties. TactStyle accomplishes this using a modified image-generation model fine-tuned to generate heightfields for given surface textures. By optimizing 3D model surfaces to embody a generated texture, TactStyle creates models that match the desired style and replicate the tactile experience. We present TactStyle's user interface to create stylized 3D models with accurate textures, present multiple textured tiles for blind perception experience, and present five application scenarios with fabricated 3D models. ",
    "title": "Demonstration of TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication",
    "id": 194190,
    "sequence": 1646,
    "queryCoordinates": {
      "visualization": [
        10.470864723162293,
        -7.704608487732224
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "People with disabilities that affect their speech may use speech-generating devices (SGD), commonly referred to as Augmentative and Alternative Communication (AAC) technology. This technology enables practical conversation; however, delivering expressive and timely comments remains challenging. This paper explores how to extend AAC technology to support a subset of humorous expressions: delivering timely humorous comments -witty remarks- through AI-powered interfaces. To understand the role of humor in AAC and the challenges and experiences of delivering humor with AAC, we conducted seven qualitative interviews with AAC users. Based on these insights and the lead author's firsthand experience as an AAC user, we designed four AI-powered interfaces to assist in delivering well-timed humorous comments during ongoing conversations.\r\nOur user study with five AAC users found that when timing is critical (e.g., delivering a humorous comment), AAC users are willing to trade agency for efficiency—contrasting prior research where they hesitated to delegate decision-making to AI. We conclude by discussing the trade-off between agency and efficiency in AI-powered interfaces, how AI can shape user intentions, and offer design recommendations for AI-powered AAC interfaces.\r\nSee our project and demo at: https://tobiwg.github.io/research/why_so_serious",
    "title": "Why So Serious? Exploring Timely Humorous Comments in AAC Through AI-Powered Interfaces",
    "id": 194191,
    "sequence": 1647,
    "queryCoordinates": {
      "visualization": [
        -17.55371111771445,
        -7.270985214936704
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Multi-material 3D printing combines the functional properties of different materials (e.g., mechanical, electrical, color) within a single object that is fabricated without manual assembly. However, this presents sustainability challenges as multi-material objects cannot be easily recycled. Because each material has a different processing temperature, considerable effort must be used to separate them for recycling. This paper presents a computational fabrication technique to generate dissolvable interfaces between different materials in a 3D printed object without affecting the object’s intended use. When the interfaces are dissolved, the object is disassembled to enable recycling of the individual materials. We describe the computational design of these interfaces alongside experimental evaluations of their strength and water solubility. Finally, we demonstrate our technique across 8 multi-material 3D printed objects of varying structural and functional complexity. Our technique enables us to recycle 89.24% of the total mass of these objects, promoting greater sustainability in 3D printing.",
    "title": "Enabling Recycling of Multi-Material 3D Printed Objects through Computational Design and Disassembly by Dissolution",
    "id": 194192,
    "sequence": 1648,
    "queryCoordinates": {
      "visualization": [
        8.565056918547304,
        -6.902159081189375
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Dating app users can now utilize AI features to streamline and improve their self-presentation to potential meeting partners, such as auto-generated bios or AI-modified photos. While these tools can aid impression management, they can also create doubts about authenticity and trust, raising new questions about if and how automated disclosure of AI-generated content should be implemented. To address these tensions, we designed a prototype called Transparent Hearts, informed by a self-reflective diary study and participatory design insights. By balancing needs for privacy and disclosure, Transparent Hearts seeks to empower daters to customize how much of their own usage of AI-modified content is disclosed to others, while also establishing settings for disclosure of AI in other users’ content. In addition to user-controlled AI-disclosure toggles and explanations of AI-use, the prototype includes a conflict resolution mechanic for when two users have mismatched AI disclosure settings. This work aligns with SDGs 10 and 16, highlighting design considerations for fairness, inclusivity, and trust in AI-mediated social platforms.\r\n",
    "title": "Transparent Hearts: Balancing Privacy and Trust in AI-Generated Self-Presentation for Online Dating",
    "id": 194205,
    "sequence": 1649,
    "queryCoordinates": {
      "visualization": [
        -10.162674857624156,
        -4.209517756015987
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Chemistry laboratory courses are essential for developing experimental skills, yet students face challenges with pre-laboratory activities and materials due to the lack of details and changing environments. This study identifies these challenges and suggests design implications for future systems to help students understand and plan chemistry laboratory experiments: supplementing detail deficiencies, reflecting real lab environments, and facilitating active planning and execution. Based on these findings, this study developed ChemLab Planner, a web-based tool that converts text-based lab manuals into an interactive, timeline interface. The system breaks down procedures into substeps to provide detailed descriptions that meet student needs, adapts procedures to actual lab conditions, and supports team-based planning and execution. These features directly address the identified challenges, enabling students to prepare for experiments effectively. Building upon traditional pre-laboratory materials, ChemLab Planner offers a scalable approach to help laboratory understanding and planning, exemplifying the role of computer-aided tools in laboratory education.",
    "title": "Designing An Educational Tool to Improve Understanding and Planning in Chemistry Laboratory Courses",
    "id": 194208,
    "sequence": 1650,
    "queryCoordinates": {
      "visualization": [
        -9.843705449290026,
        -12.613542842025703
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "This study explores fine-tuned Large Language Models (LLMs) integration into diary studies within the Human-Computer Interaction (HCI) field to enhance data collection and analysis. Leveraging a Mistral 7B model fine-tuned with a curated dataset of over 1,000 diary entries, this research addresses challenges such as participant engagement and data richness. The fine-tuned model offers personalized feedback, facilitating deeper reflection and structured recording while reducing the cognitive load on participants. The DiaryQuest educational platform, enhanced with advanced visualization tools and semantic search capabilities, enables educators to efficiently analyze diary data, extract thematic insights, and provide targeted guidance. Results from user evaluations reveal that the optimized platform improves learning outcomes, teaching efficiency, and overall user experience. By bridging traditional diary methodologies with state-of-the-art LLMs, this study advances HCI education and establishes a scalable framework for applying AI in broader educational and research contexts.",
    "title": "Boosting Diary Study Outcomes with a Fine-Tuned Large Language Model",
    "id": 194209,
    "sequence": 1651,
    "queryCoordinates": {
      "visualization": [
        -9.754160215099379,
        6.989732362413632
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Location-based games (LBGs) create hybrid spaces where digital and physical worlds converge, enabling new social interactions but leaving under-explored social dynamics regarding interpersonal trust. This study investigates interpersonal trust perceptions through in-depth interviews with 26 participants from four LBGs: Pokémon GO, Monster Hunter Now, Ingress, and Pikmin Bloom. Findings highlight the critical role of online communities (e.g., Discord, Facebook) in fostering initial trust for real-world meet-ups through the \"online to offline'' and \"group to individual'' scaffolding, alongside the careful risk-benefit calculations players make when sharing location data through game interactions. Based on these insights, I propose design recommendations, such as integrating seamless online community entry points and improving location privacy controls within games. This work contributes to an empirical understanding of interpersonal trust perceptions in LBGs and offers theoretical insights into how digital and physical interactions facilitate new forms of social collaboration within hybrid spaces.",
    "title": "Interpersonal Trust Perceptions in a Hybrid Space: Understanding Social Dynamics in Location-Based Games",
    "id": 194210,
    "sequence": 1652,
    "queryCoordinates": {
      "visualization": [
        -8.050839743998978,
        7.495597335532804
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Camera layout is a critical aspect of digital production, shaping the narrative and emotional tone of animation, CGI, and previsualization. However, managing camera movements in 3D scenes is challenging due to the complexity of controlling six degrees of freedom (DoF), particularly with traditional 2D input devices. Virtual camera systems aim to replicate the functionality of physical cameras by allowing users to manipulate a virtual camera within a digital scene, but often make it difficult to account for environmental constraints and can lead to spatial disorientation. To address these limitations, we present an augmented reality (AR) system for an intuitive and spatially aware camera layout. The system visualizes camera trajectories in AR, facilitating collaboration and iterative design. This work highlights the potential of AR as a versatile alternative to traditional VR-based tools, bridging the gap between physical and virtual spaces for improved cinematographic workflows.\r\n ",
    "title": "CamARa: Exploring and Creating Camera Movements with Spatial Reference in Augmented Reality",
    "id": 194240,
    "sequence": 1653,
    "queryCoordinates": {
      "visualization": [
        -6.523884689106647,
        -16.776141647090366
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present ReconSkin, a shape-configurable robotic skin that utilizes multiple wirelessly connected sensor nodes and a soft silicone rubber sheet as its outer layer. Since each sensor node connects wirelessly to form a network, complex wiring is not required, enabling implementation on various shapes and allowing for fine-grained sensing. We have designed sensor nodes equipped with an MCU, sensors, and transceiver circuits, along with a proprietary network protocol that ensures efficient data transmission and scalability. We demonstrated applications where the nodes were placed on various shapes, including both flat and curved surfaces, successfully acquiring and visualizing data on pressure, temperature, and texture in various shapes. Through the implementation of hardware, software, and applications, we lay the foundation for future research in robotic skin technologies.",
    "title": "ReconSkin: Shape-Configurable Robotic Skin Utilizing Wireless Networked Sensor Nodes",
    "id": 194241,
    "sequence": 1654,
    "queryCoordinates": {
      "visualization": [
        16.776141647090366,
        -6.523884689106648
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Recent advancements in AI, particularly those focused on replicating creativity, have sparked ongoing discussions about their impact on the role of designers. This paper presents the findings from qualitative interviews with 17 design professionals, exploring their perceptions and experiences with AI tools, as well as their views on how their roles may evolve in the future. The results highlight the diverse ways in which designers are leveraging AI in their work, while also emphasizing the continued significance of expert human designers in steering development toward meaningful outcomes. The findings underscore the continued importance of contextual awareness, interdisciplinary collaboration, and human-centered design in crafting meaningful solutions, and highlights the role of relational expertise in design that manifests through interactions.",
    "title": "Steering Blind Algorithms: Exploring the Impact of Generative AI on the Role of Designers",
    "id": 194242,
    "sequence": 1655,
    "queryCoordinates": {
      "visualization": [
        -16.40802887051027,
        11.435759204552244
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "In everyday life we often find ourselves with both hands occupied, e.g. while holding a child in one hand and a dog leash in the other or riding a bicycle. These situations limit our ability to interact with our devices. Solutions such as voice commands are limited in noisy environments and may not be desirable in certain social situations. Using other body parts for interaction such as the head, arms, and foot. Recent lab study using a motion capture system has shown that toes movements might be a useful way of interacting. In this work we advance this research by exploring toe interactions through integrating pressure sensors in a sock. Through an iterative design process we address practical issues of implementation and applicability of an interactive sock capable of capturing toe interactions. We show that combining pressure with movement increases the interaction possibilities, allowing for a broad interaction vocabulary.",
    "title": "GestureSock: Exploring toe gestures as alternative input method",
    "id": 194243,
    "sequence": 1656,
    "queryCoordinates": {
      "visualization": [
        15.956647306859043,
        1.1770330175946788
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "What is it like to be a bat? \"EchoVision\" is a mixed reality art experience that simulates bat echolocation, immersing participants in the perceptual umwelt of bats. Using a custom-designed, handheld, bat-shaped mask based on the open-source HoloKit mixed reality headset, participants visualize echolocation through dynamic feedback responsive to their voices and the surrounding 3D environment. Our site-specific pop-up exhibition in a natural bat habitat demonstrated mixed reality's potential to foster empathy for non-human species. ",
    "title": "Demonstrating \"EchoVision\": Bat Echolocation Simulation via Handheld Mixed Reality Masks",
    "id": 194244,
    "sequence": 1657,
    "queryCoordinates": {
      "visualization": [
        4.765594435939469,
        -6.425660251845158
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Electrical muscle stimulation (EMS) has been leveraged to assist in learning motor skills by actuating the user’s muscles. However, existing systems provide static demonstration—actuating the correct movements, regardless of the user’s learning progress. Instead, we contrast two versions of a piano-tutoring system: a conventional EMS setup that moves the participant’s fingers to play the melody, and a novel adaptive-EMS system that changes its guidance strategy based on the participant’s performance. The adaptive-EMS dynamically adjusts its guidance: (1) demonstrate by playing the entire melody when errors are frequent; (2) correct by lifting incorrect fingers and actuating the correct one when errors are moderate; and (3) warn by lifting incorrect fingers when errors are low. We found that adaptive-EMS improved learning outcomes (recall) and was preferred by participants. We believe this approach could be adopted in physical tutoring systems and promotes adaptive over static guidance.",
    "title": "Adaptive Electrical Muscle Stimulation for Improved Muscle Memory",
    "id": 194245,
    "sequence": 1658,
    "queryCoordinates": {
      "visualization": [
        4.97488462074616,
        -12.01043392264673
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Note-taking is critical during speeches and discussions, serving for later summarization and organization and for real-time question and opinion reminding in question-and-answer sessions or timely contributions in discussions. Manually typing on smartphones for note-taking could be distracting and increase cognitive load. While LLMs are used to automatically generate summaries and highlights, the content generated by AI may not match users’ intentions without user input. Therefore, we propose an AI-copiloted AR system, GazeNoter, to allow users to swiftly select diverse LLM-generated suggestions via gaze on an AR headset for real-time note-taking. GazeNoter leverages an AR headset as a medium for users to swiftly adjust the LLM output to match their intentions, forming a user-in-the-loop AI system for both within-context and beyond-context notes. We conducted two studies to verify the usability of GazeNoter in attending speeches in a static sitting condition and walking meetings and discussions in a mobile walking condition, respectively.",
    "title": "Demonstration of GazeNoter: Enhancing AR Note-Taking Through Gaze-Based Selection of LLM Suggestions",
    "id": 194246,
    "sequence": 1659,
    "queryCoordinates": {
      "visualization": [
        10.643573670544482,
        14.516002876814685
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "This study aims to develop a system that enables ALS patients to achieve accurate and natural intentional movements and emotional expressions in daily life by integrating multiple modalities such as brain waves, electromyographic sensors, and auditory feedback. The system is designed to adapt to patients' physical and environmental conditions, providing a flexible and user-friendly interface that reduces operational burden while enhancing the alignment between motor imagery and actual movements. Additionally, the system separates the processes of action selection and execution, ensuring that patients can recognize the movements as their own intentional actions. This approach seeks to expand the range of self-expression and alleviate the constraints faced in daily life, ultimately contributing to improved quality of life (QOL) and promoting social participation. The study aims to establish a new technological foundation to support ALS patients effectively and inclusively.",
    "title": "Brain Body Jockey Project -WE CAN CONNECT-",
    "id": 194265,
    "sequence": 1660,
    "queryCoordinates": {
      "visualization": [
        -7.270985214936701,
        17.55371111771445
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "As cities embrace diverse mobility solutions, urban cyclists face significant safety challenges, particularly when interacting with speed-differential vehicles such as motorcycles in shared urban spaces.  This paper proposes Safety Sense, a study evaluating two AR warning combinations aimed at enhancing cyclists' perceived safety: (1) a centralized visual display with warning sounds and (2) a bilateral visual display with voice prompts. Conducted with 20 participants in real-world overtaking scenarios, the research assesses risk perception, directional awareness, and warning detection. Results reveal both AR combinations significantly improved perceived safety, with the bilateral display and voice prompts outperforming in directional awareness and warning detection. Interview insights suggest visual cues are more effective than audio for quick perception and response in complex traffic situations. This study offers valuable insights for future AR-based safety technologies for vulnerable road users.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "title": "Safety Sense: Enhancing Urban Cyclists' Perceived Safety during Motorcycle Overtaking through Augmented Reality Warning System",
    "id": 194269,
    "sequence": 1661,
    "queryCoordinates": {
      "visualization": [
        -13.861747250912714,
        14.417071934058379
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We introduce Pino, a novel spherical pin-array interface capable of presenting shapes in all directions as a new type of shape-changing interface. Unlike conventional pin displays limited to planar surfaces for unidirectional shape-changes or haptic feedback, Pino arranges actuators on a spherical surface, enabling omnidirectional shape presentation and tangible interactions. This dynamic capability opens possibilities for grippable and huggable haptic interactions, multi-view shape displays, omnidirectional dynamic affordances, and robots with unique locomotion. The prototyping process includes actuator arrangement, 3D modeling, circuitry, and control software development. Three prototypes (80 pins, 32 pins, 20 pins) demonstrate applications such as a Tactile Interface, Multi-Directional Physical Display, Multi-Directional Dynamic Affordances, and a Self-Propelled Shape-Changing UI. This research expands the interactivity of shape-changing interfaces by enabling omnidirectional tactile and visual interactions through a spherical pin-array system, enriching the design space of tangible interfaces.",
    "title": "Pino: Design and Development of a Spherical Pin Array Interface and Exploration of Interactivity",
    "id": 194270,
    "sequence": 1662,
    "queryCoordinates": {
      "visualization": [
        5.007102888506563,
        14.139622366382676
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Eye trackers on smart glasses enable cursor control, but an additional input trigger is required for target selection. EarWiggl'In introduces a hands-free and eyes-free input system for smart glasses that utilize pressure sensors on the nose pads. The system detects input by measuring the pressure induced when the glasses are pulled back with the ear wiggling. A user study was conducted to evaluate the input speed of ear wiggling, eight ear wiggle gestures, and the workload using NASA-RTLX. Results indicated that ear wigging input speed was comparable to, though slightly slower than, pressing a button with a finger, with an average delay of 36.28[ms]. Additionally, eight gestures were analyzed, revealing different amplitudes, numbers of peaks, and durations depending on the gesture.",
    "title": "EarWiggl'In: The Ear Wiggling Input Method for Smart Glasses using Pressure Sensors on Nose Pads",
    "id": 194271,
    "sequence": 1663,
    "queryCoordinates": {
      "visualization": [
        7.495597335532798,
        -8.050839743998983
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "The development of smart textile interfaces is hindered by the inclusion of rigid hardware components and batteries within the fabric, which pose challenges in terms of manufacturability, usability, and environmental concerns related to electronic waste. To mitigate these issues, we present a demonstration of BIT: a smart textile interface and its wireless sensing system to eliminate the need for ICs, batteries, and connectors embedded into textiles. BIT is established on the integration of multi-resonant circuits in smart textile interfaces, and utilizing near-field electromagnetic coupling between two coils to facilitate wireless power transfer and data acquisition from smart textile interface. We developed a mathematical model that accurately represents the equivalent circuit of the sensing system, and a novel algorithm to accurately estimate sensor signals based on changes in system impedance. We demonstrate that our technique effectively supports multiple textile sensors of various types.",
    "title": "Demonstrating BIT: Battery-free, IC-less and Wireless Smart Textile Interface and Sensing System",
    "id": 194272,
    "sequence": 1664,
    "queryCoordinates": {
      "visualization": [
        14.927884781355823,
        5.75832058455981
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "The growing availability of personal medical data presents new challenges for healthcare professionals tasked with communicating it to patients. Clinicians must frequently explain numerical data to patients in order to optimize patient outcomes, practice shared decision making and facilitate informed consent. However the challenges experienced by clinicians when communicating numerical medical data are not currently defined. Through the analysis of semi-structured interviews with 19 healthcare professionals I identify 12 challenges in communicating numerical healthcare data to patients and organize these challenges around four themes: Data Properties, Clinician Characteristics, Patient Characteristics and Environmental Factors. I then describe in detail how these relate to the communication of numerical medical data by clinicians from a Human Computer Interaction (HCI) perspective. Finally, motivated by these challenges, I provide 3 opportunities and associated research questions for those in the HCI community to consider when working to improve the communication of patient data. ",
    "title": "What Brings You Here Today?: Challenges for Clinicians Communicating Data to Patients",
    "id": 194273,
    "sequence": 1665,
    "queryCoordinates": {
      "visualization": [
        -4.251474431534599,
        -13.33885171812055
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "This satire video presents a fictitious system that uses projection-mapping to display advertisements on the faces of smiling people in public spaces. The video posits that by displaying advertisement co-located with (and in the moment of) positive emotional expressions of non-actors, people would naturally rechannel this true emotion to the advertised product or service. This is presented as a clear advantage compared to conventional advertising methods that involve acted smiles in printed or digital media. Further, the video presents a user evaluation that closely follows the established methodological paradigms in technical HCI research to support the claim of a socially acceptable system. The video concludes with several examples showcasing different opportunities of projection-mapping based on-face advertisement. The critique expressed in this extended abstract and in the video is inherently subjective and does not represent the views of ACM or University of Stuttgart.",
    "title": "hAdSpace: Leveraging Natural Human Emotions for Effective On-body Advertisements in Public Spaces",
    "id": 194295,
    "sequence": 1666,
    "queryCoordinates": {
      "visualization": [
        5.796577139375428,
        -18.094189494621475
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "This video introduces MIRAbot, a reimagined rearview mirror designed as a driving assistant for SAE Level 3 semi-autonomous vehicles. While Level 3 vehicles allow hands-free, eyes-off driving in specific conditions, drivers must remain ready to take control when necessary [1]. Despite their convenience, these vehicles face challenges in earning drivers' trust and achieving widespread adoption. MIRAbot seeks to enhance the semi-autonomous driving experience by making it more trustworthy and accessible to a diverse range of users. MIRAbot seamlessly switches between functioning as a standard rearview mirror and an interactive assistant, supporting manual driving, autonomous driving, and the transitions between them. Building on prior research into robotic rearview mirror ornaments for handover pre-alerts [2, 3], MIRAbot enriches the in-car experience with expressive eyes, anthropomorphic movements, and voice prompts. This video highlights MIRAbot’s design, interaction features, and functionality, showcasing its potential to make semi-autonomous driving more supportive, enjoyable, and accessible for all.",
    "title": "MIRAbot: A Rearview Mirror Driving Assistant for Semi- Autonomous Vehicles",
    "id": 194311,
    "sequence": 1667,
    "queryCoordinates": {
      "visualization": [
        -5.38123644919613,
        -2.6537321413140065
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "This paper explores Fabric Tag#, an innovative solution designed to address the environmental challenges posed by fast fashion while celebrating the cultural and industrial heritage of fabric. Focused on Tainan, once known as the \"City of Fabric,\" the study investigates the local fabric market through field studies and persona development, revealing key insights for designing a sustainable, user-centered experience. Fabric Tag# integrates physical fabric tags with a digital app, providing users with a deeper connection to fabric through detailed documentation of its material, craftsmanship, and story. The app also supports local fabric retailers by offering market trend insights, inventory management, and a platform for sharing cultural narratives. By blending technology and sustainability, Fabric Tag# aims to foster a community around fabric appreciation, promote sustainable practices, and inspire users to rethink their relationship with textiles in an era dominated by fast fashion.",
    "title": "Fabric Tag#: Envisioning a UXD Solution for Textile Culture Preservation and Fashion Sustainability",
    "id": 194322,
    "sequence": 1668,
    "queryCoordinates": {
      "visualization": [
        -12.058376795253723,
        -7.113054833451414
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "In Human-Computer Interaction (HCI) research, there is growing interest in designing superpowers, abilities that extend beyond natural human limits and are experienced as originating from one’s own body. While superpower designs hold the promise of enhancing\r\nhuman capabilities, they may also introduce negative side effects as superpower interactions transition from short demonstrations to integration into everyday life. To explore the positive and negative side effects of superpower design, we developed \"EmoPals\", a system inspired by telepathy superpower. EmoPals detects one user’s emotions through a brain-computer interface and replicates them on the other user’s face through electrical muscle stimulation, therefore one user’s happiness makes the other smile and vice versa. This system demonstrates both the potential to strengthen emotional connections and the risks of amplifying negative emotions or causing social discomfort. Ultimately, this research contributes to a deeper understanding of superpower design and its integration into everyday life.",
    "title": "“My Happiness Makes You Smile”: Towards Understanding Telepathic Superpower Design via Brain-Muscle Interfaces",
    "id": 194324,
    "sequence": 1669,
    "queryCoordinates": {
      "visualization": [
        -8.418439278177686,
        -11.186146795015484
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Human interactions are fundamentally driven by reciprocity, a tit-for-tat strategy where favors are returned with favors and hostility with hostility. However, this dynamic shifts when interacting with AI, as humans often adopt an exploitative approach, leveraging AI’s goodwill for their own benefit. This study examines factors that promote cooperative attitudes toward AI using the Modified Reciprocity Game (MRG). Specifically, it investigates the effects of social presence and reward system structure on human-AI cooperation. The results show that when AI has higher social presence and the reward system is relatively small, participants exhibit more cooperative behaviors in response to AI’s goodwill. These findings suggest that increasing AI’s social presence and optimizing reward structures can foster human-AI cooperation. This has significant implications for AI development in domains requiring sustained collaboration, such as education, teamwork-oriented environments, and mixed-traffic scenarios involving autonomous vehicles.",
    "title": "The Benevolence Paradox: When Do Humans Stop Exploiting AI?",
    "id": 194348,
    "sequence": 1670,
    "queryCoordinates": {
      "visualization": [
        -0.3924931306603407,
        -6.988987705124716
      ]
    }
  },
  {
    "session": "Student Research Competition Session 2",
    "abstract": "Medication and dietary supplement usage are prevalent in community-dwelling older adults. However, medication or dietary supplements non-adherence is a challenge, as are risks of misuse, abuse, and diversion (MAD). Due to the increased prevalence of progressive deficits in cognition among community-dwelling older adults, the ability to plan, organize, and execute medicine-management behaviors is further compromised, leading to an increased risk of unintentional non-adherence, medication errors, and preventable medication-related hospitalizations. HUG Smart Sticker is a personalized intelligent medication management system promoting informed and safe medication usage for community-dwelling older adults. This Artificial Intelligent of Things (AIoT) intervention records users’ medication usage in real-time, reports the latest alerts or potential side effects, and reminds users to ensure the safe usage of medications. Our study highlights the significance of this AIoT-based medication management intervention in improving medication adherence, enhancing the medication adherence of older adults, and contributing to aging populations' healthy lifespans.",
    "title": "HUG Smart Sticker: Enhancing Personalized Intelligent Medication Management for Community-Dwelling Older Adults with an AIoT Intervention",
    "id": 194349,
    "sequence": 1671,
    "queryCoordinates": {
      "visualization": [
        -11.483284028786505,
        3.4834161270535535
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Urban pollution poses significant challenges to both human and wildlife health, necessitating innovative approaches to promote sustainable coexistence. This study explores the potential of human-animal interaction as a lens to foster environmental awareness and empathy. We propose HabitAt, a conceptual design prototype that leverages animals’ superior sensory capabilities to detect urban pollution, enabling a deeper understanding of environmental conditions while encouraging sustainable behavior. To inform the design, we conducted a participatory workshop where participants engaged in role-playing activities to experience urban environments from multiple angles. Observations of the workshop were synthesized into HabitAt’s design, which integrates ecological data visualization and interactive elements to create deeper human-animal connections and provoke daily actions in environmental protection. Moving forward, we will refine app features, resolve technical challenges, and expand its applications to better support sustainable urban development.",
    "title": "HabitAt: Bridging Humans and Wildlife toward a Sustainable Future",
    "id": 194350,
    "sequence": 1672,
    "queryCoordinates": {
      "visualization": [
        -18.318276086023058,
        5.043883547053378
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Household food waste is one of the largest contributors to global waste, with private households in the EU generating over 50% annually. Older generations, who grew up valuing sustainability, find this trend disheartening. Their knowledge of food preservation and waste reduction is increasingly lost in a world of modern convenience and generational disconnect. This not only exacerbates waste but also hinders progress toward SDG 11 (Sustainable Cities and Communities) and SDG 12 (Responsible Consumption and Production).\r\n\r\nQualitative research revealed two key insights: younger generations often lack the time and knowledge for sustainable living, while older generations feel lonely and wish to share their wisdom. Grannify bridges this gap by connecting generations on a dual-purpose platform, where younger users learn sustainable practices from elders. Through gamification, practical tasks, and a community dashboard, Grannify transforms traditional knowledge into actionable solutions, reducing waste and fostering inclusive, sustainable communities.",
    "title": "Grannify – Sustainable Living through Generational Knowledge",
    "id": 194351,
    "sequence": 1673,
    "queryCoordinates": {
      "visualization": [
        -3.3334213981176117,
        4.988817673815272
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "Everyday objects have been explored as input devices, but their intended functionality is compromised when these objects are absent or unsuitable. Mid-air gestures are convenient, but lack haptic feedback. Combining both can be beneficial, yet existing work lacks systematic exploration. We proposed a bimanual interaction design space for everyday objects and mid-air gestures, with a functional prototype using only hand tracking in mixed reality headsets. Study 1 with 12 participants on common 3D manipulations showed our approach was significantly more accurate, required less arm movement, and had no significant differences in task completion time compared to free-hand manipulations. Study 2 with the same group on real-life applications found our approach intuitive, engaging, expressive, with interest in everyday use. We identified 30 potential applications spanning everyday tasks, creative arts, education, healthcare, engineering, and gaming. This video showcase complements a full paper under review for TOCHI, where detailed results are presented.",
    "title": "Objestures: Bimanual Interactions with Everyday Objects and Mid-Air Gestures in Mixed Reality",
    "id": 194389,
    "sequence": 1674,
    "queryCoordinates": {
      "visualization": [
        8.613109359986634,
        -14.656546221839259
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Our project \"Identity Boards'' on Discord, is an extension tool to promote healthy communication within LGBTQIA+ communities, that aim to reduce microaggressions and foster a more inclusive online environment. \"Identity Boards\" enable users to visually express their experiences and identities through customized media collections, creating a space for self-expression and understanding. Drawing insights from our co-design workshops, the \"Identity Boards'' highlights how non-verbal communication, such as sharing movies, songs, and memes, can help users navigate identity, reduce reliance on strict or fixed definitions in defining people's identities, and promoting conversations within queer spaces. This approach aligns with broader inclusive design goals by address challenges such as \"term-policing'', and limited representation in digital environment. In this article, we demonstrate how integrating extensions like \"Identity Boards'' into existing platforms can create safer, more supportive environments for LGBTQIA+ users, encouraging equality and respect in online spaces.",
    "title": "Identity Boards: Exploring Use of Mixed Media Expression in Online Queer Spaces",
    "id": 194393,
    "sequence": 1675,
    "queryCoordinates": {
      "visualization": [
        -13.55624930971166,
        3.4968706943411747
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Voice interaction has become an integral part of our daily digital experience, from controlling smart homes to accessing AI assistants. However, privacy concerns and social considerations severely limit voice interface adoption in public spaces. While silent speech interfaces promise a solution, existing approaches require user-specific training data, support limited vocabularies, or demand intrusive sensors in contact with the user's face. We present SilentWhisper, which enables private voice interaction through ultra-low volume whispered speech that is inaudible beyond 30cm while maintaining high recognition accuracy. Using a headset microphone and deep learning, our system achieves 97.7% word recognition accuracy across a vocabulary of 454 words without requiring per-user training. We demonstrate that SilentWhisper enables unobtrusive voice interaction while preserving privacy. Our approach represents a significant advancement in making voice interfaces practical for sensitive information and public spaces.",
    "title": "SilentWhisper: inaudible faint whisper speech input for silent speech interaction",
    "id": 194394,
    "sequence": 1676,
    "queryCoordinates": {
      "visualization": [
        7.9611964239420185,
        -16.14370934758839
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present HaptiCoil, an embedded system and interaction method for prototyping low-cost, compact, and customizable wide-bandwidth soft haptic buttons. HaptiCoil devices are built using mass-produced, waterproof planar micro-speakers which are adapted to direct energy to the skin using a novel hydraulic coupling mechanism. They can sense force input, using a measurement of self-inductance, and provide output in a single package, yielding a flexible all-in-one button solution. Our devices offer a wider perceptual range (10-500 Hz) of tactile stimuli than industry standard approaches, while maintaining comparable power threshold levels (typical threshold under 40 mW). We detail the construction and underlying principles of our approach, as well as an extensive physical quantification of both input and output. We share psychophysical data on device bandwidth and click smoothness discrimination. Finally we show three illustrative examples of how HaptiCoil buttons can implemented in use cases such as spatial computing, digital inking, and remote control.",
    "title": "Demonstrating HaptiCoil: Soft Programmable Buttons with Hydraulically Coupled Haptic Feedback and Sensing",
    "id": 194395,
    "sequence": 1677,
    "queryCoordinates": {
      "visualization": [
        -1.6629392246050907,
        1.1111404660392044
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Existing rehabilitation training for post-stroke hemiplegic patients depends primarily on the guidance of the clinicians. However, training effectiveness is influenced by various factors, including training intensity, and there is no immediate feedback and objective evaluation data. This work introduces a portable rehabilitation support system that combines motion capture, electromyography (EMG) and physical feedback (vibration, electrical stimulation). By comparing the difference in EMG signals between the normal and affected sides during standard movements, the system quantifies rehabilitation progress and highlights muscle activation differences. The accompanying mobile app can provide stage-by-stage rehabilitation guidance to help patients choose exercises that are appropriate for their level of performance, and potentially allows online consultation with a physician for immediate feedback. This approach can possibly integrate evaluation, training recommendations, telehealth assistance, and physical therapy in one place to create an accessible and tailored home rehabilitation program.",
    "title": "Portable Rehabilitation System for Stroke Patients with Hemiplegia using Limb Movement Recognition and EMG",
    "id": 194396,
    "sequence": 1678,
    "queryCoordinates": {
      "visualization": [
        5.773321504383242,
        -15.98964536214065
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "This study explores a novel interaction method in Spatial Augmented Reality (SAR) that enables direct interaction with images without relying on external devices. In the proposed method, a single image is decomposed into multiple frames and projected at high speed. Through temporal additive color mixing and afterimage effects, the image perceived by the user changes based on their gaze movement. This paper introduces two demonstrations based on different decomposition methods: Demo 1 uses mosaic patterns to guide user gaze by displaying highly salient images during movement while allowing the original image to appear when stationary. Demo 2 adjusts the display ratios of the target and complementary images to make the target image visible in the afterimage of a moving object. The proposed method facilitates interaction solely through user or object movement, without requiring cameras or sensors, and holds potential for applications in public advertisements and signage.",
    "title": "Motion-Aware Image Interaction Using Temporal Additive Color Mixing and High-Speed Projection",
    "id": 194397,
    "sequence": 1679,
    "queryCoordinates": {
      "visualization": [
        3.501680457838572,
        -14.585548805965152
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Textile fabrication methods and techniques are an active and growing research trajectory within the CHI community. We look to contribute to this trajectory by demonstrating  \"experimental weaving\" as it has been explored by students and experimental weavers in residence at the Unstable Design Lab at the University of Colorado Boulder. The demo will feature interactive woven textiles, software to support complex woven structure design, and instructional resources for visitors to explore within their research. ",
    "title": "Experimental Weaving at the Unstable Design Lab ",
    "id": 194398,
    "sequence": 1680,
    "queryCoordinates": {
      "visualization": [
        13.95046091764667,
        -1.1767073490094597
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We propose an interactive tool that enables reusing printed circuit boards (PCB) as prototyping materials to implement new circuits—this extends the utility of PCBs rather than discards them as e-waste. To enable this, our tool takes a user’s desired circuit schematic and analyzes its components and connections to find methods of creating the user’s circuit on discarded PCBs (e.g., e-waste, old prototypes). In our technical evaluation, we utilized our tool across a diverse set of PCBs and input circuits to characterize how often circuits could be implemented on a different board, implemented with minor interventions (trace-cutting or bodge-wiring), or implemented on a combination of multiple boards—demonstrating how our tool assists with exhaustive matching tasks that a user would not likely perform manually. We believe our tool offers: (1) a new approach to prototyping with electronics beyond the limitations of breadboards and (2) a new approach to reducing e-waste during electronics-prototyping.",
    "title": "Demonstrating ProtoPCB: Reclaiming Printed Circuit Board E-waste as Prototyping Material",
    "id": 194399,
    "sequence": 1681,
    "queryCoordinates": {
      "visualization": [
        -1.1767073490094648,
        13.95046091764667
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present the walking meditation mat research, leveraging targeted heat to help meditators focus attention inward. The mat, measuring three meters in length, is designed with 10 visual signifiers and 10 corresponding heater pads arranged in a step-by-step pattern. Walking meditation is challenging, as it requires both inward and outward attention. In a qualitative study we studied the walking meditation experience with or without heat, evaluating the impact of the mat’s visual signifiers and the gentle feet-focused targeted heat during the walking experience. Our findings reveal the tension participants experience between external design factors and their internal meditation process. Visual signifiers were more commonly associated with outward attention, dizziness and imbalance, while targeted heat affordances were more commonly associated with attention to bodily sensations, calmness, grounding, and reflection. We conclude with insights regarding the role of targeted heat in balancing inward and outward attention in walking meditation and introspective processes.\r\n",
    "title": "The Walking Meditation Mat: Leveraging Targeted Heat Sensation to Guide Attention Inward",
    "id": 194400,
    "sequence": 1682,
    "queryCoordinates": {
      "visualization": [
        -4.112821953545774,
        -6.861828880002176
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Der Trog is a prototype for a contactless, embodied breath-to-water interface, exploring the potential of Artificial Intelligence as a mediator to facilitate emotional and sensory interactions with nature. By tracking respiration via thermal image analysis  and translating it into wave patterns on a water surface, the installation provides a tangible experience translating the user’s corporal rhythm onto a natural material. The present research project investigates whether such interactions can help bridging the gap between environmental knowledge and action within the ecological crisis, encouraging holistic empathy for nature. Der Trog aims to inspire new perceptions of our connection to natural elements, advocating for sustainable behaviour through meaningful, embodied encounters with the environment.\r\n",
    "title": "Der Trog – Prototype for an embodied, contactless Breath-To-Water-Interface",
    "id": 194402,
    "sequence": 1683,
    "queryCoordinates": {
      "visualization": [
        8.724960070727972,
        4.886212414969549
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "\"Being Mosquitone\" is a head-mounted display (HMD) system designed to create a compelling illusion of a mosquito entering the interior of the head through the ears. This sensation is achieved by combining a mosquito sound signal (delivered via mobile speaker or headphones) with a visual representation of the mosquito flying or rotating inside a semi-transparent head avatar, synchronized with the participant's head tilt, as viewed through the HMD. The critical aspect of the experience is the synchronization between the mosquito's visual position inside the head and the left-right panning of the stereo audio signal. The system was tested in a public exhibition with 123 participants, followed by a post-experience questionnaire. Results showed that over 70% of participants experienced the illusory sensation inside their head as \"strong\" or \"very strong,\" and more than 85% provided positive feedback. Additionally, a controlled experiment revealed that synchronization of audiovisual stimuli significantly enhanced the illusion.",
    "title": "Being Mosquitone: Illusory Deep Intrusion of Mosquito into the Head driven by HMD-Based Audiovisual Integration",
    "id": 194403,
    "sequence": 1684,
    "queryCoordinates": {
      "visualization": [
        7.140180062621116,
        5.478852861078486
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We demonstrate Power-on-Touch, a novel method for powering devices during interaction. Power-on-Touch comprises two main components: (1) a wearable-transmitter attached to the user’s body (e.g., fingernail, back of the hand, feet) with wireless power-coils and a battery; and (2) receiver-tags embedded in interactive devices, making them battery-free. Many devices only require power during interaction (e.g., TV remotes, digital calipers). We leverage this interactive opportunity by inductively transferring energy from the user’s coil to the device’s coil when in proximity. To achieve this, we engineered receiver-tags and coils, including thin pancake-coils best-suited for wearables and spherical-coils that receive power omnidirectionally. We illustrate our approach in a demo in which participants wearing our transmitter can power a range of interactive devices. Our technical approach can inspire ubiquitous computing with new ways to scale up the number and diversity of battery-free devices, not just sensors (µWatts) but also actuators (Watts).",
    "title": "Demonstrating Power-on-Touch: Powering Actuators, Sensors, and Devices during Interaction",
    "id": 194404,
    "sequence": 1685,
    "queryCoordinates": {
      "visualization": [
        3.5191089959489203,
        -21.716718717951647
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Coding assistants are increasingly leveraged in game design, both generating code and making high-level plans. To what degree can these tools align with developer workflows, and what new modes of human-computer interaction can emerge from their use?\r\nWe present DreamGarden, an AI system capable of assisting with the development of diverse game environments in Unreal Engine. At the core of our method is an LLM-driven planner, capable of breaking down a single, high-level prompt---a dream, memory, or imagined scenario provided by a human user---into a hierarchical action plan, which is then distributed across specialized submodules facilitating concrete implementation. This system is presented to the user as a garden of plans and actions, both growing independently and responding to diverse forms of user intervention. Our GUI features a node-based tree editor in which users can provide seed prompts, prune and expand action plans, and provide feedback in real time.",
    "title": "Demonstrating DreamGarden: A Designer Assistant for Growing Games from a Single Prompt",
    "id": 194405,
    "sequence": 1686,
    "queryCoordinates": {
      "visualization": [
        -10.88061556518431,
        10.325318635406314
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Loneliness is on the rise, accelerating during and after the COVID-19 Pandemic. Loneliness contributes major costs from higher mortality rates and economic costs where individuals lack human connection in natural settings. Pursuit to the UN Sustainable Development Goal 3.4 to promote mental health and well-being, our project, “HAPPI” is a facilitator to create togetherness by sympathizing parts of the shared human experience through (1) responding to prompts that harmonizes with each other's lives and (2) receiving these responses through printed pamphlets made for each unique individual user. HAPPI is to be used in natural settings such as at a college campus. Our design is formulated on psychological and cultural studies on loneliness, positivity/happiness, and social connection, along with interviews with students of different backgrounds and working psychologists. HAPPI is a robot-like device that takes an input from a user through an iPad, outputs a printed message through a printer, and has a body that takes the shape of a robot! In this article, we describe our steps in creating HAPPI to foster positive connections through authentic messages.",
    "title": "Fostering Positive Connections Through Interactive Messages: HAPPI",
    "id": 194423,
    "sequence": 1687,
    "queryCoordinates": {
      "visualization": [
        5.38123644919613,
        2.6537321413140074
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "Emotional embodiment has become an emerging focus in both art therapy and interactive design. This paper presents a data-driven system that transforms users’ emotional expressions into tangible cocktail recipes, providing a novel way to externalize and “taste” one’s feelings. Through natural language processing and an emotion-embedding approach, we map textual input onto base spirits, flavors, and garnishes. Users can refine their “emotional curve” to produce unique personalized cocktails, each reflecting a distinct affective profile. The system employs a multi-dimensional optimization framework and a visual “recipe sphere” interface, balancing classic mixology principles with individual emotional needs. By uniting artificial intelligence, flavor theory, and an interactive design, this work offers a fresh avenue for emotional embodiment in art therapy, where users gain deeper insight into their own affective states through the creative act of cocktail making.",
    "title": "Sip Your Emotions: Blending Emotion and Data in Cocktail Design",
    "id": 194424,
    "sequence": 1688,
    "queryCoordinates": {
      "visualization": [
        -15.231650878252282,
        -11.357676325861577
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Swarm User Interfaces allow dynamic arrangement of user environments through the use of multiple mobile robots, but their operational range is typically confined to a single plane due to constraints imposed by their two-wheel propulsion systems. We present corobos, a proof-of-concept design that enables these robots to cooperatively transition between table (horizontal) and wall (vertical) surfaces seamlessly, without human intervention. Each robot is equipped with a uniquely designed slope structure that facilitates smooth rotation when another robot pushes it toward a target surface. Notably, this design relies solely on passive mechanical elements, eliminating the need for additional active electrical components. We investigated the design parameters of this structure and evaluated its transition success rate through experiments. Furthermore, we demonstrate various application examples to showcase the potential of corobos in enhancing user environments.",
    "title": "Demonstrating corobos: A Design for Mobile Robots Enabling Cooperative Transitions between Table and Wall Surfaces",
    "id": 194429,
    "sequence": 1689,
    "queryCoordinates": {
      "visualization": [
        7.886371075676542,
        -13.921391857739383
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "In this demonstration, we propose the HoloArm, an actuated autostereoscopic display system that constantly maintains the view in front of the user.\r\nThree-dimensional displays aid spatial awareness and increase immersion in the content. As a common display type, autostereoscopic displays attract attention as they do not require users extra gears to watch 3D content. However, autostereoscopic displays have challenges in limited viewing angles and a viewing area dependent on the display size.\r\nWe thus propose a face-following autostereoscopic display, the HoloArm, which dynamically adjusts the autostereoscopic display according to the user's face orientation. It provides a wide viewing angle and large viewing area without requiring users to wear additional equipment such as glasses.\r\nThrough the demonstration with the HoloArm, we provide an experience to the visitors as if they have a dynamic window into the virtual world, providing the user with a deep immersion as if looking into another world.",
    "title": "HoloArm: A Face-Following 3D Display Using Autostereoscopic Display and Robot Arm",
    "id": 194431,
    "sequence": 1690,
    "queryCoordinates": {
      "visualization": [
        -2.77163859753386,
        1.1480502970952697
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We demonstrate a card actuation platform that externally drives cards using airborne ultrasound. Our system comprises phased arrays of transducers, an acoustic transparent mesh screen, a woven fabric cloth, and cards. The driving force is applied to the surface of the card through air and actuate it without adding any optional parts to the card. The actuated cards perform functional movements on the workspace, such as aligning to a set position, flipping, standing up by gradually lifting one edge, and vibrating. Additionally, they can carry lightweight objects on them. In the demonstrations, rectangular playing cards of 6.3 cm × 8.8 cm and weighing 1.6 g are used as representative cards. Other cards of different sizes and weights, such as business cards, postcards, and trading cards can perform the same movement. Our system is expected to be useful as automated physical card-based tools and card game platforms.",
    "title": "TelekineticDealer: Card Actuation Platform Using Airborne Ultrasound",
    "id": 194433,
    "sequence": 1691,
    "queryCoordinates": {
      "visualization": [
        16.88673440470715,
        1.95913275325586
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "In recent years, HCI researchers have explored water as a medium for interactive experiences by integrating it with computational technologies. However, much of the existing research has focused on controlling single characteristics of water. To address this gap, we present WETform, a water surface manipulation testbed designed to explore multimodal interactive experiences. WETform introduces four distinct modalities—Pattern, Texture, Actuation, and Mist—each highlighting specific material properties and interaction affordances of shape-changing water surfaces. These modalities enable applications such as creating animated water pixel patterns, augmenting visual content with dynamic textures, manipulating objects on water surfaces, and engaging multiple senses, including scent, through mist. By integrating technical and design approaches, WETform serves as a platform for exploring the interactive potential of water, opening up opportunities in fields such as art, design, and HCI research.\r\n",
    "title": "WETform: A Multimodal Water Experience Testbed with Surface Manipulation",
    "id": 194436,
    "sequence": 1692,
    "queryCoordinates": {
      "visualization": [
        14.749283686549392,
        11.977421706431148
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "The application of acoustic levitation as a three-dimensional interface has been widely proposed. In this paper, we propose an interactive real-space three-dimensional interface using the technique we developed to interactively levitate objects larger than a wavelength farther than the wavelength. The proposed method can interactively control an object about 9.8cm in size with simple controls. The proposed method can levitate and control an object sufficiently larger than its wavelength, and its workspace is as wide as 20x20x40cm, making it possible to realize an interface that is highly visible from a distance. In addition, since the shape of the levitated object is relatively robust in the proposed method, it is expected to have a wide range of applications beyond data visualization, such as allowing users to change the shape of the levitated object according to their specific needs and project images accordingly. This demonstration provides an interactive experience of levitation control.",
    "title": "LeviBowl: Acoustic Levitation System for Interactive Handling of Large Lightweight Objects",
    "id": 194437,
    "sequence": 1693,
    "queryCoordinates": {
      "visualization": [
        4.861849601988383,
        -1.1672268192795259
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present a method for rendering two-dimensional distributions of non-contact thermal stimuli using high-intensity ultrasound. This approach applies thermo-acoustic effect induced by ultrasound propagation in air. By utilizing an airborne ultrasound phased array with an aperture size of 576 × 555 mm, a powerful single focus with a pressure of 1.80 × 10^5 Pa is generated. By spatio-temporally modulating focus according to the desired temperature distribution, thermal stimulus are rendered on the skin surface. The amount of heat presented can be adjusted by controlling acoustic intensity. Our method provides heat generated by the attenuation of ultrasound waves as well as a pressure stimulus based on acoustic radiation pressure. Among various types of stimuli, the effect of circular patterns was particularly focused on in this study. This circular pattern provides a non-vibratory pressure sensation. This paper also describes a user survey to evaluate the performance and user perception.",
    "title": "Rendering 2D Distribution of Non-Contact Thermal Stimulus Using High-Intensity Ultrasound",
    "id": 194439,
    "sequence": 1694,
    "queryCoordinates": {
      "visualization": [
        6.7264212536156975,
        -1.9378485799739442
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Breath has a fundamentally influence on our psychophysiological system. Deep exhalation is beneficial for both meditation and running. Many systems support breathing through visual or auditory guidance. In contrast, our work uses electrical muscle stimulation (EMS) to stimulate the abdominal muscles during the exhalation phase of the breath. We explored both a guided approach, in which the EMS functions as a passive guidance, and a force approach, in which EMS is used to force an exhalation. We present both implementations and reflect on using EMS for breathing as a form of human-computer integration.",
    "title": "BreathCrunch and BellyBreath: Exploring EMS-based Breath Guidance and Enforcement for Meditation and Running",
    "id": 194441,
    "sequence": 1695,
    "queryCoordinates": {
      "visualization": [
        10.658310319596579,
        -2.7203715060963787
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "Imagine a game where your body is both the controller and the game. Our work explores how body-actuating technologies, such as Electrical Muscle Stimulation (EMS), transform the body into a playful interface, bridging physical and virtual worlds. While digital bodily games typically rely on external displays – creating a disconnect between the player’s body and the virtual experience – we introduce the “Body as a Play Material” approach, where players loan control of their body to a computer via EMS. Building on the idea of self-competition, we designed three games in which players face off against their own EMS-actuated hand. In a seven-day study (n=12), players embraced loaning bodily control, enjoyed the ambiguity of computer-controlled movements, and were captivated by their hand’s involuntary motions. By turning the body into a playful interface, this work opens new possibilities for interactive play that blurs boundaries between physical embodiment and virtual engagement.",
    "title": "Playing with Yourself: How Electrical Muscle Stimulation Can Turn Your Body Into A Playful Interface",
    "id": 194454,
    "sequence": 1696,
    "queryCoordinates": {
      "visualization": [
        -2.7335328823822165,
        -14.748823613459317
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Nature Connectedness (NC) is directly linked to an individual’s well-being and a sense of an Ecological Self that includes the natural environment and feelings of care towards it. However, modern day life has largely severed our connection with nature, removing an integral part of our being, a source of meaning, and our awareness of how our actions are affecting the climate. As a potential solution, we present Druid, a Computational Fashion Wearable (CFW) designed to help foster NC and redevelop the bond between people and nature. Druid is a wearable ensemble of vibrating socks and fashionable gaiters linked to a virtual avatar and a virtual forest environment in Virtual Reality (VR). The design safely guides the user to points of interest in real forests, encouraging observation and active engagement with their surroundings. This in turn impacts the virtual forests, calling for further nature exploration. This design has been evaluated in terms of function, visual design and comfort, and potential future directions. Results positively indicate that Druid could already be applied in practice, and the broader concept of fostering NC through the use of CFWs and VR has many positive potential applications.",
    "title": "Druid: (Re)connecting with Nature through Computational Fashion Wearables",
    "id": 194455,
    "sequence": 1697,
    "queryCoordinates": {
      "visualization": [
        -6.726421253615697,
        1.9378485799739462
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Project Kaláka workshops with female crafters to create soft volumetric interactive textile sculptures where minimalistic ORSO toolkits are integrated into the fabric. This small custom designed circuit provides playful interactions to enable a more (cyber)feminist approach to this discipline. Kaláka is an old Hungarian female tradition of creating textiles together in a community space. This practice has two equally important aspects - the process and the outcome. The outcome - textiles - were needed at that time, but the process of creating an intimate circle for women was also essential. It served as a safe space to exchange trusted knowledge horizontally. The tactile process of crafting also provided a healing effect as they exerted control over this small part of their lives making their lives more meaningful to them.The tangible HCI discipline can benefit from this craft expertise. \r\n",
    "title": "Soft Interface Sculpture: Participatory Social Crafting Through Project Kaláka",
    "id": 194457,
    "sequence": 1698,
    "queryCoordinates": {
      "visualization": [
        15.687995049934562,
        -10.718526545809768
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "While generative AI is advancing writing support tools, creative writing is often seen as the exclusive domain of skilled writers. This paper introduces \"1001 Nights\", a co-creative story-crafting game that transforms writing into a playful and rewarding activity. In this game, the AI agent takes on the role of a \"moody\" king with distinct storytelling preferences, not merely assisting but actively influencing the narrative. Players engage with the king agent through strategic storytelling, guiding him to mention weapon-related keywords, which materialize as battle equipment. The king agent provides dynamic feedback, expressing satisfaction or displeasure, prompting players to adjust their approach. By combining storytelling, game mechanics, and AI-driven responses, our system motivates creativity through playful constraints. Inspired by Oulipo's literary techniques, this approach demonstrates how AI-powered game experiences can make creative writing more accessible and engaging, encouraging players to explore their creative potential.",
    "title": "\"I Like Your Story!\": Co-creative story-crafting game with a persona-driven AI character based on generative AI",
    "id": 194458,
    "sequence": 1699,
    "queryCoordinates": {
      "visualization": [
        9.280808951595287,
        14.24312413777219
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Eye contact, even momentarily between strangers, plays a pivotal role in fostering human connection, promoting happiness, and enhancing belonging. Yet, the physical rigidity of public spaces, such as airport terminals, often limits opportunities for meaningful interactions between strangers who often remain absorbed in their personal activities. This paper introduces \\textit{Mirrorbot}, a robotic mirror system that transforms static environments into dynamic, socio-spatial interfaces. Through autonomous navigation and adaptive mirror control, Mirrorbot facilitates serendipitous, non-verbal interactions by dynamically transitioning reflections from self-focused to mutual recognition, sparking eye contact, shared awareness, and playful engagement. By integrating mirrors—a familiar and accessible architectural element—Mirrorbot disrupts conventional isolation in public spaces, enabling embodied, accessible interactions that go beyond screen-based solutions. This work demonstrates the potential of interactive mirrors to enrich public spaces, fostering spontaneous connections in shared environments.",
    "title": "MirrorBot: Exploring Socio-Spatial Interactions that Foster Serendipitous Human Connections Through Robotic Mirrors",
    "id": 194475,
    "sequence": 1700,
    "queryCoordinates": {
      "visualization": [
        16.89332309464452,
        8.69572508879795
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "When manipulating objects, we use not only the finger pad but the entire fingertip, including the sides and hemispherical tip. Therefore, understanding the tactile acuity distribution of the entire fingertip is essential for a natural and intuitive tactile experience. Our detailed measurements revealed that tactile acuity decreases linearly from the tip to the pad and drops steeply at the sides. Using these findings, we optimized electrodes for an electro-tactile device by extending the sensory range from the DIP joint to the fingertip, narrowing electrode spacing toward the tip, and increasing spacing on the sides compared to the finger pad. This optimization enables a wider and higher-density tactile presentation compared to the conventional one and is expected to increase the speed and accuracy of recognition and manipulation tasks using tactile sensation by increasing the amount of information transmitted. ",
    "title": "Optimal design of electrode placement in electro-tactile display and cutaneous sensory presentation to multiple fingers",
    "id": 194477,
    "sequence": 1701,
    "queryCoordinates": {
      "visualization": [
        3.9560748906004104,
        -4.511038844873866
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": " Recently, open-plan offices have often been used in the company and workspaces, but those offices are insufficient in security and privacy because much of the information is unintentionally available to unrelated persons. In this work, we propose an interactive AR partitioning system that allows users to visually and auditory divide or connect working spaces on an AR headset and a noise-canceling headphone setup. We design and implement a first proof-concept prototype using MR HMD's video passthrough function and sound/noise-controllable headphones. This interactivity demonstrates the variety of interactive partitioning scenarios and their flexibility and effectiveness in managing individual or group activities in the future open-plan office. ",
    "title": "Controlling Visual and Auditory Information Propagation System using Interactive AR Partition in Open-plan office",
    "id": 194482,
    "sequence": 1702,
    "queryCoordinates": {
      "visualization": [
        -13.799306509009245,
        -9.928702829192499
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "In this demo, we present OpenEarable 2.0, an open-source earphone platform designed to provide an interactive exploration of physiological ear sensing. Attendees will have the opportunity to explore real-time sensor data and understand the capabilities of OpenEarable 2.0's sensing components. OpenEarable 2.0 integrates a rich set of sensors, including two ultrasound-capable microphones (inward/outward), a 3-axis ear canal accelerometer/bone microphone, a 9-axis head inertial measurement unit, a pulse oximeter, an optical temperature sensor, an ear canal pressure sensor, and microSD storage. Participants will be able to try out the web-based dashboard and mobile app for real-time control and data visualization. Furthermore, the demo will show different applications and real-time data based on OpenEarable 2.0 across physiological sensing and health monitoring, movement and activity tracking, and human-computer interaction.",
    "title": "Demonstrating OpenEarable 2.0: An AI-Powered Ear Sensing Platform",
    "id": 194484,
    "sequence": 1703,
    "queryCoordinates": {
      "visualization": [
        17.569183002134814,
        11.5032086235753
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Traditional scene authoring workflows that demand realistic 3D environment scans often require a resource-intensive process involving data capture, processing, and model editing before integration into a 3D scene, typically using various hardware and software. This paper presents demoConstruct, an open-source collaborative platform that offers a unified 3D scene authoring environment. It enables simultaneous (1) 3D reconstruction and integration into a shared scene, (2) scene editing, and (3) VR exploration. During the interactivity session, attendees will experience the seamless capabilities of demoConstruct in collaborative capturing, editing, and experiencing of a shared 3D scene. This hands-on experience helps attendees explore innovative ways to leverage near real-time 3D reconstruction for advancing research in scene authoring, fostering the creation of new workflows and enhancing collaborative practices in the field.",
    "title": "Collaborative Scene Authoring with Near Real-Time 3D Reconstruction",
    "id": 194485,
    "sequence": 1704,
    "queryCoordinates": {
      "visualization": [
        -11.942216720066362,
        -1.1762056839547217
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "Although IoT devices are becoming increasingly prevalent in our living spaces, their integration into daily life often remains rudimentary. This video explores a novel concept of transforming everyday objects into intuitive interfaces for controlling IoT devices in smart environments. Through a scenario movie titled 'A Day in the Life of Peter', the video illustrates a speculative user experience where various types of everyday objects enable seamless IoT coordination. Grounded in 11 representative cases derived from our prior research, the video showcases potential use cases and highlights both the opportunities and challenges of utilizing everyday objects for IoT interaction. By reimagining non-digital artifacts as meaningful components of future IoT ecosystems, this video aims to inspire fresh perspectives on IoT user experiences and foster discussions on creating more engaging, personalized, and diverse smart environments.",
    "title": "Exploration on Everyday Objects as an IoT Control Interface",
    "id": 194501,
    "sequence": 1705,
    "queryCoordinates": {
      "visualization": [
        -11.688145478950538,
        -5.6909801671494264
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "This video introduces the diegetic prototypes from Interfuit, a design fiction film about near-future virtual funerals in Japan. These prototypes, including physical/virtual funeral venues, are fictional objects used in the story to show how people mourn, memorialize, and reconnect with the deceased in a society where virtual funerals are common. The film imagines a world where traditional funeral practices are freed from time and space limitations, with examples like attending funerals remotely or revisiting virtual venues years later. Our research through filmmaking highlights the potential for creative collaboration across fields to imagine alternative futures. The diegetic prototypes shown in this video are a key result of this research.",
    "title": " Designing Diegetic Prototypes in Interfuit: A Design Fiction Film on Near-Future Virtual Funerals in Japan",
    "id": 194505,
    "sequence": 1706,
    "queryCoordinates": {
      "visualization": [
        -1.1705419320967771,
        -5.884711682419381
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Academic conferences face increasing challenges as Generative AI accelerates academic writing, dramatically increasing submission volumes and straining reviewer capacity. Simultaneously, shifts in knowledge consumption, driven by AI tools and multimedia platforms, highlight the need for more engaging dissemination formats. Our interactive demonstration, KaraokAI, is a karaoke-based presentation platform which transforms academic papers into lyrics performed alongside popular songs. Drawing on the participatory nature of karaoke, this approach enhances engagement, recall, and emotional connection, making research dissemination more accessible and memorable. With CHI 2025 being held in Japan, the birthplace of karaoke, this demonstration explores how cultural and playful methods can reimagine academic presentations, inviting collaborative and inclusive participation. By blending scholarship with entertainment, KaraokAI aims to challenge traditional dissemination norms and inspire innovative, audience-centred approaches to sharing research across diverse contexts. So, grab the mic, hit the stage and let your research take the spotlight.",
    "title": "KaraokAI: Exploring the Potential of AI-Generated Karaoke for Academic Conferences and Research Experiences",
    "id": 194508,
    "sequence": 1707,
    "queryCoordinates": {
      "visualization": [
        -6.505618350206522,
        -15.705952052691876
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We propose a new projector screen material based on the freezing phenomenon of soap bubble film. Soap film is transparent, but by freezing it at low temperatures, the translucency of the film is decreased and it can be used for projection screen.\r\nIn this study, we focus on the frozen soap film and the freezing process and propose the possibility of using it as a new screen material. We also describe an implementation method of an omni-directional pro-cam system that reproduces the freezing phenomenon at room temperature and enables interactive projection onto the frozen soap film. We will also propose an application implemented using a prototype and discuss the possibilities of the extended technology and the prospects for our research.",
    "title": "Frozen Bubble Flake Display: A Novel Projection Screen using a Frozen Soap Bubble",
    "id": 194509,
    "sequence": 1708,
    "queryCoordinates": {
      "visualization": [
        12.994069198363935,
        -0.392639361411555
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We demonstrate Thermochromorph, a novel relief printing technique that produces multicolored images that transition into each other through changes in temperature. Our process utilizes two sets of CMYK thermochromic inks that exhibit complementary color-changing behaviors: one shifting from color to transparency, the other from transparency to color at the same activation temperature. We describe our printmaking workflow, provide an open-source software toolkit, showcase prints made with our system, and explore how our system can be used in creative practice through an artist workshop. By incorporating new materials and technology with the rich history of printmaking, our work extends the expressive capabilities of relief printing as the medium continues to evolve.",
    "title": "Demonstrating Thermochromorph: Dynamic Relief Printing with Thermochromic Inks",
    "id": 194510,
    "sequence": 1709,
    "queryCoordinates": {
      "visualization": [
        9.624552364536473,
        -2.7144044986507425
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Mobile augmented reality (AR) games have shown great potential in blending physical and digital experiences, yet the potential of 3D interactive markers remains understudied. We see this gap as an opportunity to investigate how these markers, including everyday objects, can redefine interactions in mobile AR games. To address this, we present Rūḥ, a serious mobile AR game that balances physical and virtual realities through 3D interactive markers. By transforming everyday objects into interactive markers, Rūḥ leverages their familiarity and tangibility to enhance user engagement and presence. Designed within the Double-Diamond Design process and guided by co-design practices, Rūḥ utilises interactive markers to create immersive and collaborative gameplay. By introducing a novel approach to tangible digital balance, Rūḥ demonstrates how 3D interactive markers can enhance user engagement and redefine gameplay mechanics. Our work highlights the untapped potential of these markers and sets the stage for further exploration in mobile AR games.",
    "title": "Demonstrating Rūḥ: A Serious Mobile AR Game Exploring 3D Interactive Markers to Harmonise Physical and Virtual Realities",
    "id": 194513,
    "sequence": 1710,
    "queryCoordinates": {
      "visualization": [
        -11.266622499313064,
        14.037920695671872
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We propose a novel integrated fiber-based EHD pump for modular hydraulic control. The pump integrates a hydraulic pump function directly into the tube itself, eliminating the need for external mechanical pumps. The principle of generating liquid flow is based on the Electrohydrodynamics (EHD) phenomenon. To enable this functionality, we present a design and fabrication approach of fiber-based EHD pump. In the proposed pump, electrodes that trigger the EHD phenomenon are embedded inside the tube using heat-shrink tubing, allowing the tube itself to silently generate liquid flow. This approach includes a design support tool that support parametric design tailored to specific pressure and flow rate requirements for each pump, allowing for rapid and customized fabrication. This paper details the design and fabrication and demonstrates application scenarios.",
    "title": "Design and Rapid Fabrication of Integrated Fiber-Based EHD Pumps",
    "id": 194522,
    "sequence": 1711,
    "queryCoordinates": {
      "visualization": [
        9.081431738250812,
        4.186597375374281
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "This video showcases StorageChat Timeline, an AI-powered system utilizing a Large Language Model (LLM) and generative AI technologies (e.g., style transfer, image-to-video) for art appreciation education. By offering real-time interactive question-and-answer experiences, the system enables users to construct the meaning of artworks based on their knowledge and experiences. It also provides immersive generative animations reflecting the artworks' styles and multimodal features, including text-to-speech and dynamic visuals, to enhance emotional engagement. Through this design, the system aims to boost immersion, learning motivation, and visual literacy, fostering active participation in art appreciation. This innovative approach enhances accessibility to art and proposes a generative AI-driven methodology for art education. The video demonstrates how the system's key features—AI conversational interface, immersive animations, and multimodal integration—create an engaging and visually interactive experience, showcasing its potential to transform art appreciation.",
    "title": "StorageChat Timeline: A Generative AI-Based Art Appreciation System for Enhancing Immersion and Exploratory Experience",
    "id": 194534,
    "sequence": 1712,
    "queryCoordinates": {
      "visualization": [
        -19.996144809641297,
        0.39267384921257065
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Gender equality is a fundamental human right, essential for building a peaceful, prosperous, and sustainable community. Despite the progress made over the last decades, old-fashioned sexist attitudes are still common in many professional fields, including DJing. Virtual Reality offers a potential solution for reducing bias by hiding the biological gender identity, thereby shifting the public focus from human features and stereotypes to DJ's quality. In this paper, we design and curate an interactive live house event in VRChat to explore the role of avatar gender in shaping social interactions and performer identity in DJ performances. Additionally, we integrate a rich array of features to support seamless interaction between the real and virtual worlds in live house events. Preliminary findings from user feedback indicated that our design solution has promising potential to promote gender equality and inclusive interaction. This contributes to a more equitable DJing community aligned with sustainable development goals.",
    "title": "LivehouseVR: Creating an Immersive and Inclusive Social VR Experience for DJs and Audiences towards Gender Equality",
    "id": 194535,
    "sequence": 1713,
    "queryCoordinates": {
      "visualization": [
        18.624298695176073,
        7.289409997582993
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Intelligent music production has garnered attention for over a decade. Despite this interest, there are few prototypes functional in practical workflows, especially those that consider context, essential to the mixing process. In this demonstration, we introduce Diff-MSTC, a deep learning-based multitrack mixing system, developed with a user-centric approach, that is both controllable and context-sensitive, and seamlessly integrates within a popular digital audio workstation. This system adapts to variations in track number and order and produces a mix in the style of provided reference song. We explore its application, provide a subjective perspective from both a researcher and user standpoint, and delve into the questions it raises regarding usability, effectiveness, workflow transformation, and the need for further investigation into the human-centered design of these tools.",
    "title": "Demonstrating Diff-MSTC: A Controllable and Context-Aware AI System for Multitrack Mixing in Digital Audio Workstation Cubase",
    "id": 194539,
    "sequence": 1714,
    "queryCoordinates": {
      "visualization": [
        -2.6951188271377595,
        7.5323525214641665
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Immersive authoring provides a powerful 3D content creation experience in virtual reality (VR) by freeing users from the tedious loop of desktop editing and VR validation. However, complex control panels required for creative tasks often disrupt immersion with awkward or unstable spatial interactions. To address this, we present Desk Console, an authoring interface that transforms 2D control panels into virtual 3D controls on a physical desk, enabling intuitive spatial interaction. Desk Console transforms traditional control panels into 3D representations based on input types and provides passive haptic feedback through the desk’s physical surface. We demonstrate Desk Console’s capabilities through an interactive 3D scene design application.",
    "title": "Desk Console: Augmenting 3D Virtual Controls on Physical Desks for Immersive Authoring",
    "id": 194540,
    "sequence": 1715,
    "queryCoordinates": {
      "visualization": [
        3.092041813450948,
        2.537573136654582
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "SquishySonics is an interface designed to explore mappings between organic physical shapes made through interactions with deformable materials and sound production using machine learning. Deformable materials are proposed as an intuitive yet ambiguous medium for interfacing with AI-driven techniques, such as navigating the latent space in complex AI audio models, which are often difficult for musicians to understand and control expressively. \r\n\r\nThe system comprises three `modular' elements: a camera, an interface-to-sound mapping tool, and sound generation methods. Flexibility and modularity are afforded by loosely coupled components and a `bottom-up' design approach. Polymer clay is used for its ergonomic, low-cost, and familiar properties, enabling hands-on exploration without fear of damaging the interface. Users can represent their perceptual links between shapes and sound by mapping deformations to parameters controlling real-time sound processes. SquishySonics encourages curiousity in the unknown, minimising frustration in complex information tasks, by allowing for physical engagement with abstract concepts.",
    "title": "SquishySonics: A Deformable Interface for the Physical Control of Real-time AI Sound Generation Tools",
    "id": 194542,
    "sequence": 1716,
    "queryCoordinates": {
      "visualization": [
        -7.113054833451406,
        -12.058376795253729
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Wireless mouse rings offer subtle, reliable pointing interactions for wearable computing platforms. However, the small battery below 27 mAh in the miniature rings restricts the ring's continuous lifespan to just 1-2 hours, because current low-powered wireless communication such as BLE is power-consuming for ring's continuous use. The ring's short lifespan persistently disrupts users' mouse use for frequent charging. This interactivity demonstrates picoRing mouse, enabling a continuous ring-based mouse interaction with ultra-low-powered ring-to-wristband wireless communication.  picoRing mouse employs a coil-based impedance sensing named semi-passive inductive telemetry, allowing a wristband coil to capture a unique frequency response of a nearby ring coil via inductive coupling between the coils. The ring coil converts the corresponding user's mouse input into the unique frequency response via an 820 uW mouse-driven modulation module. Therefore, picoRing mouse can operate continuously for over 92 hours on a 20 mAh battery while supporting subtle scrolling and pressing interactions.",
    "title": "Demonstration of picoRing mouse: an ultra-low-powered wireless mouse ring with ring-to-wristband coil-based sensitive impedance sensing",
    "id": 194543,
    "sequence": 1717,
    "queryCoordinates": {
      "visualization": [
        9.836477968456823,
        -4.923789310689839
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Perceptual manipulations (PMs) like redirected walking (RDW) are frequently applied in Virtual Reality (VR) to overcome technological limitations. These PMs manipulate the user’s visual perceptions (e.g. rotational gains), which is currently challenging in Augmented Reality (AR). We propose SwitchAR, a PM for video pass-through AR leveraging change and inattentional blindness to imperceptibly switch between the camera stream of the real environment and a 3D reconstruction. This enables VR redirection techniques in what users still perceive as AR. We present our pipeline consisting of (1) Reconstruction, (2) Switch (AR -> VR), (3) PM and (4) Switch (VR -> AR), together with a prototype implementing this pipeline. SwitchAR is a fundamental basis enabling AR PMs.",
    "title": "SwitchAR: Enabling Perceptual Manipulations in Augmented Reality Leveraging Change Blindness and Inattentional Blindness",
    "id": 194544,
    "sequence": 1718,
    "queryCoordinates": {
      "visualization": [
        6.901097129627651,
        1.1725435631331549
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Sensory-substitution devices enable perceiving objects by translating one modality (e.g., vision) into another (e.g., tactile). While many explored the placement of the haptic-output (e.g., torso, forehead), the camera’s location remains largely unexplored—typically seeing from the eyes’ perspective. Instead, we propose that seeing & feeling information from the hands’ perspective could enhance flexibility & expressivity of sensory-substitution devices to support manual interactions with physical objects. To this end, we engineered and demonstrated a back-of-the-hand electrotactile-display that renders tactile images from a wrist-mounted camera, allowing the user’s hand to feel objects while reaching & hovering. This enables flexible manual interactions, and supports ergonomic interactions.",
    "title": "Seeing with the Hands: A Sensory Substitution That Supports Manual Interactions",
    "id": 194545,
    "sequence": 1719,
    "queryCoordinates": {
      "visualization": [
        -9.131421435130813,
        -11.900300104368524
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "While many haptic systems have been demonstrated for use in virtual and augmented reality, they most often enable a single category of feedback (e.g., kinematic breaking, object compliance, textures). Putting together different systems to achieve multi-dimensional effects is unwieldy, expensive, and often physically impossible. We believe this is holding back the ubiquity of rich haptics in both the consumer and industrial AR/VR/XR domains. In this work, we describe Reel Feel, a novel shoulder-worn haptic system capable of rendering rigid geometry, animated effects, impulsive forces, compliance, and textures all in one unified device. Second, we aimed to minimize the weight on the hands (<10 g), where a system's mass is most felt, as many prior systems are large, heavy gloves and exoskeletons. Finally, we sought to keep the device practical being self-contained, low-cost, and low enough power so as to be feasible for consumer adoption and a high degree of mobility.",
    "title": "Reel Feel: Rich Haptic XR Experiences Using an Active, Worn, Multi-String Device ",
    "id": 194547,
    "sequence": 1720,
    "queryCoordinates": {
      "visualization": [
        -8.559961918193556,
        -13.517657043995314
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Fabric is integral to everyday life, from clothing to furniture, and its tactile qualities greatly influence comfort. Although digital reproduction of fabric textures promises to broaden access to personalized textiles, achieving realistic haptic feedback remains challenging. This study investigates how visual overlays affect tactile perception in a Pinching Tactile Display (PTD). We augmented the physical feedback of an electrically conductive cloth (ECC) with synchronized virtual textures in a virtual reality environment. User evaluations revealed that visual cues significantly modified perceived fabric sensations, including roughness and thickness. These findings highlight the potential of cross-modal integration for more immersive fabric representation, offering guidelines for future haptic design in applications such as online fashion retail and VR-based interaction.\r\n",
    "title": "Demonstrating Pinching Visuo-Haptic Display: A Dynamic Cloth Texturization Via Visually Enhanced Tactile Sensation",
    "id": 194548,
    "sequence": 1721,
    "queryCoordinates": {
      "visualization": [
        -6.483861024079836,
        14.627356091256491
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Posters are widely used for information dissemination, but their static nature and limited interactivity often hinder engagement and personalized learning experiences. We introduce a guide agent Visiobo designed to enhance poster reading by providing personalized support and dynamic visual augmentations. Visiobo overlays cueing (e.g., highlights, arrows) to help users quickly locate key information and employs concept mapping to address the content limitations of static posters by offering structured, relevant information. The user study with 12 participants demonstrated that by dynamically adapting to user interests and seamlessly integrating voice interaction with visual overlay cueing and concept mapping, Visiobo provides an engaging and enriched poster reading experience.",
    "title": "Visiobo: Enriching Static Posters with Dynamic Visual Cueing and Concept Mapping",
    "id": 194558,
    "sequence": 1722,
    "queryCoordinates": {
      "visualization": [
        2.6124928235797444,
        4.263200821770461
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "The emergence of virtual sensors in recent years has opened up new possibilities for the development of human activity recognition (HAR) systems. For instance, we can synthesized virtual sensor data for those scarce datasets, such as accelerometer data, from the widely available multimedia resources online through cross-modal approaches. However, existing solutions on virtual sensors primarily focus on batch pipelines, relying heavily on lengthy processing workflows and sophisticated computer vision techniques, which often lack interactivity and flexibility for the usage in customized and small-scale scenarios. In this work, we present the Vsens Toolkit, an AR-based open-ended system for virtual sensors, which serves as an preliminary exploration of the user interface for virtual sensors. It integrates functionalities such as scene construction, data collection, data augmentation, and visualization. In this interactivity demonstration, we showcase exemplar scenarios including wearable accelerometers, capacitive sensing, wrist-worn sensor tracking, and sandbox for free exploration",
    "title": "Vsens Toolkit: AR-based Open-ended System for Virtual Sensors",
    "id": 194559,
    "sequence": 1723,
    "queryCoordinates": {
      "visualization": [
        -4.952484357652735,
        10.930365899054111
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "XRAYHEAD Garden creates a powerful sensation as if an experimenter's hand is penetrating the participant's skull with tactile and audio feedback. It builds on the earlier XRAYHEAD, which produced the illusion of seeing a skeleton inside the head. The illusion is generated by the experimenter touching a smart-skull model with LEDs synchronized to the participant's head surface. The primary innovation is the ability to open the skull along the forehead line and include a compact sound instrument with a light sensor. This system modifies the sound's timbre based on hand penetration depth, enhancing the illusion of sound emanating from inside the head. To evaluate its effectiveness, we conducted two experiments. In the first, 86% of participants reported experiencing an illusory sensation of skull intrusion and a lingering object inside the head. The second experiment showed that audio-tactile integration strengthened the sensation of sound originating from one's head (magnet-head illusion).\r\n",
    "title": "XRAYHEAD Garden: Intrusion of a Sound-emitting Object into the Head via Audiovisual Integration",
    "id": 194560,
    "sequence": 1724,
    "queryCoordinates": {
      "visualization": [
        3.2472402416509194,
        -3.802029828000154
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Virtual Reality (VR) technologies are rapidly becoming mainstream. However, VR headsets largely rely on visuals to convey information, making them inaccessible to blind and low vision people (BLV). Therefore, we present VRSight, an end-to-end system using state-of-the-art machine learning models to empower BLV to more effectively interact with VR environments. VRSight applies to VR applications post-hoc, not needing developer implementation. VRSight uses our fine-tuned object detection model trained on VR scenes to recognize virtual elements in each frame like interactables, signs, and seating areas. VRSight automatically prioritizes important objects like safety information while including an audio-based menu system for users to query other objects. All objects are sonified corresponding to their spatial locations in VR with sound effects and text-to-speech in an application-relevant tone. VRSight increases VR accessibility for BLV, serving as a foundation for more inclusive VR design and encourages broader participation in social virtual spaces.",
    "title": "Demonstration of VRSight: Automated Real-Time Visual Descriptions for VR",
    "id": 194562,
    "sequence": 1725,
    "queryCoordinates": {
      "visualization": [
        -7.193781274473711,
        -14.291588819128243
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Increasing tangible technologies have been developed to support children on the autism spectrum develop their gross motor and communicative skills through play activities. However, most research focuses on one-on-one interactions between the children and the objects with adult participants. Few designs can be readily integrated into classroom settings where dynamic child-child and child-teacher interactions are essential to the children’s play and learning experiences. We design RainbowForest, a playful educational tool that can engage children on the autism spectrum in learning through play. The design idea emerged from a preliminary investigation of existing educational toys commonly used in special education and therapies for children with autism. RainbowForest can engage the children in the structured play of color-matching games as well as the open-ended play of block-building. Our design also serves as a teaching tool, enabling educators to set play rules aligned with specific learning objectives.",
    "title": "RainbowForest: A Playful Educational Tool to Engage Children with ASD in Learning through Play in Classrooms",
    "id": 194566,
    "sequence": 1726,
    "queryCoordinates": {
      "visualization": [
        20.96696311537415,
        1.1774793919810276
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Stories shape our identities and connections across generations, yet the digital divide continues to exclude many older adults from emerging storytelling technologies. We present Time Travel Tours (TTT), an accessible social VR content creation system that enables older adults to craft and share location-based narrative experiences without requiring advanced technical skills or VR hardware. TTT combines a conversational AI-guided web interface with automated game development pipelines to transform users' personal stories and meaningful locations into persistent, multi-user virtual environments. The system leverages an AI-assisted creation tool to generate navigable virtual spaces where storytellers can guide others through their memories in real time. We discuss the system architecture, design considerations for accessibility and agency, and planned evaluation protocols focused on measuring usability, impacts on social connection and digital storytelling empowerment among older adults.",
    "title": "Time Travel Tours: An Accessible Social VR Storytelling Tool for Older Adults",
    "id": 194568,
    "sequence": 1727,
    "queryCoordinates": {
      "visualization": [
        -13.15449893185177,
        -13.709819760008177
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "When several individuals collaborate on a shared task, their brain activities often synchronize. This phenomenon, known as Inter-brain Synchronization (IBS), is notable for inducing prosocial outcomes such as enhanced interpersonal feelings, including closeness, trust, empathy, and more. The Neuresonance project investigates whether visual, auditory, and haptic feedback of the IBS level can further enhance its intensity, offering design recommendations for feedback systems in IBS. Through this interactive experience, we demonstrate the findings of Neuresonance by showcasing three different types of IBS level feedback, including on-body projection mapping, sonification using chords, and vibration bands attached to the wrist. Using a slider interface visitors can vary the IBS level, controlling the feedback exactly how they would have felt if they were the participants of the study.",
    "title": "Demonstrating NeuResonance: Inter-brain Synchronization and Feedback Modalities in Collaboration",
    "id": 194571,
    "sequence": 1728,
    "queryCoordinates": {
      "visualization": [
        -1.111140466039206,
        -1.6629392246050896
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Humans are giants compared to the objects in their environments, which shapes how we encounter them. The Audible Giant explores a shift in perspective by scaling objects to their own 1:1 scale and enabling humans to experience their world through auditory immersion.\r\n\r\nWe designed a miniature floor where objects inhabit their true scale, capturing the sounds of their movements, impacts, and vibrations. These sounds are then transmitted and amplified through a human-scale floor, creating an auditory experience that transforms human perception. This system bridges the gap between human and object scales, allowing humans to inhabit the world of objects and perceive them as equals.\r\n\r\nBy distorting barriers of size and scale, our project aims to redefine the relationship between humans and their surroundings, encouraging a deeper appreciation of everyday objects through sound.",
    "title": "The Audible Giant: Transforming Tiny Sounds into Human-Scale Experiences",
    "id": 194573,
    "sequence": 1729,
    "queryCoordinates": {
      "visualization": [
        12.010433922646724,
        -4.974884620746175
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Providing haptic feedback for soft, deformable objects is challenging, requiring complex mechanical hardware combined with modeling and rendering software.\r\nAs an alternative, we advance the concept of self-haptics, where the user's own body delivers physical feedback, to convey dynamically varying softness in VR.\r\nSkin can exhibit different levels of contact softness by altering the biomechanical state of the body.\r\nWe propose SkinHaptics, a device-free approach that changes the states of musculoskeletal structures and virtual hand-object representations.\r\nTo demonstrate this methodology, we designed interaction scenarios with SkinHaptics.",
    "title": "Demonstrating SkinHaptics: Exploring Skin Softness Perception and Virtual Body Embodiment Techniques to Enhance Self-Haptic Interactions",
    "id": 194575,
    "sequence": 1730,
    "queryCoordinates": {
      "visualization": [
        5.03692225255784,
        -17.280897378946722
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Solving the problem of one-bit text entry has many applications to accessibility and ubiquitous computing--from text entry for individuals with Locked-in syndrome to consumers searching for videos with a TV remote control. Dotter is a timing-based text entry system that maximizes utilization of a one-bit input channel by presenting an adaptive trie. Having only a single rule, Dotter is easy to explain and exhibits a gentle learning curve. Dotter’s use of large language models facilitates domain adaptation. Here we describe our system, its mathematical foundations, and a validating pilot study. Our exhibition will give attendees an opportunity to experience our system and help us foster broader discussions about its utility within the human-computer interaction community.",
    "title": "Dotter: A One-Bit Predictive Text-Entry System",
    "id": 194576,
    "sequence": 1731,
    "queryCoordinates": {
      "visualization": [
        10.825223247697277,
        -1.95308515879734
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present INDRA, an Interactive Deep-Dreaming Robotic Artist, designed to assist in real-time, embodied collaboration on a traditional painting canvas.\r\nINDRA enhances fine art creation by dynamically adapting to users' needs, offering support throughout the artistic process. Visually represented as a cybernetic avatar of a mechanical Maneki-neko, the Japanese beckoning cat, INDRA serves as a creative AI companion that paints alongside artists. Its mission is to improve artist-friendly perception of AI among creatives, blending technology with traditional arts to inspire  innovation. INDRA integrates robotic painting with advanced AI processes, including speech recognition, computer vision, and generative image synthesis to facilitate co-creation. INDRA differs from existing AI art generators and art robots in its turn-based framework, where user and robot actively share the same canvas.",
    "title": "INDRA: Interactive Deep-dreaming Robotic Artist. Painting with a Real-Time Embodied AI",
    "id": 194598,
    "sequence": 1732,
    "queryCoordinates": {
      "visualization": [
        -2.3800600208737053,
        1.8262842870261626
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "FloraWear is a wearable living interface where participants can experience close relationships with plants by caring for and wearing them. While plants can have positive effects on both mental and physical well-being, we are increasingly losing our connection to plants due to industrialization and urbanization. To build a stronger relationship with plants, we present FloraWear--a DIY, wearable living interface that facilitates an intimate connection with plants. We demonstrate the original FloraWear design as well as the updated design with sustainable materials. With the interaction with FloraWear, the audience can experience cohabitation with other agents, such as plants.",
    "title": "FloraWear Research and Development",
    "id": 194599,
    "sequence": 1733,
    "queryCoordinates": {
      "visualization": [
        7.1401800626211145,
        -5.478852861078489
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "In this paper, we propose a modular system based on a spring structure that achieves texture variation expression using real objects, with a configuration equivalent to a pin-based shape display. Using only the actuators as the driving source, the deformation of a single spring module attached in an arch shape by the linkage of two actuators achieves texture variation expression with simple wiring and control. With a reconfigurable structure using a magnet attachment, users can easily change the expression by simply replacing the spring module. We propose a spring design method for creating texture changes through spring deformation, and demonstrate the expandability of expression using this system by showing examples of the work. We also introduce examples of interactive expression combined with a sensing system.",
    "title": "Color and Texture-Changeable Modules for Pin-based Shape Display with Spring Structures",
    "id": 194600,
    "sequence": 1734,
    "queryCoordinates": {
      "visualization": [
        1.94384143922611,
        -7.760250025556352
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "In this Demo, we present Xstrings, a method for designing and fabricating 3D printed objects with integrated cable-driven mechanisms that can be printed in one go without the need for manual assembly. Xstrings supports four types of cable-driven interactions—bend, coil, screw and compress—which are activated by applying an input force to the cables. To facilitate the design of Xstrings objects, we developed a design tool that allows users to embed cable-driven mechanisms into the object geometry based on the desired interaction by automatically placing joints and cables at the respective locations. The application potential of Xstrings is demonstrated through examples such as manipulable gripping, bionic robot manufacturing, and dynamic prototyping.",
    "title": "Demonstrating Xstrings: 3D printing cable-driven mechanism for actuation, deformation, and manipulation",
    "id": 194605,
    "sequence": 1735,
    "queryCoordinates": {
      "visualization": [
        8.31491579260158,
        3.444150891285808
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Oral pH is a key health indicator, playing a vital role in enamel protection and reflecting systemic conditions. However, existing devices for detecting pH are either one-time tests or require additional extraoral equipment, which fails to capture the dynamic changes in oral pH. This paper introduces BIOral, a novel system that integrates pH biosensors with dental braces for continuous oral pH monitoring. BIOral combines biocompatible dental braces, edible colorimetric biosensors, and electric color detectors to monitor salivary pH levels, offering a new approach to personalized oral care management. We present the fabrication process of the BIOral device and a preliminary technical evaluation to assess the system's performance, reaction time and detection range. We envision BIOral as a cost-effective solution for daily use, and could advance preventive healthcare and facilitate early intervention.",
    "title": "BIOral: Fabricating Intraoral pH Sensor for Continuous Health Monitoring",
    "id": 194607,
    "sequence": 1736,
    "queryCoordinates": {
      "visualization": [
        -1.8262842870261626,
        -2.380060020873705
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Exoskeletons open up a unique interaction space that seamlessly integrates users' body movements with robotic actuation. Despite its potential, human-exoskeleton interaction remains an underexplored area in HCI, largely due to the lack of accessible prototyping tools that enable designers to easily develop exoskeleton designs and customized interactive behaviors. We present ExoKit, a do-it-yourself toolkit for rapid prototyping of low-fidelity, functional exoskeletons targeted at novice roboticists. ExoKit includes modular hardware components for sensing and actuating shoulder and elbow joints, which are easy to fabricate and (re)configure for customized functionality and wearability. To simplify the programming of interactive behaviors, we propose functional abstractions that encapsulate high-level human-exoskeleton interactions. These can be readily accessed either through ExoKit's command-line or graphical user interface, a Processing library, or microcontroller firmware, each targeted at different experience levels. Findings from implemented application cases and two usage studies demonstrate the versatility and accessibility of \\toolkit~for early-stage interaction design. ",
    "title": "Demonstrating ExoKit: A Toolkit for Rapid Prototyping of Interactions for Arm-based Exoskeletons",
    "id": 194611,
    "sequence": 1737,
    "queryCoordinates": {
      "visualization": [
        -5.690980167149427,
        11.688145478950538
      ]
    }
  },
  {
    "session": "Remote Doctoral Consortium",
    "abstract": "    Public institutions have begun to use AI systems in areas that directly impact people's lives, including labor, law, health, and migration. Explainability ensures that these systems are understandable to the involved stakeholders, while its emerging counterpart contestability enables them to challenge AI decisions. Both principles support the responsible use of AI systems, but their implementation needs to take into account the needs of people without technical background, AI novices. I conduct interviews and workshops to explore how explainable AI can be made suitable for AI novices, how explanations can support their agency by allowing them to contest decisions, and how this intersection is conceptualized. My research aims to inform policy and public institutions on how to implement responsible AI by designing for explainability and contestability. The Remote Doctoral Consortium would allow me to discuss with peers how these principles can be realized and account for human factors in their design. \r\n",
    "title": "Explainability and Contestability for the Responsible Use of Public Sector AI",
    "id": 194639,
    "sequence": 1738,
    "queryCoordinates": {
      "visualization": [
        -16.99546453789783,
        -0.3926641581010117
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "The design of this custom-fitted 3D printed wrist brace is meant to create a brace which is breathable, cost-efficient, customizable, and comfortable while still functioning as a brace for immobilization. Customized braces are not widely available on the market, specifically at an affordable price using freely available resources. This project serves as a method to create custom, affordable braces which are comfortable and functional for the user, supporting good health and well-being. The 3D printed wrist brace, featuring a Voronoi pattern, merges applied mathematics with creative design. It showcases the bridge between mathematical concepts and modern fabrication techniques resulting in a tangible piece of art.",
    "title": "Custom 3D Printed Wrist Brace Featuring a Voronoi Pattern",
    "id": 194642,
    "sequence": 1739,
    "queryCoordinates": {
      "visualization": [
        12.288897595450322,
        4.240636259871301
      ]
    }
  },
  {
    "session": "Video Showcase 1",
    "abstract": "Physical augmentation offers opportunities to enhance human abilities, yet these systems can also embed dark patterns that deceive users in ways that against their best interests. To explore these dark patterns, we developed “Flytrap Hand”, a system that employs electrical muscle stimulation to automate grasping and releasing actions. While the system enhances grasping speed and reduces physical effort, it also exposes dark patterns in physical augmentation, such as manipulating users through involuntary hand movements and imposing forced control, which diminishes user agency. Ultimately, we hope that our work can deepen the understanding of dark patterns and support practitioners in mitigating these issues within physical augmentation technologies.",
    "title": "Flytrap Hand: Towards Understanding Dark Patterns of Physical Augmentation via Electrical Muscle Stimulation",
    "id": 194666,
    "sequence": 1740,
    "queryCoordinates": {
      "visualization": [
        8.923003752364293,
        -1.174735729980465
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "As music streaming libraries continually grow, finding meaningful ways to revisit, reflect on, and share these collections over time—both individually and socially—becomes increasingly important. Queue Player is a network of four domestic music players that allow for synchronous distributed co-listening across geographical distance and for the long-term exploration of the collective music listening histories among four close friends. Queue Player leverages tempo metadata (i.e., beats per minute) as the cornerstone of its interaction design, enabling users to explore an ever-changing queue of songs from their collective pasts shaped by tempos steadily tapped out on their respective device. While the four Queue Players exist in real, highly finished physical form, this video offers an artistic explanation and user scenario of their outer and inner workings, drawing on stop motion, collage, and zine aesthetics to emphasize the reflective, temporal, material and subtly evolving conceptual qualities shaping the design of this system. ",
    "title": "Queue Player: Distributed Co-Listening of Shared Digital Music Histories through Tempo, Time, and Space ",
    "id": 194690,
    "sequence": 1741,
    "queryCoordinates": {
      "visualization": [
        -9.741720724952762,
        -11.406089484000459
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Pregnancy loss, encompassing miscarriage, stillbirth, and elective termination, is a deeply emotional experience with significant psychological impacts. Despite its prevalence, societal norms and cultural sensitivities often silence discussions, leaving affected individuals isolated and underserved. This study addresses the critical gap in pregnancy loss support, particularly in Taiwan, through the design and development of Xiao Yun Duo, which means“Little Cloud” in Mandarin, a mobile application that aims at providing culturally sensitive, accessible, and empathetic support. Grounded in interviews with affected women and healthcare professionals, the application integrates tailored emotional support, professional resources, and gamified therapeutic features. Key functionalities include a personalized healing journey with AR-based planting, a care calendar for post-miscarriage recovery, anonymous community chat rooms, and a professional health blog accessible to users and the public. Iterative design processes informed by user testing emphasized emotional comfort, usability, and cultural alignment. While limitations such as a small sample size and the absence of real-time pregnancy loss participants were identified, future iterations will prioritize these areas. Aligned with the SDGs 3 Good Health and Well-Being, Xiao Yun Duo aspires to enhance emotional well-being and societal awareness, creating a supportive ecosystem for women experiencing pregnancy loss.",
    "title": "Little Cloud：A Digital Companion App to Support Those Experiencing Pregnancy Loss",
    "id": 194697,
    "sequence": 1742,
    "queryCoordinates": {
      "visualization": [
        2.735390220164818,
        15.76444227822306
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "We present Factually, novel concept of a live, wearable, fact-checking system that extends users’ ability to discern truth in real time. Integrated into devices like smartwatches or rings, Factually could use tactile vibrations to discreetly provide instant feedback on potential falsehoods. Unlike previous systems such as Wearable Reasoner or Factiverse, which focus on verbal feedback or broad applications, Factually emphasizes individual-level usability with non-intrusive, practical feedback. Through three illustrative scenarios, we demonstrate Factually's  potential: extending perceptual abilities to detect misinformation in real time, enabling socially integrated and inconspicuous interactions, and fostering mindfulness by encouraging users to critically assess information. By addressing challenges of convenience, social dynamics, and misinformation, Factually showcases a step forward in empowering individuals to navigate an increasingly complex information landscape with enhanced critical thinking and truth-centered engagement.",
    "title": "Factually: A Live, Wearable Fact-Checker",
    "id": 194700,
    "sequence": 1743,
    "queryCoordinates": {
      "visualization": [
        8.014976662062821,
        18.323759142342716
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Technology has become embedded in everyday life, leading to a rapidly increasing online carbon footprint, yet individuals lack awareness of the environmental impact of these activities. We created the Purple app, targeting students as our users, to help them understand, monitor, and reduce their online carbon footprint in an engaging and practical way. We conducted user research to explore perceptions of their online carbon footprint and behaviours. Based on these insights, we iteratively designed and prototyped an app that integrates gamification, social accountability, and educational tools to encourage sustainable online habits. User testing highlighted the importance of clear information architecture, consistent metrics, and features that combine individual progress tracking with community-based motivation. This work contributes to the current HCI literature by addressing the environmental challenges associated with digital consumption. The Purple app serves as a model for how environmental awareness can be integrated into everyday technology use.",
    "title": "Purple: Combining Individual and Collective Action to Increase Online Sustainability",
    "id": 194715,
    "sequence": 1744,
    "queryCoordinates": {
      "visualization": [
        -12.687865683272918,
        -15.460209067254734
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "A child with motor and communication disabilities due to cerebral palsy learned music and piano in an artistic school in Portugal through an intervention that emphasized pedagogical differentiation and curricular adaptations, integrating technology, software, and assistive devices. This article introduces the Netychords Accessible Digital Musical Instrument (ADMI), which the child uses alongside Assistive Technologies to perform on a virtual piano with the Symphony Orchestra of the University of Aveiro. Netychords demonstrates how digital technologies can create accessible instruments, enabling musical expression for individuals with motor limitations. The adaptive design process behind Netychords, tailored to the child's abilities, serves as a model for similar solutions in special needs contexts. By extending access to music education and artistic participation, such innovations highlight the potential of inclusive approaches to empower individuals with disabilities, fostering creativity and enabling active involvement in cultural and artistic endeavours.",
    "title": "I WANT TO PLAY PIANO Chasing a Dream with Netychords",
    "id": 194720,
    "sequence": 1745,
    "queryCoordinates": {
      "visualization": [
        8.65779784054898,
        15.781081602735139
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "The importance of empathy cannot be overstated in modern societies where people of diverse backgrounds increasingly interact together. The HCI community has strived to foster affective empathy through immersive technologies. Many previous techniques are built upon a premise that presenting the same experience as-is may help evoke the same emotion, which however faces limitations in matters where the emotional responses largely differ across individuals.\r\nIn this paper, we present a novel concept of generating a personalized experience based on a large language model (LLM) to facilitate affective empathy between individuals despite their differences. As a case study to showcase its effectiveness, we developed EmoSync, an LLM-based agent that generates personalized analogical microaggression situations, facilitating users to personally resonate with a specific microaggression situation of another person. EmoSync is designed and evaluated along a 3-phased user study with 100+ participants. We comprehensively discuss implications, limitations, and possible applications.",
    "title": "Toward Affective Empathy via Personalized Analogy Generation: A Case Study on Microaggression",
    "id": 194724,
    "sequence": 1746,
    "queryCoordinates": {
      "visualization": [
        14.585548805965148,
        3.5016804578385803
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "RePlate is the first food reviews app to foreground sustainability in institutional dining services, in this case enabling university students to make carbon-conscious food choices and minimize food waste while tracking sustainability. An estimated 170 million metric tons of carbon dioxide is produced annually by food waste disposal in the United States. University dining halls are a high contributor due to their production and distribution for a large student population. Consulting with representatives at the University of California, Los Angeles (UCLA), we identified the lack of student engagement and manual data collection as pain points in the current food waste stream. Researching on food waste interventions, a user survey with 24 respondents and three in-depth user interviews provided insights into how food reviews and quantitative tracking could minimize food waste on campus. RePlate has the potential to be scalable to other dining scenarios in promoting individual sustainability and utilizing aggregated data for menu development.",
    "title": "RePlate: A User-Driven Solution for Empowering Sustainable Food Consumption in University Dining",
    "id": 194745,
    "sequence": 1747,
    "queryCoordinates": {
      "visualization": [
        19.947777080129768,
        -6.564007126858524
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Touchscreens and touchpads offer intuitive interfaces but provide limited tactile feedback, usually just mechanical vibrations. These devices lack continuous feedback to guide users’ fingers toward specific directions. Recent innovations in surface haptic devices, however, leverage ultrasonic traveling waves to create active lateral forces on a bare fingertip. This paper investigates the effects and design possibilities of active forces feedback in touch interactions by rendering artificial potential fields on a touchpad. Three user studies revealed that: (1) users perceived attractive and repulsive fields as bumps and holes with similar detection thresholds; (2) step-wise force fields improved targeting by 22.9% compared to friction-only methods; and (3) active force fields effectively communicated directional cues to the users. Several applications were tested, with user feedback favoring this approach for its enhanced tactile experience, added enjoyment, realism, and ease of use.",
    "title": "Attracting Fingers with Waves: Potential Fields from Active Lateral Forces Enhance Touch Interactions",
    "id": 194748,
    "sequence": 1748,
    "queryCoordinates": {
      "visualization": [
        21.91243736897701,
        1.96088973444707
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present a novel method to enhance the tactile properties of fabric interfaces through embroidery, enabling appearance-independent tactile design. Unlike existing approaches that alter geometric properties, such as shape or contours, our method uses commercially available embroidery techniques to achieve tactile variations while preserving the visual consistency of the fabric. By adjusting parameters like stitch length, density, and deviation, we establish a design space for reproducible and tactilely diverse embroidery patterns. Our user study, involving 26 embroidered samples, demonstrates how different stitching techniques influence tactile perception, including qualities like smoothness, roughness, and directional guidance. Attendees will experience several use cases at the demonstration, such as eyes-free interfaces for sliders and directional keypads, tactile learning tools for children, and assistive applications for visually impaired individuals. This work highlights the potential of embroidery as a versatile and practical solution for designing tactilely engaging fabric interfaces.",
    "title": "Appearance-Independent Tactile Design Using Different Embroidery Stitches",
    "id": 194750,
    "sequence": 1749,
    "queryCoordinates": {
      "visualization": [
        -19.351981847205195,
        5.049831540303163
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "We present Spatial Haptics, a sensory substitution method for representing locations of remote objects in 3D space via haptics.\r\nSpatial Haptics imitates auditory localization processes to enable vibrotactile localization abilities similar to those of some animal species. Two implementations of the localization method were developed, that modulate the vibration amplitude of the controllers relative to a target object in Virtual Reality. In Ear-Based Localization, vibrations are modulated based on the relative locations of the ears to the target, while in Hand-Based Localization, the amplitude is determined based on the relative locations of the hands to the target. In this interactive demonstration, users can experience the vibrotactile localization approaches in an interactive VR mini-game. Their task is to locate the target object in a scene consisting of multiple moving objects. By experiencing spatial localization using haptics hands-on, participants can evaluate the benefits of this sensory substitution approach for detecting distal objects.",
    "title": "Demonstrating Spatial Haptics: A Sensory Substitution Method for Distal Object Detection Using Tactile Cues",
    "id": 194752,
    "sequence": 1750,
    "queryCoordinates": {
      "visualization": [
        16.23921596258436,
        -5.0287040995215975
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Numerous haptic devices have been proposed to support motor learning. Understanding the impact of each type of feedback on users’ learning performance and experience, as well as the effects of customizing the haptic feedback each user receives, is vital to achieving both efficient and highly motivating learning. To explore this, we developed three devices to assist piano learning: a hand exoskeleton with mechanical linkages (linkage), a vibrotactile glove (tactile), and Electrical Muscle Stimulation (EMS). Furthermore, we demonstrate a haptic customization, where users can customize the feedback order based on their preferences.",
    "title": "Demonstrating Hapticus: Exploring the Effects of Haptic Feedback and its Customization on Motor Skill Learning: Tactile, Haptic, and Somatosensory Approaches",
    "id": 194754,
    "sequence": 1751,
    "queryCoordinates": {
      "visualization": [
        -8.203107624274452,
        8.75836887237403
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "We present PhoneCanvas++, a smartphone-based 3D design system that enables users to create and modify 3D sketches through various hand gestures and voices. \r\nPhoneCanvas++ supports 3D sketching via pen gestures, surface gestures, delete gestures, and object rotation through smartphone motion. By combining hand gestures with smartphone rotation, the system delivers a canvas-like 3D design experience.\r\nAdditionally, it integrates multimodal inputs, allowing users to apply colors and generate objects using a combination of voices and hands. Applications of PhoneCanvas++ include rapid prototyping, rotation-based 3D sketching, object modification, annotation, and collaborative design tasks.",
    "title": "PhoneCanvas++: Multimodal 3D Sketching System Using a Depth Camera-Equipped Smartphone as a Canvas",
    "id": 194755,
    "sequence": 1752,
    "queryCoordinates": {
      "visualization": [
        0.39265422461809707,
        14.99485987463336
      ]
    }
  },
  {
    "session": "Interactivity",
    "abstract": "Driven by the vision of everyday haptics, the HCI community is advocating for “design touch first” and investigating “how to touch well.” However, a gap remains between the exploratory nature of haptic design and technical reproducibility. We present Shape-Kit, a hybrid design toolkit embodying our “crafting haptics” metaphor. The Shape-Kit analog tool can transduce human touch behaviors into pin-based haptic sensations through a flexible and long transducer, enabling free-form sensorial exploration of touch across the body. An ad-hoc tracking module captures and digitizes these patterns, while our GUI includes real-time 3D visualization, recording, tuning, and playback functionalities. We also built a programmable shape display for tangible playback. This demonstration invites attendees to experience how the analog crafting method offers an intuitive entry point for collaborative touch prototyping while excelling at uncovering subtle nuances that shape touch quality and how touch digitization enables touch recording and playback while enhancing reflective creation.",
    "title": "Demonstrating Shape-Kit: A Design Toolkit for Crafting On-Body Expressive Haptics",
    "id": 194756,
    "sequence": 1753,
    "queryCoordinates": {
      "visualization": [
        -5.758320584559811,
        14.927884781355822
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "With approximately 95% of deaf children born to hearing parents, the need for accessible, self-paced, and effective sign language learning tools is critical. This paper explores the integration of Sign Language Recognition (SLR) models into educational games for teaching American Sign Language (ASL) production, focusing on the development of PopSignAI, an arcade-style bubble-bursting game designed to teach ASL sign production through gesture recognition. PopSignAI builds on the existing PopSign game, which teaches sign reception, by incorporating a 560-sign SLR model to recognize player-generated signs. Through the development of this game, we demonstrate the potential of integrating SLR models into sign language game mechanics as an effective method for teaching sign production. We also outline key considerations for their integration, addressing challenges related to cognitive load, gameplay intuitiveness, and the technical demands of gesture recognition. \r\n",
    "title": "PopSignAI: Integrating Sign Recognition into Gameplay to Teach Sign Language",
    "id": 194758,
    "sequence": 1754,
    "queryCoordinates": {
      "visualization": [
        4.923789310689838,
        9.836477968456824
      ]
    }
  },
  {
    "session": "Student Design Competition Session 1",
    "abstract": "Le Petit Care is an AI-powered extended reality solution designed to complement limitations in medication by providing highly user-efficient and personalized management of ADHD symptoms. It aims to alleviate children’s sense of negative self-identity and guilt throughout the diagnostic and treatment process. We conducted expert interviews and interdisciplinary literature reviews to explore a practical design approach. By thoughtfully understanding children with ADHD, we aimed to integrate their unique characteristics into a user-centered design and storytelling framework. Le Petit Care, an extended reality program designed with this approach, uses AI to analyze multifaceted data such as head movements, eye tracking, behavior, and voice based on the internationally recognized diagnostic standard DSM-5 to screen for ADHD. Building on this analysis, it provides personalized behavioral development training solutions. In this article, we describe a comprehensive approach that integrates insights from interdisciplinary research, suggesting an innovative solution for effective therapeutic interventions for ADHD.",
    "title": "Le Petit Care: A Child-Attuned Design for Personalized ADHD Symptom Management Through AI-powered Extended Reality",
    "id": 194761,
    "sequence": 1755,
    "queryCoordinates": {
      "visualization": [
        16.99546453789783,
        0.3926641581010186
      ]
    }
  },
  {
    "session": "Video Showcase 2",
    "abstract": "What if a clock could do more than just tell time - what if it could actually look around? I designed and fabricated a timepiece with visual perception capabilities, featuring three interactive applications that enable Human-Time Interactions. This clock is unique because, rather than using pre-made components, I handled the entire process—design, prototyping, PCB milling, 3D printing, programming, spray painting, and more—with the only exceptions being the camera and motors.",
    "title": "Clo(o)k: Human-Time Interactions Through a Clock That “Looks”",
    "id": 194763,
    "sequence": 1756,
    "queryCoordinates": {
      "visualization": [
        7.157381403894114,
        -13.182256689929487
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Video games are becoming increasingly accessible, but there are still scant resources for gamers with disabilities to reliably discover and evaluate which games are accessible to them. \r\nTo remedy this, I designed OURCADE: a social simulation role-playing game that utilizes player engagement to produce a wiki-based resource for game accessibility information.\r\nThis design leverages existing insights around game accessibility, citizen science, and video game communities, while also exploring new questions around the potential of social video games as a medium for answering complex game accessibility questions.",
    "title": "OURCADE: A Game to Solve Real-World Game Accessibility Puzzles",
    "id": 194767,
    "sequence": 1757,
    "queryCoordinates": {
      "visualization": [
        18.624298695176066,
        -7.289409997583004
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "Immigrant children face unique challenges, including dual-language development, cultural differences, and acculturation, which shape their mental health, academic performance, and social integration. Proficient bilingualism and bicultural competence are essential for enhancing their well-being while promoting empathy, cultural pride, and meaningful intergenerational dialogue. My Home Path is designed to explore how game design can serve as a transformative tool for second-generation Chinese immigrant children, enabling them to navigate and embrace their bicultural identity. By immersing players in the first-person experiences of their parents' immigrant journeys, the game leverages bilingual storytelling and interactive cultural objects to foster empathy and a deeper understanding of heritage. Players engage with narratives rooted in childhood experiences, memories, and anecdotes from first-generation immigrants, supporting cultural connection and belonging. Through this game, we hope to investigate the potential of games for cultural education, preserving heritage, and promoting intergenerational dialogue within immigrant communities.",
    "title": "My Home Path: Leveraging Game Design to Foster Bicultural Identity and Intergenerational Connection in Immigrant Communities",
    "id": 194789,
    "sequence": 1758,
    "queryCoordinates": {
      "visualization": [
        -14.291588819128245,
        -7.193781274473706
      ]
    }
  },
  {
    "session": "Student Game Competition",
    "abstract": "This paper introduces The Reversed Turing Test, an innovative game that reimagines Alan Turing's iconic question, \"Can machines think?\" by reversing the evaluation process. Players interact with a large language model (LLM) impersonating Turing, who seeks to determine if the player is human or AI. Set in the 1940s and 1950s historical context, the game combines immersive storytelling with period-accurate design. Developed using Unity and generative AI tools, it leverages LLM-driven dialogue to explore AI capabilities and limitations, such as coherence and interpretative challenges. By embedding AI's imperfections into gameplay, the project fosters an understanding of LLM constraints while encouraging reflections on human-AI dynamics. Through its accessible yet thought-provoking design, the game contributes to the discourse on AI, which is often dominated by moralistic critiques or oversimplified portrayals that fail to capture AI’s complexities. This engaging approach contributes to the broader discourse on AI’s evolving role.",
    "title": "The Reversed Turing Test",
    "id": 194791,
    "sequence": 1759,
    "queryCoordinates": {
      "visualization": [
        6.336814207804418,
        10.190426178318948
      ]
    }
  },
  {
    "session": "From Individual to Society",
    "abstract": "Creating information technologies intended for broad use that allow everyone to participate safely online—which we refer to as inclusive digital safety—requires understanding and addressing the digital-safety needs of a diverse range of users who face elevated risk of technology-facilitated attacks or disproportionate harm from such attacks—i.e., at-risk users. This paper draws from more than nine years of our work at Google to understand and support the digital safety of at-risk users—including survivors of intimate partner abuse, people involved with political campaigns, content creators, youth, and more—in technology intended for broad use. Among our learnings is that designing for inclusive digital safety across widely varied user needs and dynamic contexts is a wicked problem with no ‘correct’ solution. Given this, we describe frameworks and design principles we have developed to help make at-risk research findings practically applicable to technologies intended for broad use and lessons we have learned about communicating them to practitioners.\r\n",
    "title": "Supporting the Digital Safety of At-Risk Users: Lessons Learned from 9+ Years of Research & Training",
    "id": 195252,
    "sequence": 1760,
    "queryCoordinates": {
      "visualization": [
        2.7203715060963694,
        10.65831031959658
      ]
    }
  },
  {
    "session": "From Individual to Society",
    "abstract": "In this paper, we report on a three-year endeavour that fostered 18 collaborations between academic and non-academic organizations to co-create responses to social (in)justice issues in digital societies. The projects and range of individuals and organisations connected to this programme offer a snapshot of the state of social justice thinking within the UK digital economy research sector. Our analysis shows how the programme’s constellations of actions enacted different modes of resistance attempting to reshape people’s relationship to power dynamics, addressing institutions and exposing systems,\r\nand developing and restoring values for social justice. We explore how these efforts invite nuanced understanding of what constitutes resistance in knowledge co-production endeavours and how they helped surface tensions at the intersection of agencies and the distribution of responsibilities. Drawing from our insights and experience, we discuss implications for HCI concerned with the creation of the conditions for social justice in our digital societies. ",
    "title": "co-creating conditions for social justice in digital societies",
    "id": 195253,
    "sequence": 1761,
    "queryCoordinates": {
      "visualization": [
        -10.173244508476376,
        9.617956964488625
      ]
    }
  },
  {
    "session": "From Individual to Society",
    "abstract": "Equitable access to sport for disabled people remains challenging, and technology is often viewed as a way of addressing barriers. However, little is known about how disability is approached in such research and the purpose of sport that is afforded to disabled people. We address this issue in a review of 60 publications in the field of Human-Computer Interaction. We leverage Template Analysis in combination with Mueller and Young's lenses on virtues of sport to also explore the experiential side of sports technology for disabled people. Our results are threefold: (1) We show that disability shifts the intended purpose of sports technology away from leisure to health, and that technologies such as exergames are viewed as an opportunity to replace real-world sport to address barriers and increase motivation. (2) We highlight that in(ter)dependence plays a strong role in technology development, but that disabled people are not extensively involved in research. (3) We show that virtues beyond health as per Mueller and Young do apply to existing work, but that value frameworks need to be re-worked in the context of disability, placing a stronger emphasis on sport as leisure, and the enriching role that technology can play.",
    "title": "HCI, Disability, and Sport: A Literature Review",
    "id": 195254,
    "sequence": 1762,
    "queryCoordinates": {
      "visualization": [
        -3.4611705707749336,
        -9.381913359224841
      ]
    }
  },
  {
    "session": "From Individual to Society",
    "abstract": "LLM chains enable complex tasks by decomposing work into a sequence of subtasks.\r\nSimilarly, the more established techniques of crowdsourcing workflows decompose complex tasks into smaller tasks for human crowdworkers. Chains address LLM errors analogously to the way crowdsourcing workflows address human error. To characterize opportunities for LLM chaining, we survey 107 papers across the crowdsourcing and chaining literature to construct a design space for chain development. The design space covers a designer's objectives and the tactics used to build workflows. We then surface strategies that mediate how workflows use tactics to achieve objectives. To explore how techniques from crowdsourcing may apply to chaining, we adapt crowdsourcing workflows to implement LLM chains across three case studies: creating a taxonomy, shortening text, and writing a short story. From the design space and our case studies, we identify takeaways for effective chain design and raise implications for future research and development.",
    "title": "Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows",
    "id": 195255,
    "sequence": 1763,
    "queryCoordinates": {
      "visualization": [
        -3.092041813450948,
        2.537573136654582
      ]
    }
  },
  {
    "session": "From Individual to Society",
    "abstract": "The Internet of Things (IoT) has witnessed remarkable advancements, enabling smart homes with user-centric features. To effectively articulate their personalized needs, it becomes crucial to equip end users with programming capabilities. Currently, the {executable} Trigger-Action Programming (TAP) rules have become the mainstream paradigm for IoT end-user programming. To simplify the creation of TAP rules, many studies have proposed various levels of requirements abstraction, yet the connections between them remain unclear. In this paper, we employ a mixed-methods study to identify the preferred way of expressing end users' requirements in practical scenarios. {Subsequently, from the perspective of requirements engineering, we categorize the needs of smart home into three hierarchical levels of abstraction}. Accordingly, we propose an innovative multi-level requirements description language called SH-RDL. We also address potential challenges and conduct an evaluation to validate SH-RDL's usability, understandability and error-prevention. This will aid in the broader adoption of IoT end-user programming.",
    "title": "Expressing the Needs in Smart Home: What is the End Users' Favorite Way",
    "id": 195256,
    "sequence": 1764,
    "queryCoordinates": {
      "visualization": [
        -5.656760841911967,
        10.583055172180263
      ]
    }
  },
  {
    "session": "From Individual to Society",
    "abstract": "Designed haptic feedback—technology-mediated touch feedback—has the potential to mediate positive and meaningful experiences. These experiences are rich and complex in nature and thus challenging to design. Established User Experience (UX) and Haptic Experience (HX) models describe the design of experiences; however, they are too general and evaluation-focused to inform haptic experience design. We review 104 publications designing haptic experiences and analyse how researchers consider pragmatic, hedonic, and eudaimonic qualities of haptic experience. Our findings show that researchers mainly engage with the pragmatic qualities of the experience. We thus propose a unified model for HX for understanding the design of haptic experiences, combining key elements of UX and HX research to give haptic designers a tool for thinking about the rich and complex haptic experiences elicited by their designs. This raises open questions for haptic experience research, as designing mediated touch experiences through haptic technology remains challenging.",
    "title": "A Unified Model for Haptic Experience",
    "id": 195258,
    "sequence": 1765,
    "queryCoordinates": {
      "visualization": [
        -8.756176437987891,
        19.08741402565643
      ]
    }
  },
  {
    "session": "Designing, Making, Exploring",
    "abstract": "Modeling a complex system from data can aid understanding and decision-making. Bayesian networks are one such method that, when accurately constructed, can support inference and help understand the underlying system that generated the data. However, the outputs of these models are not always intuitive, especially for users that lack a statistical background. In this work, we examine how the recent advancements in modern Large Language Models (LLMs) may be applied to help explain machine learning (ML) models. Following a user-centered design methodology, we collaborated with a team of ML modelers and a domain expert in the French breadmaking industry to develop a causal inference application with an integrated chat assistant. From qualitative feedback sessions with modelers and the domain expert, we note some unique advantages but also a host of challenges in using current LLMs for model explainability. ",
    "title": "Explaining Complex ML Models to Domain Experts Using LLM & Visualization: An Exploration in the French Breadmaking Industry ",
    "id": 195263,
    "sequence": 1766,
    "queryCoordinates": {
      "visualization": [
        -5.758320584559807,
        -14.927884781355823
      ]
    }
  }
]